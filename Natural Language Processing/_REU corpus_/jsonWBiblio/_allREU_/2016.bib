@inproceedings{Chen:2016:TME:2883851.2883951,
 author = {Chen, Ye and Yu, Bei and Zhang, Xuewei and Yu, Yihan},
 title = {Topic Modeling for Evaluating Students' Reflective Writing: A Case Study of Pre-service Teachers' Journals},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {1--5},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883951},
 doi = {10.1145/2883851.2883951},
 acmid = {2883951},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {LDA, automated grading, education, journal writing, learning analytics, reflection, text mining, topic modeling},
abstract = {Journal writing is an important and common reflective practice in education. Students' reflection journals also offer a rich source of data for formative assessment. However, the analysis of the textual reflections in class of large size presents challenges. Automatic analysis of students' reflective writing holds great promise for providing adaptive real time support for students. This paper proposes a method based on topic modeling techniques for the task of themes exploration and reflection grade prediction. We evaluated this method on a sample of journal writings from pre-service teachers. The topic modeling method was able to discover the important themes and patterns emerged in students' reflection journals. Weekly topic relevance and word count were identified as important indicators of their journal grades. Based on the patterns discovered by topic modeling, prediction models were developed to automate the assessing and grading of reflection journals. The findings indicate the potential of topic modeling in serving as an analytic tool for teachers to explore and assess students' reflective thoughts in written journals.},
}

@inproceedings{Crossley:2016:CCD:2883851.2883931,
 author = {Crossley, Scott and Paquette, Luc and Dascalu, Mihai and McNamara, Danielle S. and Baker, Ryan S.},
 title = {Combining Click-stream Data with NLP Tools to Better Understand MOOC Completion},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {6--14},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/2883851.2883931},
 doi = {10.1145/2883851.2883931},
 acmid = {2883931},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {MOOC, click-stream data, educational data mining, educational success, natural language processing, predictive analytics, sentiment analysis},
abstract = {Completion rates for massive open online classes (MOOCs) are notoriously low. Identifying student patterns related to course completion may help to develop interventions that can improve retention and learning outcomes in MOOCs. Previous research predicting MOOC completion has focused on click-stream data, student demographics, and natural language processing (NLP) analyses. However, most of these analyses have not taken full advantage of the multiple types of data available. This study combines click-stream data and NLP approaches to examine if students' on-line activity and the language they produce in the online discussion forum is predictive of successful class completion. We study this analysis in the context of a subsample of 320 students who completed at least one graded assignment and produced at least 50 words in discussion forums, in a MOOC on educational data mining. The findings indicate that a mix of click-stream data and NLP indices can predict with substantial accuracy (78%) whether students complete the MOOC. This predictive power suggests that student interaction data and language data within a MOOC can help us both to understand student retention in MOOCs and to develop automated signals of student success.},
}

@inproceedings{Kovanovic:2016:TAC:2883851.2883950,
 author = {Kovanovi\'{c}, Vitomir and Joksimovi\'{c}, Sre\'{c}ko and Waters, Zak and Ga\v{s}evi\'{c}, Dragan and Kitto, Kirsty and Hatala, Marek and Siemens, George},
 title = {Towards Automated Content Analysis of Discussion Transcripts: A Cognitive Presence Case},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {15--24},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883950},
 doi = {10.1145/2883851.2883950},
 acmid = {2883950},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {community of inquiry (CoI) model, content analysis, content analytics, online discussions, text classification},
abstract = {In this paper, we present the results of an exploratory study that examined the problem of automating content analysis of student online discussion transcripts. We looked at the problem of coding discussion transcripts for the levels of cognitive presence, one of the three main constructs in the Community of Inquiry (CoI) model of distance education. Using Coh-Metrix and LIWC features, together with a set of custom features developed to capture discussion context, we developed a random forest classification system that achieved 70.3% classification accuracy and 0.63 Cohen's kappa, which is significantly higher than values reported in the previous studies. Besides improvement in classification accuracy, the developed system is also less sensitive to overfitting as it uses only 205 classification features, which is around 100 times less features than in similar systems based on bag-of-words features. We also provide an overview of the classification features most indicative of the different phases of cognitive presence that gives an additional insights into the nature of cognitive presence learning cycle. Overall, our results show great potential of the proposed approach, with an added benefit of providing further characterization of the cognitive presence coding scheme.},
}

@inproceedings{Hu:2016:TPE:2883851.2883959,
 author = {Hu, Xiao and Zhang, Yinfei and Chu, Samuel K. W. and Ke, Xiaobo},
 title = {Towards Personalizing an e-Quiz Bank for Primary School Students: An Exploration with Association Rule Mining and Clustering},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {25--29},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883959},
 doi = {10.1145/2883851.2883959},
 acmid = {2883959},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {association rule mining, clustering, e-quiz bank, reading},
abstract = {Given the importance of reading proficiency and habits for young students, an online e-quiz bank, Reading Battle, was launched in 2014 to facilitate reading improvement for primary-school students. With more than ten thousand questions in both English and Chinese, the system has attracted nearly five thousand learners who have made about half a million question answering records. In an effort towards delivering personalized learning experience to the learners, this study aims to discover potentially useful knowledge from learners' reading and question answering records in the Reading Battle system, by applying association rule mining and clustering analysis. The results show that learners could be grouped into three clusters based on their self-reported reading habits. The rules mined from different learner clusters can be used to develop personalized recommendations to the learners. Implications of the results on evaluating and further improving the Reading Battle system are also discussed.},
}

@inproceedings{Bull:2016:ILV:2883851.2883853,
 author = {Bull, Susan and Ginon, Blandine and Boscolo, Clelia and Johnson, Matthew},
 title = {Introduction of Learning Visualisations and Metacognitive Support in a Persuadable Open Learner Model},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {30--39},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883853},
 doi = {10.1145/2883851.2883853},
 acmid = {2883853},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {learning analytics for learners, open learner models, persuading the learner model, visual learning analytics},
abstract = {This paper describes open learner models as visualisations of learning for learners, with a particular focus on how information about their learning can be used to help them reflect on their skills, identify gaps in their skills, and plan their future learning. We offer an approach that, in addition to providing visualisations of their learning, allows learners to propose changes to their learner model. This aims to help improve the accuracy of the learner model by taking into account student viewpoints on their learning, while also promoting learner reflection on their learning as part of a discussion of the content of their learner model. This aligns well with recent calls for learning analytics for learners. Building on previous research showing that learners will use open learner models, we here investigate their initial reactions to open learner model features to identify the likelihood of uptake in contexts where an open learner model is offered on an optional basis. We focus on university students' perceptions of a range of visualisations and their stated preferences for a facility to view evidence for the learner model data and to propose changes to the values.},
}

@inproceedings{Pelanek:2016:IDC:2883851.2883868,
 author = {Pel\'{a}nek, Radek and Rih\'{a}k, Jir\'{\i} and Papou\v{s}ek, Jan},
 title = {Impact of Data Collection on Interpretation and Evaluation of Student Models},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {40--47},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2883851.2883868},
 doi = {10.1145/2883851.2883868},
 acmid = {2883868},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {attition, bias, data sets, evaluation, parameter fitting, student modeling},
abstract = {Student modeling techniques are evaluated mostly using historical data. Researchers typically do not pay attention to details of the origin of the used data sets. However, the way data are collected can have important impact on evaluation and interpretation of student models. We discuss in detail two ways how data collection in educational systems can influence results: mastery attrition bias and adaptive choice of items. We systematically discuss previous work related to these biases and illustrate the main points using both simulated and real data. We summarize specific consequences for practice -- not just for doing evaluation of student models, but also for data collection and publication of data sets.},
}

@inproceedings{Hsiao:2016:SVA:2883851.2883915,
 author = {Hsiao, I-Han and Pandhalkudi Govindarajan, Sesha Kumar and Lin, Yi-Ling},
 title = {Semantic Visual Analytics for Today's Programming Courses},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {48--53},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2883851.2883915},
 doi = {10.1145/2883851.2883915},
 acmid = {2883915},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {auto grading, dashboard, intelligent authoring, orchestration technology, programming, semantic analytics, visual analytics},
abstract = {We designed and studied an innovative semantic visual learning analytics for orchestrating today's programming classes. The visual analytics integrates sources of learning activities by their content semantics. It automatically processs paper-based exams by associating sets of concepts to the exam questions. Results indicated the automatic concept extraction from exams were promising and could be a potential technological solution to address a real world issue. We also discovered that indexing effectiveness was especially prevalent for complex content by covering more comprehensive semantics. Subjective evaluation revealed that the dynamic concept indexing provided teachers with immediate feedback on producing more balanced exams.},
}

@inproceedings{Beheshitha:2016:RAG:2883851.2883904,
 author = {Beheshitha, Sanam Shirazi and Hatala, Marek and Ga\v{s}evi\'{c}, Dragan and Joksimovi\'{c}, Sre\'{c}ko},
 title = {The Role of Achievement Goal Orientations when Studying Effect of Learning Analytics Visualizations},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {54--63},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883904},
 doi = {10.1145/2883851.2883904},
 acmid = {2883904},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {achievement goal orientation, dashboards, learning analytics, online discussions, visualizations},
abstract = {When designing learning analytics tools for use by learners we have an opportunity to provide tools that consider a particular learner's situation and the learner herself. To afford actual impact on learning, such tools have to be informed by theories of education. Particularly, educational research shows that individual differences play a significant role in explaining students' learning process. However, limited empirical research in learning analytics has investigated the role of theoretical constructs, such as motivational factors, that are underlying the observed differences between individuals. In this work, we conducted a field experiment to examine the effect of three designed learning analytics visualizations on students' participation in online discussions in authentic course settings. Using hierarchical linear mixed models, our results revealed that effects of visualizations on the quantity and quality of messages posted by students with differences in achievement goal orientations could either be positive or negative. Our findings highlight the methodological importance of considering individual differences and pose important implications for future design and research of learning analytics visualizations.},
}

@inproceedings{Pijeira-Diaz:2016:ICL:2883851.2883897,
 author = {Pijeira-D\'{\i}az, H{\'e}ctor J. and Drachsler, Hendrik and J\"{a}rvel\"{a}, Sanna and Kirschner, Paul A.},
 title = {Investigating Collaborative Learning Success with Physiological Coupling Indices Based on Electrodermal Activity},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {64--73},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883897},
 doi = {10.1145/2883851.2883897},
 acmid = {2883897},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {biosensors, collaborative learning, electrodermal activity, learning analytics, physiological coupling indices},
abstract = {Collaborative learning is considered a critical 21st century skill. Much is known about its contribution to learning, but still investigating a process of collaboration remains a challenge. This paper approaches the investigation on collaborative learning from a psychophysiological perspective. An experiment was set up to explore whether biosensors can play a role in analysing collaborative learning. On the one hand, we identified five physiological coupling indices (PCIs) found in the literature: 1) Signal Matching (SM), 2) Instantaneous Derivative Matching (IDM), 3) Directional Agreement (DA), 4) Pearson's correlation coefficient (PCC) and the 5) Fisher's z-transform (FZT) of the PCC. On the other hand, three collaborative learning measurements were used: 1) collaborative will (CW), 2) collaborative learning product (CLP) and 3) dual learning gain (DLG). Regression analyses showed that out of the five PCIs, IDM related the most to CW and was the best predictor of the CLP. Meanwhile, DA predicted DLG the best. These results play a role in determining informative collaboration measures for designing a learning analytics, biofeedback dashboard.},
} 

@inproceedings{Koh:2016:PFL:2883851.2883914,
 author = {Koh, Elizabeth and Shibani, Antonette and Tan, Jennifer Pei-Ling and Hong, Helen},
 title = {A Pedagogical Framework for Learning Analytics in Collaborative Inquiry Tasks: An Example from a Teamwork Competency Awareness Program},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {74--83},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883914},
 doi = {10.1145/2883851.2883914},
 acmid = {2883914},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {assessment, collaboration, dispositional analytics, evaluation, learning design, pedagogical model, teamwork, teamwork competency, twenty-first century skills},
abstract = {Many pedagogical models in the field of learning analytics are implicit and do not overtly direct learner behavior. While this allows flexibility of use, this could also result in misaligned practice, and there are calls for more explicit pedagogical models in learning analytics. This paper presents an explicit pedagogical model, the Team and Self Diagnostic Learning (TSDL) framework, in the context of collaborative inquiry tasks. Key informing theories include experiential learning, collaborative learning, and the learning analytics process model. The framework was trialed through a teamwork competency awareness program for 14 year old students. A total of 272 students participated in the program. This paper foregrounds students' and teachers' evaluative accounts of the program. Findings reveal positive perceptions of the stages of the TSDL framework, despite identified challenges, which points to its potential usefulness for teaching and learning. The TSDL framework aims to provide theoretical clarity of the learning process, and foster alignment between learning analytics and the learning design. The current work provides trial outcomes of a teamwork competency awareness program that used dispositional analytics, and further efforts are underway to develop the discourse layer of the analytic engine. Future work will also be dedicated to application and refinement of the framework for other contexts and participants, both learners and teachers alike.},
} 

@inproceedings{Cukurova:2016:AFC:2883851.2883900,
 author = {Cukurova, Mutlu and Avramides, Katerina and Spikol, Daniel and Luckin, Rose and Mavrikis, Manolis},
 title = {An Analysis Framework for Collaborative Problem Solving in Practice-based Learning Activities: A Mixed-method Approach},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {84--88},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883900},
 doi = {10.1145/2883851.2883900},
 acmid = {2883900},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {analysis framework, collaborative learning, practice-based learning, problem solving},
abstract = {Systematic investigation of the collaborative problem solving process in open-ended, hands-on, physical computing design tasks requires a framework that highlights the main process features, stages and actions that then can be used to provide 'meaningful' learning analytics data. This paper presents an analysis framework that can be used to identify crucial aspects of the collaborative problem solving process in practice-based learning activities. We deployed a mixed-methods approach that allowed us to generate an analysis framework that is theoretically robust, and generalizable. Additionally, the framework is grounded in data and hence applicable to real-life learning contexts. This paper presents how our framework was developed and how it can be used to analyse data. We argue for the value of effective analysis frameworks in the generation and presentation of learning analytics for practice-based learning activities.},
} 

@inproceedings{Drachsler:2016:PAD:2883851.2883893,
 author = {Drachsler, Hendrik and Greller, Wolfgang},
 title = {Privacy and Analytics: It's a DELICATE Issue a Checklist for Trusted Learning Analytics},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {89--98},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883893},
 doi = {10.1145/2883851.2883893},
 acmid = {2883893},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data management, educational data mining, ethics, implementation, learning analytics, legal aspects, privacy, trust},
abstract = {The widespread adoption of Learning Analytics (LA) and Educational Data Mining (EDM) has somewhat stagnated recently, and in some prominent cases even been reversed following concerns by governments, stakeholders and civil rights groups about privacy and ethics applied to the handling of personal data. In this ongoing discussion, fears and realities are often indistinguishably mixed up, leading to an atmosphere of uncertainty among potential beneficiaries of Learning Analytics, as well as hesitations among institutional managers who aim to innovate their institution's learning support by implementing data and analytics with a view on improving student success. In this paper, we try to get to the heart of the matter, by analysing the most common views and the propositions made by the LA community to solve them. We conclude the paper with an eight-point checklist named DELICATE that can be applied by researchers, policy makers and institutional managers to facilitate a trusted implementation of Learning Analytics.},
}

@inproceedings{Cooper:2016:ACA:2883851.2883946,
 author = {Cooper, Martyn and Ferguson, Rebecca and Wolff, Annika},
 title = {What Can Analytics Contribute to Accessibility in e-Learning Systems and to Disabled Students' Learning?},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {99--103},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883946},
 doi = {10.1145/2883851.2883946},
 acmid = {2883946},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {HCI, accessibility, higher education, learning analytics, metrics, technology enhanced learning},
abstract = {This paper explores the potential of analytics for improving accessibility of e-learning and supporting disabled learners in their studies. A comparative analysis of completion rates of disabled and non-disabled students in a large five-year dataset is presented and a wide variation in comparative retention rates is characterized. Learning analytics enable us to identify and understand such discrepancies and, in future, could be used to focus interventions to improve retention of disabled students. An agenda for onward research, focused on Critical Learning Paths, is outlined. This paper is intended to stimulate a wider interest in the potential benefits of learning analytics for institutions as they try to assure the accessibility of their e-learning and provision of support for disabled students.},
}

@inproceedings{Grawemeyer:2016:AOB:2883851.2883936,
 author = {Grawemeyer, Beate and Mavrikis, Manolis and Holmes, Wayne and Gutierrez-Santos, Sergio and Wiedmann, Michael and Rummel, Nikol},
 title = {Affecting Off-task Behaviour: How Affect-aware Feedback Can Improve Student Learning},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {104--113},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883936},
 doi = {10.1145/2883851.2883936},
 acmid = {2883936},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {affect, exploratory learning environments, feedback},
abstract = {This paper describes the development and evaluation of an affect-aware intelligent support component that is part of a learning environment known as iTalk2Learn. The intelligent support component is able to tailor feedback according to a student's affective state, which is deduced both from speech and interaction. The affect prediction is used to determine which type of feedback is provided and how that feedback is presented (interruptive or non-interruptive). The system includes two Bayesian networks that were trained with data gathered in a series of ecologically-valid Wizard-of-Oz studies, where the effect of the type of feedback and the presentation of feedback on students' affective states was investigated. This paper reports results from an experiment that compared a version that provided affect-aware feedback (affect condition) with one that provided feedback based on performance only (non-affect condition). Results show that students who were in the affect condition were less bored and less off-task, with the latter being statically significant. Importantly, students in both conditions made learning gains that were statistically significant, while students in the affect condition had higher learning gains than those in the non-affect condition, although this result was not statistically significant in this study's sample. Taken all together, the results point to the potential and positive impact of affect-aware intelligent support.},
}

@inproceedings{Allen:2016:IBE:2883851.2883939,
 author = {Allen, Laura K. and Mills, Caitlin and Jacovina, Matthew E. and Crossley, Scott and D'Mello, Sidney and McNamara, Danielle S.},
 title = {Investigating Boredom and Engagement During Writing Using Multiple Sources of Information: The Essay, the Writer, and Keystrokes},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {114--123},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883939},
 doi = {10.1145/2883851.2883939},
 acmid = {2883939},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {corpus linguistics, intelligent tutoring systems, natural language processing, stealth assessment, writing},
abstract = {Writing training systems have been developed to provide students with instruction and deliberate practice on their writing. Although generally successful in providing accurate scores, a common criticism of these systems is their lack of personalization and adaptive instruction. In particular, these systems tend to place the strongest emphasis on delivering accurate scores, and therefore, tend to overlook additional indices that may contribute to students' success, such as their affective states during writing practice. This study takes an initial step toward addressing this gap by building a predictive model of students' affect using information that can potentially be collected by computer systems. We used individual difference measures, text indices, and keystroke analyses to predict engagement and boredom in 132 writing sessions. The results suggest that these three categories of indices were successful in modeling students' affective states during writing. Taken together, indices related to students' academic abilities, text properties, and keystroke logs were able classify high and low engagement and boredom in writing sessions with accuracies between 76.5% and 77.3%. These results suggest that information readily available in writing training systems can inform affect detectors and ultimately improve student models within intelligent tutoring systems.},
}

@inproceedings{Martinez-Maldonado:2016:ISL:2883851.2883873,
 author = {Martinez-Maldonado, Roberto and Schneider, Bertrand and Charleer, Sven and Shum, Simon Buckingham and Klerkx, Joris and Duval, Erik},
 title = {Interactive Surfaces and Learning Analytics: Data, Orchestration Aspects, Pedagogical Uses and Challenges},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {124--133},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883873},
 doi = {10.1145/2883851.2883873},
 acmid = {2883873},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {awareness, dashboard, design, face-to-face, groupware, studies in the wild, visualizations},
abstract = {The proliferation of varied types of multi-user interactive surfaces (such as digital whiteboards, tabletops and tangible interfaces) is opening a new range of applications in face-to-face (f2f) contexts. They offer unique opportunities for Learning Analytics (LA) by facilitating multi-user sensemaking of automatically captured digital footprints of students' f2f interactions. This paper presents an analysis of current research exploring learning analytics associated with the use of surface devices. We use a framework to analyse our first-hand experiences, and the small number of related deployments according to four dimensions: the orchestration aspects involved; the phases of the pedagogical practice that are supported; the target actors; and the levels of iteration of the LA process. The contribution of the paper is twofold: 1) a synthesis of conclusions that identify the degree of maturity, challenges and pedagogical opportunities of the existing applications of learning analytics and interactive surfaces; and 2) an analysis framework that can be used to characterise the design space of similar areas and LA applications.},
}

@inproceedings{Papousek:2016:EAP:2883851.2883884,
 author = {Papou\v{s}ek, Jan and Stanislav, V\'{\i}t and Pel\'{a}nek, Radek},
 title = {Evaluation of an Adaptive Practice System for Learning Geography Facts},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {134--142},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/2883851.2883884},
 doi = {10.1145/2883851.2883884},
 acmid = {2883884},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {attrition bias, computerized adaptive practice, engagement, evaluation, learning curve, survival analysis},
abstract = {Computerized educational systems are increasingly provided as open online services which provide adaptive personalized learning experience. To fully exploit potential of such systems, it is necessary to thoroughly evaluate different design choices. However, both openness and adaptivity make proper evaluation difficult. We provide a detailed report on evaluation of an online system for adaptive practice of geography, and use this case study to highlight methodological issues with evaluation of open online learning systems, particularly attrition bias. To facilitate evaluation of learning, we propose to use randomized reference questions. We illustrate application of survival analysis and learning curves for declarative knowledge. The result provide an interesting insight into the impact of adaptivity on learner behaviour and learning.},
}

@inproceedings{Karkalas:2016:TAE:2883851.2883943,
 author = {Karkalas, Sokratis and Mavrikis, Manolis and Labs, Oliver},
 title = {Towards Analytics for Educational Interactive e-Books: The Case of the Reflective Designer Analytics Platform (RDAP)},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {143--147},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883943},
 doi = {10.1145/2883851.2883943},
 acmid = {2883943},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract = {This paper presents an analytics dashboard that has been developed for designers of interactive e-books. This is part of the EU-funded MC Squared project that is developing a platform for authoring interactive educational e-books. The primary objective is to develop technologies and resources that enhance creative thinking for both designers (authors) and learners. The learning material is expected to offer learners opportunities to engage creatively with mathematical problems and develop creative mathematical thinking. The analytics dashboard is designed to increase authors' awareness so that they can make informed decisions on how to redesign and improve the e-books. This paper presents architectural and design decisions on key features of the dashboard and discusses future steps with respect to the potential for exploratory data analysis.},
}

@inproceedings{Prieto:2016:TAT:2883851.2883927,
 author = {Prieto, Luis P. and Sharma, Kshitij and Dillenbourg, Pierre and Jes\'{u}s, Mar\'{\i}a},
 title = {Teaching Analytics: Towards Automatic Extraction of Orchestration Graphs Using Wearable Sensors},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {148--157},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883927},
 doi = {10.1145/2883851.2883927},
 acmid = {2883927},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {activity detection, multimodal learning analytics, teacher reflection, teaching analytics, wearable sensors},
abstract = {'Teaching analytics' is the application of learning analytics techniques to understand teaching and learning processes, and eventually enable supportive interventions. However, in the case of (often, half-improvised) teaching in face-to-face classrooms, such interventions would require first an understanding of what the teacher actually did, as the starting point for teacher reflection and inquiry. Currently, such teacher enactment characterization requires costly manual coding by researchers. This paper presents a case study exploring the potential of machine learning techniques to automatically extract teaching actions during classroom enactment, from five data sources collected using wearable sensors (eye-tracking, EEG, accelerometer, audio and video). Our results highlight the feasibility of this approach, with high levels of accuracy in determining the social plane of interaction (90%, ?=0.8). The reliable detection of concrete teaching activity (e.g., explanation vs. questioning) accurately still remains challenging (67%, ?=0.56), a fact that will prompt further research on multimodal features and models for teaching activity extraction, as well as the collection of a larger multimodal dataset to improve the accuracy and generalizability of these methods.},
}

@inproceedings{McPherson:2016:SPD:2883851.2883945,
 author = {McPherson, Jen and Tong, Huong Ly and Fatt, Scott J. and Liu, Danny Y. T.},
 title = {Student Perspectives on Data Provision and Use: Starting to Unpack Disciplinary Differences},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {158--167},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883945},
 doi = {10.1145/2883851.2883945},
 acmid = {2883945},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {disciplinary differences, knowledge, learning analytics, legitimation code theory, sociology of education, student needs},
abstract = {How can we best align learning analytics practices with disciplinary knowledge practices in order to support student learning? Although learning analytics itself is an interdisciplinary field, it tends to take a 'one-size-fits-all' approach to the collection, measurement, and reporting of data, overlooking disciplinary knowledge practices. In line with a recent trend in higher education research, this paper considers the contribution of a realist sociology of education to the field of learning analytics, drawing on findings from recent student focus groups at an Australian university. It examines what learners say about their data needs with reference to organizing principles underlying knowledge practices within their disciplines. The key contribution of this paper is a framework that could be used as the basis for aligning the provision and/or use of data in relation to curriculum, pedagogy, and assessment with disciplinary knowledge practices. The framework extends recent research in Legitimation Code Theory, which understands disciplinary differences in terms of the principles that underpin knowledge-building. The preliminary analysis presented here both provides a tool for ensuring a fit between learning analytics practices and disciplinary practices and standards for achievement, and signals disciplinarity as an important consideration in learning analytics practices.},
}

@inproceedings{Mavrikis:2016:DET:2883851.2883909,
 author = {Mavrikis, Manolis and Gutierrez-Santos, Sergio and Poulovassilis, Alex},
 title = {Design and Evaluation of Teacher Assistance Tools for Exploratory Learning Environments},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {168--172},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883909},
 doi = {10.1145/2883851.2883909},
 acmid = {2883909},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {exploratory learning, teacher assistance tools},
abstract = {We present our approach to designing and evaluating tools that can assist teachers in classroom settings where students are using Exploratory Learning Environments (ELEs), using as our case study the MiGen system, which targets 1114 year old students' learning of algebra. We discuss the challenging role of teachers in exploratory learning settings and motivate the need for visualisation and notification tools that can assist teachers in focusing their attention across the whole class and inform their interventions. We present the design and evaluation approach followed during the development of MiGen's Teacher Assistance tools, drawing parallels with the recently proposed LATUX workflow but also discussing how we go beyond this to include a large number of teacher participants in our evaluation activities, so as to gain the benefit of different view points. We discuss the results of the evaluations, which show that participants appreciated the capabilities of the tools and were mostly able to use them quickly and accurately.},
}

@inproceedings{Oster:2016:LAR:2883851.2883925,
 author = {Oster, Meghan and Lonn, Steven and Pistilli, Matthew D. and Brown, Michael G.},
 title = {The Learning Analytics Readiness Instrument},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {173--182},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883925},
 doi = {10.1145/2883851.2883925},
 acmid = {2883925},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ethics, higher education, learning analytics, readiness, reflection, survey design},
abstract = {Little is known about the processes institutions use when discerning their readiness to implement learning analytics. This study aims to address this gap in the literature by using survey data from the beta version of the Learning Analytics Readiness Instrument (LARI) [1]. Twenty-four institutions were surveyed and 560 respondents participated. Five distinct factors were identified from a factor analysis of the results: Culture; Data Management Expertise; Data Analysis Expertise; Communication and Policy Application; and, Training. Data were analyzed using both the role of those completing the survey and the Carnegie classification of the institutions as lenses. Generally, information technology professionals and institutions classified as Research Universities--Very High research activity had significantly different scores on the identified factors. Working within a framework of organizational learning, this paper details the concept of readiness as a reflective process, as well as how the implementation and application of analytics should be done so with ethical considerations in mind. Limitations of the study, as well as next steps for research in this area, are also discussed.},
}

@inproceedings{Manai:2016:RIT:2883851.2883942,
 author = {Manai, Ouajdi and Yamada, Hiroyuki and Thorn, Christopher},
 title = {Real-time Indicators and Targeted Supports: Using Online Platform Data to Accelerate Student Learning},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {183--187},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883942},
 doi = {10.1145/2883851.2883942},
 acmid = {2883942},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cognitive and non-cognitive factors, community college developmental mathematics, hierarchical linear modeling, learning analytics, networked improvement community, online engagement},
abstract = {Statway® is one of the Community College Pathways initiatives designed to promote students' success in their developmental math sequence and reduce the time required to earn college credit. A recent causal analysis confirmed that Statway dramatically increased students' success rates in half the time across two different cohorts. These impressive results were also obtained across gender and race/ethnicity groups. However, there is still room for improvement. Students who did not succeed in Statway often did not complete the first of the two-course sequence. Therefore, the objective of this study is to formulate a series of indicators from self-report and online learning system data, alerting instructors to students' progress during the first weeks of the first course in the Statway sequence.},
}

@inproceedings{Wise:2016:BOC:2883851.2883916,
 author = {Wise, Alyssa Friend and Cui, Yi and Vytasek, Jovita},
 title = {Bringing Order to Chaos in MOOC Discussion Forums with Content-related Thread Identification},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {188--197},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883916},
 doi = {10.1145/2883851.2883916},
 acmid = {2883916},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {discussion forum, machine learning, massive open online courses, natural language processing, social interaction},
abstract = {This study addresses the issues of overload and chaos in MOOC discussion forums by developing a model to categorize and identify threads based on whether or not they are substantially related to the course content. Content-related posts were defined as those that give/seek help for the learning of course material and share/comment on relevant resources. A linguistic model was built based on manually-coded starting posts in threads from a statistics MOOC (n=837) and tested on thread starting posts from the second offering of the same course (n=304) and a different statistics course (n=298). The number of views and votes threads received were tested to see if they helped classification. Results showed that content-related posts in the statistics MOOC had distinct linguistic features which appeared to be unrelated to the subject-matter domain; the linguistic model demonstrated good cross-course reliability (all recall and precision > .77) and was useful across all time segments of the courses; number of views and votes were not helpful for classification.},
}

@inproceedings{Hecking:2016:ISS:2883851.2883924,
 author = {Hecking, Tobias and Chounta, Irene-Angelica and Hoppe, H. Ulrich},
 title = {Investigating Social and Semantic User Roles in MOOC Discussion Forums},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {198--207},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883924},
 doi = {10.1145/2883851.2883924},
 acmid = {2883924},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {MOOCs, blockmodeling, discussion forums, socio-semantic analysis},
abstract = {This paper describes the analysis of the social and semantic structure of discussion forums in massive open online courses (MOOCs) in terms of information exchange and user roles. To that end, we analyse a network of forum users based on information-giving relations extracted from the forum data. Connection patterns that appear in the information exchange network of forum users are used to define specific user roles in a social context. Semantic roles are derived by identifying thematic areas in which an actor seeks for information (problem areas) and the areas of interest in which an actor provides information to others (expertise). The interplay of social and semantic roles is analysed using a socio-semantic blockmodelling approach. The results show that social and semantic roles are not strongly interdependent. This indicates that communication patterns and interests of users develop simultaneously only to a moderate extent. In addition to the case study, the methodological contribution is in combining traditional blockmodelling with semantic information to characterise participant roles.},
}

@inproceedings{Oleksandra:2016:UML:2883851.2883919,
 author = {Oleksandra, Poquet and Shane, Dawson},
 title = {Untangling MOOC Learner Networks},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {208--212},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883919},
 doi = {10.1145/2883851.2883919},
 acmid = {2883919},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {MOOCs, forums, interpersonal interactions, networked learning},
abstract = {Research in formal education has repeatedly offered evidence of the importance of social interactions for student learning. However, it remains unclear whether the development of such interpersonal relationships has the same influence on learning in the context of large-scale open online learning. For instance, in MOOCs group members frequently change and the volume of interactions can quickly amass to chaos, therefore impeding an individual's propensity to foster meaningful relationships. This paper examined a MOOC for its potential to develop social processes. As it is exceedingly difficult to establish a relationship with somebody who seldom accesses a MOOC discussion, we singled out a cohort defined by its participants' regularity of forum presence. The study, analysed this 'cohort' and its development, in comparison to the entire MOOC learner network. Mixed methods of social network analysis (SNA), content analysis and statistical network modelling, revealed the potential for unfolding social processes among a more persistent group of learners in the MOOC setting.},
}

@inproceedings{Shum:2016:RRW:2883851.2883955,
 author = {Shum, Simon Buckingham and S\'{a}ndor, \'{A}gnes and Goldsmith, Rosalie and Wang, Xiaolong and Bass, Randall and McWilliams, Mindy},
 title = {Reflecting on Reflective Writing Analytics: Assessment Challenges and Iterative Evaluation of a Prototype Tool},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {213--222},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883955},
 doi = {10.1145/2883851.2883955},
 acmid = {2883955},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {education, learning analytics, metadiscourse, natural language processing, reflection, rhetoric, writing analytics},
abstract = {When used effectively, reflective writing tasks can deepen learners' understanding of key concepts, help them critically appraise their developing professional identity, and build qualities for lifelong learning. As such, reflecting writing is attracting substantial interest from universities concerned with experiential learning, reflective practice, and developing a holistic conception of the learner. However, reflective writing is for many students a novel genre to compose in, and tutors may be inexperienced in its assessment. While these conditions set a challenging context for automated solutions, natural language processing may also help address the challenge of providing real time, formative feedback on draft writing. This paper reports progress in designing a writing analytics application, detailing the methodology by which informally expressed rubrics are modelled as formal rhetorical patterns, a capability delivered by a novel web application. This has been through iterative evaluation on an independently human-annotated corpus, showing improvements from the first to second version. We conclude by discussing the reasons why classifying reflective writing has proven complex, and reflect on the design processes enabling work across disciplinary boundaries to develop the prototype to its current state.},
}

@inproceedings{Zhu:2016:LEP:2883851.2883934,
 author = {Zhu, Mengxiao and Bergner, Yoav and Zhang, Yan and Baker, Ryan and Wang, Yuan and Paquette, Luc},
 title = {Longitudinal Engagement, Performance, and Social Connectivity: A MOOC Case Study Using Exponential Random Graph Models},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {223--230},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2883851.2883934},
 doi = {10.1145/2883851.2883934},
 acmid = {2883934},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ERGM, MOOC, exponential random graph model, forum participation, learning, network analysis},
abstract = {This paper explores a longitudinal approach to combining engagement, performance and social connectivity data from a MOOC using the framework of exponential random graph models (ERGMs). The idea is to model the social network in the discussion forum in a given week not only using performance (assignment scores) and overall engagement (lecture and discussion views) covariates within that week, but also on the same person-level covariates from adjacent previous and subsequent weeks. We find that over all eight weekly sessions, the social networks constructed from the forum interactions are relatively sparse and lack the tendency for preferential attachment. By analyzing data from the second week, we also find that individuals with higher performance scores from current, previous, and future weeks tend to be more connected in the social network. Engagement with lectures had significant but sometimes puzzling effects on social connectivity. However, the relationships between social connectivity, performance, and engagement weakened over time, and results were not stable across weeks.},
}

@inproceedings{Epp:2016:ELL:2883851.2883896,
 author = {Epp, Carrie Demmans},
 title = {English Language Learner Experiences of Formal and Informal Learning Environments},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {231--235},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883896},
 doi = {10.1145/2883851.2883896},
 acmid = {2883896},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {affect, analytics, communication, experience sampling methodology (ESM), formal learning, informal learning, language learning},
abstract = {Many people who do not know English have moved to English-speaking countries to learn English. Once there, they learn English through formal and informal methods. While considerable work has studied the experiences of English language learners in different learning environments, we have yet to see analytics that detail the experiences of this population within formal and informal learning environments. This study used the experience sampling methodology to capture the information that is needed to detail the communication and affective experiences of advanced English language learners. The collected data reveals differences in how English language learners perceived their communication success based on their learning context, with higher levels of communicative success experienced in formal learning settings. No such differences were found for learners', highly negative, affect. The data suggest a need for additional emotional support within formal and informal learning environments as well as a need for oral communication support within informal contexts.},
}

@inproceedings{Wells:2016:AEO:2883851.2883894,
 author = {Wells, Marc and Wollenschlaeger, Alex and Lefevre, David and Magoulas, George D. and Poulovassilis, Alexandra},
 title = {Analysing Engagement in an Online Management Programme and Implications for Course Design},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {236--240},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883894},
 doi = {10.1145/2883851.2883894},
 acmid = {2883894},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {analysing interaction data, engagement and performance, predicting student performance},
abstract = {We analyse engagement and performance data arising from participants' interactions with an in-house LMS at Imperial College London while a cohort of students follow two courses on a new online postgraduate degree in Management. We identify and investigate two main questions relating to the relationships between engagement and performance, drawing recommendations for improved guidelines to inform the design of such courses.},
}

@inproceedings{Harrison:2016:MFI:2883851.2883923,
 author = {Harrison, Scott and Villano, Renato and Lynch, Grace and Chen, George},
 title = {Measuring Financial Implications of an Early Alert System},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {241--248},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2883851.2883923},
 doi = {10.1145/2883851.2883923},
 acmid = {2883923},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {early alert systems, evaluation, financial, student retention},
abstract = {The prevalence of early alert systems (EAS) at tertiary institutions is increasing. These systems are designed to assist with targeted student support in order to improve student retention. They also require considerable human and capital resources to implement, with significant costs involved. It is therefore an imperative that the systems can demonstrate quantifiable financial benefits to the institution. The purpose of this paper is to report on the financial implications of implementing an EAS at an Australian university as a case study. The case study institution implemented an EAS in 2011 using data generated from a data warehouse. The data set is comprised of 16,124 students enrolled between 2011 and 2013. Using a treatment effects approach, the study found that the cost of a student discontinuing was on average $4,687. Students identified by the EAS remained enrolled for longer, with the institution benefiting with approximately an additional $4,004 in revenue per student over the length of enrolment. All schools had a significant positive effect associated with the EAS and the EAS showed significant value to the institution regardless of the timing when the student was identified. The results indicate that EAS had significant financial benefits to this institution and that the benefits extended to the entire institution beyond the first year of enrolment.},
}
@inproceedings{Khan:2016:DSR:2883851.2883911,
 author = {Khan, Imran and Pardo, Abelardo},
 title = {Data2U: Scalable Real Time Student Feedback in Active Learning Environments},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {249--253},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883911},
 doi = {10.1145/2883851.2883911},
 acmid = {2883911},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {dashboard, feedback, learning analytics, visualizations},
abstract = {The majority of applications and products that use learning analytics to understand and improve learning experiences assume the creation of actionable items that will affect students through an intermediary. Much less focus is devoted to exploring how to provide insight directly to students. Furthermore, student engagement has always been a relevant aspect to increase the quality of a learning experience. Learning analytics techniques can be used to provide real-time insight tightly integrated with the learning outcomes directly to the students. This paper describes a case study deployed in a first year engineering course using a flipped learning strategy to explore the behavior of students interacting with a dashboard updated in real time providing indicators of their engagement with the course activities. The results show different patterns of use and their evolution throughout the experience and shed some light on how students perceived this resource.},
}

@inproceedings{Ruiz:2016:SLC:2883851.2883888,
 author = {Ruiz, Samara and Charleer, Sven and Urretavizcaya, Maite and Klerkx, Joris and Fern\'{a}ndez-Castro, Isabel and Duval, Erik},
 title = {Supporting Learning by Considering Emotions: Tracking and Visualization a Case Study},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {254--263},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883888},
 doi = {10.1145/2883851.2883888},
 acmid = {2883888},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {face to face interactions, quantified-self, self-reflection, students' emotions, visual dashboards, visualization},
abstract = {The adequate emotional state of students has proved to be essential for favoring learning. This paper explores the possibility of obtaining students' feedback about the emotions they feel in class in order to discover potential emotion patterns that might indicate learning fails. This paper presents a visual dashboard that allows students to track their emotions and follow up on their evolution during the course. We have compiled the principal classroom related emotions and developed a two-phase inquiry process to: verify the possibility to measure students' emotions in classroom; discover how emotions can be displayed to promote self-reflection; and confirm the impact of emotions on learning performance. Our results suggest that students' emotions in class are related to evaluation marks. This shows that early information about students' emotions can be useful for teachers and students to improve classroom results and learning outcomes.},
}

@inproceedings{Muslim:2016:RID:2883851.2883921,
 author = {Muslim, Arham and Chatti, Mohamed Amine and Mahapatra, Tanmaya and Schroeder, Ulrik},
 title = {A Rule-based Indicator Definition Tool for Personalized Learning Analytics},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {264--273},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883921},
 doi = {10.1145/2883851.2883921},
 acmid = {2883921},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {indicator, learning analytics, open learning analytics, personalized learning analytics},
abstract = {In the last few years, there has been a growing interest in learning analytics (LA) in technology-enhanced learning (TEL). Generally, LA deals with the development of methods that harness educational data sets to support the learning process. Recently, the concept of open learning analytics (OLA) has received a great deal of attention from LA community, due to the growing demand for self-organized, networked, and lifelong learning opportunities. A key challenge in OLA is to follow a personalized and goal-oriented LA model that tailors the LA task to the needs and goals of multiple stakeholders. Current implementations of LA rely on a predefined set of questions and indicators. There is, however, a need to adopt a personalized LA approach that engages end users in the indicator definition process by supporting them in setting goals, posing questions, and self-defining the indicators that help them achieve their goals. In this paper, we address the challenge of personalized LA and present the conceptual, design, and implementation details of a rule-based indicator definition tool to support flexible definition and dynamic generation of indicators to meet the needs of different stakeholders with diverse goals and questions in the LA exercise.},
}

@inproceedings{Kevan:2016:DMS:2883851.2883941,
 author = {Kevan, Jonathan M. and Menchaca, Michael P. and Hoffman, Ellen S.},
 title = {Designing MOOCs for Success: A Student Motivation-oriented Framework},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {274--278},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883941},
 doi = {10.1145/2883851.2883941},
 acmid = {2883941},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {MOOC, confirmatory factor analysis, framework, learning analytics, motivation, structural equation modeling},
abstract = {Considerable literature exists regarding MOOCs. Evaluations of MOOCs range from ringing endorsements to its vilification as a delivery model. Much evaluation focuses on completion rates and/or participant satisfaction. Overall, MOOCs are ill-defined and researchers struggle with appropriate evaluation criteria beyond attrition rates. In this paper, we provide a brief history of MOOCs, a summary of some evaluation research, and we propose a new model for evaluation with an example from a previously-delivered MOOC. Measurement of the MOOC success framework through four student satisfaction types is proposed in this paper with a model for informal learning satisfaction, one of the proposed types, theorized and tested. Results indicated theoretical underpinnings, while intended to improve instruction, might not have influenced the same satisfaction construct. Therefore, future research into alternative satisfaction factor models is needed.},
}

@inproceedings{Ostrow:2016:ALI:2883851.2883872,
 author = {Ostrow, Korinn S. and Selent, Doug and Wang, Yan and Van Inwegen, Eric G. and Heffernan, Neil T. and Williams, Joseph Jay},
 title = {The Assessment of Learning Infrastructure (ALI): The Theory, Practice, and Scalability of Automated Assessment},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {279--288},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883872},
 doi = {10.1145/2883851.2883872},
 acmid = {2883872},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {assessment of learning infrastructure, automated analysis, randomized controlled experiments at scale, the assistments testbed, tools for learning analytics, universal data reporting},
abstract = {Researchers invested in K-12 education struggle not just to enhance pedagogy, curriculum, and student engagement, but also to harness the power of technology in ways that will optimize learning. Online learning platforms offer a powerful environment for educational research at scale. The present work details the creation of an automated system designed to provide researchers with insights regarding data logged from randomized controlled experiments conducted within the ASSISTments TestBed. The Assessment of Learning Infrastructure (ALI) builds upon existing technologies to foster a symbiotic relationship beneficial to students, researchers, the platform and its content, and the learning analytics community. ALI is a sophisticated automated reporting system that provides an overview of sample distributions and basic analyses for researchers to consider when assessing their data. ALI's benefits can also be felt at scale through analyses that crosscut multiple studies to drive iterative platform improvements while promoting personalized learning.},
}

@inproceedings{Kaser:2016:STU:2883851.2883961,
 author = {K\"{a}ser, Tanja and Klingler, Severin and Gross, Markus},
 title = {When to Stop?: Towards Universal Instructional Policies},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {289--298},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883961},
 doi = {10.1145/2883851.2883961},
 acmid = {2883961},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {individualization, instructional policies, noisy data, student modeling, wheel-spinning},
abstract = {The adaptivity of intelligent tutoring systems relies on the accuracy of the student model and the design of the instructional policy. Recently an instructional policy has been presented that is compatible with all common student models. In this work we present the next step towards a universal instructional policy. We introduce a new policy that is applicable to an even wider range of student models including DBNs modeling skill topologies and forgetting. We theoretically and empirically compare our policy to previous policies. Using synthetic and real world data sets we show that our policy can effectively handle wheel-spinning students as well as forgetting across a wide range of student models.},
}

@inproceedings{Papamitsiou:2016:ACT:2883851.2883926,
 author = {Papamitsiou, Zacharoula and Karapistoli, Eirini and Economides, Anastasios A.},
 title = {Applying Classification Techniques on Temporal Trace Data for Shaping Student Behavior Models},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {299--303},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883926},
 doi = {10.1145/2883851.2883926},
 acmid = {2883926},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {assessment analytics, computer-based testing, learner behavioral modeling, supervised learning classification},
abstract = {Differences in learners' behavior have a deep impact on their educational performance. Consequently, there is a need to detect and identify these differences and build suitable learner models accordingly. In this paper, we report on the results from an alternative approach for dynamic student behavioral modeling based on the analysis of time-based student-generated trace data. The goal was to unobtrusively classify students according to their time-spent behavior. We applied 5 different supervised learning classification algorithms on these data, using as target values (class labels) the students' performance score classes during a Computer-Based Assessment (CBA) process, and compared the obtained results. The proposed approach has been explored in a study with 259 undergraduate university participant students. The analysis of the findings revealed that a) the low misclassification rates are indicative of the accuracy of the applied method and b) the ensemble learning (treeBagger) method provides better classification results compared to the others. These preliminary results are encouraging, indicating that a time-spent driven description of the students' behavior could have an added value towards dynamically reshaping the respective models.},
}

@inproceedings{Renz:2016:UAT:2883851.2883876,
 author = {Renz, Jan and Hoffmann, Daniel and Staubitz, Thomas and Meinel, Christoph},
 title = {Using A/B Testing in MOOC Environments},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {304--313},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883876},
 doi = {10.1145/2883851.2883876},
 acmid = {2883876},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {A/B testing, MOOC, controlled online tests, e-learning, microservice},
abstract = {In recent years, Massive Open Online Courses (MOOCs) have become a phenomenon offering the possibility to teach thousands of participants simultaneously. In the same time the platforms used to deliver these courses are still in their fledgling stages. While course content and didactics of those massive courses are the primary key factors for the success of courses, still a smart platform may increase or decrease the learners experience and his learning outcome. The paper at hand proposes the usage of an A/B testing framework that is able to be used within an micro-service architecture to validate hypotheses about how learners use the platform and to enable data-driven decisions about new features and settings. To evaluate this framework three new features (Onboarding Tour, Reminder Mails and a Pinboard Digest) have been identified based on a user survey. They have been implemented and introduced on two large MOOC platforms and their influence on the learners behavior have been measured. Finally this paper proposes a data driven decision workflow for the introduction of new features and settings on e-learning platforms.},
}

@inproceedings{Joksimovic:2016:TNP:2883851.2883928,
 author = {Joksimovi\'{c}, Sre\'{c}ko and Manataki, Areti and Ga\v{s}evi\'{c}, Dragan and Dawson, Shane and Kovanovi\'{c}, Vitomir and de Kereki, In{\'e}s Friss},
 title = {Translating Network Position into Performance: Importance of Centrality in Different Network Configurations},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {314--323},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883928},
 doi = {10.1145/2883851.2883928},
 acmid = {2883928},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ERGM, MOOC, academic achievement, learning, social network analysis, social processes},
abstract = {As the field of learning analytics continues to mature, there is a corresponding evolution and sophistication of the associated analytical methods and techniques. In this regard social network analysis (SNA) has emerged as one of the cornerstones of learning analytics methodologies. However, despite the noted importance of social networks for facilitating the learning process, it remains unclear how and to what extent such network measures are associated with specific learning outcomes. Motivated by Simmel's theory of social interactions and building on the argument that social centrality does not always imply benefits, this study aimed to further contribute to the understanding of the association between students' social centrality and their academic performance. The study reveals that learning analytics research drawing on SNA should incorporate both - descriptive and statistical methods to provide a more comprehensive and holistic understanding of a students' network position. In so doing researchers can undertake more nuanced and contextually salient inferences about learning in network settings. Specifically, we show how differences in the factors framing students' interactions within two instances of a MOOC affect the association between the three social network centrality measures (i.e., degree, closeness, and betweenness) and the final course outcome.},
}

@inproceedings{Mostafavi:2016:DPP:2883851.2883935,
 author = {Mostafavi, Behrooz and Barnes, Tiffany},
 title = {Data-driven Proficiency Profiling: Proof of Concept},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {324--328},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883935},
 doi = {10.1145/2883851.2883935},
 acmid = {2883935},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {clustering, data-driven, student classification, tutoring system},
abstract = {Data-driven methods have previously been used in intelligent tutoring systems to improve student learning outcomes and predict student learning methods. We have been incorporating data-driven methods for feedback and problem selection into Deep Thought, a logic tutor where students practice constructing deductive logic proofs. In this latest study we have implemented our data-driven proficiency profiler (DDPP) into Deep Thought as a proof of concept. The DDPP determines student proficiency without expert involvement by comparing relevant student rule scores to previous students who behaved similarly in the tutor and successfully completed it. The results show that the DDPP did improve in performance with additional data and proved to be an effective proof of concept.},
}

@inproceedings{Bakharia:2016:CFL:2883851.2883944,
 author = {Bakharia, Aneesha and Corrin, Linda and de Barba, Paula and Kennedy, Gregor and Ga\v{s}evi\'{c}, Dragan and Mulder, Raoul and Williams, David and Dawson, Shane and Lockyer, Lori},
 title = {A Conceptual Framework Linking Learning Design with Learning Analytics},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {329--338},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883944},
 doi = {10.1145/2883851.2883944},
 acmid = {2883944},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {intervention design, learning analytics, learning design},
abstract = {In this paper we present a learning analytics conceptual framework that supports enquiry-based evaluation of learning designs. The dimensions of the proposed framework emerged from a review of existing analytics tools, the analysis of interviews with teachers, and user scenarios to understand what types of analytics would be useful in evaluating a learning activity in relation to pedagogical intent. The proposed framework incorporates various types of analytics, with the teacher playing a key role in bringing context to the analysis and making decisions on the feedback provided to students as well as the scaffolding and adaptation of the learning design. The framework consists of five dimensions: temporal analytics, tool-specific analytics, cohort dynamics, comparative analytics and contingency. Specific metrics and visualisations are defined for each dimension of the conceptual framework. Finally the development of a tool that partially implements the conceptual framework is discussed.},
}

@inproceedings{Rienties:2016:ILD:2883851.2883875,
 author = {Rienties, Bart and Toetenel, Lisette},
 title = {The Impact of 151 Learning Designs on Student Satisfaction and Performance: Social Learning (Analytics) Matters},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {339--343},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883875},
 doi = {10.1145/2883851.2883875},
 acmid = {2883875},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative learning, data analytics, distance learning},
abstract = {An increasing number of researchers are taking learning design into consideration when predicting learning behavior and outcomes across different modules. This study builds on preliminary learning design work that was presented at LAK2015 by the Open University UK. In this study we linked 151 modules and 111.256 students with students' satisfaction and performance using multiple regression models. Our findings strongly indicate the importance of learning design in predicting and understanding performance of students in blended and online environments. In line with proponents of social learning analytics, our primary predictor for academic retention was the amount of communication activities, controlling for various institutional and disciplinary factors. Where possible, appropriate communication tasks that align with the learning objectives of the course may be a way forward to enhance academic retention.},
}

@inproceedings{Bos:2016:SDR:2883851.2883890,
 author = {Bos, Nynke and Brand-Gruwel, Saskia},
 title = {Student Differences in Regulation Strategies and Their Use of Learning Resources: Implications for Educational Design},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {344--353},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883890},
 doi = {10.1145/2883851.2883890},
 acmid = {2883890},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {blended learning, cluster analysis, individual differences, learning dispositions, regulation strategies},
abstract = {The majority of the learning analytics research focuses on the prediction of course performance and modeling student behaviors with a focus on identifying students who are at risk of failing the course. Learning analytics should have a stronger focus on improving the quality of learning for all students, not only identifying at risk students. In order to do so, we need to understand what successful patterns look like when reflected in data and subsequently adjust the course design to avoid unsuccessful patterns and facilitate successful patterns.
However, when establishing these successful patterns, it is important to account for individual differences among students since previous research has shown that not all students engage with learning resources to the same extent. Regulation strategies seem to play an important role in explaining the different usage patterns students' display when using digital learning recourses. When learning analytics research incorporates contextualized data about student regulation strategies we are able to differentiate between students at a more granular level.
The current study examined if regulation strategies could account for differences in the use of various learning resources. It examines how students regulated their learning process and subsequently used the different learning resources throughout the course and established how this use contributes to course performance.
The results show that students with different regulation strategies use the learning resources to the same extent. However, the use of learning resources influences course performance differently for different groups of students. This paper recognizes the importance of contextualization of learning data resources with a broader set of indicators to understand the learning process. With our focus on differences between students, we strive for a shift within learning analytics from identifying at risk students towards a contribution of learning analytics in the educational design process and enhance the quality of learning; for all students.},
}

@inproceedings{David:2016:SEC:2883851.2883885,
 author = {David, Yossi Ben and Segal, Avi and Gal, Ya'akov (Kobi)},
 title = {Sequencing Educational Content in Classrooms Using Bayesian Knowledge Tracing},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {354--363},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883885},
 doi = {10.1145/2883851.2883885},
 acmid = {2883885},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract = {Despite the prevalence of e-learning systems in schools, most of today's systems do not personalize educational data to the individual needs of each student. This paper proposes a new algorithm for sequencing questions to students that is empirically shown to lead to better performance and engagement in real schools when compared to a baseline approach. It is based on using knowledge tracing to model students' skill acquisition over time, and to select questions that advance the student's learning within the range of the student's capabilities, as determined by the model. The algorithm is based on a Bayesian Knowledge Tracing (BKT) model that incorporates partial credit scores, reasoning about multiple attempts to solve problems, and integrating item difficulty. This model is shown to outperform other BKT models that do not reason about (or reason about some but not all) of these features. The model was incorporated into a sequencing algorithm and deployed in two classes in different schools where it was compared to a baseline sequencing algorithm that was designed by pedagogical experts. In both classes, students using the BKT sequencing approach solved more difficult questions and attributed higher performance than did students who used the expert-based approach. Students were also more engaged using the BKT approach, as determined by their interaction time and number of log-ins to the system, as well as their reported opinion. We expect our approach to inform the design of better methods for sequencing and personalizing educational content to students that will meet their individual learning needs.},
}

@inproceedings{Martori:2016:SRB:2883851.2883901,
 author = {Martori, Francesc and Cuadros, Jordi and Gonz\'{a}lez-Sabat{\'e}, Lucinio},
 title = {Studying the Relationship Between BKT Fitting Error and the Skill Difficulty Index},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {364--368},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883901},
 doi = {10.1145/2883851.2883901},
 acmid = {2883901},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {BKT, BKT-BF, RMSE modeling, difficulty index, educational data mining},
abstract = {Bayesian Knowledge Tracing (BKT) is one of the most popular knowledge inference models due to its interpretability and ability to infer student knowledge. A proper student modeling can help guide the behavior of a cognitive tutor system and provide insight to researchers on understanding how students learn. Using four different datasets we study the relationship between the error coming from fitting the parameters and the difficulty index of the skills and the effect of the size of the dataset in this relationship. The relationship between the fitting error and the difficulty index can be very easy modeled and might be indicating some problems with BKTs performance. However, large datasets are required to clearly see this connection as there is an important sample size effect.},
}

@inproceedings{Liu:2016:MCM:2883851.2883967,
 author = {Liu, Ran and Patel, Rony and Koedinger, Kenneth R.},
 title = {Modeling Common Misconceptions in Learning Process Data},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {369--377},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/2883851.2883967},
 doi = {10.1145/2883851.2883967},
 acmid = {2883967},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {additive factors model, fraction arithmetic, knowledge component model, misconceptions, q-matrix},
abstract = {Student mistakes are often not random but, rather, reflect thoughtful yet incorrect strategies. In order for educational technologies to make full use of students' performance data to estimate the knowledge of a student, it is important to model not only the conceptions but also the misconceptions that a student's particular pattern of successes and errors may indicate. The student models that drive the "outer loop" of Intelligent Tutoring Systems typically do not represent or track misconceptions. Here, we present a method of representing misconceptions in the Knowledge Component models, or Q-Matrices, that are used by student models to estimate latent knowledge. We show, in a case study on a fraction arithmetic dataset, that incorporating a misconception into the Knowledge Component model dramatically improves the overall model's fit to data. We also derive qualitative insights from comparing predicted learning curves across models that incorporate varying misconception-related parameters. Finally, we show that the inclusion of a misconception in the Knowledge Component model can yield individual student estimates of misconception strength that are significantly correlated with out-of-tutor measures of student errors.},
} 

@inproceedings{Bakharia:2016:RSL:2883851.2883882,
 author = {Bakharia, Aneesha and Kitto, Kirsty and Pardo, Abelardo and Ga\v{s}evi\'{c}, Dragan and Dawson, Shane},
 title = {Recipe for Success: Lessons Learnt from Using xAPI Within the Connected Learning Analytics Toolkit},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {378--382},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883882},
 doi = {10.1145/2883851.2883882},
 acmid = {2883882},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CLA toolkit, CLRecipe, architecture, learning analytics, learning record store, xAPI},
abstract = {An ongoing challenge for Learning Analytics research has been the scalable derivation of user interaction data from multiple technologies. The complexities associated with this challenge are increasing as educators embrace an ever growing number of social and content-related technologies. The Experience API (xAPI) alongside the development of user specific record stores has been touted as a means to address this challenge, but a number of subtle considerations must be made when using xAPI in Learning Analytics. This paper provides a general overview to the complexities and challenges of using xAPI in a general systemic analytics solution - called the Connected Learning Analytics (CLA) toolkit. The importance of design is emphasised, as is the notion of common vocabularies and xAPI Recipes. Early decisions about vocabularies and structural relationships between statements can serve to either facilitate or handicap later analytics solutions. The CLA toolkit case study provides us with a way of examining both the strengths and the weaknesses of the current xAPI specification, and we conclude with a proposal for how xAPI might be improved by using JSON-LD to formalise Recipes in a machine readable form.},
} 

@inproceedings{Robinson:2016:FSA:2883851.2883932,
 author = {Robinson, Carly and Yeomans, Michael and Reich, Justin and Hulleman, Chris and Gehlbach, Hunter},
 title = {Forecasting Student Achievement in MOOCs with Natural Language Processing},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {383--387},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883932},
 doi = {10.1145/2883851.2883932},
 acmid = {2883932},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {MOOCS, learning analytics, motivation},
abstract = {Student intention and motivation are among the strongest predictors of persistence and completion in Massive Open Online Courses (MOOCs), but these factors are typically measured through fixed-response items that constrain student expression. We use natural language processing techniques to evaluate whether text analysis of open responses questions about motivation and utility value can offer additional capacity to predict persistence and completion over and above information obtained from fixed-response items. Compared to simple benchmarks based on demographics, we find that a machine learning prediction model can learn from unstructured text to predict which students will complete an online course. We show that the model performs well out-of-sample, compared to a standard array of demographics. These results demonstrate the potential for natural language processing to contribute to predicting student success in MOOCs and other forms of open online learning.},
}

@inproceedings{Koedinger:2016:DEC:2883851.2883957,
 author = {Koedinger, Kenneth R. and McLaughlin, Elizabeth A. and Jia, Julianna Zhuxin and Bier, Norman L.},
 title = {Is the Doer Effect a Causal Relationship?: How Can We Tell and Why It's Important},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {388--397},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883957},
 doi = {10.1145/2883851.2883957},
 acmid = {2883957},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {course effectiveness, doer effect, learn by doing, learning engineering, prediction},
abstract = {The "doer effect" is an association between the number of online interactive practice activities students' do and their learning outcomes that is not only statistically reliable but has much higher positive effects than other learning resources, such as watching videos or reading text. Such an association suggests a causal interpretation--more doing yields better learning--which requires randomized experimentation to most rigorously confirm. But such experiments are expensive, and any single experiment in a particular course context does not provide rigorous evidence that the causal link will generalize to other course content. We suggest that analytics of increasingly available online learning data sets can complement experimental efforts by facilitating more widespread evaluation of the generalizability of claims about what learning methods produce better student learning outcomes. We illustrate with analytics that narrow in on a causal interpretation of the doer effect by showing that doing within a course unit predicts learning of that unit content more than doing in units before or after. We also provide generalizability evidence across four different courses involving over 12,500 students that the learning effect of doing is about six times greater than that of reading.},
}

@inproceedings{Wang:2016:TTH:2883851.2883964,
 author = {Wang, Xu and Wen, Miaomiao and Ros{\'e}, Carolyn P.},
 title = {Towards Triggering Higher-order Thinking Behaviors in MOOCs},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {398--407},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883964},
 doi = {10.1145/2883851.2883964},
 acmid = {2883964},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {LDA topic modeling, coding manual, discussion, learning analytics, propensity score matching, regression analysis},
abstract = {With the aim of better scaffolding discussion to improve learning in a MOOC context, this work investigates what kinds of discussion behaviors contribute to learning. We explored whether engaging in higher-order thinking behaviors results in more learning than paying general or focused attention to course materials. In order to evaluate whether to attribute the effect to engagement in the associated behaviors versus persistent characteristics of the students, we adopted two approaches. First, we used propensity score matching to pair students who exhibit a similar level of involvement in other course activities. Second, we explored individual variation in engagement in higher-order thinking behaviors across weeks. The results of both analyses support the attribution of the effect to the behavioral interpretation. A further analysis using LDA applied to course materials suggests that more social oriented topics triggered richer discussion than more biopsychology oriented topics.},
}

@inproceedings{The:2016:SEF:2883851.2883871,
 author = {The, Benedict and Mavrikis, Manolis},
 title = {A Study on Eye Fixation Patterns of Students in Higher Education Using an Online Learning System},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {408--416},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/2883851.2883871},
 doi = {10.1145/2883851.2883871},
 acmid = {2883871},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cognitive activity, eye tracking, human-computer interaction, instructional design, online learning},
abstract = {We study how the use of online learning systems stimulate cognitive activities, by conducting an experiment with the use of eye tracking technology to monitor eye fixations of 60 final year students engaging in online interactive tutorials at the start of their Final Year Project module. Our findings show that the students' visual scanning behaviours fall into three different types of eye fixation patterns, and the data corresponding to the different types relates to the performance of the students in other related academic modules. We conclude that this method of studying eye fixation patterns can identify different types of learners with respect to cognitive activities and academic potentials, allowing educators to understand how their instructional design using online learning environments can stimulate higher-order cognitive activities.},
}

@inproceedings{Sharma:2016:GLA:2883851.2883902,
 author = {Sharma, Kshitij and Alavi, Hamed S. and Jermann, Patrick and Dillenbourg, Pierre},
 title = {A Gaze-based Learning Analytics Model: In-video Visual Feedback to Improve Learner's Attention in MOOCs},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {417--421},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883902},
 doi = {10.1145/2883851.2883902},
 acmid = {2883902},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {MOOCs, eye-tracking, student attention, video based learning},
abstract = {In the context of MOOCs, "With-me-ness" refers to the extent to which the learner succeeds in following the teacher, specifically in terms of looking at the area in the video that the teacher is explaining. In our previous works, we employed eye-tracking methods to quantify learners' With-me-ness and showed that it is positively correlated with their learning gains. In this contribution, we describe a tool that is designed to improve With-me-ness by providing a visual-aid superimposed on the video. The position of the visual-aid is suggested by the teachers' dialogue and deixis, and it is displayed when the learner's With-me-ness is under the average value, which is computed from the other students' gaze behavior. We report on a user-study that examines the effectiveness of the proposed tool. The results show that it significantly improves the learning gain and it significantly increases the extent to which the students follow the teacher. Finally, we demonstrate how With-me-ness can create a complete theoretical framework for conducting gaze-based learning analytics in the context of MOOCs.},
}

@inproceedings{Pardo:2016:ERS:2883851.2883883,
 author = {Pardo, Abelardo and Han, Feifei and Ellis, Robert A.},
 title = {Exploring the Relation Between Self-regulation, Online Activities, and Academic Performance: A Case Study},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {422--429},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2883851.2883883},
 doi = {10.1145/2883851.2883883},
 acmid = {2883883},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {SEM, higher education, learning analytics, self-regulation},
abstract = {The areas of educational data mining and learning analytics focus on the extraction of knowledge and actionable items from data sets containing detailed information about students. However, the potential impact from these techniques is increased when properly contextualized within a learning environment. More studies are needed to explore the connection between student interactions, approaches to learning, and academic performance. Self-regulated learning (SRL) is defined as the extent to which a student is able to motivationally, metacognitively, and cognitively engage in a learning experience. SRL has been the focus of research in traditional classroom learning and is also argued to play a vital role in the online or blended learning contexts. In this paper, we study how SRL affects students' online interactions with various learning activities and its influence in academic performance. The results derived from a naturalistic experiment among a cohort of first year engineering students showed that positive self-regulated strategies (PSRS) and negative self-regulated strategies (NSRS) affected both the interaction with online activities and academic performance. NSRS directly predicted academic outcomes, whereas PSRS only contributed indirectly to academic performance via the interactions with online activities. These results point to concrete avenues to promote self-regulation among students in this type of learning contexts.},
}

@inproceedings{Tan:2016:FCL:2883851.2883965,
 author = {Tan, Jennifer Pei-Ling and Yang, Simon and Koh, Elizabeth and Jonathan, Christin},
 title = {Fostering 21st Century Literacies Through a Collaborative Critical Reading and Learning Analytics Environment: User-perceived Benefits and Problematics},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {430--434},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883965},
 doi = {10.1145/2883851.2883965},
 acmid = {2883965},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {21st century skills, CSCL, critical literacy, learning analytics},
abstract = {The affordances of learning analytics (LA) are being increasingly harnessed to enhance 21st century (21C) pedagogy and learning. Relatively rare, however, are use cases and empirically based understandings of students' actual experiences with LA tools and environments at fostering 21C literacies, especially in secondary schooling and Asian education contexts. This paper addresses this knowledge gap by 1) presenting a first iteration design of a computer-supported collaborative critical reading and LA environment and its 16-week implementation in a Singapore high school; and 2) foregrounding students' quantitative and qualitative accounts of the benefits and problematics associated with this learning innovation. We focus the analytic lens on the LA dashboard components that provided visualizations of students' reading achievement, 21C learning dispositions, critical literacy competencies and social learning network positioning within the class. The paper aims to provide insights into the potentialities, paradoxes and pathways forward for designing LA that take into consideration the voices of learners as critical stakeholders.},
}

@inproceedings{Pardos:2016:IEA:2883851.2883949,
 author = {Pardos, Zachary A. and Xu, Yanbo},
 title = {Improving Efficacy Attribution in a Self-directed Learning Environment Using Prior Knowledge Individualization},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {435--439},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883949},
 doi = {10.1145/2883851.2883949},
 acmid = {2883949},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Bayesian knowledge tracing, education, efficacy attribution, individualization, massive open online courses (MOOCs), prior knowledge, self-directed learning, self-selection bias},
abstract = {Models of learning in EDM and LAK are pushing the boundaries of what can be measured from large quantities of historical data. When controlled randomization is present in the learning platform, such as randomized ordering of problems within a problem set, natural quasi-randomized controlled studies can be conducted, post-hoc. Difficulty and learning gain attribution are among factors of interest that can be studied with secondary analyses under these conditions. However, much of the content that we might like to evaluate for learning value is not administered as a random stimulus to students but instead is being self-selected, such as a student choosing to seek help in the discussion forums, wiki pages, or other pedagogically relevant material in online courseware. Help seekers, by virtue of their motivation to seek help, tend to be the ones who have the least knowledge. When presented with a cohort of students with a bi-modal or uniform knowledge distribution, this can present problems with model interpretability when a single point estimation is used to represent cohort prior knowledge. Since resource access is indicative of a low knowledge student, a model can tend towards attributing the resources with low or negative learning gain in order to better explain performance given the higher average prior point estimate. In this paper we present several individualized prior strategies and demonstrate how learning efficacy attribution validity and prediction accuracy improve as a result. Level of education attained, relative past assessment performance, and the prior per student cold start heuristic were employed and compared as prior knowledge individualization strategies.},
}

@inproceedings{Hicks:2016:UGA:2883851.2883953,
 author = {Hicks, Drew and Eagle, Michael and Rowe, Elizabeth and Asbell-Clarke, Jodi and Edwards, Teon and Barnes, Tiffany},
 title = {Using Game Analytics to Evaluate Puzzle Design and Level Progression in a Serious Game},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {440--448},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/2883851.2883953},
 doi = {10.1145/2883851.2883953},
 acmid = {2883953},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {complex problem solving, educational data mining, learning analytics, serious games, survival analysis},
abstract = {Our previous work has demonstrated that players who perceive a game as more challenging are likely to perceive greater learning from that game [8]. However, this may not be the case for all sources of challenge. In this study of a Science learning game called Quantum Spectre, we found that students' progress through the first zone of the game seemed to encounter a "roadblock" during gameplay, dropping out when they cannot (or do not want to) progress further. Previously we had identified two primary types of errors in the learning game, Quantum Spectre: Science Errors related to the game's core educational content; and Puzzle Errors related to rules of the game but not to science knowledge. Using this prior analysis, alongside Survival Analysis techniques for analyzing time-series data and drop-out rates, we explored players' gameplay patterns to help us understand player dropout in Quantum Spectre. These results demonstrate that modeling player behavior can be useful for both assessing learning and for designing complex problem solving content for learning environments.},
}

@inproceedings{Taraghi:2016:BMS:2883851.2883895,
 author = {Taraghi, Behnam and Saranti, Anna and Legenstein, Robert and Ebner, Martin},
 title = {Bayesian Modelling of Student Misconceptions in the One-digit Multiplication with Probabilistic Programming},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {449--453},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883895},
 doi = {10.1145/2883851.2883895},
 acmid = {2883895},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Bayesian modelling, learning analytics, one-digit multiplication, probabilistic programming},
abstract = {One-digit multiplication errors are one of the most extensively analysed mathematical problems. Research work primarily emphasises the use of statistics whereas learning analytics can go one step further and use machine learning techniques to model simple learning misconceptions. Probabilistic programming techniques ease the development of probabilistic graphical models (bayesian networks) and their use for prediction of student behaviour that can ultimately influence learning decision processes.},
}

@inproceedings{Wang:2016:EER:2883851.2883910,
 author = {Wang, Yan and Ostrow, Korinn and Beck, Joseph and Heffernan, Neil},
 title = {Enhancing the Efficiency and Reliability of Group Differentiation Through Partial Credit},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {454--458},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883910},
 doi = {10.1145/2883851.2883910},
 acmid = {2883910},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data mining, group differentiation, partial credit, randomized controlled trial, resampling},
abstract = {The focus of the learning analytics community bridges the gap between controlled educational research and data mining. Online learning platforms can be used to conduct randomized controlled trials to assist in the development of interventions that increase learning gains; datasets from such research can act as a treasure trove for inquisitive data miners. The present work employs a data mining approach on randomized controlled trial data from ASSISTments, a popular online learning platform, to assess the benefits of incorporating additional student performance data when attempting to differentiate between two user groups. Through a resampling technique, we show that partial credit, defined as an algorithmic combination of binary correctness, hint usage, and attempt count, can benefit assessment and group differentiation. Partial credit reduces sample sizes required to reliably differentiate between groups that are known to differ by 58%, and reduces sample sizes required to reliably differentiate between less distinct groups by 9%.},
}

@inproceedings{Brown:2016:RCT:2883851.2883907,
 author = {Brown, Michael Geoffrey and DeMonbrun, R. Matthew and Lonn, Steven and Aguilar, Stephen J. and Teasley, Stephanie D.},
 title = {What and when: The Role of Course Type and Timing in Students' Academic Performance},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {459--468},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2883851.2883907},
 doi = {10.1145/2883851.2883907},
 acmid = {2883907},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {disciplinary fields, early warning system, time based learning analytics, undergraduate education},
abstract = {In this paper we discuss the results of a study of students' academic performance in first year general education courses. Using data from 566 students who received intensive academic advising as part of their enrollment in the institution's pre-major/general education program, we investigate individual student, organizational, and disciplinary factors that might predict a students' potential classification in an Early Warning System as well as factors that predict improvement and decline in their academic performance. Disciplinary course type (based on Biglan's [7] typology) was significantly related to a student's likelihood to enter below average performance classifications. Students were the most likely to enter a classification in fields like the natural science, mathematics, and engineering in comparison to humanities courses. We attribute these disparities in academic performance to disciplinary norms around teaching and assessment. In particular, the timing of assessments played a major role in students' ability to exit a classification. Implications for the design of Early Warning analytics systems as well as academic course planning in higher education are offered.},
}

@inproceedings{Adjei:2016:PSP:2883851.2883867,
 author = {Adjei, Seth A. and Botelho, Anthony F. and Heffernan, Neil T.},
 title = {Predicting Student Performance on Post-requisite Skills Using Prerequisite Skill Data: An Alternative Method for Refining Prerequisite Skill Structures},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {469--473},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883867},
 doi = {10.1145/2883851.2883867},
 acmid = {2883867},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {learning maps, placements, prerequisite structures, refinements, skill relationships},
abstract = {Prerequisite skill structures have been closely studied in past years leading to many data-intensive methods aimed at refining such structures. While many of these proposed methods have yielded success, defining and refining hierarchies of skill relationships are often difficult tasks. The relationship between skills in a graph could either be causal, therefore, a prerequisite relationship (skill A must be learned before skill B). The relationship may be non-causal, in which case the ordering of skills does not matter and may indicate that both skills are prerequisites of another skill. In this study, we propose a simple, effective method of determining the strength of pre-to-post-requisite skill relationships. We then compare our results with a teacher-level survey about the strength of the relationships of the observed skills and find that the survey results largely confirm our findings in the data-driven approach.},
}

@inproceedings{Pardo:2016:GAP:2883851.2883870,
 author = {Pardo, Abelardo and Mirriahi, Negin and Martinez-Maldonado, Roberto and Jovanovic, Jelena and Dawson, Shane and Ga\v{s}evi\'{c}, Dragan},
 title = {Generating Actionable Predictive Models of Academic Performance},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {474--478},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2883851.2883870},
 doi = {10.1145/2883851.2883870},
 acmid = {2883870},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {feedback, learning analytics, personalization, recursive partitioning},
abstract = {The pervasive collection of data has opened the possibility for educational institutions to use analytics methods to improve the quality of the student experience. However, the adoption of these methods faces multiple challenges particularly at the course level where instructors and students would derive the most benefit from the use of analytics and predictive models. The challenge lies in the knowledge gap between how the data is captured, processed and used to derive models of student behavior, and the subsequent interpretation and the decision to deploy pedagogical actions and interventions by instructors. Simply put, the provision of learning analytics alone has not necessarily led to changing teaching practices. In order to support pedagogical change and aid interpretation, this paper proposes a model that can enable instructors to readily identify subpopulations of students to provide specific support actions. The approach was applied to a first year course with a large number of students. The resulting model classifies students according to their predicted exam scores, based on indicators directly derived from the learning design.},
}

@inproceedings{Ringtved:2016:LDF:2883851.2883856,
 author = {Ringtved, Ulla and Milligan, Sandra and Corrin, Linda},
 title = {Learning Design and Feedback Processes at Scale: Stocktaking Emergent Theory and Practice},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {479--480},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883856},
 doi = {10.1145/2883851.2883856},
 acmid = {2883856},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {crowd-sourced learning, feedback, learning analytics, learning at scale, learning design, management performance, scaled courses},
abstract = {Design for learning in scaled courses is shifting away from replication of traditional on-campus or online teaching towards exploiting the distinctive characteristic and potentials of scale to transform both teaching and learning. Scaled learning environments such as MOOCs may represent a new paradigm for teaching. This workshop involves consideration of the how learning occurs in scaled environments, and how learning designers and analysts can assist. It will explore questions at the heart of effective learning design, using expert panelists and collaborative knowledge-building techniques to arrive at a stocktake of thinking.},
}

@inproceedings{Shum:2016:CPW:2883851.2883854,
 author = {Shum, Simon Buckingham and Knight, Simon and McNamara, Danielle and Allen, Laura and Bektik, Duygu and Crossley, Scott},
 title = {Critical Perspectives on Writing Analytics},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {481--483},
 numpages = {3},
 url = {http://doi.acm.org/10.1145/2883851.2883854},
 doi = {10.1145/2883851.2883854},
 acmid = {2883854},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {education, natural language processing, writing},
abstract = {Writing Analytics focuses on the measurement and analysis of written texts for the purpose of understanding writing processes and products, in their educational contexts, and improving the teaching and learning of writing. This workshop adopts a critical, holistic perspective in which the definition of "the system" and "success" is not restricted to IR metrics such as precision and recall, but recognizes the many wider issues that aid or obstruct analytics adoption in educational settings, such as theoretical and pedagogical grounding, usability, user experience, stakeholder design engagement, practitioner development, organizational infrastructure, policy and ethics.},
} 

@inproceedings{Ley:2016:LAW:2883851.2883860,
 author = {Ley, Tobias and Klamma, Ralf and Lindstaedt, Stefanie and Wild, Fridolin},
 title = {Learning Analytics for Workplace and Professional Learning},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {484--485},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883860},
 doi = {10.1145/2883851.2883860},
 acmid = {2883860},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {learning analytics, workplace learning},
abstract = {Recognizing the need for addressing the rather fragmented character of research in this field, we have held a workshop on learning analytics for workplace and professional learning at the Learning Analytics and Knowledge (LAK) Conference. The workshop has taken a broad perspective, encompassing approaches from a number of previous traditions, such as adaptive learning, professional online communities, workplace learning and performance analytics. Being co-located with the LAK conference has provided an ideal venue for addressing common challenges and for benefiting from the strong research on learning analytics in other sectors that LAK has established. Learning Analytics for Workplace and Professional Learning is now on the research agenda of several ongoing EU projects, and therefore a number of follow-up activities are planned for strengthening integration in this emerging field.},
}

@inproceedings{Martinez-Maldonado:2016:CLA:2883851.2883855,
 author = {Martinez-Maldonado, Roberto and Hernandez-Leo, Davinia and Pardo, Abelardo and Suthers, Dan and Kitto, Kirsty and Charleer, Sven and Aljohani, Naif Radi and Ogata, Hiroaki},
 title = {Cross-LAK: Learning Analytics Across Physical and Digital Spaces},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {486--487},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883855},
 doi = {10.1145/2883851.2883855},
 acmid = {2883855},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {integration, learning analytics, monitoring, seamless learning},
abstract = {It is of high relevance to the LAK community to explore blended learning scenarios where students can interact at diverse digital and physical learning spaces. This workshop aims to gather the sub-community of LAK researchers, learning scientists and researchers from other communities, interested in ubiquitous, mobile and/or face-to-face learning analytics. An overarching concern is how to integrate and coordinate learning analytics to provide continued support to learning across digital and physical spaces. The goals of the workshop are to share approaches and identify a set of guidelines to design and connect Learning Analytics solutions according to the pedagogical needs and contextual constraints to provide support across digital and physical learning spaces.},
}

@inproceedings{Chen:2016:PTA:2883851.2883865,
 author = {Chen, Bodong and Wise, Alyssa F. and Knight, Simon and Cheng, Britte Haugan},
 title = {Putting Temporal Analytics into Practice: The 5th International Workshop on Temporality in Learning Data},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {488--489},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883865},
 doi = {10.1145/2883851.2883865},
 acmid = {2883865},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CSCL, analytics for action, learning analytics, practitioner knowledge, temporality},
abstract = {Interest in temporal analytics---analytics that probe temporal aspects of learning so as to gain insights into the processes through which learning occurs---continues to grow. The relationships of temporal patterns to learning outcomes is a central area of interest. However, while the literature on temporal analyses is developing, there has been less consideration of the methods by which temporal analyses might be translated to actionable insights and thus, put into use in educational practice. Emerging temporal analysis techniques present both theoretical and practical challenges for producing and interpreting results. Synergetic actions are needed in order to support practitioners.},
}

@inproceedings{Whyte:2016:LWE:2883851.2883858,
 author = {Whyte, Anthony and Nayak, Prashant and Johnston, John},
 title = {LAK16 Workshop: Extending IMS Caliper Analytics\&Trade; with Learning Activity Profiles},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {490--491},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883858},
 doi = {10.1145/2883851.2883858},
 acmid = {2883858},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {IMS caliper, controlled vocabularies, information modeling, learning activity profiles, learning analytics},
abstract = {Educational institutions are evolving away from the one-application-fits-all learning management system to a loosely connected digital learning ecosystem comprising diverse services that increasingly leverage data analytics to drive pedagogical innovation. Yet an ecosystem rich in services but lacking a common approach to measuring learning activity will find data collection, aggregation and analysis time-consuming and costly. The IMS Caliper Analytics specification addresses the need for data and semantic interoperability by providing an extensible information model, controlled vocabularies and an API for instrumenting learning applications and systems that log learning events. However, many learning activities have yet to be modeled by the Caliper working group. Engaging the SoLAR community directly in this effort will help ensure that the needs of researchers and other consumers of learning analytics data will inform future versions of the specification. The LAK16 Caliper workshop is being offered with this goal in mind. The half-day session, facilitated by members of Team Caliper, will provide LAK16 participants with an opportunity to extend the Caliper specification by modeling new learning activity profiles. New profiles, new connections and new friendships are expected outcomes.},
}

@inproceedings{Drachsler:2016:EPI:2883851.2883933,
 author = {Drachsler, Hendrik and Hoel, Tore and Cooper, Adam and Kismih\'{o}k, G\'{a}bor and Berg, Alan and Scheffel, Maren and Chen, Weiqin and Ferguson, Rebecca},
 title = {Ethical and Privacy Issues in the Design of Learning Analytics Applications},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {492--493},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883933},
 doi = {10.1145/2883851.2883933},
 acmid = {2883933},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data ownership, ethics, learning analytics, legal rights, privacy, surveillance},
abstract = {Issues related to Ethics and Privacy have become a major stumbling block in application of Learning Analytics technologies on a large scale. Recently, the learning analytics community at large has more actively addressed the EP4LA issues, and we are now starting to see learning analytics solutions that are designed not only as an afterthought, but also with these issues in mind. The 2nd EP4LA@LAK16 workshop will bring the discussion on ethics and privacy for learning analytics to a the next level, helping to build an agenda for organizational and technical design of LA solutions, addressing the different processes of a learning analytics workflow.},
}

@inproceedings{Greer:2016:LAC:2883851.2883899,
 author = {Greer, Jim and Molinaro, Marco and Ochoa, Xavier and McKay, Timothy},
 title = {Learning Analytics for Curriculum and Program Quality Improvement (PCLA 2016)},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {494--495},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883899},
 doi = {10.1145/2883851.2883899},
 acmid = {2883899},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ACM proceedings, LATEX, text tagging},
abstract = {This workshop on Learning Analytics for Curriculum and Program Quality Improvement investigates how LAK can drive improvements in teaching practices, instructional and curricular design, and academic program delivery. This workshop brings forward research and examples of how LAK can help build the case for instructional, curricular, or programmatic change and further how LAK can be used to foster acceptance of change processes by teachers, administrators, and other stakeholders in the educational enterprise.},
}

@inproceedings{Bull:2016:LWL:2883851.2883852,
 author = {Bull, S. and Ginon, B. and Kay, J. and Kickmeier-Rust, M. and Johnson, M. D.},
 title = {LAL Workshop: Learning Analytics for Learners},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {496--497},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883852},
 doi = {10.1145/2883851.2883852},
 acmid = {2883852},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {dashboards, learning analytics for learners, learning data for learners, open learner models, visual learning analytics},
abstract = {With the arrival of 'big data; in education, the potential was recognised for learning analytics to track students' learning, to reveal patterns in their learning, or to identify at-risk students, in addition to guiding reform and supporting educators in improving teaching and learning processes [1]. Learning Analytics dashboards have been used at all levels, including institutional, regional and national level [2]. In classroom use, while learning visualisations are often based on counts of activity data or interaction patterns, there is increasing recognition that learning analytics relate to learning, and should therefore provide pedagogically useful information [3]. While increasing numbers of technology-enhanced learning applications are embracing the potential of learning analytics at the classroom level, often these are aimed at teachers. However, learners can also benefit from learning analytics data (e.g. [4][5]).},
}

@inproceedings{Ochoa:2016:MLA:2883851.2883913,
 author = {Ochoa, Xavier and Worsley, Marcelo and Weibel, Nadir and Oviatt, Sharon},
 title = {Multimodal Learning Analytics Data Challenges},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {498--499},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883913},
 doi = {10.1145/2883851.2883913},
 acmid = {2883913},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data challenge, multimodal, multimodal datasets},
abstract = {This is a proposal for organizing a Multimodal Learning Analytics (MLA) data challenge as part of the workshop offering of the Learning Analytics and Knowledge (LAK) conference. It explains the motivation of the event, its objectives, target groups, expected format, organization, dissemination strategy and schedule.},
}

@inproceedings{Wolff:2016:DLL:2883851.2883864,
 author = {Wolff, Annika and Moore, John and Zdrahal, Zdenek and Hlosta, Martin and Kuzilek, Jakub},
 title = {Data Literacy for Learning Analytics},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {500--501},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883864},
 doi = {10.1145/2883851.2883864},
 acmid = {2883864},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {analysis, communication, data literacy, learning analytics, visualization},
abstract = {This workshop explores how data literacy impacts on learning analytics both for practitioners and for end users. The term data literacy is used to broadly describe the set of abilities around the use of data as part of everyday thinking and reasoning for solving real-world problems. It is a skill required both by learning analytics practitioners to derive actionable insights from data and by the intended end users, such that it affects their ability to accurately interpret and critique presented analysis of data. The latter is particularly important, since learning analytics outcomes can be targeted at a wide range of end users, some of whom will be young students and many of whom are not data specialists.
Whilst data literacy is rarely an end goal of learning analytics projects, this workshop aims to find where issues related to data literacy have impacted on project outcomes and where important insights have been gained. This workshop will further encourage the sharing of knowledge and experience through practical activities with datasets and visualisations. This workshop aims to highlight the need for a greater understanding of data literacy as a field of study, especially with regard to communicating around large, complex, data sets.},
}

@inproceedings{Giannakos:2016:SEA:2883851.2883898,
 author = {Giannakos, Michail N. and Sampson, Demetrios G. and Kidzi\'{n}ski, \Lukasz and Pardo, Abelardo},
 title = {Smart Environments and Analytics on Video-based Learning},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {502--504},
 numpages = {3},
 url = {http://doi.acm.org/10.1145/2883851.2883898},
 doi = {10.1145/2883851.2883898},
 acmid = {2883898},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {interaction design, learning analytics, smart environments, video-based learning, visual analytics},
abstract = {The International Workshop of Smart Environments and Analytics on Video-Based Learning (SE@VBL) aims to connect research efforts on Video-Based Learning with Smart Environments and Analytics to create synergies between these fields. The main objective is to build a research community around the intersection of these topical areas. In particular, SE@VBL aims to develop a critical discussion about the next generation of video-based learning environments and their analytics, the form of these analytics and the way they can be analyzed in order to help us to better understand and improve the value of educational videos to support teaching and learning. SE@VBL is based on the rationale that combining and analyzing learners' interactions with other available data obtained from learners, new avenues for research on video-based learning have emerged. This can have a significant impact in current educational trends such as Massive Open Online Courses (MOOCs) and Flipped Classroom.},
} 

@inproceedings{Brooks:2016:IDM:2883851.2883879,
 author = {Brooks, Christopher A. and Thompson, Craig and Kovanovi\'{c}, Vitomir},
 title = {Introduction to Data Mining for Educational Researchers},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {505--506},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883879},
 doi = {10.1145/2883851.2883879},
 acmid = {2883879},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data mining, learning analytics, predictive modeling},
abstract = {The goal of this tutorial is to share data mining tools and techniques used by computer scientists with educational social scientists. We broadly define educational social scientists as being made up of people with backgrounds in the learning sciences, cognitive psychology, and educational research. The learning analytics community is heavily populated with researchers of these backgrounds, and we believe those that find themselves at the intersection of research, theory, and practice have a particular interest in expanding their knowledge of data driven tools and techniques.},
}

@inproceedings{Agnihotri:2016:EDM:2883851.2883857,
 author = {Agnihotri, Lalitha and Mojarad, Shirin and Lewkow, Nicholas and Essa, Alfred},
 title = {Educational Data Mining with Python and Apache Spark: A Hands-on Tutorial},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {507--508},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883857},
 doi = {10.1145/2883851.2883857},
 acmid = {2883857},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {big data, data mining, educational data mining, exploratory data analysis, learning analytics, machine learning, parallel computing, predictive analytics, python, simulation, spark, visualization},
abstract = {Enormous amount of educational data has been accumulated through Massive Open Online Courses (MOOCs), as well as commercial and non-commercial learning platforms. This is in addition to the educational data released by US government since 2012 to facilitate disruption in education by making data freely available. The high volume, variety and velocity of collected data necessitate use of big data tools and storage systems such as distributed databases for storage and Apache Spark for analysis.
This tutorial will introduce researchers and faculty to real-world applications involving data mining and predictive analytics in learning sciences. In addition, the tutorial will introduce statistics required to validate and accurately report results. Topics will cover how big data is being used to transform education. Specifically, we will demonstrate how exploratory data analysis, data mining, predictive analytics, machine learning, and visualization techniques are being applied to educational big data to improve learning and scale insights driven from millions of student's records.
The tutorial will be held over a half day and will be hands on with pre-posted material. Due to the interdisciplinary nature of work, the tutorial appeals to researchers from a wide range of backgrounds including big data, predictive analytics, learning sciences, educational data mining, and in general, those interested in how big data analytics can transform learning. As a prerequisite, attendees are required to have familiarity with at least one programming language.},
}

@inproceedings{Clow:2016:LF:2883851.2883918,
 author = {Clow, Doug and Ferguson, Rebecca and Macfadyen, Leah and Prinsloo, Paul and Slade, Sharon},
 title = {LAK Failathon},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {509--511},
 numpages = {3},
 url = {http://doi.acm.org/10.1145/2883851.2883918},
 doi = {10.1145/2883851.2883918},
 acmid = {2883918},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {failure, negative results, positive results, publication bias},
abstract = {As in many fields, most papers in the learning analytics literature report success or, at least, read as if they are reporting success. This is almost certainly not because learning analytics research and activity are always successful. Generally, we report our successes widely, but keep our failures to ourselves. As Bismarck is alleged to have said: it is wise to learn from the mistakes of others. This workshop offers an opportunity for researchers and practitioners to share their failures in a lower-stakes environment, to help them learn from each other's mistakes.},
}

@inproceedings{Mol:2016:LTG:2883851.2883859,
 author = {Mol, Stefan and Kobayashi, Vladimer and Kismih\'{o}k, G\'{a}bor and Zhao, Catherine},
 title = {Learning Through Goal Setting},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {512--513},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883859},
 doi = {10.1145/2883851.2883859},
 acmid = {2883859},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {goal setting, learning analytics, learning record store},
abstract = {Despite the mounting evidence supporting the role that goal setting has on the learning process, there seems to be only a handful of studies that directly investigate goal setting in the context of Learning Analytics (LA). Although investigations have incorporated elements of goal setting, the attention afforded to theory and operationalization have been modest. In this workshop we plan to position goal setting at the forefront of LA research. The workshop will serve as a venue to bring together researchers interested in advancing Goal Setting (GS) research in the LA field. Topics include: (1) GS theory and measurement; (2) analysis and visualization of GS data; (3) strategies for integrating GS in the learning experience; and (4) implementation of GS technologies. Participants who need tools to execute their GS ideas and those who already have tools and are exploring better ways to integrate a goal setting feature can gain a lot from this workshop. Moreover, participants will have the opportunity to contribute to the conceptualization and staging of GS ideas in LA research.},
}

@inproceedings{vanLeeuwen:2016:LAF:2883851.2883874,
 author = {van Leeuwen, Anouschka},
 title = {Learning Analytics in a Flipped University Course},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {514--515},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883874},
 doi = {10.1145/2883851.2883874},
 acmid = {2883874},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {blended learning, formative assessment, higher education, learning analytics, web lectures},
abstract = {In this poster, we describe the design of a university course with a blended learning character. Learning analytics were used both within the course to facilitate effective teacher-student interaction, as well as after the course to examine patterns between students' activities during the course and their performance on the test and the group assignment at the end of the course.},
} 

@inproceedings{Grover:2016:MAS:2883851.2883877,
 author = {Grover, Shuchi and Bienkowski, Marie and Tamrakar, Amir and Siddiquie, Behjat and Salter, David and Divakaran, Ajay},
 title = {Multimodal Analytics to Study Collaborative Problem Solving in Pair Programming},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {516--517},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883877},
 doi = {10.1145/2883851.2883877},
 acmid = {2883877},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaboration, collaborative problem solving, k-12 computer science education, kinect, multimodal analytics, pair programming},
abstract = {Collaborative problem solving (CPS) is seen as a key skill in K-12 education---in computer science as well as other subjects. Efforts to introduce children to computing rely on pair programming as a way of having young learners engage in CPS. Characteristics of quality collaboration are joint exploring or understanding, joint representation, and joint execution. We present a data driven approach to assessing and elucidating collaboration through modeling of multimodal student behavior and performance data.},
}

@inproceedings{Hu:2016:AAC:2883851.2883963,
 author = {Hu, Xiao and Ng, Tzi-Dong Jeremy and Tian, Lu and Lei, Chi-Un},
 title = {Automating Assessment of Collaborative Writing Quality in Multiple Stages: The Case of Wiki},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {518--519},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883963},
 doi = {10.1145/2883851.2883963},
 acmid = {2883963},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automated assessment, metadiscourse, wiki},
abstract = {This study attempts to investigate to what extent indicators of academic writing and cognitive thinking can help measure the writing quality of group collaborative writings on Wikis. Particularly, comparisons were made on Wiki content in different stages of the projects. Preliminary results from a multiple linear regression analysis reveal that linguistic indicators such as engagement markers and self-mention were significant predictors in earlier stages to the projects, whereas verbs indicating cognitive thinking in the evaluation level were significant in later project stages.},
}

@inproceedings{Ferguson:2016:LAC:2883851.2883878,
 author = {Ferguson, Rebecca and Clow, Doug},
 title = {Learning Analytics Community Exchange: Evidence Hub},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {520--521},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883878},
 doi = {10.1145/2883851.2883878},
 acmid = {2883878},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ethics, evidence, learning, learning analytics, take-up, teaching},
abstract = {This poster sets out the background and development of the LACE Evidence Hub, a site that gathers evidence about learning analytics in an accessible form. The poster also describes the functionality of the site, summarises its quantitative and thematic content to date, and assesses the state of evidence. In addition, it encourages people to add to and make use of the Hub.},
}

@inproceedings{Spikol:2016:EIH:2883851.2883920,
 author = {Spikol, Daniel and Avramides, Katerina and Cukurova, Mutlu and Vogel, Bahtijar and Luckin, Rose and Ruffaldi, Emanuele and Mavrikis, Manolis},
 title = {Exploring the Interplay Between Human and Machine Annotated Multimodal Learning Analytics in Hands-on STEM Activities},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {522--523},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883920},
 doi = {10.1145/2883851.2883920},
 acmid = {2883920},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CSCL, learning analytics, mobile},
abstract = {This poster explores how to develop a working framework for STEM education that uses both human annotated and machine data across a purpose-built learning environment. Our dual approach is to develop a robust framework for analysis and investigate how to design a learning analytics system to support hands-on engineering design tasks. Data from the first user tests are presented along with the framework for discussion.},
}

@inproceedings{Koile:2016:UMA:2883851.2883922,
 author = {Koile, Kimberle and Rubin, Andee and Chapman, Steve and Kliman, Marlene and Ko, Lily},
 title = {Using Machine Analysis to Make Elementary Students' Mathematical Thinking Visible},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {524--525},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883922},
 doi = {10.1145/2883851.2883922},
 acmid = {2883922},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {elementary education, formative assessment, learning analytics, mathematics, pen-based computing, visual representations},
abstract = {The INK-12: Teaching and Learning Using Interactive Ink Inscriptions in K-12 project has been developing and investigating the use of pen-based technology in elementary math classes. This paper reports on progress made on machine analysis of students' visual representations created using digital tools developed to support learning multiplication and division. The goal of the analysis is to make student thinking visible in order to (a) better understand how students learn multiplication and division, and (b) provide feedback to teachers, e.g., about strategies students use to solve problems. Student work from a five-week trial in a third grade class provides a corpus for development and evaluation of the machine analysis routines. Preliminary findings indicate that the routines can reproduce human analyses.},
}
@inproceedings{Jayaprakash:2016:BSP:2883851.2883940,
 author = {Jayaprakash, Sandeep M. and Laur\'{\i}a, Eitel J. M. and Gandhi, Pritesh and Mendhe, Dinesh},
 title = {Benchmarking Student Performance and Engagement in an Early Alert Predictive System Using Interactive Radar Charts},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {526--527},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883940},
 doi = {10.1145/2883851.2883940},
 acmid = {2883940},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {benchmarking, data mining, information visualizations, instructional assessment, intervention, interventions, learning analytics, open source, predictive analytics, visualization},
abstract = {This poster synthesizes the design features of a visualization layer applied on the Open Academic Analytics Initiative (OAAI), an open source academic early alert system based on predictive analytics. The poster explores ways to convey the predictive model outputs and benchmark student performances using visually intuitive radar plots.},
}

@inproceedings{Dillon:2016:SAD:2883851.2883960,
 author = {Dillon, John and Ambrose, G. Alex and Wanigasekara, Nirandika and Chetlur, Malolan and Dey, Prasenjit and Sengupta, Bikram and D'Mello, Sidney K.},
 title = {Student Affect During Learning with a MOOC},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {528--529},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883960},
 doi = {10.1145/2883851.2883960},
 acmid = {2883960},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {affect, data collection, technology and learning},
abstract = {This paper presents affect data collected from periodic emotion detection surveys throughout an introductory Statistics MOOC called "I Heart Stats." This is the first MOOC, to our knowledge, to capture valuable student affect data through self-reported surveys. To collect student affect, we used two self-reporting methods: (1) The Self-Assessment Manikin and (2) A discrete emotion list. We found that the most common reported MOOC emotion was Hope followed by Enjoyment and Contentment. There were substantial shifts in affective states over the course, notably with Anxiety and Pride. The most valuable result of our study is a preliminary description of the methods for collecting self-reported student affect at scale in a MOOC setting.},
}

@inproceedings{Hagood:2016:IPA:2883851.2883958,
 author = {Hagood, Danielle and Ching, Cynthia Carter and Schaefer, Sara},
 title = {Integrating Physical Activity Data in Videogames with User-centered Dashboards},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {530--531},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883958},
 doi = {10.1145/2883851.2883958},
 acmid = {2883958},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {activity monitors (Fitbit), dashboards, health, quantified self, sociocultural theory},
abstract = {To promote healthy awareness and activity learning, we gave 12-to 14-year-old youth activity monitors (Fitbits) to track their physical activity, which was then integrated into a videogame we created. The players' real-world steps transform into in-game resources needed for gameplay. In addition to requiring real-world steps for various in-game activities, a dashboard in this game presents visual representations of activity patterns, ostensibly informing students about patterns of their own activity. In this paper and poster, we discuss challenges in initial designs of our dashboard. We present findings and challenges in the process of creating a user-centered dashboard and conclude with our future design goals.},
}

@inproceedings{Schwendimann:2016:ULG:2883851.2883930,
 author = {Schwendimann, Beat A. and Rodr\'{\i}guez-Triana, Mar\'{\i}a Jes\'{u}s and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
 title = {Understanding Learning at a Glance: An Overview of Learning Dashboard Studies},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {532--533},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883930},
 doi = {10.1145/2883851.2883930},
 acmid = {2883930},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {dashboards, educational data mining, information visualization, learning analytics, systematic review},
abstract = {Research on learning dashboards aims to identify what data is meaningful to different stakeholders in education, and how data can be presented to support sense-making processes. This paper summarizes the main outcomes of a systematic literature review on learning dashboards, in the fields of Learning Analytics and Educational Data Mining. The query was run in five main academic databases and enriched with papers coming from GScholar, resulting in 346 papers out of which 55 were included in the final analysis. Our review distinguishes different kinds of research studies as well as different aspects of learning dashboards and their maturity in terms of evaluation. As the research field is still relatively young, many of the studies are exploratory and proof-of-concept. Among the main open issues and future lines of work in the area of learning dashboards, we identify the need for longitudinal research in authentic settings, as well as studies that systematically compare different dashboard design options.},
} 

@inproceedings{Rienties:2016:RTC:2883851.2883886,
 author = {Rienties, Bart and Boroowa, Avinash and Cross, Simon and Farrington-Flint, Lee and Herodotou, Christothea and Prescott, Lynda and Mayles, Kevin and Olney, Tom and Toetenel, Lisette and Woodthorpe, John},
 title = {Reviewing Three Case-studies of Learning Analytics Interventions at the Open University UK},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {534--535},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883886},
 doi = {10.1145/2883851.2883886},
 acmid = {2883886},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative learning, distance learning, online learning settings},
abstract = {This study provides a conceptual framework how organizations may adopt evidence-based interventions at scale, and how institutions may evaluate the costs and benefits of such interventions. Building on a new conceptual model developed by the Open University UK (OU), we will analyse three case-studies of evidence-based interventions. By working with 90+ large-scale modules for a period of two years across the five faculties and disciplines within the OU, Analytics4Action provides a bottom-up-approach for working together with key stakeholders within their respective contexts. Using principles of embedded case-study approaches by Yin [1], by comparing the learning behavior, satisfaction and performance of 11079 learners the findings indicated that each of the three learning designs led to satisfied students and average to good student retention. In the second part we highlighted that the three module teams made in-presentation interventions based upon real-time analytics, whereby initial user data indicated VLE behaviour in line with expectations. In 2-5 years, we hope that a rich, robust evidence-base will be presented to show how learning analytics can help teachers to make informed, timely and successful interventions that will help learners to achieve their learning outcomes.},
}

@inproceedings{Ruiperez-Valiente:2016:ASI:2883851.2883947,
 author = {Ruip{\'e}rez-Valiente, Jos{\'e} A. and Mu\~{n}oz-Merino, Pedro J. and Kloos, Carlos Delgado},
 title = {Analyzing Students' Intentionality Towards Badges Within a Case Study Using Khan Academy},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {536--537},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883947},
 doi = {10.1145/2883851.2883947},
 acmid = {2883947},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Khan academy, badges, learning analytics, modelling behavior},
abstract = {One of the most common gamification techniques in education is the use of badges as a reward for making specific student actions. We propose two indicators to gain insight about students' intentionality towards earning badges and use them with data from 291 students interacting with Khan Academy courses. The intentionality to earn badges was greater for repetitive badges, and this can be related to the fact that these are easier to achieve. We provide the general distribution of students depending on these badge indicators, obtaining different profiles of students which can be used for adaptation purposes.},
}

@inproceedings{Molenaar:2016:LAP:2883851.2883892,
 author = {Molenaar, Inge and van Campen, Carolien Knoop},
 title = {Learning Analytics in Practice: The Effects of Adaptive Educational Technology Snappet on Students' Arithmetic Skills},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {538--539},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883892},
 doi = {10.1145/2883851.2883892},
 acmid = {2883892},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ability levels, arithmetic's, educational technologies, primary education},
abstract = {Even though the recent influx of tablets in primary education goes together with the vision that educational technology empowered with learning analytics will revolutionize education, empirical results supporting this claim are scares. Adaptive educational technology Snappet combines extracted and embedded learning analytics daily in classrooms. While students make exercises on the tablet this technology displays real-time data of learner performance in a teacher dashboard (extracted analytics). At the same time, learner performance is used to adaptively adjust exercises to students' progress (embedded analytics). This quasiexperimental study compares the development of students' arithmetic skills over one schoolyear (grade 2 and 4) in a traditional paper based setting to learning with the adaptive educational technology Snappet. The results indicate that students in the Snappet condition make significantly more progress on arithmetic skills in grade 4. Moreover, in this grade students with a high ability level, benefit the most from working with this adaptive educational technology. Overall the development pattern of students with different abilities was more divergent in the AET condition compared to the control condition. These results indicate that adaptive educational technologies combining extracted and embedded learning analytics are indeed creating new education scenarios that contribute to personalized learning in primary education.},
}

@inproceedings{Feng:2016:EDI:2883851.2883908,
 author = {Feng, Mingyu and Krumm, Andrew E. and Bowers, Alex J. and Podkul, Timothy},
 title = {Elaborating Data Intensive Research Methods Through Researcher-practitioner Partnerships},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {540--541},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883908},
 doi = {10.1145/2883851.2883908},
 acmid = {2883908},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data intensive research, learning analytics, researcher-practitioner partnership},
abstract = {Technologies used by teachers and students generate vast amounts of data that can be analyzed to provide insights into improving teaching and learning. However, practitioners are left out of the process. We describe the development of an approach by which researchers and practitioners can work together to use data intensive research methods to launch improvement efforts within schools. This paper describes elements of the first year of a researcher-practitioner partnership, highlighting initial findings, challenges, and strategies for overcoming these challenges.},
} 

@inproceedings{Jo:2016:PEL:2883851.2883912,
 author = {Jo, Yohan and Tomar, Gaurav and Ferschke, Oliver and Ros{\'e}, Carolyn Penstein and Ga\v{s}evi\'{c}, Dragan},
 title = {Pipeline for Expediting Learning Analytics and Student Support from Data in Social Learning},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {542--543},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883912},
 doi = {10.1145/2883851.2883912},
 acmid = {2883912},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {learning analytics, social learning},
abstract = {An important research problem in learning analytics is to expedite the cycle of data leading to the analysis of student progress and the improvement of student support. For this goal in the context of social learning, we propose a pipeline that includes data infrastructure, learning analytics, and intervention, along with computational models for individual components. Next, we describe an example of applying this pipeline to real data in a case study, whose goal is to investigate the positive effects that goal-setting students have on their peers, which suggests ways in which we might foster these social benefits through intervention.},
}

@inproceedings{Berg:2016:DXE:2883851.2883968,
 author = {Berg, Alan and Scheffel, Maren and Drachsler, Hendrik and Ternier, Stefaan and Specht, Marcus},
 title = {The Dutch xAPI Experience},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {544--545},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883968},
 doi = {10.1145/2883851.2883968},
 acmid = {2883968},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data silos, data standardization, learning analytics, learning record store, xAPI},
abstract = {We present the collected experiences since 2012 of the Dutch Special Interest Group (SIG) for Learning Analytics in the application of the xAPI standard. We have been experimenting and exchanging best practices around the application of xAPI in various contexts. The practices include different design patterns centered around Learning Record Stores. We present three projects that apply xAPI in very different ways and publish a consistent set of xAPI recipes.},
}

@inproceedings{Milligan:2016:VFC:2883851.2883956,
 author = {Milligan, Sandra and He, Jiazhen and Bailey, James and Zhang, Rui and Rubinstein, Benjamin I. P},
 title = {Validity: A Framework for Cross-disciplinary Collaboration in Mining Indicators of Learning from MOOC Forums},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {546--547},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883956},
 doi = {10.1145/2883851.2883956},
 acmid = {2883956},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {MOOC, collaborative learning, crowd-sourced learning, learner performance, learning analytics, learning progression, measurement theory, non-negative matrix factorisation, rasch analysis, topic modelling, validity},
abstract = {Two research teams from the University of Melbourne's Learning Analytics Research Group used validation as applied in educational measurement to provide a framework for collaboration. One team was focussed on defining and building measures of learning capability of MOOCs participants, and the other on using topic modelling to discover topics in MOOC forums. The collaboration explored the suitability of items discovered from MOOC forums using topic modelling as measures of learning capability of participants in MOOCs.},
}

@inproceedings{Kitto:2016:CLA:2883851.2883881,
 author = {Kitto, Kirsty and Bakharia, Aneesha and Lupton, Mandy and Mallet, Dann and Banks, John and Bruza, Peter and Pardo, Abelardo and Shum, Simon Buckingham and Dawson, Shane and Ga\v{s}evi\'{c}, Dragan and Siemens, George and Lynch, Grace},
 title = {The Connected Learning Analytics Toolkit},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {548--549},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883881},
 doi = {10.1145/2883851.2883881},
 acmid = {2883881},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {dashboards, sensemaking, social learning analytics},
abstract = {This demonstration introduces the Connected Learning Analytics (CLA) Toolkit. The CLA toolkit harvests data about student participation in specified learning activities across standard social media environments, and presents information about the nature and quality of the learning interactions.},
}

@inproceedings{Hu:2016:WLA:2883851.2883966,
 author = {Hu, Xiao and Ip, Jason and Sadaful, Koossulraj and Lui, George and Chu, Sam},
 title = {Wikiglass: A Learning Analytic Tool for Visualizing Collaborative Wikis of Secondary School Students},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {550--551},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883966},
 doi = {10.1145/2883851.2883966},
 acmid = {2883966},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative writing, statistics, timeline, visualization, wiki},
abstract = {This demo presents Wikiglass, a learning analytic tool for visualizing the statistics and timelines of collaborative Wikis built by secondary school students during their group project in inquiry-based learning. The tool adopts a modular structure for the flexibility of reuse with different data sources. The client side is built with the Model-View-Controller framework and the AngularJS library whereas the server side manages the database and data sources. The tool is currently used by secondary teachers in Hong Kong and is undergoing evaluation and improvement.},
}

@inproceedings{Freeman:2016:DUS:2883851.2883903,
 author = {Freeman, J. D.},
 title = {Demonstration of the Unizin Sentiment Visualizer},
 booktitle = {Proceedings of the Sixth International Conference on Learning Analytics \& Knowledge},
 series = {LAK '16},
 year = {2016},
 isbn = {978-1-4503-4190-5},
 location = {Edinburgh, United Kingdom},
 pages = {552--553},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2883851.2883903},
 doi = {10.1145/2883851.2883903},
 acmid = {2883903},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Unizin, discussion, intervention, learning analytics, natural language processing, real time, real-time, sentiment analysis, student, text mining},
abstract = {While much promise has been demonstrated in the learning analytics field with sentiment analysis, the analyses are typically post hoc. The Unizin Sentiment Visualizer demonstrates that the application of sentiment analysis in real-time provides a powerful new tool to support students in complex learning environments.},
}