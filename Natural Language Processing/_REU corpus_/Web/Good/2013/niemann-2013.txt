
Aggregating Social and Usage Datasets for Learning
Analytics: Data-oriented Challenges

Katja Niemann, Martin Wolpers
Fraunhofer Institute for Applied Information

Technology
Schloss Birlinghoven, Sankt Augustin, Germany

{katja.niemann,
martin.wolpers}@fit.fraunhofer.de

Giannis Stoitsis, Georgios Chinis, Nikos
Manouselis

Agro-Know Technologies
17 Grammou str., Vrilissia

15235, Athens, Greece
{stoitsis, gchinis, nikosm}@agroknow.gr

ABSTRACT
Recent work has studied real-life social and usage datasets
from educational applications, highlighting the opportunity
to combine or merge them. It is expected that being able
to put together different datasets from various applications
will make it possible to support learning analytics of a much
larger scale and across different contexts. We examine how
this can be achieved from a practical perspective by carrying
out a study that focuses on three real datasets. More specif-
ically, we combine social data that has been collected from
the users of three learning portals and reflect on how they
should be handled. We start by studying the data types
and formats that these portals use to represent and store
social and usage data. Then we develop crosswalks between
the different schemas, so that merged versions of the source
datasets may be created. The results of this bottom-up,
hands-on investigation reveal several interesting issues that
need to be overcome before aggregated sets of social and us-
age data can be actually used to support learning analytics
research or services.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval—information filtering

General Terms
Algorithms, Measurement, Performance, Experimentation.

Keywords
Dataset, data-driven analysis, experimental investigation,
education, usage data formats

1. INTRODUCTION
Social and usage data about learning resources are be-

ing collected within various applications such as educational

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
LAK ’13 April 08 - 12 2013, Leuven, Belgium
Copyright 2013 ACM 978-1-4503-1785-6/13/04 ...$15.00.

web portals and learning management systems. They in-
clude information on the types of activities that users per-
form over the resources (usage data) as well as information
that the users provide as annotations to the resources (social
data). For instance, attention or usage metadata represent
the activities of users and their usage of data objects in the
applications.

In learning analytics, such social or usage data provide
the basis for a number of different learning support systems
[1, 2, 3, 6]. For example, based on an analysis of usage
data, irregularities of learning behaviour of students can be
identified [4] and the results of corrective activities by the
teacher can be monitored. Another example of the success-
ful application of analysing usage data in learning settings
is the reflection and comparison of learning activities among
students of a learning group. A further example of success-
ful use of usage data are personalized recommender systems
that base their learner support on the analysis of social data
[8].

A representation of implicit or explicit information from
the users on how they have used or experienced a particu-
lar resource is valuable for any type of service that would
like to provide advanced services based on user data. This
information can be in several forms. For example, in the
case of collaborative filtering systems it can be explicit (e.g.
how a resource was rated) or implicit (e.g. if a resource
has been accessed, downloaded, or bookmarked). In the
case of content-based recommender systems it can be tex-
tual reviews or simple tags (keywords) that users provide on
resources. Additional information is required if the desired
support is going to be adapted for specific users and specific
items.

A number of widely adopted data representation formats
for social and usage data from educational applications have
already evolved.

In this paper, we examine some of the practical require-
ments on what is achievable by transforming and combining
existing social and usage datasets. We particularly examine
datasets coming from three specific portals: Organic.Edunet1,
MACE2, and Learning Resource Exchange3. Our aim is to
see how data coming from the two latter portals may be
cross walked and transformed into the social data schema
used by Organic.Edunet, and then explore what would be
possible by the combined, aggregated dataset.

1http://www.organic-edunet.eu
2http://portal.mace-project.eu
3http://lreforschools.eun.org

245



2. BACKGROUND
The context in which this study is taking place is the

European initiative titled Open Discovery Space4 (ODS), a
large-scale pilot project that tries to increase the adoption
of digital learning resources by European schools. Part of
its activities includes setting up a back end infrastructure
that will allow existing learning portals and repositories to
be connected, in order to allow the exchange of information
and therefore accelerate the sharing, adoption, usage, and
re-purposing of the already existing educational content.

ODS will not only interconnect different applications to al-
low exchange of metadata about content resources, but also
tries to set up a mechanism for the exchange and re-use of so-
cial and usage information among the different applications.
This mechanism is actually a social and usage data aggrega-
tion layer that will try to collect, store, process and expose
such data across all applications that will join the network.
The aggregation layer is expected to offer to these applica-
tions (such as learning portals that are already running or
will be built on top of the infrastructure) the ability to pro-
vide enhanced visualization and social navigation features
based on the social and usage data. Additionally, parts of
this data can be used to support cross-portal services, such
as federated recommendation of resources, people and learn-
ing paths, based on the social activity around resources and
enabling large-scale learning analytics.

As a first exploratory investigation of how social and us-
age data may be aggregated within Open Discovery Space,
we decided to study a very specific and well-defined sce-
nario: how social data (that is ratings, tags, and comments)
generated in the MACE (Metadata for Architectural Con-
tents in Europe) portal and in the LRE (Learning Resource
Exchange) portal could be used to enhance the recommen-
dation services of the Organic.Edunet portal. We start with
an overview of the use social and usage metadata formats to
then define specific transformations for the CAM instances
collected in MACE and the NSDL instances collected in LRE
into Organic.Edunet format. Thereafter, we visualise the
properties of the new merged dataset and compare them to
the original ones.

3. USAGE DATA FORMATS

3.1 Contextualized Attention Metadata
The CAM schema [5] was defined as an extension of At-

tention.XML5 which is an early approach to capturing and
storing attention metadata for single users. In the current
CAM version6, the focus has moved from the user and the
data object to the event itself. This is due to the insight
that not every event has a fixed set of attributes. Addition-
ally, only the basic information about an event is stored, e.g.
the event type and the time stamp. All other information,
e.g. metadata describing users or documents involved in the
event, are linked. This way, each entity and also each ses-
sion can be described in a different and suitable way and no
information is duplicated.

Fig. 1 shows the complete CAM schema. The main ele-
ment of a CAM instance is the event entry which comprises

4http://www.opendiscoveryspace.eu/
5http://tantek.com/presentations/2005/01/-
attentionxml.html
6https://sites.google.com/site/camschema/

Figure 1: CAM Schema

its id, the event type, the timestamp, and a sharing level ref-
erence. The sharing level reference points to a description of
the specific sharing level which describes the privacy related
issues of the event. Depending on the event, various entities
with different roles can be involved, e.g. when sending an
e-mail, there is a person with the role ”sender”, at least one
person with the role ”receiver” and a document with the role
”e-mail”. Each event can be conducted in a session.

The current CAM schema does not have fixed bindings so
far. The information can be stored in XML, RDF, JSON
or in a relational database, depending on the purpose of
capturing the data. See Fig. 4 in section 4 for an exemplary
CAM instance in XML format.

3.2 NSDL Paradata
The NSDL Paradata format was defined to capture aggre-

gated usage data about a resource (e.g. downloaded, favour-
ited, rated) which is designated by audience, subject or edu-
cation level7. In contrast to the CAM schema, this format is
not event, but object-centric. Each data object has exactly
one NSDL Paradata record, which is identified by a recor-
dId and must contain the URL of the resource to which the
paradata record applies (usageDataResourceURL). A record
can also contain the title and a description of the record,
the title of the resource, and any additional XML element.

Figure 2: Simplified excerpt of the NSDL schema

The most important element is the usageDataSummary,
that comprises all available usage statistics/information about

7https://wiki.ucar.edu/display/nsdldocs/comm para

246



a resource using five different types of values. An Inte-
ger/Float value represents the number of times certain ac-
tions have been performed on the resource. A String value
is a textual value that has been associated to the resource.
A RatingType value is the numerical average that represents
the judging of a resource on a numerical scale. A Vote-
Type value represents the number of positive and negative
responses to a resource. A RankType value represents the
standing of a resource in a hierarchy.

Please see Fig. 6 in chapter 4 for an exemplary NSDL
instance. For an example using all types, please see the
exemplary NSDL Paradata instance for the learning object
”The Capacity of the Planets”8.

3.3 Organic.Edunet Format
The Organic.Edunet format was defined in the Organic.Edu-

net project to store social data provision activities, e.g. tag-
ging, rating, and commenting. It is designed in an extend-
able way, so other user activities, e.g. downloading could be
easily stored as well.

Figure 3: Organic.Edunet schema

Similarly to the NSDL format, it is not event, but object-
centric (see. Fig. 3). This means all social data provision
activities for one object are stored in a single commSocial-
Data instance which is identified by its recordId, linked to
the respective object by the socialDateResourceUrl and con-
tains the name of the socialDataProvider. For each user
that added social data to the object the commSocialData
instance holds one socialDataSummary instance that com-
prises all activities of the respective user which is identi-
fied by the userId. The activities are represented by string
and rating instances, each of these instances holds the date-
Time of the event and its type, e.g. ”tag” or ”comment” for
string and ”star” for rating instances. Additionally, string
instances hold a language attribute and rating instances hold
attributes to store the minumin (min) and maximum (max)
possible rating values, a dim attribute to store the dimen-
sion of the rating to enable multi-dimensional ratings, e.g.
relevance to a topic, quality of metadata and usefulness and
a total attribute that is used if the user’s average rating of
several dimensions is stored.

8http://ns.nsdl.org/ncs/comm para/1.00/-
records/planets.xml

Please see Fig. 5 and Fig. 7 in chapter 4 for exemplary
Organic.Edunet instances. Similarly to the CAM schema,
the Organic.Edunet format doesn’t contain any detailed in-
formation about the user or the object but links and ids to
not duplicate any information. However, it contains all in-
formation about the social data activity that is represented.

4. APPLICATION SPECIFIC MAPPINGS
As each format has been created with a specific purpose in

mind, no one-size-fits-all mapping among all three formats
is possible. In contrast, mapping can only be defined for
specific application scenarios.

4.1 Transforming CAM to Organic.Edunet
The MACE CAM instances reference the user and the

object by an id, however, the event values, i.e. rating, tag,
comment and competence, can be directly put into the CAM
instances when they don’t contain any further information
and, thus, don’t hold an own metadata instance that can be
referenced.

Figure 4: MACE CAM instance for a tag

See Fig. 4 for a MACE CAM instance representing a tag-
ging activity. The transformation of MACE CAM instances
to Organic.Edunet takes place for the three event types ”ad-
dRating”, ”addTag”, and ”addComment”. Fig. 5 shows the
same tagging event in Organic.Edunet format.

Figure 5: Organic.Edunet instance for MACE data

When transforming the instances from CAM to Orga-
nic.Edunet, for each learning object contained in the CAM
instances one commSocialData element is created with the
value of the CAM entity with the role ”item” as Social-
DataResourceURL. Additionally, an automatically generated
recordId is added, while the value of the DataProvider can
be set manually. For each user that rated, tagged or com-
mented this object, a SocialDataSummary is added to the

247



commSocialData instance containing the value of the CAM
entity with the role ”user” as userId.

Then, each CAM event is added as string or rating in-
stance to the respective Organic.Edunet commSocialData
instance. For the CAM event types ”addTag” and ”addCom-
ment” a string instance is added with the type ”tagged” or
”commented”. For the CAM event type ”addRating”a rating
instance with type ”star” is added, the min and max values
can be set automatically as they are similar for all MACE
CAM instances. Both, the string and rating instances hold
the CAMtimestamp as dateTime attribute, it’s important to
mention that a transformation of the date format is needed
here as well.

4.2 Transforming NSDL to Organic.Edunet
Fig. 6 shows a LRE instance in NSDL format. Similar

to the Organic.Edunet format, each object is represented by
one XML instance that comprises all events the object was
involved in. However, the Organic.Edunet format was de-
signed to store single events while NSDL stores aggregated
events without a link to the user. The NSDL instance in Fig.
6 represents 153 rating events conducted by (anonymous)
educators. Fig. 7 shows these events as Organic.Edunet
instance, please note that the rating events that were ag-
gregated in NSDL are represented as one single event in
Organic.Edunet. In other settings, it might be useful to add
an event as often as it occurred (total attribute), e.g. when
tags are weighted in a tag cloud.

Figure 6: LRE NSDL instance

5. DATASET ANALYSIS
Developing the mappings between the schemas used in

the three studied portals allows us to develop a set of data
transformation components that could ingest data coming
from MACE and LRE and crosswalk them into a database
storing data using the Organic.Edunet schema. To better
understand how the transformed datasets may be used to
facilitate research and development of new algorithms and
services for the Organic.Edunet portal, we carry out an anal-
ysis that engages different techniques to examine and visu-
alise the dataset properties in order to understand how easily
they can be used for experimentation.

Figure 7: Organic.Edunet instance for LRE data

5.1 Method, Materials and Tools
In the following, we only focus on the aggregating of the

numerical data (the ratings) and create two aggregated data-
sets: Aggregate A comprises the datasets that include unique
user identification information (i.e. Organic.Edunet and
MACE) and Aggregate B comprises all three datasets but
without storing any user information. Table 1 provides an
overview of the datasets.

Table 1: Overview of the MACE, LRE, Or-
ganic.Edunet (OE), Aggregate A and B datasets

MACE LRE OE A B
# users 76 n/a 162 238 238
# items 429 1007 569 998 2005

# ratings 532 989 978 1510 2499
rating

dimensions 1 1 3 1 1

The properties of the examined datasets include: 1) The
Skewness which measures the asymmetry of an item (item
skewness) or user (user skewness) rating frequency (popular-
ity) distribution. This metric determines whether the mass
of the distribution is concentrated on the right side of the
mean or the left side of the mean, i.e., representing nega-
tive or positive skewness. 2) The Gini which measures the
concentration (or inequality) of an item (item Gini) or user
(user Gini) rating frequency distribution. A value of 0 rep-
resents total equality (all items are equally popular), and
a value of 1 represents maximal inequality (a few popular
items have all the ratings).

5.2 Results
We calculate all mentioned data properties for each one

of the five studied datasets, namely the Organic.Edunet,
MACE, LRE, Aggregate A and Aggregate B. For Orga-
nic.Edunet, we observe that 67% of the total rated items
have received only one rating and only 4% of the items have
received more than 6 ratings. Similarly, only two items in
the MACE dataset received more than five ratings and 95%
of the items have received less than 3 ratings. The distri-
bution of ratings per items for LRE shows that almost 99%
of the items have received less than two ratings. Although
there are differences between the datasets, they generally

248



seem to be rather sparse ones.
Comparing the distributions of the Organic.Edunet and

MACE ratings, we note that in Organic.Edunet the distri-
bution is more concentrated around few ratings. To further
investigate this, we also calculate the user-related statistics
for these two datasets.

Table 2 illustrates the values of User Skewness and User
Gini for all datasets, for Organic.Edunet, it includes the val-
ues for the average rating (Organic.Edunet offers a multi-
criteria rating). The high value of Item Skewness in the
Organic.Edunet data confirms the observation that the dis-
tribution of ratings per item is concentrated around a few
ratings. Table 2 also indicates that the MACE distribution
is characterized by a larger equality compared to the Orga-
nic.Edunet case and this is evident from the rating distribu-
tion. For the LRE dataset it can be observed that there is
a high value of item skewness. This is also evident from the
distribution of ratings per item where we can observe that
the vast majority of items have received only one rating. The
Aggregate A dataset follows the distribution pattern of the
Organic.Edunet dataset. This may be due to the fact that
the number of ratings provided in Organic.Edunet is almost
double in size of that from MACE and thus the aggregated
dataset tends to adopt the properties of this dataset. The
dataset Aggregate B shows a higher item skewness than the
OE and MACE datasets which is still lower than the item
skewness of the LRE dataset.

Table 2: Data characteristics of the MACE, LRE,
Organic.Edunet (OE), Aggregate A and B datasets

MACE LRE OE A B
User Skewness 61.08 - 54.80 57.57 n/a

User Gini 0.65 - 0.63 0.63 n/a
Item Skewness 2.58 9.40 3.85 3.88 5.47

Item Gini 0.17 0.13 0.33 0.28 0.24

According to the results of this analysis we can conclude
that the aggregation of different datasets had no significant
effect on the data properties. Aggregating social data from
different learning portals can provide useful insights about
the popularity of the items but should be supported by the
adoption of unified resources identifiers. It is critical to sup-
port aggregation by an identification service that will anal-
yse the items’ URLs, compare the different items and will
create a unique identifier for each item in the aggregation.

6. CONCLUSION
Recent studies around dataset-driven research on learning

analytics [3, 7] have identified the potential of using real-life
social and usage datasets to support research and develop-
ment. They have also outlined the potential of aggregating
and combining datasets from different sources, in order to
facilitate large-scale and cross-context tasks.

In this paper we investigated on a particular case study
that we worked on in the context of the networked infrastruc-
ture of ODS. It is expected that being able to put together
different datasets from various applications will make it pos-
sible to support learning analytics of a much larger scale and
across different contexts. We tried to understand how easy
it is to aggregate social data from different learning portals
and what are the practical challenges that emerge.

The overview of the used social and usage data formats
showed that there’s no one-size-fits-all application, however,
the adopted approach to defining the mappings between dif-
ferent data formats is not efficient and scalable. A more
suitable solution would be to have a common data model
for ODS and map the existing formats into it; the number
of required mappings in that case would be far less. In this
way, the data from the different portals could be combined
and analysed.

In our next steps, we will take the semantic differences
and mappings between domains into account and deal with
resource/user disambiguation. Furthermore, we will carry
out experiments with more datasets to examine how ser-
vices such as recommender systems can benefit from such
aggregations.

7. ACKNOWLEDGMENTS
The work presented in this paper has been funded with

support by the European Commission and more specifically
the grant agreement no 297229 (Open Discovery Space) of
the Information and Communication Technologies Policy
Support Programme (CIP PSP). The authors would like to
thank David Massart and the European Schoolnet for shar-
ing an instance of the LRE dataset with them.

8. REFERENCES
[1] Elias, T. Learning analytics - definitions, processes

and potential, http://learninganalytics.net/learning-
analyticsdefinitionsprocessespotential.pdf,
2012.

[2] Ferguson, R. The state of learning analytics in 2012:
A review and future challenges. Tech. Rep. Technical
Report KMI-12-01, Knowledge Media Institute, The
Open University, UK, 2011.

[3] Massart, D., and Shulman, E. Interaction data
exchange. D-Lib Magazine 21, 5/6 (2013).

[4] Scheffel, M., Niemann, K., Leony, D., Pardo, A.,
Schmitz, H.-C., Wolpers, M., and
Delgado Kloos, C. Key action extraction for
learning analytics. In EC-TEL (2012), A. Ravenscroft,
S. N. Lindstaedt, C. Delgado Kloos, and
D. Herna?ndez Leo, Eds., vol. 7563 of Lecture Notes in
Computer Science, Springer, pp. 320–333.

[5] Schmitz, H.-C., Wolpers, M., Kirschenmann, U.,
and Niemann, K. Dynamic ambient paradigms. In
Paradigm Gems 2, A. Doe, Ed. Addison Wesley, 2005,
pp. 223–233.

[6] Shane, D. Analytics to literacies: Emergent learning
analytics to evaluate new literacies. Workshop on New
Media, New Literacies, and New Forms of Learning,
2011.

[7] Verbert, K., Manouselis, N., Drachsler, H., and
Duval, E. Dataset-driven research to support learning
and knowledge analytics. Educational Technology &
Society 15, 3 (2012), 133–148.

[8] Verbert, K., Manouselis, N., Ochoa, X.,
Wolpers, M., Drachsler, H., Bosnic, I., and
Duval, E. Context-aware recommender systems for
learning: A survey and future challenges. IEEE
Transactions on Learning Technologies 99, PrePrints
(2012).

249





