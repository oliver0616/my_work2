
Analytics of collaborative planning in Metafora -
architecture, data, and analytic methods

Andreas Harrer
Department of Computer Science

Catholic University Eichstätt-Ingolstadt
Ostenstr. 14

85072 Eichstätt, Germany
andreas.harrer@ku-eichstaett.de

ABSTRACT
This paper describes our approach for learning analytics
in the Metafora system, a collaborative learning framework
that supports self-regulated and constructionist activities in
groups. Our specific interest in analysis is the nature of
collaborative planning behaviour and aspects of learning to
learn together (L2L2). For that end we will describe the
architecture supporting diverse analytic components across
all the tools used in Metafora, the data formats, storage
and access methods, and the analytic principles we designed
and implemented. We will also describe our first insights
using these methods on real Metafora data collected during
practical experimentation in schools.

Categories and Subject Descriptors
K.3.1 [Computers and Education]: Computer Uses in
Education—Collaborative Learning ; D.2.11 [Software En-
gineering]: Software Architectures—Domain-specific archi-
tectures

General Terms
Human Factors, Measurement, Design

Keywords
Collaborative Learning, Analytics Architecture, Analysis In-
dicators

1. INTRODUCTION
The analysis of learner actions has been a research topic

for approximately 20 years in the field of Computer-Supported
Collaborative Learning (CSCL)1. Collaborative learning sys-
tems are a natural focus for learning analytic methods be-
cause their mostly distributed nature requires the trans-

1URL to the established conference in the field:
http://www.isls.org/cscl.html

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
LAK ’13, April 08 - 12 2013 Leuven, Belgium
Copyright 2013 ACM 978-1-4503-1785-6/13/04 ...$15.00.

mission and logfile collection from the different users’ com-
puters. Thus, a valuable data set of interactional data is
recorded and can be analysed from various perspectives.
Among these perspectives can be the support of students
during their learning process by providing feedback, the sup-
port of teachers by giving awareness of their student groups’
activities, and the support of researchers in answering ques-
tions about how and under which condictions CSCL sys-
tems can benefit learning. In this paper we will present
the Metafora project, a specific pedagogic and technological
CSCL approach, the architecture facilitating analyses, and
our approaches and method for data analysis.

2. PEDAGOGICAL BACKGROUND
Metafora2 is a project that combines pedagogically differ-

ent learning appoaches, namely constructionism with collab-
oration in small groups of 3-6, resulting in an approach we
call learning to learn together (L2L2). Constructionism [4]
entails an active role of the learner who is (re-)constructing
knowledge by herself instead of knowledge being transferred
from the teacher. Usually this is achieved by direct con-
struction of artefacts, models, programs etc. Collaboration
is another facet to engage students to a more active atti-
tude during learning, stimulating argumentation, negotia-
tion, planning and different kinds of strategic skills referring
to management and task solution. Specific L2L2 behaviours
we want to explore in our research and on which the stu-
dents are planned to be supported are mutual engagement
when performing collaborative tasks, distributed leadership,
dialogue in appropriate spaces and formats, and peer as-
sessment [2]. For that end Metafora brings together a set
of different learning tools from science and math within a
framework for collaborative and self-regulated learning and
organization of the learning process. Among these tools are
so called Microworlds for Math and Physics, game-like envi-
ronments for sustainabilty and ballistics, and editors for the
construction of mathematical patterns and algebraic equa-
tions. This is combined with Metafora’s general features for
collaboration via a planning space, a group chat and the
LASAD3 discussion environment [6].

2The Metafora project is co-funded by the European
Union under the Information and Communication Technolo-
gies (ICT) theme of the 7th Framework Programme for
R&D (FP7), Contract No. 257872, http://www.metafora-
project.org/
3ht, p://cscwlab.in.tu-clausthal.de/lasad

255



Figure 1: Screenshot of the Planning Tool with pro-
cess documentation – yellow cards have been started
and are currently used, green cards have been fin-
ished by students’ explicit marking

3. COLLABORATIVE PLANNING TOOL
The Planning Tool is a web-based application that pro-

vides a visual language for planning, enactment, and reflec-
tion of Metafora learning activities. This language consists
of activities, methods to realise activities, roles, attitudes,
and connectors between these graphical components. Even
though it is built as a stand-alone web application it unfolds
its full potential embedded into the Metafora platform and
connected to the other learning tools. It is possible to create
plans for conducting a challenge / inquiry, and to enter di-
rectly tools from this plan seamlessly, using automatic login
to the other tools and providing the work context needed to
tackle specific tasks within the challenge. The plan can also
be used as a documentation tool, by checking / unchecking
activities as ”started”and ”finished”, so that the students can
use the plan as a graphical organizer of their achievements
(an example for this will be described in the next section
and can be seen in figure 1).

Finally, the plan can be considered a living document that
is constantly being revised, checked and taken as an artefact
for reflection about students’ own work and organization.
The functionality of the planning tool with its scaffolds for
the learners to structure the learning process, allow naviga-
tion, and promote reflection can be related to the guidelines
given in the scaffolding design framework [10] for educational
software.

The planning tool also interacts with other components of
the Metafora system, especially with the platform but also
with other tools, to allow seamless transition and semantic
references from and into learning tools.

4. THE FRAMEWORK FOR ANALYTICS
IN METAFORA

Computer-based learning tools allow the provision of feed-
back to the students through the system directly relieving
a teacher of answering each and every question a class of
students might have. Intelligent feedback also allows tem-
poral and spatial distribution of learning, because the sys-
tem is not constrained by availability limits like a teacher is.
Surely, even in the most sophisticated systems, it is not the

purpose to replace a teacher, but rather relieving the teacher
so that she/he can concentrate on the most relevant support
tasks for the students. This is especially valuable directly in
class, where the load of supporting several student teams at
the same time cannot be handled by just one person.

Analytic systems have a relatively long history in the
strand of Intelligent Tutoring Systems (ITS) and have been
a research topic since approx. the 1970s [7]. They have also
been moving into the field of Computer Supported Collab-
orative Learning (CSCL) in the last decade. Examples for
analytic systems that create so called indicators for specific
learning aspects are usually built into the system such as
in the feedback system provided by the MiGen project [11].
Other rather loosely coupled analysis systems have been de-
veloped e.g. for the collaborative discussion and modera-
tion framework Argunaut [8] with the potential to transfer
analysis methods and indictors to follow-up projects, such
as LASAD. Providing feedback in a system as complex as
Metafora is especially challenging, since there is neither a
closed learning domain nor a constrained set of tools for
which feedback should be given. Thus, we need on the one
hand a flexible architecture allowing multiple types of ana-
lytic components and on the other hand to provide a mech-
anism to allow the combination, aggregation and joint inter-
pretation of partial feedbacks into integrated and cross-tool
feedback created by domain-independent analytic compo-
nents.

4.1 Architecture and Interplay of Analysis -
Components in Metafora

Our proposal for Metafora’s analytic system can be seen
as a modified blackboard architecture [1]: several analytic
components can be used at the same time and do not in-
teract directly with each other (loose coupling). Yet, all
analytic components will be able to read and take up results
from other analytic components, because a unified language
is used between all these components. This allows a flexi-
ble combination of domain-specific and tool-specific analytic
components with cross-tool or domain-independent compo-
nents and can also be used with already existing indicator-
based analyses as e.g. from MiGen’s eXpresser. Our techni-
cal decision to achieve this is to use the well-known and sta-
ble communication eXtensible Messaging and Presence Pro-
tocol (XMPP) infrastructure, where we use a multi-user-chat
(MUC) channel instead of a blackboard. Each analytic com-
ponent is able to subscribe and publish the chat. To create
more structure in our communication approach, we defined
a log-channel where learning tools post user actions and
an analysis-channel where analytic components post their
analysis results. Tool-specific analysis components will only
subscribe to the log-channel and post their results to the
analysis-channel, while cross-tool analysis components can
subscribe to both log-channel and analysis-channel and will
post their results to the analysis-channel (potentially taken
up there by even more general cross-tool components). Fig-
ure 2 shows the overview of the Metafora architecture includ-
ing the blackboard-like approach for the analytic subsystem.
The messages sent via XMPP are represented in the unified
CoLoForm [5] format described in the next subsection, to
allow a uniform interpretation across the different analytic
components, regardless of where the feeback / analysis was
produced.

The architectural backbone of the Metafora analysis sys-

256



Figure 2: Architecture overview of the Metafora
System

tem is fully implemented, while several analysis components
are currently under development both for tool-specific and
cross-tool analyses. In this paper we will focus on the Plan-
ning Tool Observer (PlaTO), a rule-based intelligent agent
implemented mainly for analyzing user actions within the
Planning Tool of Metafora.

4.2 Databases, data formats, and access
Besides the communication architecture described in the

previous subsection Metafora also provides persistent stor-
age of user actions and produced artifacts for data analyt-
ics. User actions and the most recent states of planning
maps are stored in a relational data base to allow querying
of the data. Artifacts produced and shared by the users are
stored in the nonSQL Couch database 4. The main source
respectively raw data for analytics are the user actions that
are uniformly represented in the CoLoForm format [5], a
structured format defined for interaction analysis by several
research groups in the Kaleidoscope Network of Excellence.
The format is based on XML to allow convenient parsing
and handling of the structured data. Similarly, indicators
produced by analytic components are also represented in
CoLoForm and stored persistently for documentation and
further analyses.

For analytic components that are processing on-the-fly it
is possible to subscribe directly to the respective logger and
analysis channels of the Metafora communication architec-
ture. Components that perform offline analysis, e.g. for
data mining, are provided with a query interface where the
period of interest (start and end time) and the scope of inter-
est (logging, analysis, command, or all channels combined)
can be specified. The result of this query is provided from
the Metafora server in a self-contained XML document with
the complete history queried for. Access to this document is
available using the URL handle the query response message
contains.

4http://couchdb.apache.org/

4.3 Analytic principles for Planning Analysis
and the PlaTO analysis agent

Our intention in Metafora is to support learners, teachers,
and researchers while conducting activities in the Metafora
L2L2 scenarios: Learners should be made aware of their
current progress in the learning process and potential weak-
nesses in their planning. Teachers should get information
about the success of learner groups while working on the
challenges. Researchers finally should be able to get infor-
mation about specific L2L2 behaviours that manifest while
using the system and co-relate these behaviours with the
quality of results and the learning process. The analysis of
planning behaviour manifested by the users’ activities with
the planning tool can be conducted at several levels of data
and respresentations. Both the actions directly performed
by the user as well as the states and structures of plan-
ning maps can be analysed to detect indicators for specific
planning abilities and behaviours of the students. Thus, ac-
cording to [3] both action-based and state-based analysis
methods are possible and have been implemented into the
current analytic component PlaTO.

PlaTO is an analysis component with the specific task to
analyse planning behaviour and the interrelations between
planning and actions in the respective learning tools. Its
purpose can be considered both as a domain-specific / tool-
specific component when focussing on the planning process
of users inside the dedicated Planning Tool, but also as a
cross-tool component, because it adresses (at least partially)
the transition between planning and enacting in other tools.

Currently, PlaTO provides several indicators tackling dif-
ferent facets of planning and enacting behaviour in relation
to the L2L2 principles [2] of Metafora:

• creation / deletion of plans as possible indicators for
milestones and cleanup

• opening of plans and changing of planning maps as
possible indicators for changing the work context and
choosing an appropriate space for planning

• working on the same map and connecting to others’
objects as indicators for collaboration and takeup

• checks for connectivity of activity stages as indicators
for the students’ capabilities of creating coherent plans

• checks for splits and joins in a planning process as in-
dicators for divergent and confluent planning activities

• indicators for starting, working and finalizing specific
work phases and student’s awareness of these phases

• cross-tool interactions initiated in the planning tool
(such as open a learning tool, share a mathematical
model, discuss this in LASAD) as indicators for seam-
less transition between planning and domain actions

The complexity of the different indicators varies widely from
relatively straightforward singular actions as triggers (e.g.
create map) to complex sequences of actions (for collabo-
ration / takeup) and structural checks on planning maps
(splits, joins, and connections). Using the terminology of
[3] PlaTO uses both action-based and state-based analyis
on different complexity levels (actions vs. action sequences,
objects vs. graph structures).

257



Since PlaTO is designed as an analysis component that
separates handling of incoming messages from the semantic
processing, it is possible without further changes to replace
the rulesets defining the L2L2 indicators with other analytic
approaches. One of our current activities in that direction
is the creation of a ruleset that is conducting analysis ac-
cording to the contingency and uptake analysis approach of
Suthers and colleagues [12]. We already have rules available
for media dependency, temporal proximity, spacial proxim-
ity, and a simple version of inscriptional similarity. This
shows - on the technical level - the flexibility and extensi-
bility of our architecture and analysis agent, while - on the
analytic level - broadens the scope of analysis and makes
a multi-perspective analysis possible at the same time. We
will describe the method we intend to use for this multi-
perspective analysis in the next section.

5. ANALYSIS RESULTS AND EXPERIMEN-
TAL METHODS

While this paper is mainly focusing on the architectural
and methodical aspects for conducting learning analytics,
we also want to share some insights on real captured data of
the Metafora system. We will describe our current data set
captured during practical classroom experimentation with
the Metafora scenarios. Then we present the method how
to get insights applying our analyses on the existing dataset
and how to use these in the future for on-the-fly support.

5.1 The current dataset
The Metafora system has been used now for pilot studies

and classroom studies for approximately 7 months. The
experimentation sites are schools and universities located
in England, Greece, Israel, Spain, and most recently China.
As of end of 2012 our database contained:

• 905 distinct user accounts using the system

• 714 planning maps created in the Planning Tool

• 134111 user actions performed using the different tools
of the Metafora system

• 78321 analytic indicators produced by the different
analysis components of the Metafora analysis frame-
work. The indicators range between relatively simple
domain-specific indicators (e.g. re-editing text in a dis-
cussion card) and more abstract L2L2 behaviours we
call landmarks (e.g. students organizing their work by
means of creating and using new workspaces).

With the ongoing practical experimentation and the planned
usage of the system with a wider audience than just the
project members and their partner schools we expect a rapid
growth of the dataset being available for analytic purposes
within the next months.

5.2 Analytics method on classroom data
The direct support for the learners in our system is de-

signed to happen on-the-fly. Since we want to collect ev-
idence of the usefulness of our type of feedback before di-
rect intervention in the learning process we set up a process
of data analytics making use of archived interaction data.
This has also the advantage that we can make use of data
collected from Metafora during a time before the analytic
components available now have been ready for use.

Figure 3: Schema for the process of re-analysing
archived data with analytic components and human
evaluator

Our approach is based on a controlled setting where a
person representing the intended end user of feedback eval-
uates the timelyness and usefulness of provided feedback for
a situation that is created from exisiting logfile data. For
that end we devised a replay mechanism that recreates the
learning situation by re-sending of the captured user actions
into the analysis architecture. Every component that makes
analysis based on this logfile information can be enabled to
allow specific types of indicators being tested with the re-
cipient users. Figure 3 shows the schema we designed for
the re-analysis of archived data with our current analysis
components.

Feeding archived planning actions into the Metafora sys-
tem can be directly observed in the planning tool as if the
interaction would happen right now. So the feedback evalua-
tor can experience the learning situation similarly to watch-
ing a video. Analysis components can create the feedback
on the basis of the replayed user actions and the feedback
will be provided to the user impersonated by the evaluating
person, i.e. the evaluator will take the place of the previ-
ously recorded user and see the feedback directed to that
user, similarly to the the learning approach called vicarious
learning [9], but here for the purpose of analysis and evalua-
tion. Figure 4 shows an example of the visual representation
of different types of feedback in the Metafora system.

We are currently setting up the systematic investigation
of the feedback’s usefulness. The space for experimentation
is multi-dimensional with the following facets:

• number and combination of analytic tools used: seper-
ate and systematic evaluation of each analytic com-
ponent is desirable, yet Metafora with its integrated
multi-tool scenarios surely needs additionally the eval-
uation of combined and cross-tool feedback also. In
our specific case of PlaTO we can even consider each
different ruleset (currently the L2L2 set described in
detail above and the draft-status contingency / uptake
ruleset) as a different analytic perspective to be tested
seperately and in combination.

• target user: students, teachers, researchers all have
different information needs, so usefulness of produced
feedback has to be evaluated for each target group

258



Figure 4: User receiving different types of feedback
in Metafora. In the middle of the screen a highly
interruptive modal prompt is sent, on the lower right
a temporary notification; feedback can be revisited
in the ”feedback box” on the left hand that shows
different types of feedback colour-coded

• representation of the feedback: the analytic compo-
nents of our system make use of a framework for dif-
ferent types of feedback for the visualisation / repre-
sentation of feedback. The analytic components don’t
have visual components on their own, but make use of
the framework functionality. Textual and visual feed-
back variants will have to be explored in their useful-
ness and also in their perceptibility. In this area we are
currently preparing an eye-tracking study to measure
the effects that current implementations of feedback
have on the users’ awareness of that feedback.

Exploring this large design and experiment space will be
one of the main topics in the rest of the project lifetime; the
evaluation results will directly feed again into the implemen-
tation of analytic components and feedback presentation.

6. CONCLUSIONS
In this paper we presented our approach for learning an-

alytics within and for the Metafora system, a web-based
multi-tool environment providing complex learning scenar-
ios to be solved by collaboration groups in a self-regulated
manner. The pedagogical focus and thus also the goal of
analytics is the investigation in aspects of learning to learn
together (L2L2). We showed the implemented architecture
facilitating a de-centralized analysis system with heteroge-
neous analytic components coordinated using a blackboard
approach. Then we introduced analytics on planning be-
haviour performed by an agent called PlaTO. The dataset
collected in our ongoing experimentation and a method for
validation and re-analysis of data are presented to show the
practical applicability of our approach. Based on the results
we gain with the described method we will improve and re-
vise our analytic components and also broaden our scope of
analyses using other perspectives, such as the uptake anal-
ysis perspective from Suthers and colleagues [12].

7. ACKNOWLEDGMENTS
We thank our colleagues in the project for fruitful discus-

sions and cooperation to support L2L2. A special thanks
goes to our programmers that contributed to system archi-
tecture and development of analytic components.

8. REFERENCES
[1] F. Buschmann, R. Meunier, H. Rohnert,

P. Sommerlad, and M. Stal. A System of Patterns.
John Wiley & Sons, Chichester, 1996.

[2] T. Dragon, M. Mavrikis, B. McLaren, A. Harrer,
C. Kynigos, R. Wegerif, and Y. Yang. Metafora: A
web-based platform for learning to learn together in
science and mathematics. IEEE Transactions on
Learning Technologies, Preprint(99):1, 2013.

[3] K. Gassner, M. Jansen, A. Harrer, K. Herrmann, and
U. Hoppe. Analysis methods for collaborative models
and activities. In B. Wasson, S. Ludvigsen, and
U. Hoppe, editors, Proc. of CSCL 2003, pages
369–377. Kluwer Academic Publishers, 2003.

[4] I. Harel and S. Papert, editors. Constructionism.
Ablex Publishing, Norwood, NJ, 1991.

[5] A. Harrer, A. Martinez-Mones, and
A. Dimitracopoulou. Users’ data: Collaborative and
social analysis. In N. Balacheff, S. Ludvigsen, T. de
Jong, A. Lazonder, and S. Barnes, editors,
Technology-Enhanced Learning – Principles and
Products, chapter 11, pages 175–193. Springer, Berlin,
2009.

[6] F. Loll. Domain-Independent Support for
Computer-based Education of Argumentation Skills.
PhD thesis, TU Clausthal-Zellerfeld, 2012.

[7] H. Mandl and A. Lesgold, editors. Learning Issues for
Intelligent Tutoring Systems. Springer, New York,
Berlin, Heidelberg, London, Paris, Tokyo, 1988.

[8] B. M. McLaren, O. Scheuer, M. D. Laat, R. Hever,
R. D. Groot, and C. P. Rose?. Using machine learning
techniques to analyze and support mediation of
student e-discussions. In Artificial Intelligence in
Education, pages 331–338, 2007.

[9] D. Muller, M. Sharma, J. Eklund, and P. Reimann.
Conceptual change through vicarious learning in an
authentic physics setting. Instructional Science,
35(6):519–533, 2007.

[10] C. Quintana, B. Reiser, E. Davis, J. Krajcik, E. Fretz,
R. Duncan, E. Kyza, D. Edelson, and E. Solloway. A
scaffolding design framework for software to support
science inquiry. The Journal of the Learning Sciences,
13(3):337–386, 2004.

[11] S. G. Santos, M. Mavrikis, and G. D. Magoulas.
Layered development and evaluation for intelligent
support in exploratory environments: The case of
microworlds. In Intelligent Tutoring Systems, pages
105–114, 2010.

[12] D. D. Suthers, N. Dwyer, R. Medina, and R. Vatrapu.
A framework for conceptualizing, representing, and
analyzing distributed interaction. I. J.
Computer-Supported Collaborative Learning,
5(1):5–42, 2010.

259





