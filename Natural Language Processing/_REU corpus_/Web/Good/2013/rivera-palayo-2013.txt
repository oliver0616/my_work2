
Live Interest Meter – Learning from Quantified Feedback in
Mass Lectures

Verónica Rivera-Pelayo, Johannes Munk, Valentin Zacharias and Simone Braun
FZI Research Center for Information Technology

Haid-und-Neu-Str. 10-14
Karlsruhe, Germany

{rivera, munk, zach, braun}@fzi.de

ABSTRACT
There is currently little or no support for speakers to learn
by reflection when addressing a big audience, like mass lec-
tures, virtual courses or conferences. Reliable feedback from
the audience could improve personal skills and work perfor-
mance. To address this shortcoming we have developed the
Live Interest Meter App (LIM App) that supports the gath-
ering, aggregation and visualization of feedback. This appli-
cation allows audience members to easily provide and quan-
tify their feedback through a simple meter. We conducted
several experimental tests to investigate the acceptance and
perceived usefulness of the LIM App and a user study in
an academic setting to inform its further development. The
results of the study illustriate the potential of the LIM App
to be used in such scenarios. Main findings show the need
for motivating students to use the application, the readiness
of presenters to learn retrospectively, and distraction as the
main concern of end users.

Categories and Subject Descriptors
H.5.2 [Information interfaces and presentation]: User
interfaces; K.3.2 [Computers and Education]: Computer
Science Education

Keywords
Live feedback, Data capturing, Mobile application, Learning
Analytics, Reflective Learning, Quantified Self

1. INTRODUCTION
For lectures and conferences – one of the main daily activ-

ities of researchers, professors, lecturers and students – there
is currently little or no support to learn by reflection, even
though in these scenarios there seems to be a great potential
to improve professional skills and presenter’s performance by
learning from personal experience. Especially in mass lec-
tures, virtual courses or conferences, reliable feedback from
the audience is missing and the speaker lacks support to

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
LAK ’13, April 08 - 12 2013, Leuven, Belgium
Copyright 2013 ACM 978-1-4503-1785-6/13/04 ...$15.00.

quickly evaluate the overall development and react accord-
ingly. To realize this technical support, research questions
such as how to optimally aggregate and present individual
feedback of a large group of participants during the talk
must be answered. Until now, traditional surveys after the
lectures or conferences have been used, which are usually
centered on the content of the course/talk and performed
only once in retrospective, with the results not always being
shared with the participants.

In order to address these shortcomings, we have devel-
oped the Live Interest Meter App (LIM App). Its goal is to
quantify and track abstract feedback from an audience (e.g.
emotions and thoughts especially referred to their percep-
tion of the event) and to provide this feedback live as well as
retrospectively to the presenter in order to forster learning
processes through reflection. The LIM App also aims for
improving students’ attitude, attention and concentration
during a lecture. With this approach, we investigate po-
tential improvements in managing learning in practice and
apply learning analytics on data gathered during the lecture.
Since lectures belong to the continuous learning process of
students, improving these activities contributes to the im-
provement of the general learning process itself.

Reflection in terms of learning is defined by Boud et al. [3],
as “those intellectual and affective activities in which in-
dividuals engage to explore their experiences in order to
lead to new understandings and appreciations”. The reflec-
tive process is based on the re-evaluation of the learner’s
experiences, considered as “the total response of a person
to a situation, including behavior, ideas and feelings”, and
thereby producing outcomes. In our concrete scenario, re-
flecting about data derived from captured feedback may
help users improve their presentation skills and performance
when addressing an audience. Besides, such data will help
the speaker reflect about the differences between her own
perspective on an event and how it is perceived by the par-
ticipants. Our approach is based on an integrated model
of reflective learning and Quantified Self (QS) [10, 11], that
shows how QS tools can technically support the cognitive
process described by Boud et al.

In the following, we will present a review of related work,
before describing the Live Interest Meter App (Section 3).
In Section 4 we describe the experimental tests and the user
study with their results. Finally, we conclude this paper with
a discussion of the results and future work in Section 5.

2. RELATED WORK
Audience Response Systems (ARS), also known as click-

23



ers [5, 9, 12], enable instructors in a large lecture class to
instantaneously collect student responses to a posted ques-
tion, generally multiple choice. The answers are immedi-
ately tallied and graphically displayed on a classroom pro-
jection screen where both students and instructor can see
and discuss them [4]. These systems generally aim at im-
proving student outcomes such as improved exam scores or
passing rates, student comprehension, and learning and as
well as student attendance and interest on the course. There
are also some approaches that explore questions and answers
(Q&A) in a bidirectional way using micro-blogging [1, 8],
i.e. not only the lecturer can create questions to evaluate
students, but students can also pose questions.

There are also some available products with the aim of en-
hancing students engagement in class, for example, GoSoap-
Box1, ShakeSpeak2 or Socrative3. Several projects have also
developed systems to support real-time feedback during lec-
tures at university [2, 14], which offered elementary tools
for cooperation to enable electronic feedback, hand-raising
and multiple-choice-polls with live-results.

Most of the related work above explores and focuses on
giving a benefit for students and are tightly related to the
content of the lectures and the knowledge they acquire, be-
ing limited to polling of questions and answers in many
cases. On the contrary, the use case we are considering takes
the lecturer and presenter as the center of the scenario and
focuses on professional performance improvement. In this
case, students play a very important role, as they are the
ones who provide feedback, but they are not the only target
group to get a benefit from the tool. We enrich the feedback
meter function with other features that support the lecture
like polls, questions and chats are intended to improve the
lecture itself, but also to add context to the feedback that
students are giving to the lecturer.

In the field of Technology Enhanced Learning there are
few approaches to support self-reflection and increase aware-
ness for both learners and teachers, and they are mainly
centered on the activities of the students, like the Student
Activity Meter (SAM) [7], which provides a set of visual-
izations to be used in digital learning platforms (or LMS)
or the EnquiryBlogger [6], an extension of a blog developed
to support awareness and reflection for enquiry-based learn-
ers. Outside of the learning management system there are
also approaches to track the activity of students [13], with
several visualizations intended to increase motivation of stu-
dents and help them reflect on their learning process.

In these related approaches we have reviewed tools to sup-
port reflection on several sources of data, but none of them
considers the gathering of feedback and other data during
the lectures for reflective learning purposes. Additionally,
these approaches broadly cover the support for students,
but do not take into account the potential of this data for
the lecturer’s self-improvement.

3. LIVE INTEREST METER – LIM APP

3.1 LIM App: Features and Interface
The LIM App has two interfaces: an Android App as well

as a JavaScript-based application, which provides a broader

1GoSoapBox, www.gosoapbox.com
2ShakeSpeak, www.shakespeak.com
3Socrative, www.socrative.com

access from any device. The core of the LIM App is the me-
ter component (see Figure 1), which allows users to vote on
a quantifiable aspect. A title and captions for minimum and
maximum value are to be defined by the presenter (master)
and can range from aspects like comprehension (difficult or
easy to understand?) to performance (too fast or too slow
for me?). The colored background represents the scale and
an input slider allows entering the desired value.

Figure 1: Live Interest Meter: meter with touch
interface and poll results (both on the Android ver-
sion) c©Vero?nica Rivera-Pelayo et al.

Users can update their vote at any time and are encour-
aged to do so, whenever they think of it. A given value stays
valid only for a specific amount of time, in order to maintain
a certain timeliness of the feedback.

Figure 2: Evolution graph showing the feedback in
time. a) Android interface b) JavaScript interface
c©Vero?nica Rivera-Pelayo et al.

The evolution graph (see Figure 2) shows three different
aspects of the meter-values in a timeline (x-axis): (a) the
colored area spans between the 10th and 90th percentile of
all the users values sent to the master (y-axis), (b) the black
line displays the group average feedback and (c) in red is de-
picted the feedback value provided by the ’local’ user (not
available for the master as she is not actively contributing
to the evaluation). In the top-right corner the number of
currently valid user-votes is displayed – important to esti-
mate the relevance of the given feedback. The red cycles at
the bottom represent topic markers, that the presenter can
introduce as contextualization of the time series.

Both master and client application show this graph live,
updated every second. That is how the feedback is pre-
sented to the users, for their personal inspection as well as

24



for subsequent reflection.
In order to increase the interactivity between audience

and presenter, the tool additionally offers instant-polls that
can be prepared and suggested by users, questions that are
rated by the audience and optionally an open chat.

3.2 Reflective Learning from Feedback
As introduced before, the Live Interest Meter aims at sup-

porting reflective learning from feedback in events where a
person addresses a large audience. The way Live Interest
Meter tracks and shares feedback, allows both the presen-
ter to receive feedback from a large audience as well as for
each participant to compare his learning experience with his
peers.

Figure 3: LIM App use case: integrated feedback
and reflection loop c©Vero?nica Rivera-Pelayo et al.

The model in [10, 11] describes how Quantified Self tools
like the LIM app can support reflective learning. It defines
three support dimensions, which can be tackled by tools,
namely: (i) tracking cues (capturing certain kinds of data
as basis for the reflective learning process), (ii) triggering
(fostering the initiation of reflective processes in the learner),
and (iii) recalling and revisiting experiences (through the
enrichment and presentation of data in order to make sense
of past experiences).

In our approach, tracking is based on self-reporting through
the LIM App. The tracked aspect is the users’ quanti-
fied vote on the meter scale. Upon inspection the evolu-
tion graph can passively trigger reflection. Trigger may be
visually significant differences between the user’s vote and
that of the group or sudden changes in the evolution graph
(”Adaption/Reaction” in Figure 3). During recalling and re-
visiting the user can inspect the topic markers in the time-
line, questions and polls. They provide contextualization
and help to align the time series with the users’ memorized
experiences.

The collected highly contextualized data can serve as an-
chor for several aspects and perspectives of reflection: First,
the presenter can assess the evolution of the quality of her
presentation through time. Then she can reflect about dif-
ferences between the participants’ perception of events and
hers on a very detailed scale. Second, members of the au-
dience can compare their own ratings with the group ag-
gregation (”Peer comparison” in Figure 3), which represents
their social context and become aware of dissimilarities. By
exploring the graph, it is possible to detect topics where a
user’s capability or speed of understanding deviates from the
other classmates. Reflection might help identify reasons and

improve the learning experience. The presenter can assess if
a topic needs further explanation and examples in order to
be comprehensible for the majority of the audience.

That is how the LIM App provides an integrated feedback
and reflection loop for both the presenter and the audience.

4. EXPERIMENTS AND USER STUDY

4.1 Experimental Tests
The LIM App was firstly investigated through two exper-

iments, in a lesson and a project meeting. The first informal
test was conducted in a project meeting of 20 participants,
with 10 active LIM users. This event was mainly discussion
driven and the participants expressed in one of the ques-
tions of the survey how well did the LIM App perform for
the following purposes (see Figure 4):

Figure 4: How well did the LIM App work for the
following options?

Half of the participants opined that the LIM App per-
formed well or very well to track their interest in the topic.
The participants were willing to compare their interest with
the others (50% indicated they could do it well with the app
and 20% very well) but they also admitted to have played
with the app (so the fun factor was already recognized).

A second technical test was performed in a lecture at the
university, where we collected informal feedback from the
participants. Technically the app performed well but the
acceptance of the app was rather limited, as the lecture had
a small group of students and the session itself was quite
interactive. In such cases, the use of technical means to
capture feedback and response answers are not considered
as necessary.

In these informal tests, we got the first insights about the
application: the LIM App is suitable for big audiences where
personal contact is not established but it is not so suitable
for events which are discussion driven, as then the role of the
presenter is not well defined. After these experimental tests,
and before moving towards bigger audiences, we conducted a
user study to help refining the use case and guide the further
development of the LIM app.

4.2 User Study
The user study was designed around the following research

questions:
RQ1: In which scenarios and how can the quantification
of feedback performed by the LIM App support reflective
learning?

25



RQ2: Which features are more appreciated by users, both
presenters and audience?

Firstly, 20 qualitative interviews with groups of the LIM
App end users were conducted in order to investigate the
use case scenarios and the application of the app itself. The
interviewees included professors, teachers and students.

Many presenters or lecturers already collect feedback from
their presentations and lectures, but they do it in the conven-
tional way through written questionnaires or direct contact
to their students. Technology supported feedback systems
were not used among the participants and the idea of hav-
ing a system like the LIM App, which allows them to give
and get feedback, was very well received. This was also
true for the audience, who was willing to give feedback not
only after but also during their lectures. According to the
participants, the anonymity of the feedback would result in
higher audience participation and students would voice their
own opinion more openly, without the fear of contradicting
opinions or ideas.

The poll function was considered especially useful for lec-
tures, because it allows lecturers to quickly evaluate the
knowledge of their students. On the other hand, the chat
was considered distracting and unnecessary. However, many
interviewees were afraid of the distraction of both presenter
and audience, if they focus more on the application itself
than on the content of the lecture. Many of them also agreed
that reflection needs time, and therefore they would better
reflect after the event had taken place than during the pre-
sentation feeling under pressure.

In a second phase, we conducted an online survey based
on our experience and the feedback from the interviews. Our
aim was to get to know the disposition, opinion and ideas
of potential users. For that purpose, we explained them
the concept of reflective learning and its support with the
LIM App (also including screenshots), before asking them
several questions for assessment and evaluation. Questions
referring to the role of the presenter (e.g. as teacher, profes-
sor or in conferences) were only asked to participants who
had confirmed that they give talks and presentations(44,82
%), whereas other questions concerning the role of the au-
dience (e.g. which criteria they would like to evaluate) were
only answered by the rest (55,17 %).

The survey was online for a month (May-June 2012) and
120 people participated. We obtained 87 valid and com-
plete datasets. In order to diversify the participants’ back-
ground, we distributed our survey through various channels:
personal relations to professors, colleagues and institutions,
social media and our website. The age distribution of the
participants was the following: 17-24 (36,78 %), 25-35 (41,37
%), 36-50 (12,64 %), and more than 50 (9,19 %).

Participants in the survey do presentations in different
contexts: teacher at school (7,69 %), lecturer at a university
(41,02 %), speaker in conferences (56,41 %) or presentations
as part of their professional work (56,41 %). Regarding their
audience, only 12,81 % present in front of more than 60 peo-
ple, whereas the majority of the participants have audiences
of 11-30 (46,15 %) or 31-60 (25,64 %) people.
The 48 participants who do attend presentations do it as stu-
dents (89,58 %), in their free time (8,33 %), in conferences
(6,25 %) and/or at work (22,91 %).

From the presenter’s side, nearly 90 % of the participants
would like to get feedback after each presentation, whereas
around 72 % would also agree to get feedback during the

event, for example after each section. Receiving feedback
live during the whole presentation was chosen as ideal by
12,82 % of the participants and as OK by 25,64 %, but 33 %
were indecisive.

Although the pressure for immediate feedback adaption
was a concern among many participating presenters, 53,84 %
think that they could achieve it during the presentation.
Reacting to the feedback periodically (e.g. some days later)
and in relation to the content blocks (e.g. between content
blocks) seems to be the most popular option (76,91 %), what
may be directly related to reflective learning practices from
the data they gathered in past events.

All respondents expressed their opinion regarding several
aspects of the LIM App, like if the adoption of a tool like this
would completely distract the audience (18,39 %: strongly
agree, 56,32 %: agree, 20,68 %: disagree, 1,14 %: strongly
disagree) or if feedback must be anonym in order to be re-
liable and honest (41,37 %: strongly agree, 27,58 %: agree,
26,43 %: disagree, 3,44 %: strongly disagree).

We also asked in the survey about the capturing of the
data. 64,36 % of the participants agreed with data collected
live and continuously being better and more significant than
only periodically collected data.

The second part of the survey contained questions about
the concrete characteristics that the LIM App offers and
which new features would improve the application. The
chat function in the LIM App was considered unnecessary
(4,59 %: very meaningful, 16,09 %: rather meaningful, 43,67 %:
unnecesary, 33,33 %: absolutely unnecesary, 2,29 %: I can-
not judge). On the contrary, the participants appreciated
very much polling questions (34,48 %: very meaningful,
54,02 %: rather meaningful, 8,04 %: unnecesary, 3,44 %:
absolutely unnecesary) and also the possibility to review old
polled questions (28,73 %: very meaningful, 50,57 %: rather
meaningful, 13,79 %: unnecesary, 2,29 %: absolutely un-
necesary, 4,59 %: I cannot judge).

We also investigated which information they would like
to track. Figure 5 shows that both speakers and audience
members agree on pace and clarity of the examples being
important, but disagree regarding the slides and documents
of the lecture.

Summarizing the positive results, more than 3/4 of the
participants (78,16 %) in the survey found the idea behind
LIM App very positive and found advantages in using it.

5. CONCLUSION
This paper presented the Live Interest Meter, an appli-

cation for gathering, quantification, aggregation and visual-
ization of feedback in mass lectures and conferences.

It was developed with the aim of supporting reflective
learning from feedback, by reacting to the feedback live as
well as by exploring the data retrospectively. We conducted
two experimental tests and a user study to investigate the ac-
ceptance, perceived usefulness and potential improvements
of the LIM App.

Our acceptance study delivered a highly positive reso-
nance and the idea of using a technology driven feedback
system was well received. Our test subjects recognized the
advantages of our feedback system and saw a possible bene-
fit in its use. We also confirmed one of the main fears of end
users: the potential distraction of the audience, by concen-
trating on the application instead of the presentation itself.
In order to improve this, we will address this issue in dif-

26



Figure 5: Which information would the presenters
like to know about and which information does the
audience want to evaluate?

ferent directions, e.g. by keeping the application as simple
as possible to demand the minimum cognitive effort from
users. To this end, the next prototype will only show the
necessary information to the users or offer an introductory
training to teachers in order to show them how to integrate
the LIM App in their lectures and make the best of it.

Our efforts in developing the next prototype will focus
on improving the support of recalling and revisiting past
events, by creating a platform that allows users to explore
their gathered data retrospectively.

Additionally, further improvements based on the feedback
from the user study will be adapted, e.g. alternatives to the
chat functionality will be explored and futher features to
support the presenter will be adopted.

With the new prototype we will then be able to evaluate
the LIM App again in the field and in this way validate our
current results, which show the expectations and opinions
of the end users. The main goal of this evaluation will be
to prove that reflective learning among participants takes
place with the support of the LIM App and that this brings
a benefit and improvement for the learner.

Finally, some concerns regarding the students voluntar-
ily participating and giving feedback were also mentioned
in our study. To this extent, we currently work on motiva-
tion techniques to engage our users to use the application
and investigate how gamification techniques can improve the
adoption and long term use of the LIM App.

6. ACKNOWLEDGMENTS
The authors would like to thank A. Brjezovski, C. Cather-

ine, M. Kohaupt and S. Kuhn for their collaboration in con-
ducting the user study. Work presented in this paper was
partly conducted within the project “MIRROR – Reflective
learning at work” funded under the FP7 of the European
Commission (project number 257617).

7. REFERENCES
[1] M. Akbari, G. Bo?hm, and U. Schroeder. Enabling

communication and feedback in mass lectures. In
ICALT, pages 254–258, 2010.

[2] M. Bonn, S. Dieter, and H. Schmeck.
Kooperationstools der Notebook Universita?t Karlsruhe
(TH). In Mobiles Lernen und Forschen, pages 63–71.
Klaus David, Lutz Wegener (Hrsg.), November 2003.

[3] D. Boud, R. Keogh, and D. Walker. Reflection:
Turning Experience into Learning, chapter Promoting
Reflection in Learning: a Model., pages 18–40.
Routledge Falmer, New York, 1985.

[4] J. E. Caldwell. Clickers in the large classroom:
Current research and Best-Practice tips. CBE Life Sci
Educ, 6(1):9–20, Mar. 2007.

[5] D. Duncan and E. Mazur. Clickers in the Classroom:
How to Enhance Science Teaching Using Classroom
Response Systems. Pearson Education, 2005.

[6] R. Ferguson, S. B. Shum, and R. D. Crick.
EnquiryBlogger: using widgets to support awareness
and reflection in a PLE Setting. In ARPLE11, PLE
Conference 2011, Southampton, UK, 11-13 July, 2011.

[7] S. Govaerts, K. Verbert, E. Duval, and A. Pardo. The
student activity meter for awareness and
self-reflection. In CHI ’12 Extended Abstracts on
Human Factors in Computing Systems, pages 869–884,
New York, NY, USA, 2012. ACM.

[8] J. Hadersberger, A. Pohl, and F. Bry. Discerning
actuality in backstage - comprehensible contextual
aging. In EC-TEL, volume 7563 of Lecture Notes in
Computer Science, pages 126–139. Springer, 2012.

[9] D. Kundisch, P. Herrmann, M. Whittaker,
M. Beutner, G. Fels, J. Magenheim, W. Reinhardt,
M. Sievers, and A. Zoyke. Designing a Web-Based
Application to Support Peer Instruction for Very
Large Groups. In ICIS ’12, Research in Progress,
Orlando, USA, December 2012.

[10] V. Rivera-Pelayo, V. Zacharias, L. Mu?ller, and
S. Braun. Applying quantified self approaches to
support reflective learning. In 2nd International
Conference on Learning Analytics and Knowledge,
LAK ’12, pages 111–114, USA, 2012. ACM.

[11] V. Rivera-Pelayo, V. Zacharias, L. Mu?ller, and
S. Braun. A framework for applying quantified self
approaches to support reflective learning. In IADIS
Mlearning 2012, Berlin, Germany, 2012.

[12] G. Rubner. mbclick - an electronic voting system that
returns individual feedback. In WMUTE, pages
221–222. IEEE, 2012.

[13] J. L. Santos, S. Govaerts, K. Verbert, and E. Duval.
Goal-oriented visualizations of activity tracking: a
case study with engineering students. In 2nd
International Conference on Learning Analytics and
Knowledge, LAK ’12, pages 143–152, New York, NY,
USA, 2012. ACM.

[14] A. Wessels, S. Fries, H. Horz, N. Scheele, and
W. Effelsberg. Interactive lectures: Effective teaching
and learning in lectures using wireless networks.
Comput. Hum. Behav., 23(5):2524–2537, Sept. 2007.

27





