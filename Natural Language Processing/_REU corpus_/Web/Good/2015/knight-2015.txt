
Developing a Multiple-Document-Processing 
Performance Assessment for Epistemic Literacy 

Simon Knight1 
sjgknight@gmail.com 

Karen Littleton2 

Karen.littleton@open.ac.uk 
Knowledge Media Institute

1
  

Centre for Research in Education and Educational Technology
2
 

Open University, Milton Keynes, MK7 6AA 

   

ABSTRACT 
The LAK15 theme “shifts the focus from data to impact”, noting 

the potential for Learning Analytics based on existing 

technologies to have scalable impact on learning for people of all 

ages. For such demand and potential in scalability to be met the 

challenges of addressing higher-order thinking skills should be 

addressed. This paper discuses one such approach – the creation 

of an analytic and task model to probe epistemic cognition in 

complex literacy tasks. The research uses existing technologies in 

novel ways to build a conceptually grounded model of trace-

indicators for epistemic-commitments in information seeking 

behaviors. We argue that such an evidence centered approach is 

fundamental to realizing the potential of analytics, which should 

maintain a strong association with learning theory. 

Categories and Subject Descriptors 
K.3.1 [Computers and Education]: Computer Uses in Education 

– collaborative learning. 

General Terms 
Measurement, Documentation, Design, Human Factors,  

Keywords 
Learning analytics; epistemic cognition; educational assessment; 

discourse analytics; social learning analytics 

1. INTRODUCTION 
Despite the prevalence of internet use, many students experience 

difficulties in their web based information-seeking activities [48]. 

The searching, selecting, and processing of complex documents 

and multi-media on the web can be seen as a component of 

literacy [36] and is related to epistemic cognition – the ways in 

which people conceptualize the: certainty, simplicity, source, and 

justification of knowledge [32]. In particular, the ways in which 

students source, corroborate, and integrate claims – key facets of 

literacy for mature internet use [39] – are related to their epistemic 

cognition in information seeking and literacy tasks [1, 8, 16, 31, 

44–46]. By epistemic cognition, we mean the broad set of models 

across which there is a broad agreement on two main areas of 

interest, cognitions regarding: what knowledge is; and how one 

comes to know, as Mason, Boldrin and Ariasi [32] summarise: 

There are two dimensions within the first area (knowledge): 

- Certainty of knowledge: the degree to which knowledge is 
conceived as stable or changing, ranging from absolute to 

tentative and evolving knowledge; 

- Simplicity of knowledge: the degree to which knowledge is 
conceived as compartmentalized or interrelated, ranging from 

knowledge as made up of discrete and simple facts to 

knowledge as complex and comprising interrelated concepts. 

There are also two dimensions which can be identified within 

the second area (knowing): 

- Source of knowledge: the relationship between knower and 
known, ranging from the belief that knowledge resides outside 

the self and is transmitted, to the belief that it is constructed 

by the self 

- The justification for knowing: what makes a sufficient 
knowledge claim, ranging from the belief in observation or 

authority as sources, to the belief in the use of rules of inquiry 

and evaluation of expertise [32, p.69]  

Along with the increase in internet use has come an increasing 

prevalence of ICTs (Information and Communications 

Technologies) such as Virtual Learning Environments, bringing a 

growing interest in learning analytics: the use of trace-data from 

such systems to make claims about learning [12]. However, 

presently even within the computer supported collaborative 

learning literature, only a minority of measures assess process 

data including dialogue data, with most relying on self-report 

measures [19]. Little research in epistemic cognition has taken a 

learning analytic approach, taking trace data as a data source for 

analysis  [for related exceptions, see for example, 11, 18, 21, 22, 

28, 47]. There is untapped potential here; as Winne notes: 

trace data operationalize what learners do as they do it. Trace 

data avoid shortcomings of (a) asking leaners what they 

believe they do and (b) asking learners to perform mental 

calculations of unknown kinds (c) using sample fractions of 

past or possible future experiences that have unknown size 

and biases. When traces are faithful operational definitions of 

theoretical cognitive and metacognitive operations, they 

provide sturdy grounds for testing theories about when, 

whether, and how [self regulated learning] processes affect 

learning [49, p.275] 

This potential could – as we discuss in this paper – address recent 

calls for a focus on  literacy assessments, through trace data based 

performance assessment and the development of evidence 

centered design [15, 27]. Such an approach should consider the 

elements of ‘evidence centered design’ [35] which moves through 

an evidence-based analysis of: (1) the high-level constructs we 

aim to probe, (2) the types of behavior indicative of those 

constructs, and (3) the types of task likely to elicit salient 

indicators; to develop performance assessments [10, 29, 43], 

which as Pellegrino notes, “do not offer a direct pipeline into a 

student’s mind. […] an [performance] assessment is a tool 

designed to observe students’ behavior and produce data that can 

Permission to make digital or hard copies of part or all of this work for 
personal or classroom use is granted without fee provided that copies are 

not made or distributed for profit or commercial advantage and that 

copies bear this notice and the full citation on the first page. Copyrights 
for third-party components of this work must be honored. For all other 

uses, contact the Owner/Author.  

 
Copyright is held by the owner/author(s). 

LAK '15, Mar 16-20, 2015, Poughkeepsie, NY, USA 

ACM 978-1-4503-3417-4/15/03. 
http://dx.doi.org/10.1145/2723576.2723577   

  

241

http://dx.doi.org/10.1145/2723576.2723577


be used to draw reasonable inferences about what students know.” 

[37, p.261]. In this short paper we introduce some work, in 

progress at the time of writing, to undertake such an evidence-

centered approach to designing a performance assessment – a 

tasks, related to a conceptual model of performance (or 

behavioral) expectations, with tools to capture data around those 

behavioral traces – for epistemic cognition. This is done in the 

context of complex multiple document processing tasks in which 

students read and synthesise information from multiple 

documents. Such tasks are designed to probe high-level literacy 

skills, and – as we discuss further below – are established as a tool 

in epistemic cognition research. As such, we first introduce the 

construct of interest, alongside behavioral indicators of those 

constructs. We then introduce the tasks design for our 

development of learning analytics in this area, before concluding 

with some general points on lessons learned thus far. 

2. A Model of Epistemic Cognition 
A starting question for evidence centered design is, “What are 

students supposed to do when they study multiple documents? 

And what kind of mental representation of such materials do they 

form?” [39, p.65]; in answering those questions Rouet, later built 

on by Rouet and Britt, developed a literacy model: the Multiple 

Documents—Task-based Relevance Assessment and Content 

Extraction (MD-TRACE) model [40]. 

In this model, there are 5 main steps: task model construction; 

information need assessment; document processing; task product 

creation; task product assessment. These steps unfold interactively 

(i.e. they are not linear), and represent a more complex view on 

text processing, in particular with regard to the third step in which 

the relevance of documents to the information need is assessed, 

the document model updated, and the process of information 

seeking iterated over. As Rouet [39] (citing [7]) notes, crucial to 

developing such literacy – and mature internet use – students 

should be taught: 

1. Skill of integration: the ability to connect prior and new 
information, including across documents, and including 

where claims are inconsistent or contradictory 

2. Skill of sourcing: the ability to identify parameters that 
characterize the author and conditions of production of the 

information 

3. Skill of corroboration: the ability to check information 
against multiple sources for its accuracy 

Indeed, building on the epistemic cognition literature, Bråten, et 

al., [5] outline the empirical evidence linking epistemic-cognition 

to the MD-TRACE model as indicated in Table 1 which shows a 

summary of the hypothesized relationships between MD-TRACE 

and epistemic cognition facets. 

We are, here, particularly interested in the class of constructs 

related to how students engage higher level literacy skills of 

information selection and evaluation, creation and identification 

of ties between and within documents, and development of 

outputs based on these activities which might be more or less 

elaborated in their form. Here we note that in terms of observable 

indicators there are a number of key behaviors of interest: 

1. How students select information through corroboration and 
reference to source-authority, and how these strategies are 

used in isolation, or combination – for example by 

corroborating across multiple sources, whilst making 

reference to the qualities of those sources.  

2. How students connect claims across and within sources 
whether claims are considered and stated in isolation, or 

integrated and synthesized while seeking information, and 

creating output texts.  

3. How students take claims and use them in task oriented 
ways; whether claims are stated without evaluation, or are 

evaluated and elaborated (independently of their synthesis 

with other claims). 

 

Table 1 MD-TRACE and epistemic cognition relationships [5]  

Facet of 

cognition 

Less adaptive More adaptive 

Simplicity Accumulation of 

facts, prefer simple 

sources 

Integrated, downplay 

simple sources 

Certainty Single document 

sourcing 

Corroboration, represents 

complex perspectives and 

views showing the 

diversity of angles 

Source Emphasizes own 

opinion, 

differentiates 

between sources 

less 

Emphasizes source 

characteristics, 

distinguishes between 

source trustworthiness  

Justification Emphasizes 

authority, less 

corroboration 

Emphasizes use of 

argument schema and 

combination of 

corroboration and authority 

 

Therefore we take it that when sourcing information – through 

selecting individual or multiple sources – those selections should 

be taken to as commitments to authority and corroboration, 

analysed in connection with student’s linguistic ‘stance taking’ 

towards these actions. Such sourcing does not stand alone; it is 

embedded in and connected to the continued seeking of 

information, extraction and synthesis of claims, and deploying of 

that information in task-specific contexts. For example, through 

trace indicators such as logs of document use, or identification of 

key markers linking claims to their sourcing documents, we might 

identify that a particular claim has been sourced from a document; 

in such cases, it is of interest to also identify whether or not 

sourcing metadata (dates, authorship, genre, etc.) has been 

discussed or not. This is particularly interesting given that, as 

Kobayashi [26] indicated through a controlled experimental 

design, while participants given 2 texts of varying quality are 

more likely to favor high quality sources, they make little 

reference to source features (on average only 1.85 out of 10 

features); and rarely (<6% of the 154 participants) explicitly use 

source information for justifying their evaluation of the text’s 

explanation, that is, they do not make connections between source 

metadata and their evaluative stance. 

Furthermore, given the relationship between literacy and dialogue 

[see, for example, 42], and that document use may often involve 

spoken or written communication [40], dialogue is an important 

area of interest in both supporting, and probing complex literacy 

practices. As Goldman and Scardamalia [17] note, communication 

is key in collectively authoring written outputs, particularly 

around “constructive uses of authoritative sources,” that engages 

students both in understanding what is being claimed, and how to 

contribute to developing new knowledge [17, p.260]. They argue 

that we need two foci: 

1. Productive use of metadata and meta-discourse – 
credentials, dates, source locations, quote v paraphrase, 

citations, primary/secondary source, etc. are all important 

242



parts of the discourse, and the discourse around this 

becomes an object for discourse (meta-discourse) too 

2. Use of authoritative sources (i.e. stating claims, and citing 
sources), with a focus on discourse for idea improvement 

and knowledge-creation 

The target of our interest, then, is multiple-document processing 

tasks in which students collaborate on the processing of a range of 

sources, in order to create an output document, and particularly 

tasks in which we – as researchers – have access to chat and 

document-logs. In line with this argument that collaborative 

discourse is of key interest to us, we suggest that the connections 

between trace-indicators of epistemic cognition and in particular, 

the kind of linguistic expressions associated with taking an 

‘epistemic stance’ [23], some of which (e.g. ‘because’, ‘I think’, 

‘so’) are also associated with the kind of educationally productive 

dialogue known as ‘exploratory talk’ [33] or accountable talk [34, 

38] are key. These terms include: ‘I think’, ‘he’ or ‘she’ said, ‘I 

don’t know’ ‘I guess’, ‘I thought’, epistemic adverbs such as 

‘maybe’, ‘probably’, ‘apparently’, ‘of course’, and epistemic 

modal auxiliaries such as ‘would’, ‘must’, ‘might’, ‘could’, ‘will’, 

‘may’. Such stances indicate a linguistic positioning of the 

speaker(s) with regard to their linguistic target. That is, the most 

explanatory insights come, not from an analysis of trace data in 

isolation, but from the consideration of how facets of epistemic-

trace are associated, and how ‘epistemic stance’ commits learners 

in particular ways through the use of their dialogue. Indeed, in 

earlier work [24], we have begun to model this approach on an 

existing data set. 

It is thus that the analysis of individual facets of trace in isolation 

will give only a partial insight into the ways in which people 

engage in: selecting multiple sources; claims around source 

authority; connecting pieces of information in complex ways; and 

so on, which in isolation are likely to give little insight into the 

complexity or otherwise of epistemic cognition. The challenge, 

then, is to operationalize the facets of epistemic cognition of 

interest, in such a way as to understand their connections, in the 

context of tasks. One to which we now turn. 

3. Tasks for Epistemic Performance 
An evidence-centered design process for epistemic cognition 

should build on the typical pattern in that research domain, 

particularly around multiple document processing1. This research 

has typically involved a psychometric assessment, alongside some 

task – constructing an argument, or summarizing information – 

using a number of pre-selected documents, selected for their 

variability in terms of credibility and information. In addition, 

recent work has been conducted on the impact of epistemic 

cognition on comprehension of multiple online sources – which 

may vary radically in the nature of their sources and justifications 

– on the basis that students who perceive knowledge as simple 

and finite may conduct brief and perfunctory searches with little 

recourse to integration or multiple sourcing [2, 6]. As such, 

“exploring students’ thought processes during online searching 

allows [the] examination of personal epistemology not as a 

decontextualized set of beliefs, but as an activated, situated aspect 

of cognition that influences the knowledge construction process” 

[20, p.43]. 

In the research described in this paper, two collaborative tasks are 

deployed:  a multiple document processing task, and a more open 

                                                                 
1 Bråten [3] reviews the relevant literature (to 2008) in epistemic 

cognition and multiple document processing in the context of 

learning within internet technologies. 

ended search-based information seeking task. The study employs 

a between subjects design with both groups engaging with an 

open-ended socio-scientific topic. Comparisons will be drawn 

between trace indicators in both tasks as a means to explore 

development of analytics around the more open ended information 

seeking tasks. In both cases an existing psychometric instrument 

will be used [described in, 4], and the task is to work with a 

partner to produce an etherpad based summary of the “best 

supported claims” from the information found, or provided. These 

summaries will then be peer-assessed against a rubric, with the 

rubric items mapping to constructs in the psychometric 

assessment. In addition, trace data will be gathered including: 

pages viewed (including search engine pages viewed – from 

which queries can be extracted); and chat data between partners. 

Again, our suggestion is that through this trace data we can 

identify indicators to be mapped to the constructs probed by the 

psychometric, and output document. 

4. Analytic Potential – The Tool and its Data 
We are concerned with those epistemic behaviors involved in 

literacy, particularly with regard to how sources of information 

are selected, integrated, and used to resource reasoning. By using 

a browser extension [described in, 9, 41] during the collaborative 

tasks, we can capture: the chat logs; document traces including 

which documents are opened, and what keywords and metadata 

from them is referred to; queries; and editing activity in the 

collaborative document editor (etherpad).  

Our interest is not only in the presence of indicators, but in their 

co-occurrence. That is, while it is certainly of interest to note the 

number of resources opened, and references to source metadata 

(authorship, publication date, publisher, etc.) it is perhaps of more 

interest to identify the connections made between corroborative 

and authority-identification behaviours; students whom rely on 

authorities without corroborating, or those who look for repetition 

of information primitively ‘corroborating’ both engage in less 

sophisticated behavior than those who corroborate by using 

authoritative sources [see 24 for a preliminary description of this 

potential]. We are also particularly interested in the ways in which 

such connections are made between ‘stance taking’ language, 

which in other contexts has been taken as one indicator of the kind 

of ‘exploratory’ dialogue associated with improved educational 

outcomes [see 30], and better success in search tasks [25]. An 

open question at present is the scope of these connections – for 

example, two claims may not be ‘connected’ just because they 

appear in the same text; similarly claims made in chat settings. 

Thus, a method for segmenting data, to provide a topic-level, or 

other semantically meaningful ‘stanza’ [13, 14], is key.  

Generally, then, this model focuses on whom we believe, how we 

justify claims; and how holistic our view of knowledge is. This 

provides a slight recasting of the perspective in Table 1 in 

identifying conceptually distinct objects of inquiry, with specified 

trace indicators for those constructs. In particular, note that 

‘certainty’ is recast in light of connections between criteria for 

sourcing (sourcing, authority), explanation (mobilization, 

understanding), and claims made (complexity, holistic) around 

components of information such as its age, or geographic/cultural 

origin; that is, ‘certainty’ is seen as regarding connections 

between specific claims, metadata (publication date for example), 

and justificatory indicators (explanations for why dates might 

matter, for example). Thus, in Table 2 we provide a mapping of 

our trace indicators against the remaining relevant constructs. 

These are mapped against the epistemic cognition constructs 

described above and in Table 1; in each construct, the ‘less 

243



adaptive’ element is given first, but it should be clear that in the 

case of each indicator – as described above with regard to 

authority seeking and corroboration – the presence of the indicator 

might indicate adaptive or maladaptive behavior.  

Table 2 Mapping epistemic indicators to epistemic constructs 

Psychometric 

construct 

Trace 

construct 

Indicator 

behavior 

Rubric 

indicator 

Justification Sourcing: 

corroboration 

Opening of 

multiple 

sources 

(URLs, etc.) 

A range of 

sources are 

used 

Justification Sourcing: 

authority 

Metadata 

referred to 

Individual 

sources being 

used on 

multiple 

occasions 

Source 

quality is 

evaluated 

Source Mobilization: 

Match 

Focus on 

question cue 

phrases 

A range of 

relevant 

topics are 

covered 

Source Mobilization: 

understanding 

Exploratory 

dialogue 

Information 

is evaluated 

Simplicity Complexity: 

discrete 

Single claims 

within 

meaningful 

segments 

Claims are 

stated clearly, 

with precise 

definitions, 

quotations or 

figures. 

Simplicity Complexity: 

holistic 

Number of 

claims within 

meaningful 

segments 

Information 

is synthesized 

In order to establish and validate such expectations, the 

relationships between the psychometric constructs probed in [4], 

the trace data gathered, and marks on the rubric-facets for the 

output documents will be assessed. These can be compared across 

the two task types, with the potential for insight regarding 

searching behavior coming from the information seeking task, and 

regarding use of known sources (for example, analysis of reliance 

on sources we know to be contradicted by other given evidence) 

in the multiple document processing task.  

5. Conclusions 
This paper describes an ‘in progress’ research study, designed to 

probe a key facet of high-level literacy skills; epistemic cognition. 

It uses the existing evidence, and constructs, in relation to a 

particular type of higher-order skills (literacy) to motivate a 

learning analytics approach to behavioral indicator identification, 

and task creation to illicit such behaviors. Such an approach opens 

the scope for learning analytics to directly support students in 

their information literacy; providing performance assessments of 

real world skills through real world behaviors. 

6. REFERENCES 
[1] Anmarkrud, Ø. et al. In Press. Multiple-documents literacy: 

Strategic processing, source awareness, and argumentation 

when reading multiple conflicting documents. Learning 

and Individual Differences. (In Press). 

[2] Barzilai, S. and Zohar, A. 2009. The Role of Epistemic 

Thinking in Online Learning. Proceedings of the Chais 

conference on instructional technologies research 2009: 

Learning in the technological era (Raanana: The Open 

University of Israel, 2009). 

[3] Bråten, I. 2008. Personal Epistemology, Understanding of 

Multiple Texts, and Learning Within Internet 

Technologies. Knowing, Knowledge and Beliefs. M.S. 

Khine, ed. Springer Netherlands. 351–376. 

[4] Bråten, I. et al. 2005. The Relationship Between Internet-

Specific Epistemological Beliefs and Learning Within 

Internet Technologies. Journal of Educational Computing 

Research. 33, 2 (Jul. 2005), 141–171. 

[5] Bråten, I. et al. 2011. The role of epistemic beliefs in the 

comprehension of multiple expository texts: Toward an 

integrated model. Educational Psychologist. 46, 1 (2011), 

48–70. 

[6] Bråten, I. and Strømsø, H.I. 2006. Epistemological beliefs, 

interest, and gender as predictors of Internet-based 

learning activities. Computers in Human Behavior. 22, 6 

(Nov. 2006), 1027–1042. 

[7] Britt, M.A. and Gabrys, G.L. 2001. Teaching advanced 

literacy skills for the World Wide Web. Learning and 

teaching on the World Wide Web. C. Wolfe, ed. Academic 

Press. Chapter 4. 

[8] Bromme, R. et al. 2009. Epistemological beliefs are 

standards for adaptive learning: a functional theory about 

epistemological beliefs and metacognition. Metacognition 

and Learning. 5, 1 (Dec. 2009), 7–26. 

[9] Coagmento tutorial | Collaborative Information Seeking: 

http://collab.infoseeking.org/blog. Accessed: 2011-10-18. 

[10] Darling-Hammond, L. and Adamson, F. 2010. Beyond 

basic skills: The role of performance assessment in 

achieving 21st century standards of learning. Stanford 

Center for Opportunity Policy in Education (SCOPE), 

Stanford University, School of Education. Retrieved from 

http://edpolicy. stanford. edu. 

[11] Dimopoulos, K. and Asimakopoulos, A. 2010. Science on 

the Web: Secondary School Students’ Navigation Patterns 

and Preferred Pages’ Characteristics. Journal of Science 

Education and Technology. 19, 3 (Jun. 2010), 246–265. 

[12] Ferguson, R. 2012. The State of Learning Analytics in 

2012: A Review and Future Challenges. Technical Report 

#kmi-12-01. The Open University, UK. 

[13] Gee, J.P. 2008. Learning and games. The ecology of 

games: Connecting youth, games, and learning. K. Salen, 

ed. MIT Press. 21–40. 

[14] Gee, J.P. 1989. Two styles of narrative construction and 

their linguistic and educational implications. Discourse 

Processes. 12, 3 (1989), 287–307. 

[15] Goldman, S.R. et al. 2012. A Technology for Assessing 

Multiple Source Comprehension: An Essential Skill of the 

21st Century. Technology-based assessments for 21st 

century skills: Theoretical and practical implications from 

modern research. M. Mayrath, ed. Information Age 

Publishing (IAP). 

[16] Goldman, S.R. et al. 2012. Comprehending and Learning 

From Internet Sources: Processing Patterns of Better and 

Poorer Learners. Reading Research Quarterly. 47, 4 

(2012), 356–381. 

[17] Goldman, S.R. and Scardamalia, M. 2013. Managing, 

Understanding, Applying, and Creating Knowledge in the 

Information Age: Next-Generation Challenges and 

Opportunities. Cognition and Instruction. 31, 2 (2013), 

255–269. 

[18] Greene, J.A. et al. 2010. The Role of Epistemic Beliefs in 

Students’ Self-Regulated Learning With Computer-Based 

244



Learning Environments: Conceptual and Methodological 

Issues. Educational Psychologist. 45, 4 (2010), 245–257. 

[19] Gress, C.L.Z. et al. 2010. Measurement and assessment in 

computer-supported collaborative learning. Computers in 

Human Behavior. 26, 5 (Sep. 2010), 806–814. 

[20] Hofer, B.K. 2004. Epistemological Understanding as a 

Metacognitive Process: Thinking Aloud During Online 

Searching. Educational Psychologist. 39, 1 (2004), 43–55. 

[21] Hsu, C.-Y. et al. 2013. Epistemic Beliefs, Online Search 

Strategies, and Behavioral Patterns While Exploring 

Socioscientific Issues. Journal of Science Education and 

Technology. (2013), 1–10. 

[22] Hwang, G.-J. et al. 2008. A novel approach for assisting 

teachers in analyzing student web-searching behaviors. 

Computers & Education. 51, 2 (Sep. 2008), 926–938. 

[23] Kärkkäinen, E. 2006. Stance taking in conversation: From 

subjectivity to intersubjectivity. Text & Talk. 26, 6 (2006), 

699–731. 

[24] Knight, S. et al. 2014. Epistemic Networks for Epistemic 

Commitments. International Conference of the Learning 

Sciences (Boulder, CO, 2014). 

[25] Knight, S. and Mercer, N. Forthcoming. The role of 

exploratory talk in classroom search engine tasks. 

Technology, Pedagogy and Education. (Forthcoming). 

[26] Kobayashi, K. 2014. Students’ consideration of source 

information during the reading of multiple texts and its 

effect on intertextual conflict resolution. Instructional 

Science. 42, 2 (2014), 183–205. 

[27] Lawless, K.A. et al. 2012. Assessing multiple source 

comprehension through evidence-centered design. 

Reaching an understanding: Innovations in how we view 

reading assessment. J. Sabatini P... et al., eds. Rowman & 

Littlefield. 3–17. 

[28] Lin, C. and Tsai, C. 2008. Exploring the Structural 

Relationships between High School Students’ Scientific 

Epistemological Views and their Utilization of 

Information Commitments toward Online Science 

Information. International Journal of Science Education. 

30, 15 (2008), 2001–2022. 

[29] Linn, R.L. et al. 1991. Complex, Performance-Based 

Assessment: Expectations and Validation Criteria. 

Educational Researcher. 20, 8 (Nov. 1991), 15–21. 

[30] Littleton, K. and Howe, C. 2010. Educational dialogues: 

understanding and promoting productive interaction. 

Routledge. 

[31] Mason, L. et al. 2011. Epistemic beliefs in action: 

Spontaneous reflections about knowledge and knowing 

during online information searching and their influence on 

learning. Learning and Instruction. 21, 1 (Feb. 2011), 

137–151. 

[32] Mason, L. et al. 2009. Epistemic metacognition in context: 

evaluating and learning online information. Metacognition 

and Learning. 5, 1 (Jul. 2009), 67–90. 

[33] Mercer, N. and Littleton, K. 2007. Dialogue and the 

Development of Children’s Thinking: A Sociocultural 

Approach. Routledge. 

[34] Michaels, S. et al. 2002. Accountable talk: classroom 

conversation that works. Pittsburg: University of 

Pittsburgh. (2002). 

[35] Mislevy, R. et al. 2012. Design and discovery in 

educational assessment: evidence-centred design, 

psychometrics, and educational data mining. Journal of 

Educational Data Mining. 4, 1 (2012), 11–48. 

[36] OECD 2013. PISA 2015: Draft reading literacy 

framework. OECD Publishing. 

[37] Pellegrino, J.W. 2013. Measuring What Matters in a 

Digital Age: Technology and the Design of Assessments 

for Multisource Comprehension. Ubiquitous and Mobile 

Learning in the Digital Age. D.G. Sampson et al., eds. 

Springer. 259–286. 

[38] Resnick, L.B. 2001. Making America smarter: The real 

goal of school reform. Developing minds: A resource book 

for teaching thinking. (2001), 3–6. 

[39] Rouet, J.-F. 2006. The Skills of Document Use: From Text 

Comprehension to Web-Based Learning. Routledge. 

[40] Rouet, J.-F. and Britt, M.A. 2011. Relevance processes in 

multiple document comprehension. Text relevance and 

learning from text. M.T. McCrudden et al., eds. 

Information Age Publishing (IAP). 19–52. 

[41] Shah, C. 2010. Coagmento-a collaborative information 

seeking, synthesis and sense-making framework. 

Integrated demo at CSCW. (2010), 6–11. 

[42] Snow, C. 2002. Reading for Understanding. Towards an 

R&D Program in Reading Comprehension. DTIC 

Document. 

[43] Stecher, B. 2010. Performance assessment in an era of 

standards-based educational accountability. Standford 

Center for Opportunity Policy in Education. (2010). 

[44] Van Strien, J. et al. 2012. Do prior attitudes influence 

epistemic cognition while reading conflicting 

information? (2012). 

[45] Strømsø, H.I. et al. 2011. Do students’ beliefs about 

knowledge and knowing predict their judgement of texts’ 

trustworthiness? Educational Psychology. 31, 2 (2011), 

177–206. 

[46] Tsai, P.-S. et al. 2011. The correlates of Taiwan teachers’ 

epistemological beliefs concerning Internet environments, 

online search strategies, and search outcomes. The 

Internet and Higher Education. 14, 1 (Jan. 2011), 54–63. 

[47] Tseng, J.C.R. et al. 2009. META-ANALYZER: A WEB-

BASED LEARNING ENVIRONMENT FOR 

ANALYZING STUDENT INFORMATION 

SEARCHING BEHAVIORS. Computing, Information 

and Control. 5, 3 (2009), 567–579. 

[48] Walraven, A. et al. 2008. Information-problem solving: A 

review of problems students encounter and instructional 

solutions. Computers in Human Behavior. 24, 3 (2008), 

623–648. 

[49] Winne, P.H. 2010. Improving measurements of self-

regulated learning. Educational Psychologist. 45, 4 

(2010), 267–276

245





