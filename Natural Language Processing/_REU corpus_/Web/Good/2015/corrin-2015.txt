
How do students interpret feedback delivered via 
dashboards? 

 

Linda Corrin 
 Melbourne Centre for the Study of Higher Education 

The University of Melbourne 
Melbourne, Victoria, Australia 

lcorrin@unimelb.edu.au 

Paula de Barba 
Melbourne Centre for the Study of Higher Education 

The University of Melbourne 
Melbourne, Victoria, Australia 

paula.de@unimelb.edu.au 
 

ABSTRACT 
Providing feedback directly to students on their engagement and 
performance in educational activities is important to supporting 
students’ learning. However, questions have been raised whether 
such data representations are adequate to inform reflection, 
planning and monitoring of students’ learning strategies. In this 
poster we present an investigation of how students interpret 
feedback delivered via learning analytics dashboards. The findings 
indicated that most students were able to articulate an 
interpretation of the feedback presented through the dashboard to 
identify gaps between their expected and actual performance to 
inform changes to their study strategies. However, there was also 
evidence of uncertain interpretation both in terms of the format of 
the visualization of the feedback and their inability to understand 
the connection between the feedback and their current strategies. 
The findings have been used to inform recommendations for ways 
to enhance the effectiveness of the delivery of feedback through 
dashboards to provide value to students in developing effective 
learning strategies to meet their educational goals. 

Categories and Subject Descriptors 
K.3.1 Computer uses in education  

General Terms 
Design, Human Factors. 

Keywords 
Learning analytics, feedback, dashboards, self-regulated learning. 

1. INTRODUCTION 
The use of learning analytics to provide feedback directly to 
students on their learning engagement and performance is a 
rapidly expanding area of development. Much of the initial focus 
of learning analytics tool development concentrated on delivering 
data about students’ activities to academics and institutions, 
mostly to support student retention [1]. However, new tools are 
now emerging that give students direct access to data on their 

assessment performance and engagement in activities delivered 
via learning management systems (LMS) and other online learning 
and assessment tools. A popular format for the delivery of such 
feedback to students is a dashboard that visualizes multiple 
sources of data about students’ engagement and performance in a 
single consolidated view.  

The purpose of the research was to develop a greater 
understanding of how students interpret feedback delivered 
through learning analytics dashboards and the influence this has 
on their learning strategies and motivation. The research was 
guided by three main research questions:  

1. How do students interpret feedback delivered through learning 
analytics dashboards? 

2. What actions do students take in response to dashboard 
feedback? 

3. How do access to dashboard feedback influence students’ 
motivation and performance in their course? 

This poster presents results for the first of these research questions 
considering the ways that students interpreted the data presented 
through the dashboard. By understanding more about how 
students interpret the different presentations of dashboard 
feedback, and areas where they struggle to interpret the data, 
recommendations can be made for future dashboard design as well 
as areas for student learning support. 

2. METHOD 
2.1 Participants 
The study was conducted in two large undergraduate subjects at 
the University of Melbourne in the first semester of the 2014 
academic year. The subjects, a first-year biology subject and a 
second-year Japanese language subject, were both delivered in a 
blended learning format incorporating online activities as well as 
face-to-face lectures, tutorials, labs and/or workshops. A total of 
24 students were recruited to participate in this study with 14 
students from Biology and 10 students from Japanese.  

2.2 Dashboard Design 
The dashboard design was primarily influenced by the learning 
design of the subjects and the data available from the Blackboard 
Learning Management System. The different learning activities in 
each subject resulted in variation in the layout and included data in 
the dashboard for each subject (see figures 1 and 2). The 
dashboards were populated with data on students’ assessment 
performance (both formative and summative) and their online 
engagement extracted from the LMS. 

 

Permission to make digital or hard copies of part or all of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. Copyrights 
for third-party components of this work must be honored. For all other 
uses, contact the Owner/Author.  
 
Copyright is held by the owner/author(s). 
LAK '15, Mar 16-20, 2015, Poughkeepsie, NY, USA 
ACM 978-1-4503-3417-4/15/03. 
http://dx.doi.org/10.1145/2723576.2723662 

430



2.3 Data Collection Procedures 
A mixed-methods approach was used in this study with four 
sequential phases. The first phase involved an online survey of 
participants, which was administered in the third week of the 
semester. The second phase took place in week six of the semester 
and involved an interview where participants were presented with 
a dashboard of their own data and asked to reflect on their 
interpretation of the data using the ‘think aloud’ interview method 
[4]. The third phase of the study involved a second interview, 
which took place in week 11. This interview followed a similar 
structure to the first interview, however before the participants 
were shown their updated dashboard, they were asked several 
questions about the actions they had taken in response to the first 
interview and the impact these had on their performance and 
motivation towards the subject. The final phase of the study 
involved a second online survey, which was distributed after the 
participants had received their final marks for the subject. In this 
survey the participants were asked to reflect on the usefulness of 
having access to the dashboard throughout the semester in light of 
their final grade and the impact that it had on their study 
strategies. 

3. RESULTS 
A thematic analysis was conducted on the data from across the 
four phases of the study to address the first research question, 

which asked how students interpret feedback delivered through 
learning analytics dashboards. Through the analysis of the 
interview and survey data it was found that there was diversity in 
participants’ strategies and ability to interpret the feedback. The 
majority of participants (83%) were able to offer an explanation 
for the feedback taking into consideration their judgment of the 
value of the activity, their motivation towards the subject, and 
external factors that impacted their ability to engage in the 
activity. However, there were also four out of the 24 participants 
who struggled to interpret the feedback in a way that would allow 
them to determine appropriate strategies to address the gap in their 
learning. An element of the dashboard that had a major influence 
on participants’ interpretation of the feedback was provision of the 
class average. This influence was positive to most students’ 
motivation (88%), but also caused distraction for some students 
(50%) from their overall performance goal. 
 

4. CONCLUSION 
Despite the concerns raised in the literature about students’ 
inability to meaningfully interpret feedback in this form and to 
translate this into strategies to improve their learning [2, 3], the 
findings from this study have shown that the majority of students 
were able to identify gaps in their performance. These students 
were able to attribute intrinsic or extrinsic reasons to link their 
performance with their study strategies and determine a course of 
action. However, there was also evidence of uncertainty in 
interpretation of feedback, both due to difficulty in interpreting the 
ways the data had been visualized as well as difficulty in linking 
the feedback to their learning strategies. Therefore, when 
dashboards are made available to students, it is recommended that 
support resources are provided and processes established.  

There are still many challenges to identifying the best types of 
feedback to deliver via dashboard applications. However, the 
indication of the usefulness of dashboard feedback to students 
found in this study indicates that further exploration of the 
possibilities is worthwhile. 

5. ACKNOWLEDGMENTS 
Our thanks to Tania Fernando for assistance with the dashboard 
development, and Dr Abi Brooker for assistance with processing 
the interview data. This research was funded through an early 
career academic grant from the University of Melbourne.  

6. REFERENCES 
[1] Bichsel, J. 2012. Analytics in Higher Education: Benefits, 

Barriers, Progress, and Recommendations (Research 
Report), Louisville, CO: EDUCAUSE Centre for Applied 
Research. Retrieved from 
http://net.educause.edu/ir/library/pdf/ERS1207/ers1207.pdf. 

[2] MacNeill, S., Campbell, L., and Hawksey, M. 2014. 
Analytics for Education. Journal of Interactive Media in 
Education, 1-12. 

[3] Corrin, L., Kennedy, G., and Mulder, R. 2013. Enhancing 
learning analytics by understanding the needs of teachers. In 
H. Carter, M. Gosper & J. Hedberg (Eds.), Electric Dreams. 
Proceedings ascilite 2013 Sydney, 201-205. 

[4] Ericsson, K.A., & Simon, H.A. (1980). Verbal reports as 
data. Psychological Review, 87, 215-250. 

 

 

Figure 1. Example of the student dashboard for Biology 

Figure 2. Example of the student dashboard for Japanese 

431





