
From Micro to Macro -
Analyzing Activity in the ROLE Sandbox

Dominik Renzel
Chair of Computer Science 5

Advanced Community Information Systems
D-52056 Aachen, Germany

renzel@dbis.rwth-aachen.de

Ralf Klamma
Chair of Computer Science 5

Advanced Community Information Systems
D-52056 Aachen, Germany

klamma@dbis.rwth-aachen.de

ABSTRACT

Current learning services are increasingly based on standard
Web technologies and concepts. As by-product of service
operation, Web logs capture and contextualize user interac-
tions in a generic manner, in high detail, and on a massive
scale. At the same time, we face inventions of data standards
for capturing and encoding learner interactions tailored to
learning analytics purposes. However, such standards are
often focused on institutional and management perspectives
or biased by their intended use. In this paper, we argue for
Web logs as valuable data sources for learning analytics on
all levels of Bronfenbrenner’s Ecological System Theory and
introduce a simple framework for Web log data enrichment,
processing and further analysis. Based on an example data
set from a management service for widget-based Personal
Learning Environments, we illustrate our approach and dis-
cuss the applicability of different analysis techniques along
with their particular benefits for learners.

Categories and Subject Descriptors

J.1 [Administrative Data Processing]: Education; C.2.6
[Computer Systems Organization]: Internetworking—
standards; H.3.5 [Information Systems]: Online Informa-
tion Services—Web-based services; K.3.1 [Computing Mi-
lieux]: Computer Uses in Education—collaborative learn-
ing, distance learning

General Terms

Measurement, Human Factors, Standardization

Keywords

learning analytics, ecological systems theory, Web logs, pro-
cessing pipeline, Personal Learning Environment

1. INTRODUCTION
A current trend in the community of Technology-Enhanced

Learning (TEL) is the increasing adoption of distributed

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
LAK ’13, April 08 - 12 2013, Leuven, Belgium
Copyright 2013 ACM 978-1-4503-1785-6/13/04 ...$15.00.

learning service provision based on established Web tech-
nologies, standards, and major architectural concepts. With
the openness and genericity of existing Web standards and
the flexibility of Cloud Computing, there are hardly any
limitations in heterogeneity, deployability and scalability of
learning services. The emergence of Massive Open Online
Courses (MOOC) and Responsive Open Learning Environ-
ments (ROLE) was an obvious result of this combination.
Without any additional instrumentation, such systems al-
ready produce detailed monitoring logs of learner-to-learner
and learner-to-service interaction. Logs yield unprecedented
opportunity for learning analytics on a massive scale and al-
low drill-downs on multiple levels of aggregation, ranging
from micro to macro [9].

However, the development of predictive models alerting
impending risks and recommending appropriate interven-
tions is a task hard to generalize. Existing work in Learn-
ing Analytics describes processes and benefits for particular
learning problems and domains as well as for specific techni-
cal setups. Most approaches adopt the principle of monitor-
ing learner behaviour on an initially high semantic level. To
capture and encode such high-level information for the sake
of convenient analysis, new standards for data models and
accompanying frameworks are developed. However, stan-
dardization processes are time consuming and do not nec-
essarily lead to stable specifications. Following such upris-
ing standards thus entails risks and efforts for organizations
hosting learning services regarding the integration of learn-
ing analytics into their existing systems . Once created and
implemented, unstable standards need frequent adaptation
due to evolutionary processes. Teachers or learners must be
expected to disrupt current learning analytics models and
frameworks due to the typical properties of socio-technical
systems. One common example for disruption is finding
anomalies in terms of unforeseen contexts and methods of
learning service use, which are not captured by the analyt-
ics models and frameworks, although they provide valuable
insights into learner practice.

To avoid the risks and overhead induced by the aforemen-
tioned practice of new standard development, we propose
to take a step back to currently existing standards. We
argue that learning analytics applied to Web-based learn-
ing services should be powered by standard Web data and
frameworks already in wide use among providers and proven
valuable in Web Analytics [9]. Stepping back to standard
low-level Web log data protects analysts from the danger of
losing valuable information in much to early abstraction and
aggregation steps, especially wrt. anomalies representing

250



disturbances of positive or negative nature. We furthermore
argue that every learning analytics model and framework
should support context-aware analysis on multiple abstrac-
tion levels from micro to macro, including intra- and inter-
level relations and show that standard Web logs are suitable
data sources.
In this paper, we discuss our approach toWeb-based learn-

ing analytics, starting with a processing pipeline powered
by Web logs. We demonstrate its application on the ROLE
Sandbox, a widget-based Personal Learning Environments
(PLE) platform. Based on this example scenario, we dis-
cuss potential analysis techniques and their corresponding
benefits.
The rest of this paper is structured as follows. In Sec-

tion 2 we discuss related work motivating our approach. In
Section 3 we describe our general sampling and data process-
ing approach. In Section 4 we present the ROLE Sandbox
dataset and discuss the applicability of analysis techniques
and their benefits. In Section 5 we draw conclusions and
discuss future work.

2. RELATED WORK

2.1 Focus & Level of Analysis
Since learning services on the Web are in principle accessi-

ble to everybody and increasingly social, log data produced
by such systems not only fosters analysis with regard to
particular individuals or institutions, but also allows anal-
ysis on much higher levels such as communities and cul-
tural contexts as well as the relations between them. As
conceptual foundation, we refer to Bronfenbrenner’s Ecolog-
ical Systems Theory (EST) [2] organizing personal devel-
opment in five nested and interrelated ecosystems around
the individual: microsystem (direct relation to peer/group),
mesosystem (entirety of microsystems and relations between
them), exosystem (a network the individual does not belong
to, but is indirectly influenced by), macrosystem (entirety
of all relations in a society incl. norms, rules, traditions,
ideologies, etc.), and chronosystem (temporal dimension of
development). Consequently, every individual is part of mul-
tiple nested communities with a certain focus and practice.
Wenger’s Community of Practice (CoP) [21] concept with
its main characteristics of mutual engagement, shared reper-
toire and joint enterprise models the inner workings of such
communities and allows to focus analysis of learning to par-
ticular domains. Using EST and CoP, we imply that log
data recorded on the micro-level is the basis for different
levels of analysis up to the macro-level. While most existing
work only takes selected levels into consideration (e.g. [18,
14, 1, 5]), we argue that a comprehensive learning analytics
framework should allow focus, analysis and drill-down on all
levels. With low-level Web protocol log data, a by-product of
service operation enrichable with externally available meta-
data on entities and activities, we can capture and identify
phenomena on all levels and with different foci by apply-
ing certain aggregation lenses and filters on data. However,
aggregation and filtering cause the danger of washing out
anomalies contained in the data. Snow’s master-piece of
empirical data analysis to investigate the cause of a cholera
epidemy in London [10] highlights the importance of micro-
level data explaining effects on higher levels. By investigat-
ing anomalies in death certificates and maps, Snow found a
particular water pump as cause of a severe cholera epidemy

in London and at the same time could reject the contempo-
rary miasma theory of cholera spreading.

By analogy, we argue that learning analytics may not ne-
glect micro-level data, since only the detection of exceptional
phenomena allows for targeted intervention planning on all
levels.

2.2 Timeliness of Analysis
Principally there exist multiple approaches for learning

analytics especially differing in timeliness of analysis results.
The ideal situation is to receive real-time information on the
state of an individual learner, a class, etc. (cf. Sectio 2.1) to
be able to come up with interventions as quickly as possible
or even better to predict if interventions will be necessary
in near future. We develop and constantly refine the Mob-
SOS model and test-bed [16], which. The main rationale
behind this approach is to perform community-aware quali-
tative and quantitative measurement and research on factors
relevant for community service success, mainly by borrowing
from traditional conceptual models for management infor-
mation systems [4]) and modern Web Analytics [9]. State-of-
the-art Web analytics measure key performance indicators
such as conversion as proxies for success in reaching par-
ticular, mostly profit-oriented goals. Timeliness of analysis
results is an essential competitive advantage in a fast-moving
economy. Definitely, the goal of maximizing learning success
in learning services is different and hard to measure, but the
key principle is the same. In the case of learning services the
goal is to maximize student success, and learning analytics
consists in observing the performance of individual learners
or learner populations for the early detection of issues and
recommendation of interventions. Also here, timeliness is
essential, e.g. for avoiding premature dropouts of learners
due to frustration. It should be noted that different learn-
ing services employ different success factors and even have to
differentiate between different CoPs using learning services
for particular contexts and purposes. The additional analy-
sis of data created in the past, possibly with other services
than the one under consideration additionally reveals help-
ful insights for improving present learning. For example by
crawling different Web media and mining for patterns of in-
teraction between users, communities and artifacts systems
like our Mediabase can help identify agent roles such as ques-
tioner, answerer, or malicious trolls [11] as well as learning
goals and phases [12], and thus support recommendations to
learners and other stakeholders.

We argue that any learning analytics framework must take
into account a combination of both real-time and historical
log data for the sake of improved precision, predictive qual-
ity, and qualified recommendations for future action.

2.3 Data Interoperability
One issue in current learning analytics approaches is the

acquisition and analysis of proprietary data customized to
specific learning scenarios and technical setups. In typical
scenarios, multiple Web-based learning services are com-
bined in learning applications, but monitored separately.
The absence standards agreed among services renders cross-
service analysis practically unfeasible. Surprisingly, the use
of internationally agreed and well-accepted standards is of-
ten neglected, although analysis would largely benefit [6].
Current approaches to create cross-service log data inter-
operability employ proprietary or Semantic Web-compliant

251



data modeling [22, 19]. Although inferences are more con-
venient, these approaches first require the development of
respective domain ontologies and the encoding of data com-
pliant with such ontologies. Any new standard requires care-
ful design and planning for extensibility of the underlying
monitoring model. If such extensibility is not given, any ex-
tension of the system itself will require additional work on
the extension of the corresponding monitoring data model.
The major advantage of using established standard proto-
col log data is their inherent genericity and widespread use.
The downside is that higher-level learner interaction seman-
tics are not immediately accessible and must be mined from
the raw data. However, the application of RESTful princi-
ples such as standardized URI syntax and uniform interfaces
with well-defined operational semantics [8] eases such tasks
tremendously, as we demonstrate in Section 4.
Thus, we argue that convenience with early lifting of anal-

ysis data to higher-level semantics in proprietary formats is
bought for the price of higher efforts in data encoding and
collection mechanisms and a lack of interoperability in cross-
service analysis. The approach we promote in this paper is
thus to rely on simple, standard log formats with wide up-
take by service providers.

2.4 Opacity and Uncertainty
According to our observations, there exists a certain opac-

ity relationship between media and artifacts on the one hand
and users and communities on the other, when we consider
traces of user interactions. Usually, we can unambiguously
reconstruct interactions between media and artifacts. How-
ever, the identity of real users and communities behind inter-
actions is often opaque and uncertain [3]. This relationship
becomes apparent in current MOOCs (Massive Open On-
line Courses), where learners join courses, interact with on-
line learning resources and receive certificates after success-
ful completion. Especially the uncertainty regarding user
authenticity is a weakspot of MOOCs. Learners can the-
oretically repeat tests with an arbitrary number of online
identities, until they ultimately achieve perfect grades. The
same uncertainty applies for tracking whole interaction his-
tories of individuals, ideally performed across distributed
systems. Service providers of today - themselves also rely-
ing on other services - increasingly fight this uncertainty by
relying on central authentication and authorization services
and additonally include technical means for recording client-
side activity (e.g. cookies, page tagging) [9]. However, such
technical means are often not yet in place.
We argue that the analysis of detailed low-level logs does

not yield perfect precision, but still allows sufficiently precise
identification of structural or behavioral patterns allowing
inferences to both the visible and opaque parts of the model,
especially when moving upwards in the levels of analysis.

3. LOG DATA PROCESSING PIPELINE
In this section we present our sampling and processing

pipeline based on Web logs. In general, we pursue a bottom
up approach of real-time pre-processing and persistence of
raw data for later analysis on different levels. In this work
we consider the generic use case of learners interacting with
learning resources (e.g. tools, data, peers) via RESTful Web
services [8]. Web servers host services and log all HTTP pro-
tocol communication with the services in tabular Web logs.
A single log entry represents a request/response pair. We are

?
?
?
?
?
??
?

?
?	
?
?
?
?
??
?

?
?
?
?
??



?
?
?
??
?
??
	?


??

?
?
?
??
?
??
	?


??

?
?
?
??
?
??
	?


?

??????	??	

????????????

Figure 1: Real-time log data processing pipeline

aware that current Web-based learning applications increas-
ingly incorporate other protocols, e.g. for real-time support
in instant messaging or video conferencing [17]. In previ-
ous work we successfully monitored communication via the
Extensible Messaging and Presence Protocol (XMPP) [17],
confirming the general applicability of our approach.

To collect, process and enrich log data we use a chain
of shell scripts employing the UNIX pipe concept (cf. Fig-
ure 1). The first basic elements tokenize raw log data into
a CSV format, filter noise, and persist relevant entries in a
log database.

The first important task of an analyst consists in filtering
noise, i.e. dropping irrelevant entries. Depending on the fo-
cus of analysis in later stages, the amount of dropped entries
varies. However, we argue that in this early stage as much
valuable raw data as possible should be kept. Examples of
noise are entries representing access to static content such
as libraries, stylesheets, favicons, etc. Such entries usually
do not yield much information on learner behaviour, but are
frequently occurring in the data. It should be noted that fil-
tering implies an important decision regarding the trade-off
between data richness and later analysis runtime optimiza-
tion.

Once log data is tokenized and filtered, it is stored in a
database and passed to piped through a sequence of addi-
tional processing scripts. In general, scripts are only limited
by the set of available commands. However, typical tasks
include querying past log data or storing additional data
such as metadata on entities, higher-level views, etc. Tasks
realized by these scripts include enrichment, analysis, vi-
sualization, and possibly the creation of added value from
analysis results. A simple, yet powerful example of such a
processing script is the enrichment of logged IPs with geo-
spatial context information retrieved from an external Web
service. Other scripts implemented for this work (cf. Sec-
tion 4) extract higher-level semantics of learner activity and
store them in separate tables for more convenient analysis.

4. THE ROLE SANDBOX DATASET
In this section we discuss our approach on a concrete

dataset collected in eleven months of operation of the ROLE
Sandbox. In particular, we demonstrate how data can be
enriched, how higher-level information can be extracted and
how we can make reasonable use of the generated informa-

252



Table 1: Examples of low-level requests and high-level activity semantics

GET /spaces/<space-id>/<data-id> load data item in collaborative space

POST /spaces/<space-id>:;tool=<tool-url> add widget to collaborative space

DELETE /people/<person-id>/<tool-id> remove widget from personal space

PUT /spaces/<space-id>/<data-id>:;representation update data item in collaborative space

tion for learning analytics with the goal to create benefit for
learners and other stakeholders.

4.1 Background
The ROLE Sandbox is a Web platform for managing and

using widget-based Personal Learning Environments (PLE).
As such, it was the target learning service monitored by
our approach for this work. Learners coming from diverse
CoP can create well-defined personal or collaborative learn-
ing contexts (spaces in ROLE terminology) and orchestrate
learning widgets with limited functionality to complete envi-
ronments for accomplishing complex learning tasks. A space
with four widgets supporting a collaborative physics learn-
ing activity among eleven members is depicted in Figure 2.
Learners can carry out learning tasks using widgets, commu-
nicate with each other, access learning resources and config-
ure their collaborative or personal widget dashboards. In
the example of Figure 2, learners can collaboratively watch
videos, create notes, navigate maps, and create drawings.
PLE management and the functionality of individual wid-
gets are powered by RESTful Web services for resource man-
agement [15], with people and spaces being resource special-
izations.

4.2 Log Content & Enrichment
Data fields logged per default are request time, origin IP

address, request method, response status, request URL, ref-
erer URL, and user agent. For most Web servers, the log file
format can be extended by additional information such as
request/response headers. Each entry describes the interac-
tion of an agent with a resource incl. context information.
This basic information can be enriched with additional con-
text or metadata by making use of third Web services, e.g.
IP geolocation services. In particular for RESTful services,
tuples of request method and URL encode higher-level op-
erational and structural semantics. Given standard protocol
semantics, a generic interpretation is even possible without

Figure 2: Learner collaboration in a ROLE space

further knowledge on the type of accessed resources. Table 4
provides examples for low-level request patterns and their
high-level semantics. Altogether, we classified 37 distinct
request patterns in ROLE Sandbox data. For data enrich-
ment this work includes several custom processing scripts.
An IP geolocation script retrieves geospatial information for
IP addresses. Other processing scripts realize the extraction
of higher-level learner interaction semantics given RESTful
request patterns. Finally, a widget metadata script retrieves
information on widget functionality, purpose and application
domain, thus allowing the inclusion of such information in
learning analytics.

4.3 Log Analysis & Stakeholder Benefits
From studying single operations we can infer interactions

on the micro-level. With appropriate aggregation and in-
clusion of contextual data we can perform analysis up to
the macro level. We cannot only see which learners in-
teracted with which resources, but also how and in which
context. From studying relations emerging from single op-
erations (e.g. users having used the same widgets), we can
derive networks enabling Social Network Analysis, in turn
revealing social structures among agents, either human or
machine. With URLs being substantial part of the mon-
itoring data, we are enabled to follow links to resources
learners consulted or produced. Apart from typical statis-
tical analysis, following the Hypermedia As The Engine Of
Application State (HATEOAS) [8] principle, linking struc-
tures in log data allow the derivation of actor networks [13]
and their analysis with SNA techniques [20, 7]. Thereby,
logs yield access to valuable insights into the structure of
learning networks evolving from the constant interaction of
multiple agents (e.g. persons, tools, spaces) in certain learn-
ing contexts, altogether establishing learning CoP [21].The
additional availability of contextual details such as spatio-
temporal information allows for the analysis of patterns on
a global (macro) scale. Time series analysis becomes pos-
sible, orthogonal to other analysis techniques. We success-
fully applied timeseries analysis and SNA to a small selec-
tion of networks derivable from the data, e.g. widget co-use
or learner collaboration, showing the emergence of multiple
communities active in the Sandbox. Analysis results can be
synthesized in comprehensive visualizations creating aware-
ness or serve as input to recommender systems for learning
peers, tools or resources in general.

5. CONCLUSIONS
In this paper we first analyzed existing issues in learning

analytics approaches on the aspects of focus, level, opacity,
uncertainty, timeliness and data interoperability. Regard-
ing focus and level of analysis we referred to Bronfenbren-
ner’s Ecological system theory [2] and required data to be
designed for analysis on all levels from micro to macro as
well as the orthogonal chrono level is possible and that such

253



information not only serves the improvement of individual
learning, but also the practice of learner communities as a
whole. Regarding timeliness we argue for a combination of
real-time and historical data in any learning analytics frame-
work for higher precision. Regarding data interoperability,
we argue that standard protocol logs are preferable over pro-
prietary datasets due to their genericity and suitability for
the joint analysis of multiple related learning services. After
an introduction to our processing pipeline enabling learning
analytics on Web logs, we demonstrated its application in
the ROLE Sandbox scenario and briefly discussed potential
benefits for different learning stakeholders.
From a total of 6.7?106 ROLE Sandbox requests recorded

since March 2012, 1.7 ? 106 (18%) relevant requests came
from 3200 distinct IPs in 82 countries and 462 cities. With
the availability of a suitable sampling approach, we will con-
tinue to record logs and focus on different modes of analysis
on the ROLE Sandbox dataset in future work.

6. ACKNOWLEDGMENTS
The research leading to these results has received funding

from the European Community’s Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement no 231396
(ROLE project).

7. REFERENCES

[1] R. Breuer, R. Klamma, Y. Cao, and R. Vuorikari.
Social Network Analysis of 45,000 Schools: A Case
Study of Technology Enhanced Learning in Europe. In
U. Cress, V. Dimitrova, and M. Specht, editors,
Learning in the Synergy of Multiple Disciplines,
Proceedings of 4th European Conference on Technology
Enhanced Learning, EC-TEL 2009, Nice, France,
September/October 2009, volume 5794 of Lecture
Notes in Computer Science, pages 166–180, 2009.

[2] U. Bronfenbrenner. The Ecology of Human
Development. Harvard Univ. Pr, Cambridge and Mass,
4 edition, 1981.

[3] Y. Cao, A. Glukhova, R. Klamma, and Z. Petrushyna.
Getting to “Know” People on the Web 2.0. In
H. Maurer, F. Kappe, W. Haas, and K. Tochtermann,
editors, Proceedings of I-Know’08 and I-Media’08,
International Conferences on Knowledge Management
and New Media Technology, Graz, Austria, September
3-5, 2008, pages 169–176. Journal of Universal
Computer Science (J.UCS), 2008.

[4] W. H. Delone and E. R. McLean. Information Systems
Success: The Quest for the Dependent Variable.
Information Systems Research, 3(1):60–95, 1992.

[5] M. Derntl and R. Klamma. Social Network Analysis of
European Project Consortia to Reveal Impact of
Technology-Enhanced Learning Projects. In
C. Giovannella, D. G. Sampson, and I. Aedo, editors,
ICALT, pages 746–747. IEEE, 2012.

[6] E. Duval and K. Verbert. On the Role of Technical
Standards for Learning Technologies. IEEE
Transactions on Learning Technologies, 1:229–234,
2008.

[7] R. Ferguson and S. B. Shum. Social Learning
Analytics: Five Approaches. In Proceedings of the 2nd
International Conference on Learning Analytics and

Knowledge, LAK ’12, pages 23–33, New York, NY,
USA, 2012. ACM.

[8] R. T. Fielding. Architectural Styles and the Design of
Network-based Software Architectures. PhD thesis,
University of California, Irvine, California, USA, 2000.

[9] B. J. Jansen. Understanding User-Web Interactions
via Web Analytics. Synthesis Lectures on Information
Concepts, Retrieval, and Services, 1(1):1–102, 2009.

[10] John Snow. On the Mode of Communication of
Cholera. John Churchill, New Burlington Street,
London, 2nd edition, 1855.

[11] R. Klamma, M. Spaniol, Y. Cao, and M. Jarke.
Pattern-Based Cross Media Social Network Analysis
for Technology Enhanced Learning in Europe. In
W. Nejdl and K. Tochtermann, editors, Innovative
Approaches for Learning and Knowledge Sharing,
volume 4227 of Lecture Notes in Computer Science,
pages 242–256. Springer Berlin / Heidelberg, 2006.

[12] J. Krenge, Z. Petrushyna, M. Kravcik, and
R. Klamma. Identification of Learning Goals in
Forum-based Communities. In Advanced Learning
Technologies (ICALT), 2011 11th IEEE International
Conference on, pages 307–309. IEEE Computer
Society, 2011.

[13] B. Latour. On Recalling ANT. In J. Law and
J. Hassard, editors, Actor-Network Theory and After,
pages 15–25. Oxford, 1999.

[14] E. Loken, F. Radlinkski, V. H. Crespi, J. Millet, and
L. Cushing. Online study behaviour of 100,000
students preparing for the SAT, ACT, and GRE.
Journal of Educational Computing Research,
30(3):255–262, 2004.

[15] F. Mo?dritscher. ROLE Deliverable D4.5/7.4 -
Reference implementation of mash-up personal
learning environments to foster the broad community
uptake. Technical report, ROLE Project, 2012.

[16] D. Renzel, R. Klamma, and M. Spaniol. MobSOS - A
Testbed for Mobile Multimedia Community Services.
In 2008 Ninth International Workshop on Image
Analysis for Multimedia Interactive Services, pages
139–142. IEEE, 2008.

[17] P. Saint-Andre. RFC 6120 - Extensible Messaging and
Presence Protocol (XMPP): Core. Technical report,
Internet Engineering Taskforce, Mar 2011.

[18] S. Schrire. Interaction and cognition in asynchronous
computer conferencing. Instructional Science,
32(6):475–502, 2004.

[19] J. Snell, M. Atkins, W. Norris, C. Messina,
M. Wilkinson, and R. Dolin. JSON Activity Streams
1.0. Technical report, Activity Streams Working
Group, May 2011.

[20] S. Wasserman and K. Faust. Social Network Analysis:
Methods and Applications. Cambridge University
Press, Cambridge, 1994.

[21] E. Wenger. Community of Practice: Learning,
Meaning, and Identity. Cambridge University Press,
Cambridge, 1998.

[22] M. Wolpers, J. Najjar, K. Verbert, and E. Duval.
Tracking Actual Usage: the Attention Metadata
Approach. Educational Technology & Society,
10(3):106–121, 2007.

254





