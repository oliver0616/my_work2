
Curriculum Analysis of CS Departments Based on CS2013
by Simplified, Supervised LDA

Takayuki Sekiya
Information Technology

Center,
the University of Tokyo
3-8-1 Komaba, Meguro,

Tokyo, Japan
sekiya@ecc.u-tokyo.ac.jp

Yoshitatsu Matsuda
Graduate School of Arts and

Sciences,
the University of Tokyo
3-8-1 Komaba, Meguro,

Tokyo, Japan
matsuda@graco.c.u-

tokyo.ac.jp

Kazunori Yamaguchi
Graduate School of Arts and

Sciences,
the University of Tokyo
3-8-1 Komaba, Meguro,

Tokyo, Japan
yamaguch@graco.c.u-

tokyo.ac.jp

ABSTRACT
The curricula higher educational institutions offer is a key as-
set in enabling them to systematically educate their students.
We have been developing a curriculum analysis method that
can help to find out differences among curricula. On the
basis of “Computing Science Curricula CS2013”, a report re-
leased by the ACM and IEEE Computer Society, we applied
our method to analyzing 10 computer science (CS) related
curricula offered by CS departments of universities in the
United States. Using the method enables us to compare
courses across universities. Through an analysis of course
syllabi distribution, we found that CS2013 uniformly covered
a wide area of computer science. Some universities empha-
sized human factors, while others attached greater impor-
tance to theoretical ones. We also found that some CS depart-
ments offered not only a CS curriculum but also an electrical
engineering one, and those departments showed a tendency
to have more “Architecture and Organization (AR)” related
curricula. Furthermore, we found that even though “Infor-
mation Assurance and Security (IAS)” has not yet become a
very popular field, some universities are already offering IAS
related courses.

Categories and Subject Descriptors
K.3.2 [Computers and Education]: Computer and Informa-
tion Science Education—curriculum

General Terms
Experimentation

Keywords
Syllabus, Curriculum, Curriculum Analysis, Supervised LDA

1. INTRODUCTION
The curricula higher educational institutions offer is the

key asset in enabling them to systematically educate their

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
LAK’15, March 16–20, 2015, Poughkeepsie, NY, USA
Copyright 2015 ACM 978-1-4503-3417-4/15/03...$15.00
http://dx.doi.org/10.1145/2723576.2723594

students. A wide variety of activities and studies on curricula
have been carried out, such as the development of national
curricula and methodologies for faculties to design curricula
[11].

For over 40 years, the ACM and IEEE Computer Society
jointly have been working on curricular guidelines for un-
dergraduate programs in computer science (CS) and have
been releasing reports as their work results on around a ten-
year cycle. The latest work is the report “Computing Science
Curricula CS2013” released in December 2013 [1].

We consider that curriculum guidelines like CS2013 can be
the foundation for universities to analyze their own curricula
and design new curricula. For analyzing curricula, we de-
veloped a web-based curriculum analysis tool based on the
method we reported in [13]. Using the tool, we analyzed the
curricula of MIT and those of the Open University (OU) on
the basis of the Body of Knowledge (BOK) of CS2008, and
found the characteristics of these universities [12]. For exam-
ple, the OU offered many courses in “Network Computing”,
“Computation Science” and “Social and Professional Issues”,
but few courses in “Discrete Structures.” This practical na-
ture of courses in OU is consistent with the fact that about 70
percent of OU undergraduates are in full-time employment.

We also applied our method to analyzing CS related curric-
ula of universities in Japan [14] on the basis of two computing
curricula, J07-CS in the CS field [4] and J07-IS in the informa-
tion system field [7], both developed by IPSJ. The obtained
results showed that our analysis revealed characteristics of
each department, such as “emphasizing application skills
of computers” and “researching computer and information
themselves.”

In the work reported in this paper, we used CS2013 as a ba-
sis for applying our curriculum analysis method to analyzing
CS related curricula offered by CS departments of the top 10
universities in the United States. Using the method enabled
us to compare courses across universities on the basis of the
common BOK of the computing curricula. We analyzed the
word distribution of syllabi in a topic space and found that
CS2013 uniformly covered a wide area of CS. MIT and Stan-
ford emphasized human factors, while CMU attached greater
importance to the theoretical ones. We also found some CS
departments offered not only a CS curriculum but also an
electrical engineering one, and those departments showed
a tendency to have more “Architecture and Organization
(AR)” related curricula. Furthermore, even though “Infor-

330



mation Assurance and Security (IAS)” has not yet become a
very popular field, some universities are already offering IAS
related courses.

The rest of this paper is organized as follows. In Section
2, we review related work. In Section 3, we explain the ba-
sic theories of our method and show that we improved our
curriculum analysis method by using a simplified version of
supervised LDA (ssLDA) [15, 2]. Experiment results are de-
tailed in Section 4, and Section 5 concludes the paper with a
summary of key points.

2. RELATED WORK
A number of studies have been made on methodologies

and tools for analyzing curricula by using statistically pro-
cessed syllabus data [16, 6, 10]. The approach we use enables
us to use this data to compare courses and curricula offered
by different universities.

Many educators in the CS field have read the CS2013 re-
port and some of them contributed their knowledge to it. For
example, Marshall tried to quantify the changes in the CS
structure of the ACM/IEEE curricula series [8]. He focused
attention on the BOK of computing curricula and visualized
the structure of the curricula. However, he modeled Knowl-
edge Areas (KAs) of BOK as a network graph to represent
Knowledge Units (KUs) and topics as edges of the graph in
the BOK. In applying his method to comparing the computing
curricula, it was necessary to identify corresponding topics
among the curricula. On the other hand, our method deals
with curricula merely as a set of syllabus documents, and no
identification is needed.

Gluga et al. developed a web-based system called PRO-
GOSS that maps curricula learning goals and mastery levels
to individual assessment tasks across entire degree programs
[5]. The PROGOSS system has a function for educators to
map prerequisites and goals of their courses into CS2013. Our
curriculum analysis method shows the differences among
computing curricula series, and it will help users of PRO-
GOSS to modify an old curriculum based on past computing
curricula.

Mendez et al. reported that they applied several learning
analytic techniques to a curriculum [9]. They used the long-
standing grade data of students in their institution for the
curriculum analysis, and were to inform faculty members
of their research results to improve their curriculum. We
believe that comparing different curricula is a useful means
for achieving such curriculum improvements.

3. CURRICULUM ANALYSIS
3.1 Acquiring Course Syllabi Sets

In this research, we analyzed several curricula offered by
CS departments on the basis of CS2013. We referred to an
article titled “Computer Rankings, Best Undergraduate En-
gineering Programs”1 and chose the top 10 universities in the
rankings as study subjects. Table 1 lists the universities and
the relevant departments of each. In the rest of this paper we
use the IDs in the rightmost column of the table to specify a
university.

In applying our curriculum analysis method, we regarded
a curriculum as a course syllabi set. We downloaded web

1U.S.News & World Report, http://colleges.usnews.
rankingsandreviews.com/best-colleges/rankings/
engineering-doctorate-computer (accessed 2014-08-25)

pages from each department’s website and from them ex-
tracted course descriptions. Though students cannot take the
courses freely, for simplicity we did not take such details into
consideration.

3.2 Method
3.2.1 Outline

Here, we will described the details of the analysis method
by using a machine learning approach. First, every syllabus
is regarded as a set of used words (namely, the bag of words
model). Then, each syllabus is projected to a point in the topic
space defined by CS2013. Latent Dirichlet allocation (LDA)
[3] is employed for this projection. LDA is widely used in
natural language processing and machine learning and is
known to be useful for extracting the topic space from a set of
reference documents and projecting other documents to the
extracted space. However, the original LDA is designed to ex-
tract the topics automatically. On the other hand, the topic of a
reference document is given in advance in our target dataset
(namely, the BOK of CS2013). Consequently, although we
used some complicated modifications in our previous work,
they did not guarantee that the extracted model would be
consistent with the given topics. In this paper, we propose
a new method we call “simplified supervised LDA” (ssLDA)
for giving an approximate model to our target dataset. Super-
vised LDA (sLDA) has been proposed in a different context
[15, 2] where classification labels are given as well as doc-
uments. However, the labels are not directly related to the
extracted topics in LDA. Our ssLDA is a simplified version of
sLDA, where each extracted topic is bound to a given topic
label. Table 2 shows the correspondence of terms between
the proposed ssLDA model and our curriculum analysis.

It is essential that ssLDA allows a syllabus to belong to
multiple KAs because it is based on a probabilistic model. In
the training data (namely, CS2013), every syllabus belongs to
a single KA. Therefore, many classification methods, such as
support vector machines (SVMs), would seem to be suitable
for the training phase. However, the syllabus in an actual
curriculum is often distributed over many KAs. Therefore,
methods that focus on classification are not appropriate. On
the other hand, since ssLDA learns a probabilistic model from
the training data, the dominance ratios of multiple KAs can
be estimated from an actual syllabus.

It is also essential that ssLDA can estimate a continuous
probabilistic model even from the sparse data because of the
Dirichlet prior. Simple probabilistic models, such as naive
Bayes classifiers, give a discontinuous probabilistic estima-
tion because almost all words occur only a few times in
CS2013. Therefore, such simple models are not appropriate
for syllabi belonging to multiple KAs.

3.2.2 Generative Model
The probabilistic generative model of a document with a

label in ssLDA is given as follows:

1. The probability of occurrence of topics ? = (?i) (con-
strained to

?
j ?i = 1) is generated by Dirichlet distri-

bution with a hyper-parameter ?. Here, i = 1, . . . , K
and K is the number of topics.

2. For each word w, a topic assignment zn = (zni) is given
by multinomial distribution with the parameter (? =
(?i)), where n = 1, . . . , N and N is the number of words
in the document. Each zn is the K-dimensional vector

331



Table 1: CS related departments of universities in the United States.
Rank Department, University ID

1 Electrical Engineering, Computer Science, Massachusetts Institute of Technology MIT
2 Computer Science Department, Stanford University Stanford
3 School of Computer Science, Carnegie Mellon University CMU
4 Department of Electrical Engineering and Computer Sciences, Computer Science Division,

University of California, Berkeley
UCB

5 Department of Computer Science, University of Illinois at Urbana-Champaign Illinois
6 College of Computing, Georgia Institute of Technology Georgia
7 Department of Electrical Engineering and Computer Science, University of Michigan Michigan
8 Computer Science Department, the University of Texas at Austin UTAustin
9 Department of Computer Science, Cornell University Cornell

10 The Computing +Mathematical Sciences Department, California Institute of Technology Caltech

where the assigned topic is 1 and the others are 0. Then,
the word is given by the multinomial distribution with
the parameter (? = (?i j)), where i is the assigned topic
in zn and j corresponds to the actual word wn in the
vocabulary (where

?
j ?i j = 1 for every i).

3. The allocated topic of the document c ? {1, . . . , K} is
given by the following softmax distribution with the
parameter z? =

?
n zn/N and a hyper-parameter ? > 0:

P (c|z?, ?) = exp (?z?c) /?Ki=1 exp (?z?i). Here, z? = (z?i)
can be regarded as the empirical distribution on the
topic assignments of the document.

The graphical model of the above generative model is shown
in Figure 1. This is an extension of the original LDA model
[3] with c and ?. Because each label c corresponds to an
internal topic assignment z, the model is much simpler than
the previous sLDA models [15, 2].

3.2.3 Inference and Parameter Estimation
For estimating the variables and parameters in the model,

Table 2: Term correspondence table between ssLDA model
and curriculum analysis.

ssLDA Model Curriculum Analysis
document syllabus

set of documents curriculum
topic KA

position of a document
in topic space

dominance ratios
of KAs of a syllabus

training data BOK of CS2013
allocated label
in training data

KA allocated to
each syllabus in CS2013

? = (?i) true dominance ratios of KAs
zn = (zni) KA allocated to word n

? = (?i j)
Strength of relationship

between KA i and word j
c most dominant KA

z w ?

c ?

? ?
N K

D

Figure 1: Generative model of simplified supervised LDA.

such as ? and ?, we use the maximum likelihood estima-
tion with a variational EM algorithm. Though the infer-
ence process can be regarded as a special case of a more
general method on a more complicated model in [15], it is
derived here under the simplified model. The original like-
lihood of a document with a given topic label is given as
log P (w, c|?, ?, ?) where w = (wn) is a document consisting
of words wn’s. The estimation of this original likelihood is
intractable. Thus, the following lower bound is derived by
the variational Bayesian approach in a way similar to that in
the original LDA [3]:

log P (w, c|?, ?, ?)
= log

?
d?
?

Z

P (w, c, ?, Z|?, ?, ?)

= log
?

d?
?

Z

P (w, c, ?, Z|?, ?, ?)Q (?, Z|?, ?)
Q (?, Z|?, ?)

?
?

d?
?

Z

Q (?, Z|?, ?) log P (w, c, ?, Z|?, ?, ?)
Q (?, Z|?, ?)

= Eq (log P (w, c, ?, Z|?, ?, ?)) ? Eq (log Q (?, Z|?, ?))
= Eq (log P (w, ?, Z|?, ?)) + Eq (log P (c|Z, ?))
? Eq (log Q (?, Z|?, ?)) (1)

where Z = (zn), Q (?, Z|?, ?) = q (?|?)?n q (zn|?n) is the
variational distribution, and Eq() is the expectation operator
over Q. ? = (?i) and ? = (?n) are the free variational pa-
rameters. In addition, ? and ?n = (?ni) are the Dirichlet pa-
rameter and the multinomial one (constrained to

?
i ?ni = 1),

respectively. The lower bound in Eq. (1) is the same as that in
the original LDA except for the second term Eq (log P (c|Z, ?))
in the last form, which is derived from the softmax distribu-
tion of the topic label. The lower bound of Eq (log P (c|Z, ?))
is given as follows in a way similar to that in [15]:

Eq (log P (c|Z, ?)) = Eq
(
log

exp (?z?c)?
i exp (?z?i)

)

=
Eq (?

?
n znc)

N
? Eq

???????log
???????
?

i

exp (?z?i)

???????
???????

? ?
?

n ?nc
N

? Eq
???????log
?

i

z?i exp (?)

???????
=
?
?

n ?nc
N

? ?. (2)
Here, Jensen’s inequality on the exponential function is

applied under the conditions
?

z?i = 1 and z?i ? 0. Then, the
variational and model parameters (?, ?, ?) can be estimated

332



by the variational EM algorithm. Only the update equations
are shown here. ? and ? are estimated by

?i = ?+
?

n
?ni, (3)

?ni ? ?iwn exp
???????? (?i) ??

???????
?

k

?k

???????+ ??icN
??????? (4)

where ? is the digamma function and ?ic is the Dirac delta
function. ? is estimated by

?i j ?
?

d

?
n

1
[
j = wdn

]
?dni (5)

where d = 1, . . . , D corresponds to each document in the
datasets and 1

[
j = wdn

]
is the function taking 1 only when the

n-th word wdn in the document d is equal to the word j (or
0 otherwise). The update equations for ? and ? are almost
exactly the same as those in the original LDA [3]. The only
difference is the additional term ??ic/N in the update for ?. It
strengthens ?ni only if i is equivalent to the given topic label
c. In addition, the weight depends on ? and N only. In this
paper, ? and ? are treated as fixed hyper-parameters. The
settings on them are described in Section 3.2.5. Note that ?
degenerates into 0 if it is optimized by the maximum likeli-
hood estimation because the penalty for misclassification is
overestimated. Though it is a kind of overfitting problem, it
can be avoided by the cross-validation method described in
Section 3.2.5.

3.2.4 Prediction
After the estimation of ? of the generative model, a given

document with no label is projected to a position ?? =
(
??i
)

in the topic probability space with the expected topic label
c?. In order to estimate ?? robustly, ?? is estimated as the
expectation of ? over the conditional probability with no la-
bel. In other words, ?? is the mean over P (w, ?|?, ?). This
distribution is approximated as

?
Z Q (?, Z|??, ??) = q (?|??)

by the variational approach, where ?? =
(
??i
)

and ?? = (??nc)
are the parameters estimated by the original LDA with no
label. In other words, the additional term ??ic/N is omitted
in the update process of ?? and ?? in the same way as in the
original LDA. Then, ??i = ?

?
i /
?

i ?
?
i because ?

? is the Dirichlet
parameter. Regarding c?, it is given so that log P (c = c?|?) is
the maximum over c. By Eq. (2), log P (c|?) is approximated
as
?

n ?
?
nc ? ??c where constant factors are omitted. Therefore,

c? is given so that ??c? is the largest over ??c

3.2.5 Determination of Hyper-parameters
Here, the setting of the hyper-parameters ? and ? is de-

scribed. Though ? is originally given as a K-dimensional
vector for the K-dimensional Dirichlet distribution, it is given
as a single parameter by assuming that ? is the same constant
over all the topics. ?was set to 1 in the same way as in our pre-
vious work [14] by using some empirical and theoretical con-
siderations. To determine ?we use a cross-validation method
that makes use the classification accuracy of the topic labels.
In this paper, we utilize the leave-one-out cross-validation
(LOOCV) estimation of the topic classification accuracy in
the training data CS2013. In order to avoid the effects of local
maxima, the optimizations of ssLDA were carried out in five
trials from random initial values for each ?. Then, the result

Table 3: Parameter ? and average accuracy.
? Accuracy

5.0 0.172
10.0 0.399
20.0 0.638
50.0 0.663

100.0 0.595
200.0 0.534

Table 4: Average accuracy in other methods (naive Bayes
classifier and SVMs with various kernels).

Classifier Accuracy
Naive Bayes 0.656
SVM (linear) 0.264
SVM (radial) 0.325
SVM (sigmoid) 0.620

Table 5: KAs of CS2013.
ID KA
AL Algorithms and Complexity
AR Architecture and Organization
CN Computational Science
DS Discrete Structures
GV Graphics and Visualization
HCI Human-Computer Interaction
IAS Information Assurance and Security
IM Information Management
IS Intelligent Systems
NC Networking and Communication
OS Operating Systems
PBD Platform-Based Development
PD Parallel and Distributed Computing
PL Programming Languages
SDF Software Development Fundamentals
SE Software Engineering
SF Systems Fundamentals
SP Social Issues and Professional Practice

with the largest likelihood estimation was used. The LOOCV
estimations of various ? are shown in Table 3. It can be seen
from the table that ? = 50 is the best setting.

In order to compare the proposed ssLDA model with other
classification methods, the LOOCV estimations of the classi-
fication accuracy were calculated in the same training data
CS2013. Table 4 shows the results for naive Bayes classifier
and SVMs (with the linear, radial, and sigmoid kernels). We
used the R e1071 package2 which was an implementation
of naive Bayes classifier and SVMs. The hyper-parameters
of SVMs were tuned by the cross validation. It shows that
the highest accuracy in ssLDA (0.663 in Table 3) is (more or
less) superior to all the other methods. It verifies the valid-
ity of ssLDA model from the viewpoint of the classification
accuracy.

4. EXPERIMENT
4.1 Computing Science Curricula CS2013

The ACM and the IEEE Computer Society released the
report “Computing Science Curricula CS2013” in December
2013 as a reference curriculum in CS. The BOK consists of a
set of 18 KAs, each of which contains about 10 KUs that cor-
respond to syllabi in our curriculum analysis method. Table
5 shows the names and abbreviations of KAs.
2Package ’e1071’, http://cran.r-project.org/web/
packages/e1071/e1071.pdf (accessed 2015-01-23).

333



Table 6: Top 10 words strongly related to each KA.
KA Words
AL algorithm graph tree complexity automatum solve implement algorithmic class strategy
AR instruction memory architecture familiarity assembly level organization processor representation machine
CN simulation modeling science information including datum model algorithm computational processing
DS proof probability induction propositional relation predicate usage bayes counting theorem
GV rendering visualization graphic surface image representation animation rasterization light color
HCI user interface interaction design motivation HCI evaluation technology quantitative report
IAS security attack secure forensic cryptographic threat cryptography familiarity policy SE
IM query relational database information index datum schema transaction file mining
IS search agent reasoning planning classification robot representation learning implement algorithm
NC network platform social layer familiarity application allocation industrial IP describe
OS system operating memory device access SF virtual OS file management
PBD function programming web mobile operation class constraint variant language event
PD parallel parallelism distributed shared message versus race algorithm synchronization SF
PL type program language code static analysis semantic syntax memory optimization
SDF design program software component principle coding programming error code structure
SE software requirement team risk project process specification testing development validation
SF performance logic scheduling memory machine error program simple resource figure
SP social professional privacy computing ethical computer intellectual policy HCI environmental

A general LDA model can also produce a set of topics,
but the set is not controllable. Using ssLDA we can explicitly
make each topic of ssLDA correspond to some KAs of CS2013.
Table 6 shows the sets of the top 10 words strongly related
to each KA of CS2013. For example, the words related to AL
(Algorithms and Complexity) include “algorithm”, “graph”,
and “tree”, which are types of data structures. In summary,
supervised learning of ssLDA enables us to get a model for
the intended topics with few trials.

4.2 Syllabi Distributions in Topic Space
Here, we show how we investigated the syllabi distribu-

tions in both CS2013 and the actual universities in order to
verify the appropriateness of the extracted topic space. If the
topic space is appropriate, the syllabi should be distributed
“uniformly” with a low-biased center in the topic space. First,
Table 7 shows the mean (namely, the center) and the stan-
dard deviation of the distribution along each axis of topic
for CS2013 and the actual universities. Both of the distri-
bution means seem to be near to the ideal unbiased point
(1/18 ? 5.56%, 5.56%, · · · , 5.56%). The Euclidean distance
from the unbiased point is 3.65 for CS2013 and 5.05 for the
universities. This shows that the means of the actual uni-
versities were slightly further from the unbiased point than
those of CS2013. Nevertheless, the distances were not es-
pecially large even in the actual universities. This suggests
that the extracted topic space gives a low-biased center for
the actual universities as well as the artificially constructed
CS2013. For the standard deviation and the maximum, the
values in CS2013 are relatively large. Almost all the maxima
are near to the largest value 100%. This shows that the syllabi
of CS2013 are distributed widely over the topic space. On the
other hand, both the standard deviations and maxima for the
universities were quite smaller than those on CS2013. This
shows that the syllabi of the actual universities are distributed
densely over the limited area of the topic space. However, the
results do not clarify whether the syllabi are distributed uni-
formly in the limited topic space or not. In order to investigate
the uniformity in CS2013 and the actual universities, we use
the eigenvalues of the correlation matrix of the distribution.
Since the correlation matrix is a normalized covariance matrix

whose diagonal variances are normalized to 1, the uniformity
in the limited area can be investigated. Figure 2 shows the
bar graphs of the rank-ordered eigenvalues for the following
four sets of syllabi: CS2013, all the actual universities, MIT
only, and Stanford only. The top two universities are included
only for comparison. Note that the leftmost (and the small-
est) eigenvalue on each bar graph is always 0 because of the
constraint that

?
i ?
?
i = 1 in the topic space. If the syllabi are

distributed completely uniformly in the limited space, all the
eigenvalues are assumed to be the same except for the small-
est one (=0). In Figure 2, the bar graph on CS2013 seems to
be flat. This shows that the syllabi of CS2013 are distributed
uniformly in the wide area of the topic space. Though the
slope of the bar graph for all the actual universities is steeper
than that for CS2013, it is relatively flatter than those for the
actual single universities (MIT and Stanford). This suggests
that the distribution of syllabi for the actual universities is
weakly uniform. In summary, the results show that CS2013
gives a wide and uniform distribution with a low-biased cen-
ter in the topic space. This verifies that the proposed method
extracts an appropriate topic space from the given dataset
CS2013. On the other hand, the syllabi of the actual univer-
sities are distributed within a limited area of the topic space.
However, its center is low-biased and the distribution is rel-
atively uniform. This suggests that the proposed method is
suitable as a means to analyze actual universities.

4.3 Analysis of CS Department Courses
Using the model based on BOK of CS2013 with ssLDA, we

analyzed CS department curricula of the universities in Table
1 and obtained the distributions of the KAs in CS2013. If
a course syllabus on GV (Graphics and Visualization) has a
relatively high probability, the course is considered to offer
GV related topics such as CG, Animation, and solid model-
ing. Table 8 shows a part of a course syllabus titled “CS418
Interactive Computer Graphics” at Illinois. The course CS418
is the most strongly related course to GV.

We can compare courses offered by various departments
by their distributions and find similar courses by the prox-
imity of the distributions. For example, Table 9 shows the
10 courses nearest to CS418. Here, the Euclidean distance in

334



Table 7: Mean, standard deviation (SD), and maximum of the syllabi distribution along each topic for CS2013 and actual
universities.

AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP
mean(CS) 5.6 5.1 4.1 4.4 4.5 5.6 5.6 6.3 6.4 5.3 7.1 4.4 6.1 6.9 4.7 5.9 5.7 6.3
mean(univ) 6.1 5.4 7.0 4.5 7.4 7.6 4.3 4.8 7.0 4.0 4.5 5.3 4.3 5.2 5.2 5.9 4.3 7.2
SD(CS) 16.8 15.5 14.0 13.8 15.9 17.2 16.0 18.0 18.7 12.6 15.8 12.3 16.9 18.2 13.6 17.3 15.0 18.7
SD(univ) 5.1 3.8 4.4 3.9 6.1 5.3 4.1 4.2 5.6 3.0 3.4 3.9 3.0 4.2 3.6 4.3 2.3 5.8
max(CS) 90.4 83.9 88.6 85.5 90.4 81.9 92.3 86.7 86.1 76.8 77.5 85.8 89.5 90.0 88.3 93.1 85.7 91.1
max(univ) 54.4 39.3 35.5 36.5 55.6 49.4 48.7 50.6 36.9 37.7 31.9 30.4 28.4 51.6 30.8 36.9 21.6 54.5

Table 8: Course syllabus CS418 offered by Illinois and its distribution over KAs.
syllabus
CS418 Interactive Computer Graphics
Basic mathematical tools and computational techniques for modeling, rendering, and animating 3-D scenes...
1. Rotate, translate, scale an object represented by triangle mesh, and manage hierarchies of such transformations.
(a)(b)(c)(h)(i)(j)(k)>
2. Render an image of a meshed object with lighting, texture, reflections and perspective from an arbitrary viewpoint
with hidden surfaces removed and extraneous geometry clipped. (a)(b)(c)(h)(i)(j)(k)>
3. Model and render an object using parametric curves and surfaces including Hermite, Bezier, NURBS and
Catmull-Clark subdivision surface presentations. (a)(b)(c)(h)(i)(j)(k)>...
AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP
1.0 2.8 7.2 2.7 55.6 4.8 0.6 2.3 8.2 0.6 0.6 4.2 1.4 0.9 1.5 1.1 3.0 1.5

0 5 10 15 20
0

0.5

1

1.5

2

2.5
CS2013

                                        rank

ei
ge

nv
al

ue

0 5 10 15 20
0

0.5

1

1.5

2

2.5
All Universities

                                        rank

ei
ge

nv
al

ue

0 5 10 15 20
0

0.5

1

1.5

2

2.5
MIT only

                                        rank

ei
ge

nv
al

ue

0 5 10 15 20
0

0.5

1

1.5

2

2.5
Stanford only

                                        rank

ei
ge

nv
al

ue

Figure 2: Bar graphs of rank-ordered eigenvalues of corre-
lation matrices of distributions for CS2013 (upper left), all
actual universities (upper right), MIT only (lower left), and
Stanford only (lower right))

the topic space is used as the distance. Thanks to ssLDA this
distance is more robust to word choices than a tf-idf based
distance.

4.4 Analysis of University Characteristics in
Topic Space

In this section, we show how we investigate the character-
istics of the actual universities in the extracted topic space.
Here, each university is characterized by the mean of its syl-
labi in the topic space. Table 10 shows the means of all the 10
universities. We used principal component analysis (PCA)
to extract their characteristics. Table 11 shows the three prin-
cipal components of the topics, which account for about 90
percent of the total variance. Each component is discussed in

Figure 3: Plot of the universities along the second principal
component (horizontal) and the third one (vertical).

turn below.

• The first component: The values for the topics in the first
principal component were highly correlated to those for
the mean of all the actual universities (the second row
(mean(univ)) in Table 7). The correlation coefficient
between them was 0.99. The mean of all the actual uni-
versities is the averaged bias from the ideal unbiased
point. Thus, this component can be interpreted as the
current trends common to all the universities. In other
words, the result suggests that the first component cor-
responds to the degree to which each university follows
the current trends.

• The second component: The topics with higher values
are HCI, SE, and SP, all of which include human factors.

335



Table 9: 10 nearest course to CS418.
Rank Distance Course Title University

1 0.125 EECS 487. Interactive Computer Graphics Michigan
2 0.142 CS419 Production Computer Graphics Illinois
3 0.146 15-462 Computer Graphics CMU
4 0.150 184. Foundations of Computer Graphics (4) UCB
5 0.165 CS 7490 Adv Image Synthesis Georgia
6 0.187 CS 3451 Computer Graphics Georgia
7 0.221 CS/CNS 171. Introduction to Computer Graphics Laboratory Caltech
8 0.236 CS 4620: Introduction to Computer Graphics Cornell
9 0.246 CS 5620: Introduction to Computer Graphics Cornell

10 0.258 6.837 Computer Graphics MIT

On the other hand, those with lower values are IS, CN,
and DS, which are related to theoretical or mathematical
factors. These observations suggest that the second
component could be interpreted as the weight between
the human factors and the theoretical ones.

• The third component: The topics with higher values
are CN, SP, and SDF, which seem to be related to gen-
eral problems in software development. On the other
hand, those with lower values are GV and PL, which
are related to elemental techniques. These observations
suggest that the third component could be interpreted
as the axis from the elemental techniques to the general
solutions.

Figure 3 shows the plot of the universities along the second
principal component (horizontal) and the third one (verti-
cal). Interestingly, the top three universities (MIT, Stanford,
and CMU) seem to form a triangle with the other universities
placed within it. By utilizing the above possible interpreta-
tions of the principal components, we can make the following
speculations from the results. First, both MIT and Stanford
emphasize human factors, while CMU attaches greater im-
portance to theoretical ones. Second, MIT focuses on general
solutions while Stanford emphasizes elemental techniques.

4.5 Analysis of CS Department Curricula
If a CS department offers many courses that are related to

a number of KAs, it is considered the department focuses
on the KAs. That is, we can detect the characteristics of the
curriculum of each CS department from the distribution of
its courses.

We can average all courses of a given department as shown
in Table 10. These averaged distributions can be considered
to characterize the curriculum of each department.

From the deviation of a curriculum from 1/18 of the uni-
form distribution, we can ascertain whether the curriculum
is strongly related to some KAs or not. For example, uni-
versities with departments whose name includes “Electrical
Engineering (EE)”, such as UCB, MIT, and Michigan, have
a curriculum with a higher AR (Architecture and Organi-
zation) probability than the other universities, reflecting the
characteristics of those CS departments offering courses to
EE students.

Figures 4 and 5 show box plots of course distributions for
various KAs. A short box means that only a few courses
are related to the KA and a long box means that there are
various courses related to the KA, some of them weakly and
the others strongly. The center of an arrow is the mean, and
the length of the arrow stands for 2 SDs. The courses that are
particularly strongly related to some KAs are drawn as small

circles in the figures. As mentioned above, UCB, MIT, and
Michigan offer courses that are strongly related to AR.

Overall there are comparatively few courses related to IAS
(Information Assurance and Security), NC (Networking and
Communication), PD (Parallel and Distributed Computing),
and SF (Systems Fundamentals). However, even though IAS
has not yet become a very popular field, some universities
(e.g., Illinois, Georgia, and Caltech) offer courses strongly re-
lated to it. As examples, one could cite the “CS461: Computer
Security I” course at Illinois and the “CS 6260: Applied Cryp-
tography” course at Georgia. Similarly, we find NC related
courses such as “356R: Introduction to Wireless Networks”
at UTAustin and PD related courses such as “ACM/CS 114:
Parallel Algorithms for Scientific Applications” at Caltech.

The description of SF in the CS2013 final report is as follows:
“The Systems Fundamentals Knowledge Area is designed to
present an integrative view of these fundamental concepts in
a unified albeit simplified fashion, providing a common foun-
dation for the different specialized mechanisms and policies
appropriate to the particular domain area.” Some KUs of SF
are cross-referenced by other KAs such as PD, NC, OS (Oper-
ating Systems), AL (Algorithms and Complexity), and AR. In
other words, the courses related to SF are also related to these
KAs. In this way, using our curriculum analysis method, we
were able to compare courses across universities on the basis
of common computing curricula.

5. SUMMARY
In this paper, we showed how we used a curriculum anal-

ysis method we have been developing to analyze computer
science (CS) related curricula offered by the top 10 CS de-
partments of universities in the United States. We applied
the method on the basis of “Computing Science Curricula
CS2013”, a report released by the ACM and IEEE Computer
Society. To enable our method to perform this analysis, we
improved it by using a simplified version of supervised la-
tent Dirichlet allocation (ssLDA). We found that CS2013 uni-
formly covered a wide area of CS. We found that among the
universities that served as study subjects, MIT and Stanford
emphasized human factors while CMU attached greater im-
portance to theoretical ones. We also found that some CS
departments offered not only a CS curriculum but also an
electrical engineering, and those departments showed a ten-
dency to have more “Architecture and Organization (AR)”
related curricula. Furthermore, we found that even though
“Information Assurance and Security (IAS)” has not yet be-
come a very popular field, some universities are already
offering IAS related courses. Similarly, courses related to
“Networking and Communication (NC)” and “Parallel and
Distributed Computing (PD)” are being offered. However,

336



Table 10: Distribution of each curriculum. (%)
AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP

MIT 5.9 6.2 7.5 4.5 6.1 9.5 3.6 3.9 6.3 3.7 4.2 4.6 3.7 3.3 5.7 7.6 4.1 9.5
Stanford 5.7 6.2 4.6 2.8 9.5 10.7 4.1 4.8 5.5 3.4 2.8 5.5 5.0 6.3 4.4 7.4 4.2 7.1
CMU 6.5 4.3 8.9 7.3 9.5 6.9 3.0 4.7 7.3 2.8 3.1 4.7 3.7 5.9 5.6 5.0 4.2 6.5
UCB 6.3 7.5 7.0 4.0 7.2 7.4 5.9 3.8 6.2 4.3 3.5 7.1 4.8 4.5 4.9 4.8 3.7 7.1
Illinois 5.7 4.3 7.4 3.5 9.9 7.8 3.7 5.1 7.3 3.5 4.1 4.9 4.3 7.0 4.2 5.9 4.4 6.9
Georgia 5.6 4.9 6.5 4.8 6.5 7.3 5.1 5.4 6.2 4.6 5.2 4.8 4.5 4.9 5.5 6.1 4.4 7.5
Michigan 6.3 6.2 6.1 4.4 6.8 7.0 4.0 4.5 8.9 3.8 5.2 5.4 3.6 4.9 6.3 5.5 5.0 6.1
UTAustin 5.5 5.1 8.6 4.4 6.0 7.3 5.0 4.7 5.2 5.2 4.5 6.2 4.2 5.1 5.8 5.9 4.5 6.9
Cornell 6.5 5.6 7.5 4.4 7.7 6.8 4.0 4.6 9.0 3.6 4.9 6.2 4.2 5.5 4.6 4.7 3.8 6.5
Caltech 8.7 5.3 7.0 4.4 8.0 6.1 3.9 4.9 7.5 3.5 4.9 4.6 4.2 4.9 5.5 6.0 4.3 6.1

Table 11: Three principal components in the topic space: Each component (with the dominance of the variance) is normalized
by letting its Euclidean norm be 10.

AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP
1st (69%) 1.3 -0.1 2.7 -1.9 4.2 4.1 -2.6 -1.6 2.5 -3.3 -2.6 -0.4 -2.4 -0.4 -0.7 0.7 -2.3 2.7
2nd (11%) -2.1 2.4 -3.2 -3.2 -1.7 4.9 1.6 -0.5 -4.1 1.2 -1.1 0.7 1.2 -1.1 -0.6 3.1 -0.1 2.6
3rd (7%) 0.6 1.5 3.7 1.3 -5.4 -0.5 0.1 -1.9 1.0 0.5 1.2 0.3 -2.1 -5.0 2.4 0.1 -0.9 3.2

courses related to “Systems Fundamentals (SF)” are also re-
lated to other Knowledge Areas (KAs) because some Knowl-
edge Units (KUs) of SF are cross-referenced by other KAs.
These findings confirmed that the improvement by ssLDA
brought to our method is effective.

In future work, we plan to use our method to analyze a
larger number of curricula. We also want to use it to search
various educational areas that offer curricular guidelines such
as the computing curricula and analyze curricula in those
areas.

6. REFERENCES
[1] ACM/IEEE-CS Joint Task Force on Computing

Curricula. Computer science curricula 2013. Technical
report, ACM Press and IEEE Computer Society Press,
December 2013.

[2] D. M. Blei and J. D. McAuliffe. Supervised topic
models. In NIPS, volume 7, pages 121–128, 2007.

[3] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet
allocation. Journal of Machine Learning Research,
3:993–1022, 2003.

[4] Committee of Education of Computer Science,
Information Processing Society of Japan. Computing
curriculum standard in computer science J07-CS report
(january 20, 2009), 2009. http:
//www.ipsj.or.jp/12kyoiku/J07/20090407/J07_
Report-200902/4/J07-CS_report-20090120.pdf.

[5] R. Gluga, J. Kay, and R. Lister. PROGOSS: Mastering
the curriculum. In Proceedings of The Australian
Conference on Science and Mathematics Education (formerly
UniServe Science Conference), 2012.

[6] M. Ida. Textual information and correspondence
analysis in curriculum analysis. In Proceedings of the
18th international conference on Fuzzy Systems, pages
666–669. IEEE Press, 2009.

[7] Y. Kaminuma. Summary of J07-IS curriculum, 2008.
http:
//www.ipsj.or.jp/12kyoiku/J07/20090407/J07_
Report-200902/5/J07-IS_curriculum-200803.pdf
(in Japanese).

[8] L. Marshall. A comparison of the core aspects of the
ACM/IEEE computer science curriculum 2013

strawman report with the specified core of CC2001 and
CS2008 review. In Proceedings of Second Computer Science
Education Research Conference, CSERC ’12, pages 29–34,
New York, NY, USA, 2012. ACM.

[9] G. Méndez, X. Ochoa, and K. Chiluiza. Techniques for
data-driven curriculum analysis. In Proceedings of the
Fourth International Conference on Learning Analytics And
Knowledge, LAK ’14, pages 148–157, New York, NY,
USA, 2014. ACM.

[10] S. Ota and H. Mima. Machine learning-based syllabus
classification toward automatic organization of
issue-oriented interdisciplinary curricula. Procedia -
Social and Behavioral Sciences, 27:241–247, 2011.

[11] W. F. Pinar, W. M. Reynolds, P. Slattery, and P. M.
Taubman. Understanding Curriculum: An Introduction to
the Study of Historical and Contemporary Curriculum
Discourses. Peter Lang Pub Inc., 1995.

[12] T. Sekiya, Y. Matsuda, and K. Yamaguchi. Analysis of
computer science related curriculum on LDA and
isomap. In ITiCSE’10, Proceedings of the 15th Annual
SIGCSE Conference on Innovation and Technology in
Computer Science Education, pages 48–52, 2010.

[13] T. Sekiya, Y. Matsuda, and K. yamaguchi. Development
of a curriculum analysis tool. In ITHET 2010, 9th
International Conference on Information Technology Based
Higher Education and Training, pages 413–418, 2010.

[14] T. Sekiya, Y. Matsuda, and K. Yamaguchi. Analysis of
computer science related curriculum. In Summer
Symposium in Shizukuishi 2013, SSS2013, pages 33–40,
2013. (in Japanese).

[15] C. Wang, D. Blei, and F.-F. Li. Simultaneous image
classification and annotation. In Computer Vision and
Pattern Recognition, 2009. CVPR 2009. IEEE Conference
on, pages 1903–1910. IEEE, 2009.

[16] X. Yu, M. Tungare, W. Fan, Y. Yuan, M. Pérez-Quinones,
E. Fox, W. Cameron, and L. Cassel. Automatic syllabus
classification using support vector machines. Handbook
of Research on Text and Web Mining Technologies.
Information Science Reference, 2008.

337



AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP

0
10

30
50

MIT

AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP

0
10

30
50

Stanford

AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP

0
10

30
50

CMU

AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP

0
10

30
50

UCB

AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP

0
10

30
50

Illinois

Figure 4: Distribution of courses offered by MIT, Stanford, CMU, UCB, and Illinois.338



AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP

0
10

30
50

Georgia

AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP

0
10

30
50

Michigan

AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP

0
10

30
50

UTAustin

AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP

0
10

30
50

Cornell

AL AR CN DS GV HCI IAS IM IS NC OS PBD PD PL SDF SE SF SP

0
10

30
50

Caltech

Figure 5: Distribution of courses offered by Georgia, Michigan, UTAustin, Cornell, and Caltech.339



