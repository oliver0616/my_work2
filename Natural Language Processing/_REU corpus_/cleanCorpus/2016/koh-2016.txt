A Pedagogical Framework for Learning Analytics in  Collaborative Inquiry Tasks: An Example from a   Teamwork Competency Awareness Program  Elizabeth Koh, Antonette Shibani, Jennifer Pei-Ling Tan, and Helen Hong   National Institute of Education,  Nanyang Technological University, Singapore   elizabeth.koh@nie.edu.sg, antonette.x@nie.edu.sg, jen.tan@nie.edu.sg, helen.hong@nie.edu.sg    ABSTRACT  Many pedagogical models in the field of learning analytics are  implicit and do not overtly direct learner behavior. While this  allows flexibility of use, this could also result in misaligned  practice, and there are calls for more explicit pedagogical models  in learning analytics. This paper presents an explicit pedagogical  model, the Team and Self Diagnostic Learning (TSDL)  framework, in the context of collaborative inquiry tasks. Key  informing theories include experiential learning, collaborative  learning, and the learning analytics process model. The  framework was trialed through a teamwork competency  awareness program for 14 year old students. A total of 272  students participated in the program. This paper foregrounds  students and teachers evaluative accounts of the program.  Findings reveal positive perceptions of the stages of the TSDL  framework, despite identified challenges, which points to its  potential usefulness for teaching and learning. The TSDL  framework aims to provide theoretical clarity of the learning  process, and foster alignment between learning analytics and the  learning design. The current work provides trial outcomes of a  teamwork competency awareness program that used dispositional  analytics, and further efforts are underway to develop the  discourse layer of the analytic engine. Future work will also be  dedicated to application and refinement of the framework for  other contexts and participants, both learners and teachers alike.   CCS Concepts   Applied computing~Collaborative learning    Human- centered computing~Visual analytics    Human-centered  computing~Synchronous editors    General and reference~Design   Keywords  Teamwork, teamwork competency, collaboration, pedagogical  model, learning design, dispositional analytics, assessment,  twenty-first century skills, evaluation.   1. INTRODUCTION  Several learning analytics papers have proposed pedagogical  models for learning. Greller and Drachsler [14] conceptualize that  learning analytics (LA) enable many different types of pedagogies  and this can either be implicit or made explicit in the design.   Implicit pedagogies refer to pedagogical strategies that are  implicitly contained in the input datasets that encapsulate the  pedagogic behavior of users [14, p.53]. In this paper, we broaden  this definition to include any LA model that does not overtly  direct learner behavior based on any theoretical pedagogical  model. The pedagogy is part of the input dataset or the system that  captures the pedagogic behaviors of users. In contrast, LA that  make pedagogies explicit in the design address them through the  goals and objectives of the design, and this is seen through  pedagogic behavior enabled by the LA and system, as well as the  consequence of that behavior [14; 24]. However, in our brief  review of the emerging field, there are very little LA designs that  develop an explicit pedagogical model. Many pedagogical models  in LA papers are implicit, or do not focus on any particular model.  Although this allows the flexibility and creativity of the  stakeholders in its use and sustainability of the system, it may also  lead to confusion as well as uninformed, non-ideal or misaligned  practice. In this paper, we present a pedagogical framework for  LA in collaborative inquiry tasks and demonstrate trial outcomes  in a teamwork competency awareness program.   We begin with a brief literature review of the different categories  of pedagogical frameworks in learning analytics. Next, we  introduce the background of the research problem and the studys  context, namely, the increasing focus on 21st century  competencies, and the competency of teamwork. Our pedagogical  framework was based on several informing theories and the  following sub-section (3.2) provides a theoretical understanding.  Subsequently, 4 elaborates on how the framework was used and  implemented in a school setting. We detail each stage of the  framework. 5 describes the evaluation of the pedagogical  framework, drawn from the qualitative accounts of participant  students and teachers. In 6, we elaborate on our findings, their  implications and future work, and conclude by highlighting  several potential advantages of the TSDL framework for the field  of LA (7).   2. PEDAGOGICAL FRAMEWORKS FOR  LEARNING ANALYTICS  One of the key challenges in LA is the lack of pedagogic theory  [10]. This sparsity of theory is in part attributable to numerous  extant LA studies subtly embedding pedagogical models and  strategies in the design [11; 42] and/or only providing a broad  overarching frame of the general theory [1]. Some LA designs  even claim pedagogical neutrality [10].   Knight, Buckingham Shum and Littleton [21] highlight that no  learning analytics design can exist without pedagogical and  epistemological assumptions. These assumptions determine what  methods and types of learning analytics are used. The study   Publication rights licensed to ACM. ACM acknowledges that this  contribution was authored or co-authored by an employee, contractor or  affiliate of a national government. As such, the Government retains a  nonexclusive, royalty-free right to publish or reproduce this article, or to  allow others to do so, for Government purposes only.   LAK '16, April 25 - 29, 2016, Edinburgh, United Kingdom    Copyright is held by the owner/author(s). Publication rights licensed to  ACM. ACM 978-1-4503-4190-5/16/04$15.00   DOI: http://dx.doi.org/10.1145/2883851.2883914     mailto:antonette.x@nie.edu.sg http://dx.doi.org/10.1145/2883851.2883914   surmises three forms of learning analytics that stem from various  pedagogical lenses: mastering content (generally from  transactional and constructivist lenses), evidencing membership  and processes (affect-based, apprenticeship, and connectivist  lenses), and success is use (connectivist and pragmatist lenses).   Besides epistemological assumptions, pedagogical frameworks  can be represented more practically through learning designs.  These are the sequence of learning tasks, resources, and supports  that a teacher constructs for students over part of, or the entire,  academic semester [24, p.1441-1442]. There are many kinds of  learning designs with differing levels of granularity. Chiefly,  learning designs should make explicit the planned pedagogical  action without going into the details of the specific instructional  activity such as in a typical lesson plan. This allows learning  designs to be used as a framework for the design of analytics to  support educators in learning and teaching decisions. The Social  Networks Adapting Pedagogical Practice tool based on the socio- constructivist model of learning is one such instance [24].   Wise et al. [44] provides another example of a pedagogical  framework aimed at informing learning analytics intervention  design. Based largely on constructivism, meta-cognition, and self- regulated learning, four principles (integration, agency, reference  frame and dialogue) and three processes (grounding, goal-setting  and reflection) are conceived. Moreover, pedagogical frameworks  can and should be made explicit throughout the lifecycle of the  teaching and learning curriculum. For instance, in recent work,  Rodriguez et al. [31] designed a pedagogical model that aligned  scripting and monitoring explicitly throughout the whole  development and use process, from planning, to technological  deployment, enactment and evaluation of the implementation.   These examples, which explicitly describe their pedagogical  frameworks, clearly provide direction for educators and  stakeholders. If such pedagogical underpinnings are hidden, it  limits the potential of the approach and can cause misaligned  practice. Moreover, as these approaches shape the reality they  measure, explicitly stating such frameworks makes clear what  counts as important. However, not many such examples exist, and  this paper intends to present a pedagogical framework for LA in  the context of inquiry-based collaborative tasks. The background  of our study, the larger research problem and agenda are described  next.   3. RESEARCH PROBLEM AND STUDY  CONTEXT: ASSESSMENT OF TWENTY- FIRST CENTURY COMPETENCIES  As a response to globalization and the rapid technological changes  in the world, educators and organizations have identified that  academic knowledge only is not sufficient for learners to thrive in  the world. Rather, a suite of competencies, commonly termed as  21st century competencies, are needed. Many competencies have  been proposed and highlighted by numerous international  organizations and national frameworks. Among all these  frameworks, there are many similar competencies namely,  collaboration, communication, digital literacy, citizenship,  problem solving, critical thinking, creativity and productivity [40].  Also, a number of more recent frameworks and studies attempt to  concentrate on the gap area of assessment, while focusing on a  few key competencies. For example, the Partnership for 21st  century learning (www.p21.org) consortium narrowed its focus to  4 essential skills, namely, creativity, critical thinking,  collaboration and communication.   The study presented in this paper focuses on collaboration in  small groups in group-based inquiry tasks. This is common across  many 21st century competency frameworks and is pertinent in this  day and age for school and work. We term this skill--teamwork  competency-- a multi-dimensional construct that focuses on the  process of members working in a team [34; 37]. Despite many  past studies of teamwork and collaboration, the what to measure  (teamwork conceptualizations) and how to measure (methods  including analytics) and design of teamwork activities  (pedagogical model) have yet to be firmly established to date.    In the next section, we first provide a brief description of our  conceptualization of teamwork and the associated analytics  methods, after which we turn to focus more squarely on the  development, implementation and evaluation of the TSDL  pedagogical framework.   3.1 Teamwork competency conceptualization  and analytics  Based on past literature and pilot tests, six dimensions of  teamwork competency are established: coordination [9; 27],  mutual performance monitoring [35], team decision making [13;  38], constructive conflict [38], team emotional support [6], and  team commitment [25]. (A detailed explication of these six  dimensions is beyond the scope of this paper, but documented in  the authors prior and upcoming work [22]).   For the measure of teamwork competency, we adopted a multi- method approach to add rigor and objectivity. In addition,  contemporary technological affordances, particularly learning  analytics, are being explored for its potential value-add to future  scalability   Researchers have increasingly developed several learning  analytics techniques and applications to assess competencies as  the LA field matures. To assess multiliteracies, Dawson and  Siemens [5] identified several learning analytics methods such as  modeling and knowledge domain mapping to measure literacies  relating to experimentation as well as structured mapping and  prediction to measure products and creation multiliteracies.    Ferguson and Shum [11] define five types of analytics that are  relevant in this social age: social network analytics, discourse  analytics, content analytics, disposition analytics and context  analytics. We posit that a combination of these analytics can be  meaningfully designed and implemented for the assessment of  teamwork. For instance, social network analytics through  gathering interaction data could measure the participation and the  network of collaborating student teams.   Discourse analytics are also another potent way to identify and  infer teamwork competency in online group communication [2;  32]. For instance, Crowston et al. [4] focused on group  maintenance behaviors in online groups and showed good  performance of a discourse-based system using Natural Language  Processing (NLP) rules. They examined the role of group  maintenance behaviors in the messages of online discussion lists  by applying NLP rules to automate coding, which could be  reviewed and corrected by human coders. In their approach, codes  were applied based on specific features that were evidences of  theoretical constructs of interest. It involved the steps of pre- processing, tokenization, POS tagging and rule-writing.   Dispositional analytics can also make visible teamwork  competencies. Dispositional analytics make use of the traditional  surveys of the social sciences and represent them as a visual   http://www.p21.org/   analytic [2]. This is demonstrated by Buckingham Shum and  Crick [2] who conceptualized a learning power model of learning  dispositions. This was empirically validated and visualized using  the Learning Warehouse system with self-reports of participants  from many schools and countries. The analytic could be  visualized to show aggregations across groups of learners or  across a person over time.   Self-reports can be performed for oneself as well as for others.  Besides self-ratings, there is much potential in peer ratings, where  participants evaluate how they perceive another person. Peer  ratings can allow for a more triangulated and fairer measurement  in teamwork [12; 28]. Self and peer ratings are also more scalable  than having experts (such as teachers) rate students. A Self and  Peer Assessment Resource Kit (SPARK) was developed for  college students which provided them with a confidential  assessment tool to develop their teamwork skills [12]. Most  students found it valuable as it was a fair system of assessing team  contributions, especially when the goals of using SPARK were  aligned with the learning outcomes of the course. This form of  self and peer assessment were also found to encourage the  development of teamwork skills such as team cooperation,  commitment and team engagement [43].   3.2 Pedagogical model  The learning design of collaborative inquiry tasks can be a  complex process. There have been several approaches to facilitate  effective teamwork and collaboration. Generally, teamwork  activities have their pedagogical roots in collaborative learning  which is a socio-constructivist approach of learning [7; 15; 41].  As learners discuss and negotiate, they learn from each other.    Some research has highlighted antecedents and/or task  characteristics for successful teamwork i.e., complex, open-ended,  and ill-structured tasks, interdependence (the extent to which team  members must rely and work together to perform the task), and  individual and group accountability [20; 36].    Besides these characteristics, augmenting group behavior using  analytics is an emerging and important component in research.  Some work in this has been carried out in the area of group  awareness. In social group awareness, past research has used  visual analytics for both quantitative (e.g. amount of discussion,  extent of participation, perception of collaboration) and qualitative  (e.g. agreement, quality of group discussions) awareness  information [16]. However, a gap area in the research is that  analytics use is unregulated. It is up to students to decide if they  will view the awareness information and also it is up to them to  choose how they will process and use this visualization. This  could explain some of the variability in the results of past research  experiments. Further research needs to provide a pedagogical  model for such group awareness information to be more  effectively used by students [17].   In a face-to-face collaboration study, Rummel et al. [33] found  that observational learning enhanced collaboration skills more  than a collaboration script. This pedagogical model was more  effective when elaboration support was conducted. Elaboration  support was implemented through having instructional prompts to  focus students to relevant underlying principles, and a reflective  self-explanation where participants would recall the collaboration  process and explain to themselves what aspects had been  important for the collaboration to be successful [33, p.79]. This  suggests the importance of reflection in collaborative inquiry  tasks.   Although observational learning has been shown to be effective,  research highlights that it is difficult and time-intensive to develop  ideal models of collaboration in ill-structured tasks [33]. Instead, a  pedagogical approach that focuses the effort on the learners  metacognitive processes would be helpful for internalizing  teamwork competency. Reflecting on collaboration processes  seems to be an effective pedagogical strategy to enhance  collaboration skills [26; 28]. Moreover, reflection is one of the  two fundamental objectives in LA, the other being prediction [14].  Reflection is the critical self-evaluation of users own data to  obtain self-knowledge (and may also include other data) while  prediction focuses on modeling activities for other activities and  interventions.   One of the foundational learning theories that is based on  experience and reflection is experiential learning [23].  Experiential learning theory posits that humans learn through a  transformation of experience [23]. The theory emphasizes a  cycle of four stages: concrete experience, reflective observation,  abstract conceptualization and active experimentation. It has three  major principles: learning is a process not an outcome, learning is  grounded in experience, and that learning requires the resolution  of the dialectics (experience and conceptualization, observation  and action). It has been tested in individual learner contexts as  well as in teams [19].   Another related conceptualization is the learning analytics process  model [39] which alludes to a concrete experience but emphasizes  that awareness is derived from data. In awareness, data is  visualized in various ways such as radar charts, activity streams,  tabular overviews, to help learners see their activity/interactions  better. Verbert et al. [39] also posit a continuous loop of  awareness, reflection, sensemaking and impact. Reflection is  important to help learners think about the data. This is closely  followed by sensemaking which helps generate new knowledge  and insights. Lastly, impact aims to create new meaning or change  behaviors.    Besides individual reflection, collaborative reflection or co- reflection among team members is a valuable learning process  [18; 45]. In a collaborative inquiry task, the world includes the  views of the team members. An individual reflecting on his own  behavior may not be aware of how he is perceived by other group  members and a group reflection would be helpful to help learners  learn from each other. This is closely related to socially shared  regulation [18] and recent research has delineated three learning  design principles for providing support for shared regulation:  enhancing awareness of learners own and others process of  learning; making visible the externalization of students and  others learning process and interaction; and prompting and  stimulating regulatory processes.   Integrating these principles, we posit that an experiential,  awareness and reflection approach would be an effective  pedagogical model to nurture students teamwork competency.  We term this the Team and Self Diagnostic Learning (TSDL)  framework which primarily aims to develop students teamwork  competencies and collaboration skills.   3.2.1 Team and self diagnostic learning framework  The key informing pedagogies of TSDL are experiential learning  [23], collaborative learning [7; 15; 41], and the learning analytics  process model [39].    The framework broadly follows the experiential learning cycle  [23] and integrates learning designs with learning analytics [24].     The TSDL framework comprises four stages: team-based concrete  experience, self and team awareness building, self and team  reflection and sensemaking, and self and team growth and change  (See Figure 1).                                  Figure 1: Team and Self Diagnostic Learning Framework.    Learners begin with team-based concrete experiences namely,  the collaborative inquiry task. This can be in multiple forms such  as a team-building ice-breaker activity, the collaborative writing  of a report, and a group brainstorming chat. During the process of  the experience, learners will at times perform individual work,  and at times engage with other team members and learn from each  other.    After the concrete experience, we propose that team members can  be made more aware of their experience using visual analytics  (such as through discourse and dispositional analytics). These  make visible the activities in formats such as data aggregations  and can trigger an intended change in the learner [8]. Basically,  this stage intends to build the awareness of the individuals and  the teams learning process.   The next stage is self and team reflection and sensemaking.  This is a deliberate set of activities to enable learner reflection,  abstract conceptualization and sensemaking of the awareness  information. Learners need to evaluate the visual analytics, ask  and answer reflective questions, diagnose their learning and create  new insights. Goal-setting and future-oriented questions are  particular effective strategies [29; 44]. This should be done  individually and as a team.   The last stage is self and team growth and change. The  successful resolution of the dialectics of concrete observation and  abstract conceptualization causes internal change in the learner  [23]. When learners make sense of their behaviors, and realize  areas of change and areas to change, they grow and can enact new  behaviors and attitudes. Learners better self-awareness and  change in team behavior can be seen through the differences in  earlier and later perceptions and behavior.   Several studies have explicated and shown the cycle of concrete  experience, awareness, reflection and sensemaking, and growth  and change to be a powerful pedagogical approach that is  effective in nurturing cognitive and non-cognitive skills, although  these processes have not been previously consolidated into a  single framework and termed TSDL [17; 28-30].   For instance, a series of studies by Phielix and colleagues [28; 29]  shows the potential of the pedagogical approach for secondary  school students. Phielix et al. [28] developed two tools, a peer   feedback tool (Radar) and a reflection tool (Reflector) for high  school students working together on a collaborative writing task.  Participants in dyads or groups of threes and fours, worked over  three sessions to complete their task. Students in the experimental  group performed peer feedback and reflected after each session  (three time points in total). The research found that teams using  the two tools (which encouraged awareness and reflection) had  higher social and cognitive behavior (between the first and second  session), and higher social group performance than the control  condition. The study also compared between Radar-only groups  and groups with Radar and Reflector, but did not find many  significant differences in the self-reported scores. This was  possibly due to the reflection questions which highlighted  individual contributions.   A follow-up study was conducted where the reflection questions  were modified to be more future-oriented, prompting students to  goal-set for improved team behaviors [29]. The reflection activity  consists of a series of six reflection questions which students type  out. For instance, what is your opinion of how you functioned in  the group The last question is Set specific goals (who, what,  when) to improve group performance [29, p. 1094]. Reflection  was done individually as well as together as a team. As compared  to the control group, peer feedback and reflection resulted in  higher self-reported social performance between the first and  second session, and between the first and third session. Social  performance included team development, group satisfaction, and  less group conflict, which are related to teamwork dimensions.  These suggest that the TSDL framework could be an effective  pedagogical model to enhance teamwork competency.   4. FRAMEWORK IN USE: A TRIAL  TEAMWORK COMPETENCY  AWARENESS PROGRAM  A two session (a total of 135 minutes) teamwork competency  awareness program was designed for 14 year old students in a  school. Seven classes with a total of 272 students participated in  the study and the program was carried out class by class over 4  months as part of the students curriculum in 2014. This trial was  designed as a blended learning experience using 1-1 student to  computers ratio. Students in a class were randomly grouped into  teams of 3 or 4 members. In this trial, the researchers led the  activities while the teachers co-facilitated the sessions.   The goals of the program were for students to engage in the  practice of teamwork and gain awareness of teamwork processes.  We hoped that students would learn to work better in future  collaborative inquiry tasks.   The different stages of the framework and how it was  implemented in our context are described in the following  sections.   4.1 Team-based concrete experience  This is the starting stage of the TSDL framework. Students gained  team-based concrete experience in session 1 when they engaged  in collaborative inquiry tasks in an online environment. We  designed an online group chat where students were provided with  their tasks and where they discussed and submitted their answer.   Students began with an icebreaker task to help them know their  team members and familiarize themselves with the online chat  system. This was followed by a dilemma task. The dilemma task  was an open-ended task with a scenario that challenged students  to make choices to save the environment, the people in a home for   Self and Team  Awareness   Building (visual  analytics)      Self and Team  Reflection    and  Sensemaking   Team-based  Concrete   Experience     Self and Team  Growth    and   Change     the aged, and/or their fathers livelihood. Students had to come up  with one final decision as a team regarding how the problem  could be solved. Instructions were given by a human-controlled  ChatAdmin who typed standardized instruction messages in the  chat. After this collaboration experience, students rated  themselves and their peers on an online survey portal that we  developed. The survey items were constructed based on the  teamwork competency dimensions mentioned in section 3.1.  Figures 2 and 3 show the online chat environment and the survey  interface respectively.   4.2 Self and team awareness building  The next stages of self and team awareness building and self and  team reflection and sensemaking took place in session 2. We  needed time to calculate and produce the visual analytics. For this  trial, we were only able to provide a visual analytic based on the  dispositional analytics (i.e., self and peer ratings).     Figure 2: Online chat environment.        Figure 3: Survey interface for self and peer rating.      The visual analytic was termed a teamwork micro-profile rather  than a profile to acknowledge that teamwork processes can  change, and is not a permanent status of a students teamwork  competency. It is based on the micro-time context, which  examines a short period of group processes [3]. The micro- profiles were created from the rating survey based on a Likert  scale from 1 to 5 where 5 indicates strongly agree. Ratings of  3.5 and above are generally considered high. The visualization  included the individual students numeric rating scores of each   dimension, separated into self, peer and overall (of peer and self).  A radar chart of the students scores was also presented to allow  students to see their strengths and weaknesses easily.   Additionally, an overall similarity score was calculated. This is to  enable students to see the difference between their own ratings  and those of their peers. We developed this score to compare self  and peer scores in line with [43] as it would make the differences  between team members more obvious and offer critical reflection.  The calculation is:   (Self scores  Peers scores) for each dimension  Number of dimensions     A negative value indicates that the student rated himself lower  than his peers (team members). A positive value indicates that the  student rated himself higher than his peers. A good range is  between -0.5 to +0.5 as it shows a high degree of similarity.   Figure 4 displays our visual analytic of teamwork competency.  Students were given their personal micro-profile as a colored  printout in class. They were given some time to look at it and  subsequently briefed about the aspects of the micro-profile. This  was to generate self and team awareness building.           Figure 4: Visual analytic of teamwork competency: teamwork   competency micro-profile for a student.     4.3 Self and team reflection and sensemaking  Subsequently, self and team reflection and sensemaking took  place. Students were asked to sit in their teams, and provided with  a reflection worksheet comprising 4 questions derived from past  research [29].    For individual reflection, students were asked to reflect on:    (1) What differences do you see between the rating that you  received from your peers and your self-rating      (2) Why do or dont you agree with your peers concerning your  rating    For team reflection, students reflected in their groups on:    (3) What does the group think about its functioning in general  Discuss and formulate a conclusion shared by all the group  members.   (4) Set specific goals (who, what, when) to improve group  performance   The objective of this explicitly scaffolded self- and team-based  reflection task was to create the pedagogical conditions for  students to assimilate and synthesize their reflections of their  experience in terms of both conceptual understandings and very  importantly, concrete goal-setting and plans to productively adapt  or modify their teamwork behaviors [23; 29]. To end session 2,  the facilitator consolidated what students learned by asking  students to share in class and closed the session.    One limitation of the trial cycle reported here is that the self and  team growth and change, if any, were not recorded and  documented in a structured manner, mainly because the focus of  the program was on students gaining awareness of their own  teamwork competencies and to learn to work better in future  collaborative tasks. We aim to address this limitation in future  work. Nevertheless, for the trial cycle at hand, students writing in  the reflection worksheets provided some evidence of their  growing awareness and desire for change.   5. PEDAGOGICAL FRAMEWWORK  EVALUATION  A qualitative analysis was performed to evaluate the impact and  effectiveness of the TSDL framework from the perspectives of  both the students and teachers.    5.1 Data sources and analysis method  The key data sources were focus group discussions (FGDs) with  students and interviews with teachers. Students written reflection  worksheets were also examined. There was a total of 6 FGDS  from 6 teams (3 to 4 students each) from different classes. Each  FGD lasted between 45mins to 1 hour and was video-recorded.  We also had written or face-to-face interviews with the teachers  from all the 7 classes. For this analysis, a subset of the 272  participant reflection sheets was examined.  Thematic analysis was carried out where the data was examined  and information categorized into codes and then larger themes.   5.2 Findings  5.2.1 Overall program  Generally students and teachers were receptive towards the  program. Overall, students felt that the program helped them to  know how others saw them, and understand themselves better in  terms of the teamwork dimensions.  [I was able to] find out what others think about me. I was able to  find out what I can do more. Student X.  Some students wanted to go through the program again. Student Y  said that she would like to get to talk with other people and know  other students ideas. Student Z shared, I think it is useful to  experience how other people work in a group together with a  different group.   Teachers also found the program useful for their students to be  more self-aware and relate to others better.   Overall the program is just nice, timing is not too draggy.  Students enjoyed the first session. As for session 2, it's good for  the students to know and express themselves according to their  profile. Teacher A.  The program is okay, but depends on how you execute it.  Teacher B.  The execution of the program depended a lot on the skill of the  facilitator being able to guide and manage the classroom  dynamics. In this trial, the researchers led the program. However,  a few teachers suggested that the teachers could play a greater role  in leading and facilitating this (and the researchers also  concurred). This is because the teachers know their students better  which could help in facilitating the whole activity.  The TSDL framework was not made explicit to both the teachers  and students, and during the FGDs and interviews, we asked the  participants about their perceptions towards the different stages of  the framework.   5.2.2 Team-based concrete experience  As session 1 required students' to use the computer, students  especially liked this experience. It was a break from their normal  classroom lessons. Although there were a few who thought it was  boring, the majority found it quite fun. It was something new  and interesting for them, and they could go out of their normal  class. A teacher shared that some students were keyboard  warriors and liked communicating online.  Students were generally receptive towards the collaborative  inquiry task, although there were a few who found it confusing, or  were not engaged with the task or, did not like the topic. Students  suggested task scenarios that could give them more life lessons  or be related to current affairs.  We found that students were not new to teamwork as they had to  work in teams for other projects in school. However, for many,  what was different was who they were working with, as the  research team randomly grouped the students into teams. Many of  the students found themselves in teams with classmates they had  never worked with before. Some students were unhappy about this  initially, but they got used to this and completed their team  activity. Still, there were others who enjoyed the opportunity to  perform a task with students they normally would not group with.   5.2.3 Visual analytic - self and team awareness  building  Students were provided with a personal micro-profile of their  teamwork competency based on self and peer ratings. We had  feedback relating to the accuracy of students ratings, as well as the  clarity and interpretation of the visual analytic.  Some students questioned the accuracy of the peer ratings as they  felt that certain team members may not have rated them honestly.  Similarly, teachers also felt that certain students might not have  rated their team members accurately. This brings into question  that perhaps students need to be taught how to rate others.  Nevertheless, most students generally agreed with their self and  peer ratings and during the session there were very little questions  addressed to the facilitator regarding this. Moreover, during the  earlier stage, students were also instructed to rate their friends  fairly.     As for the visual analytic, there were 3 parts to the analytic, the  radar chart comparing self, peer, and overall; the numbers shown  in a table; and an overall similarity score.  Regarding the dimensions of teamwork, the facilitator explained  and provided realistic examples to students which helped in  students becoming more aware of what the concepts meant.  Students found the radar chart a powerful visual comparison  between self, peer and overall ratings. They could see how their  peers thought of them as compared to how they thought of  themselves during the task. A student felt that this radar chart  could be shown as individual charts, in addition to the comparison  chart to make it even clearer.  The table was also useful to see the actual numbers. A teacher  remarked, my class is quite analytical; they like to see the small  details. Students liked it when they scored highly on the  dimensions.  The most confusion was regarding the overall similarity score as  the score had negative values. Students were not used to a  negative number and tended to interpret that as a negative aspect  of their teamwork. Facilitators had to repeatedly explain that it  was the magnitude that mattered, not so much the valence. This  value can probably be improved in the future with a more user- friendly visual.   5.2.4 Self and team reflection and sensemaking  In this stage, students were guided in their reflection and  sensemaking with a reflection worksheet with four questions as  mentioned earlier. Students written individual reflections ranged  widely. There were students who agreed with their peer ratings:   I do [agree with my peers concerning my rating] as I spammed  the group.  I think that maybe my teammates didnt see that I was  committed to the task so they rated me lower than I did. My team  might have a less biased point of view and may actually be more  accurate.  There were also students who disagreed with their peer ratings:  I dont agree with them as they have different views.  I dont agree because I did contribute a fair bit.  Many students felt that their peers rated them higher than they  actually should, I dont agree with my peers rating as I should  have got [a] lower [score] because I did not contribute a lot.  However, there were other students who seemed to care less or  were more philosophical in their responses. One student wrote  the ratings do not matter to me while another explained I do  not mind what they rate me as I think that it does not matter that  much and I think that since they do not know me that well, what  they rate might be wrong or might be true, there is no definite  answer.  For the team reflections, we found that many students wrote the  same answer for the whole team in their reflections, suggesting a  consensus in their team reflection. E.g., I want to be more helpful  and communicate better was written by all members of team G.  Some students were slightly vague or did not answer the question,  for instance, be more supportive and have more teamwork.  There were others too that felt that they did not need to change  and could function as what they had functioned.  Nevertheless, most students reflected and stated specific goals to  improve future team performance, for instance:   I will try to make peace with everyone and try to get them to  discuss and give opinions. When the team is not discussing the  topic, I will remind them to stay on task.  I can cooperate better with my teammates and listen to their  views more often. I will be committing more to the team and be  more active. I will be giving suggestions to the members to  improve the answer and participate in the discussion more.  We would put all our differences aside and work together as a  team.  These positive goal-directed responses indicated that students  became aware and understood how they could grow their  teamwork competency.  Overall, the activity for this stage was slightly more difficult for  students. Students were not as responsive as compared to the  earlier stages. During the FGD, a student shared that he found the  reflection questions straightforward but explained that it was  hard to think of something, to write something down when  he did not have any opinion of it.  Another student, student X,  stated that students need to know the purpose of the reflection and  suggested having more examples to help them reflect, and also to  structure it in a format likened to that of a classroom discussion.   Still, most students during the FGD shared that they were clear  about the six dimensions of teamwork and the activity helped  them to understand more about teamwork. One student shared that  she became more aware that she did not know how to share and  explain her ideas and the reasons for why she disagreed with her  teammates. This is the area she would like to work on to enhance  her teamwork competency.  These findings suggested that students individually and as a team  were able to make-sense of the dimensions of teamwork  competency and set goals to change.    5.2.4.1 Teachers views of the reflection and  sensemaking stage  A teacher acknowledged that while important, students are not  used to reflecting and expressing their opinions. He found that this  was also the case in other lessons as students were not prepared or  reluctant to share their opinions. He attributed it to the students  maturity and believed that it would require a lot of time and effort  to develop the metacognitive skills of the students.  Other teachers were less skeptical and felt that this part of the  program could be emphasized more. Teacher A commented that it  served two purposes. It was useful for students to know  themselves, and it sets them to think about how to work in a  group. It was also useful to the teachers because we are able to  better identify what kind of team players our kids are. With that  we can customize grouping to increase efficacy and learning.  Teacher C felt that there could be more room for discussion to  allow all groups a chance to present to know what students  are thinking. She was concerned that the visual analytic could be  too remote and suggested allocating more time for reflections  over a series of lessons to give teachers time to analyze students  micro-profile, in order to provide more specific advice to  students, so that students can work better in their teams.  Similarly, another teacher commented that students might know  the number [the survey scores in their micro-profile] but they  need more time to digest the significance so that it can be useful.  On the whole, the findings pointed to the fact that teachers  recognized the challenges of implementing the reflection and  sense-making stage, but at the same time, they generally  concurred on the importance of the activity and highlighted that     more time was needed for students to reflect and make greater  sense of their teamwork competency.   6. DISCUSSION, IMPLICATIONS AND  FUTURE WORK  The findings reveal both the challenges and potentialities  associated with the trial implementation of the TSDL pedagogical  framework in a teamwork competency awareness program. Both  students and teachers were found to be generally receptive  towards each stage of the framework, despite identified  challenges. In this regard, there was evidence that the broad goals  of the program were met, in that students were able to (a) gain  awareness of their personal teamwork competency and (b) state  possible ways to improve their teamwork. The pedagogical  framework contributed to a large extent in overtly scaffolding the  activities, which in turn points to the pedagogical value and  usefulness of the model.  In the beginning of this paper, we argued for a more explicit  pedagogical model for LA. Our work demonstrates one such  model where the pedagogical activities were planned as stages  according to the TSDL framework. Moreover, in the framework,  LA served as a visual analytic to build the awareness of students  teamwork competency, and for subsequent reflection and  sensemaking. This work spurred us to consider two questions: Is  such a directed theoretical model necessary Would this be  considered a good alignment of LA and learning design  To this end, we would argue that such explicit models are  necessary, and that these frameworks should show good  alignment of LA and the learning design, echoing the works from  [24; 31]. Our findings indicated some advantages of such a stance.  The framework provided the general direction for the program  and theoretical clarity of the learning process. The LA and  learning design was also adequately coupled and prevented  serious misalignments in implementation. More importantly, we  saw that the use of the TSDL framework brought about perceptual  change in students teamwork competency, meeting the goals of  the program.  Our findings also revealed that different aspects of the  pedagogical framework were welcomed by students and teachers.  Students enjoyed the team-based concrete experience, and found  the reflection and sense-making activity difficult. On the other  hand, teachers recognized the reflection and sense-making stage  as important and wanted more time for their students to fully  engage in this.  The depth and duration for the implementation of the different  stages in the TSDL framework is an area that the research team  found challenging. We were constrained by the amount of  curriculum time that the school provided us with to carry out the  program. The research team was cognizant of the trade-off of time  especially for the reflection and sensemaking stage. We  acknowledge that more time should be provided for the reflection  stage, where possible, and will take this into account in the  planning and design of our follow-up trial cycle iterations.  Relating to this issue of curriculum time, we are planning for  greater integration of our program with the schools normal  curriculum. We hope to embed the TSDL framework into a  curriculum subject that employs collaborative inquiry tasks. Plans  are underway but this integration would inadvertently require  other types of concrete experiences, visual analytics as well as  reflection and sensemaking activities. This is complex and  challenging, at the same time offering more room for research, as  requiring careful and principled execution. The principle of   integration as conceptualized in [44] would be helpful in tying  analytics to the curriculum and authentic learning goals. We also  foresee that we might need to develop more fine-grained  instructional activity for each stage of the framework for different  contexts, as guided by the overarching theoretical frame.   At this stage in our research, we only managed to employ  dispositional analytics. The plan is to include other forms of  analytics, with the upcoming phase being discourse analytics.  However, the nature of semi-automated text analysis has been  tedious and challenging for the research team to date. The team is  in the process of devising a reliable analytic engine for the  indicators of teamwork dimensions. The discourse analytics will  add another layer to the existing visual analytic, such as through a  scaled score of the sum of each coded message of each dimension  in the micro-profile. Also, for the dispositional analytics, we are  working to improve the scale validation results of the  questionnaire items and also to enable a real-time system. Besides  the discourse layer, we see potential in using trace data of the  students online usage (such as searches, browsing websites) and  also in identifying the network of interactions among students to  provide further evidences of teamwork and collaboration.   In this study, we focused on TSDL framework for students, but  the teachers were also involved in the whole process as  facilitators. The TSDL framework can also be theoretically  extended for teachers such that teachers are provided with a clear  set of principles of their role in the learning process. In our  implementation, teachers were provided with a class micro-profile  to see their students teamwork competency scores and help them  flag out students that might need early or adaptive intervention.  This was well received by teachers, many of whom found the  class micro-profile to be a useful form of validating their more  tacit and/or intuitive observations of their students. Many teachers  were able to guess the names of the students before they saw the  actual names. Further work would go toward equipping teachers  with learning design guidelines especially in this area of  teamwork competency.   This study proposed and implemented a pedagogical framework  focused on the 21st century competency of teamwork. The  findings are limited to one specific instance. Still, the findings  lean towards a collective appreciation for the pedagogical  usefulness of the program and TSDL framework, although there  are challenges to be addressed. This serves as the impetus for us  to move forward by taking into account the students and  teachers suggested refinements to further improve and develop  the program. There may be potential for the TSDL framework to  be applied to other team-related outcomes too, such as other  cognitive skills and knowledge, which constitutes an area that  may benefit from future research.   7. CONCLUSION  Many pedagogical models in LA papers are implicit which could  result in misaligned practice. This paper presents an explicit  pedagogical model for teamwork competency, the TSDL  framework, and describes its implementation and evaluation by  students and teachers in the context of collaborative inquiry tasks.  The framework was implemented in a teamwork competency  awareness program for 7 classes of 14 year old students. This  paper qualitatively evaluates the program from students and  teachers perspectives. Findings reveal positive perceptions of the  stages of the framework suggesting its pedagogical value. Some  challenges associated with its implementation within school-based  learning contexts were also highlighted. In light of the findings,     we make the case that this framework goes some length to provide  theoretical clarity of the learning process, and also aligns learning  analytics and the learning design. The current work provides trial  outcomes of a teamwork competency awareness program that  used dispositional analytics, and further efforts are underway to  develop the discourse layer of the analytic engine. Future work  will also be dedicated to application and refinement of the  framework for other contexts and participants, both learners and  teachers alike.   8. ACKNOWLEDGMENTS  This paper refers to data and analysis from the following research  projects: NRF2015-EDU001-IHL08 (funded by the Singapore  National Research Foundation, eduLab Research Program),  OER62/12EK and OER09/15EK (funded by the Education  Research Funding Program, National Institute of Education,  Nanyang Technological University, Singapore). The views  expressed in this paper are the authors and do not necessarily  represent the views of the National Institute of Education.    9. REFERENCES  [1] Ali, L., Hatala, M., Gaevi, D., and Jovanovi, J., 2012.   A qualitative evaluation of evolution of a learning  analytics tool. Computers & Education 58, 1, 470-489.   [2] Buckingham Shum, S. and Deakin Crick, R., 2012.  Learning dispositions and transferable competencies:  pedagogy, modelling and learning analytics. In  Proceedings of the 2nd International Conference on  Learning Analytics and Knowledge ACM, 92-101.   [3] Chiu, M.M., 2008. Effects of argumentation on group  micro-creativity: Statistical discourse analyses of algebra  students collaborative problem solving. Contemporary  Educational Psychology 33, 3, 382-402.   [4] Crowston, K., Allen, E.E., and Heckman, R., 2011. Using  natural language processing technology for qualitative  data analysis. International Journal of Social Research  Methodology 15, 6 (2012/11/01), 523-543. DOI=  http://dx.doi.org/10.1080/13645579.2011.625764.   [5] Dawson, S. and Siemens, G., 2014. Analytics to literacies:  The development of a learning analytics framework for  multiliteracies assessment. In The International Review of  Research in Open and Distributed Learning, 285-305.   [6] Drach-Zahavy, A. and Somech, A., 2002. Team  heterogeneity and its relationship with team support and  team effectiveness. Journal of Educational Administration  40, 1, 44-66.   [7] Duffy, T. and Jonassen, D., 1992. Constructivism and the  technology of instruction: a conversation. Lawrence  Erlbaum Associates Publishers, Hillsdale, N.J.   [8] Duval, E., 2011. Attention please!: learning analytics for  visualization and recommendation. In Proceedings of the  1st International Conference on Learning Analytics and  Knowledge ACM, 9-17.   [9] Erkens, G. and Janssen, J., 2008. Automatic coding of  dialogue acts in collaboration protocols. International  Journal of Computer-Supported Collaborative Learning  3, 4, 447-470.   [10] Ferguson, R., 2012. Learning analytics: drivers,  developments and challenges. International Journal of  Technology Enhanced Learning 4, 5-6, 304-317.   [11] Ferguson, R. and Buckingham Shum, S., 2012. Social  learning analytics: five approaches. In Proceedings of the  2nd international conference on learning analytics and  knowledge ACM, 23-33.   [12] Freeman, M. and Mckenzie, J., 2002. SPARK, a  confidential webbased template for self and peer  assessment of student teamwork: benefits of evaluating  across different subjects. British Journal of Educational  Technology 33, 5, 551-569.   [13] Garrison, D.R., Anderson, T., and Archer, W., 2001.  Critical thinking, cognitive presence, and computer  conferencing in distance education. American Journal of  distance education 15, 1, 7-23.   [14] Greller, W. and Drachsler, H., 2012. Translating learning  into numbers: A generic framework for learning analytics.  Journal of Educational Technology & Society 15, 3, 42- 57.   [15] Hung, D. and Nichani, M., 2001. Constructivism and e- learning: Balancing between the individual and social  levels of cognition. Educational Technology 41, 2, 40-44.   [16] Janssen, J. and Bodemer, D., 2013. Coordinated  Computer-Supported Collaborative Learning: Awareness  and Awareness Tools. Educational psychologist 48, 1  (2013/01/01), 40-55. DOI=  http://dx.doi.org/10.1080/00461520.2012.749153.   [17] Janssen, J., Erkens, G., and Kirschner, P.A., 2011. Group  awareness tools: Its what you do with it that matters.  Computers in Human Behavior 27, 3, 1046-1058.   [18] Jrvel, S., Kirschner, P.A., Panadero, E., Malmberg, J.,  Phielix, C., Jaspers, J., Koivuniemi, M., and Jrvenoja, H.,  2015. Enhancing socially shared regulation in  collaborative learning groups: designing for CSCL  regulation tools. Educational Technology Research and  Development 63, 1 (2015/02/01), 125-142. DOI=  http://dx.doi.org/10.1007/s11423-014-9358-1.   [19] Kayes, A.B., Kayes, D.C., and Kolb, D.A., 2005.  Experiential learning in teams. Simulation & Gaming 36,  3 (September 1, 2005), 330-354. DOI=  http://dx.doi.org/10.1177/1046878105279012.   [20] Kirschner, P.A., Strijbos, J.-W., Kreijns, K., and Beers,  P.J., 2004. Designing electronic collaborative learning  environments. Educational Technology Research and  Development 52, 3, 47-66.   [21] Knight, S., Shum, S.B., and Littleton, K., 2014.  Epistemology, assessment, pedagogy: where learning  meets analytics in the middle space. Journal of Learning  Analytics 1, 2, 23-47.   [22] Koh, E., Hong, H., and Seah, J., 2014. An Analytic Frame  and Multi-method Approach to Measure Teamwork  Competency. In 14th International Conference on  Advanced Learning Technologies (ICALT) IEEE, Athens,  264-266. DOI= http://dx.doi.org/doi:  10.1109/ICALT.2014.82.   [23] Kolb, D.A., 1984. Experiential learning: Experience as  the source of learning and development. Prentice-Hall  Englewood Cliffs, NJ.   [24] Lockyer, L., Heathcote, E., and Dawson, S., 2013.  Informing pedagogical action: Aligning learning analytics  with learning design. American Behavioral Scientist 57,  10, 1439-1459.   [25] Loughry, M.L., Ohland, M.W., and Moore, D.D., 2007.  Development of a Theory-Based Assessment of Team  Member Effectiveness. Educational and Psychological  Measurement 67, 3, 505-524. DOI=  http://dx.doi.org/10.1177/0013164406292085.   [26] Mayne, L., 2012. Reflective writing as a tool for assessing  teamwork in bioscience: Insights into student performance   http://dx.doi.org/10.1080/13645579.2011.625764 http://dx.doi.org/10.1080/00461520.2012.749153 http://dx.doi.org/10.1007/s11423-014-9358-1 http://dx.doi.org/10.1177/1046878105279012 http://dx.doi.org/doi: http://dx.doi.org/10.1177/0013164406292085   and understanding of teamwork. Biochemistry and  Molecular Biology Education 40, 4, 234-240.   [27] Meier, A., Spada, H., and Rummel, N., 2007. A rating  scheme for assessing the quality of computer-supported  collaboration processes. International Journal of  Computer-Supported Collaborative Learning 2, 1, 63-86.   [28] Phielix, C., Prins, F.J., and Kirschner, P.A., 2010.  Awareness of group performance in a CSCL-environment:  Effects of peer feedback and reflection. Computers in  Human Behavior 26, 2, 151-161. DOI=  http://dx.doi.org/10.1016/j.chb.2009.10.011.   [29] Phielix, C., Prins, F.J., Kirschner, P.A., Erkens, G., and  Jaspers, J., 2011. Group awareness of social and cognitive  performance in a CSCL environment: Effects of a peer  feedback and reflection tool. Computers in Human  Behavior 27, 3, 1087-1102.   [30] Prins, F.J., Sluijsmans, D.M., Kirschner, P.A., and  Strijbos, J.-W., 2005. Formative peer assessment in a  CSCL environment: A case study. Assessment &  Evaluation in Higher Education 30, 4, 417-444.   [31] Rodrguez-Triana, M.J., Martnez-Mons, A., Asensio- Prez, J.I., and Dimitriadis, Y., 2015. Scripting and  monitoring meet each other: Aligning learning analytics  and learning design to support teachers in orchestrating  CSCL situations. British Journal of Educational  Technology 46, 2, 330-343.   [32] Ros, C.P., Wang, Y.-C., Cui, Y., Arguello, J., Stegmann,  K., Weinberger, A., and Fischer, F., 2008. Analyzing  collaborative learning processes automatically: Exploiting  the advances of computational linguistics in computer- supported collaborative learning. International Journal of  Computer-Supported Collaborative Learning 3, 3  (2008/09/01), 237-271. DOI=  http://dx.doi.org/10.1007/s11412-007-9034-0.   [33] Rummel, N., Spada, H., and Hauser, S., 2009. Learning to  collaborate while being scripted or by observing a model.  International Journal of Computer-Supported  Collaborative Learning 4, 1, 69-92.   [34] Salas, E., Rosen, M.A., Burke, C.S., and Goodwin, G.F.,  2009. The wisdom of collectives in organizations: An  update of the teamwork competencies. In Team  Effectiveness in Complex Organizations. Cross- Disciplinary Perspectives and Approaches, E. SALAS,  G.F. GOODWIN and C.S. BURKE Eds. Routledge/Taylor  & Francis Group, New York, 39-79.   [35] Salas, E., Sims, D.E., and Burke, C.S., 2005. Is there a  Big Five in teamwork Small Group Research 36, 5,  555-599.   [36] Strijbos, J.-W., Martens, R.L., and Jochems, W.M.G.,  2004. Designing for interaction: Six steps to designing  computer-supported group-based learning. Computers &  Education 42, 4, 403-424. DOI=  http://dx.doi.org/http://dx.doi.org/10.1016/j.compedu.2003 .10.004.   [37] Valentine, M.A., Nembhard, I.M., and Edmondson, A.C.,  2012. Measuring teamwork in health care settings: A  review of survey instruments. Harvard Business School.   [38] Van Den Bossche, P., Gijselaers, W.H., Segers, M., and  Kirschner, P.A., 2006. Social and Cognitive Factors  Driving Teamwork in Collaborative Learning  Environments: Team Learning Beliefs and Behaviors.  Small Group Research 37, 5 (October 1, 2006), 490-521.  DOI= http://dx.doi.org/10.1177/1046496406292938.   [39] Verbert, K., Duval, E., Klerkx, J., Govaerts, S., and  Santos, J.L., 2013. Learning analytics dashboard  applications. American Behavioral Scientist 57, 10, 1500- 1509.   [40] Voogt, J., Erstad, O., Dede, C., and Mishra, P., 2013.  Challenges to learning and schooling in the digital  networked world of the 21st century. Journal of Computer  Assisted Learning 29, 5, 403-413.   [41] Vygotsky, L.S., 1978. Mind and society: The development  of higher mental processes Cambridge, MA: Harvard  University Press.   [42] Whitelock, D., Twiner, A., Richardson, J.T., Field, D., and  Pulman, S., 2015. OpenEssayist: a supply and demand  learning analytics tool for drafting academic essays. In  Proceedings of the Fifth International Conference on  Learning Analytics And Knowledge ACM, 208-212.   [43] Willey, K. and Freeman, M., 2006. Improving teamwork  and engagement: the case for self and peer assessment.  Australasian Journal of Engineering Education 12, 2-19.   [44] Wise, A.F., 2014. Designing pedagogical interventions to  support student use of learning analytics. In Proceedings  of the Fourth International Conference on Learning  Analytics And Knowledge ACM, 203-211.   [45] Yukawa, J., 2006. Co-reflection in online learning:  Collaborative critical thinking as narrative. International  Journal of Computer-Supported Collaborative Learning  1, 2, 203-228.        http://dx.doi.org/10.1016/j.chb.2009.10.011 http://dx.doi.org/10.1007/s11412-007-9034-0 http://dx.doi.org/http:/dx.doi.org/10.1016/j.compedu.2003.10.004 http://dx.doi.org/http:/dx.doi.org/10.1016/j.compedu.2003.10.004 http://dx.doi.org/10.1177/1046496406292938  	1. INTRODUCTION 	2. PEDAGOGICAL FRAMEWORKS FOR LEARNING ANALYTICS 	3. RESEARCH PROBLEM AND STUDY CONTEXT: ASSESSMENT OF TWENTY-FIRST CENTURY COMPETENCIES 	3.1 Teamwork competency conceptualization and analytics 	3.2 Pedagogical model 	3.2.1 Team and self diagnostic learning framework  	Figure 1: Team and Self Diagnostic Learning Framework.  	4. FRAMEWORK IN USE: A TRIAL TEAMWORK COMPETENCY AWARENESS PROGRAM 	4.1 Team-based concrete experience 	4.2 Self and team awareness building 	Figure 2: Online chat environment. 	Figure 3: Survey interface for self and peer rating. 	Figure 4: Visual analytic of teamwork competency: teamwork competency micro-profile for a student. 	4.3 Self and team reflection and sensemaking  	5. PEDAGOGICAL FRAMEWWORK EVALUATION 	5.1 Data sources and analysis method 	5.2 Findings 	5.2.1 Overall program 	5.2.2 Team-based concrete experience 	5.2.3 Visual analytic - self and team awareness building 	5.2.4 Self and team reflection and sensemaking 	5.2.4.1 Teachers views of the reflection and sensemaking stage    	6. DISCUSSION, IMPLICATIONS AND FUTURE WORK 	7. CONCLUSION 	8. ACKNOWLEDGMENTS 	9. REFERENCES   