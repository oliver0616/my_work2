Designing MOOCs for Success:   A Student Motivation-Oriented Framework   Jonathan M. Kevan  Department of Learning Design &   Technology,   University of Hawaii at Manoa   Honolulu, Hawaii 96822  jkevan@hawaii.edu   Michael P. Menchaca  Department of Learning Design &   Technology,   University of Hawaii at Manoa   Honolulu, Hawaii 96822  mikepm@hawaii.edu   Ellen S. Hoffman  Department of Learning Design &   Technology,   University of Hawaii at Manoa   Honolulu, Hawaii 96822  ehoffman@hawaii.edu        ABSTRACT  Considerable literature exists regarding MOOCs. Evaluations of  MOOCs range from ringing endorsements to its vilification as a  delivery model. Much evaluation focuses on completion rates  and/or participant satisfaction. Overall, MOOCs are ill-defined  and researchers struggle with appropriate evaluation criteria  beyond attrition rates. In this paper, we provide a brief history of  MOOCs, a summary of some evaluation research, and we propose  a new model for evaluation with an example from a previously- delivered MOOC. Measurement of the MOOC success framework  through four student satisfaction types is proposed in this paper  with a model for informal learning satisfaction, one of the  proposed types, theorized and tested. Results indicated theoretical  underpinnings, while intended to improve instruction, might not  have influenced the same satisfaction construct. Therefore, future  research into alternative satisfaction factor models is needed.   CCS Concepts   Applied computing ~ E-learning    Applied computing ~  Computer-assisted instruction    Applied computing ~ Learning  management systems    Applied computing ~ Distance learning     Applied computing ~ Computer-managed instruction   Keywords  Structural equation modeling; confirmatory factor analysis;  learning analytics; motivation; framework; MOOC.   1. INTRODUCTION: MOOC EVOLUTION  Although in existence fewer than ten years [32], MOOCs have  garnered considerable recognition both in mainstream media as  well as scholarly publications. A current search of the term  MOOC in Google Scholar (October 30, 2015) returns over  48,000 citations. A similar search in Google (October 31, 2015)   returns nearly 9 million results. Despite such cognizance, MOOCs  remain ill-defined. Two of the co-authors previously published a  paper with an extensive review of literature providing a  description of the evolution of MOOCs [13]. A brief synopsis is  provided here.    Originally conceived as courses to be provided online, for free,  and on a massive scale, contemporary MOOCs vary widely,  having differing purposes, designs, and delivery models. Some  focus on content (xMOOC) and others are student-centered  (cMOOC) [3]. MOOCs have been characterized as instructionist,  constructivist, and connectivist [9, 18, 30]. Some rely heavily on  digital media and others require intense discussion. Some follow  very formal schedules and others are loose, with the ability to start  and stop almost any time. Some are linear and others not.  Delivery may be completely asynchronous, mostly asynchronous  with some synchronous requirements, while some MOOCs even  include face-to-face meetings. Curiously, with the explosion of  MOOCs offered [7], many MOOCs lack even the Massive  quantity that supposedly defines them [3]. Massive has become  more possibility than reality.    Current MOOC research ranges from categorical support [25] to  considerable concern [34], with popular media simultaneously  lauding MOOCs and sounding their death knell [35]. Supportive  research generally falls into three categories: (a) these courses are  open and free and increase access to education for all [2], (b)  these courses can serve large numbers of participants at the same  time [2], and (c) these courses are often designed by the highest  quality experts in particular fields [24]. Those with less positive  views of MOOCs frequently mention several concerns: (a) low  levels of course completion [15, 21, 36], (b) technical problems  [11], (c) inconsistent pedagogical design [31, 35], and (d) concern  over course quality [5, 20, 32]. Regardless of the debate about the  appropriateness or sustainability of MOOCs, the fact is that they  remain and continue to grow [1, 23, 26].    A particularly important area of MOOC research covers  evaluation. Much evaluation research faults MOOCs for  considerable non-completion rates [15, 16, 21, 36]. Some studies  go beyond measuring completion, with many looking specifically  at student and/or instructor satisfaction [12, 15, 22, 28, 33, 36].  These studies tend to focus on outcomes with success often  predicated on course completion. Reich (2015) laments that the  next generation of MOOC research needs to adopt a wider range  of research designs (p. 34).       Permission to make digital or hard copies of all or part of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. Copyrights  for components of this work owned by others than the author(s) must be  honored. Abstracting with credit is permitted. To copy otherwise, or  republish, to post on servers or to redistribute to lists, requires prior  specific permission and/or a fee. Request permissions from  Permissions@acm.org.   LAK '16, April 25 - 29, 2016, Edinburgh, United Kingdom Copyright is  held by the owner/author(s). Publication rights licensed to ACM.   ACM 978-1-4503-4190-5/16/04$15.00   DOI: http://dx.doi.org/10.1145/2883851.2883941     2. A NEW LEARNING FRAMEWORK FOR  EVALUATION  In order to address the need for more complex evaluation,  Hoffman and Menchaca (2015) developed a new learning  framework for examining MOOC outcomes. Since MOOC  participants can be said to participate simultaneously in both  formal and informal learning contexts, new measures for success  are needed. In our framework, attention is directed away from  supply-side measurements to more client-based ones such as  expectations, intentions, goals, values, attitudes, enrichment, and  perceived learning. Hoffman and Menchaca stated:     Beyond simple measurements for success, a  newer framework will allow us to better  understand the experience of learners rather  than simply counting if they completed or not.  At the same time, these revised measures have  the potential to shift educational research in  new directions that will enhance our  understanding of learning in general, ways to  measure outcomes in more nuanced terms,  and assist in the design of learning  environments that will meet the requirements  of this new college-going population as well  as for those involved in formal university  course and degree programs. In sum, a newer  framework for MOOCs, one drawing on  contemporary methods for mining data, a  newer understanding of psychology and the  brain, innovations in educational technology,  and deeper theories of learning design would  provide a better vantage point for making  critical decisions when the stakes are so large.  (2015, p. 7).      3. A STRUCTURAL EQUATION MODEL  In this paper, in order to address the theoretic framework seeking  new measurements for MOOC evaluation, a structural equation  model to measure MOOC participant satisfaction is proposed.  Structural Equation Modeling (SEM), considered a superset of  other statistical approaches, is a methodology used to  quantitatively measure and assess a theoretically based model  [27]. Using this approach multiple theoretical constructs of  student satisfaction can be measured and correlated to understand  their overall influence on MOOC satisfaction. This concept  respects the complexity of student motivations and frames MOOC  success and design as a result of this diversity. In order words,  success is measured as a function of a MOOCs ability to meet  student expectations and not the other way around.    For this new learner framework, we propose student motivation be  considered a more appropriate metric to measure MOOC success.  Theoretical grounding for diversity in student satisfaction was  extracted from several recent studies categorizing motivations for  MOOC participation [4, 35, 36]. Review and consolidation of  research results yielded four initial factors proposed to weigh on  overall MOOC participant satisfaction:   1. Content Satisfaction,  2. Social Satisfaction,  3. Informal Learning Satisfaction, and  4. Formal Learning Satisfaction.      3.1 Content Satisfaction  Students seeking content satisfaction are registering for MOOCs  to access resources for immediate interest or on-demand needs.  Often, these students have no intent of participating in the course  beyond registration and are primarily interested in the type of  content available or seeking answers to an immediate intrinsic or  extrinsic need.     3.2 Social Satisfaction  MOOC participants attempting to expand their social network or  influence are trying to achieve social satisfaction. These students  could be in multiple states of prior knowledge ranging from: (a)  brand new to a topic and looking to meet fellow self-motivated  students to (b) domain experts interested in sharing their  knowledge. Regardless of existing domain knowledge, the  primary goal of this type of student is to make new social  connections in a discipline of interest.     3.3 Informal Learning Satisfaction  Informal learning students can be motivated by a variety of  intrinsic and extrinsic motivation factors ranging from personal  interest to the potential for future job opportunities. What makes  these students unique is disinterest or inability to participate in the  scheduling or workload rigidity often present in formal education.  Preferring to self-regulate instruction, these students often have  external commitments and consider high workloads or content  designed for formal delivery as barriers to satisfaction.     3.4 Formal Learning Satisfaction  This student type, often participating for extrinsic motivational  reasons, is seeking a course aligned with their experience in  formal educational environments. In the United States, this  experience is traditionally expository in nature with groups of  students progressing through content collectively. Looking for  pressure, these students prefer formal supports and often access  to instructional faculty.    Since student motivation is often multi-faceted, each learner will  show a unique combination and weighting of desires for MOOC  satisfaction. If each motivational type also corresponds to targeted  educational interventions, developing a MOOC that satisfies all  students is inherently complicated and perhaps practically difficult  to achieve. In order to explore maximization of MOOC success, if  such success is defined as student satisfaction, then instructional  design strategies that cater to individual motivational needs,  culture and instructional context must be identified and verified as  effective.    To achieve this, MOOC design elements can be separated and  measured for their unique influence on each satisfaction factor  (see Figure 1). For example, required synchronous class sessions  with group discussion may be effective as part of a strategy for  formal learning or social satisfaction yet may negatively correlate  with content or informal learning desires. Iteratively including and  measuring the impact of educational strategies on key satisfaction  factors can help guide educators in designing effective MOOCs,  analyzing summative results, and ultimately lead towards a  formative dashboard for on-demand notification of required  instructional adjustments.       Figure 1: MOOC Satisfaction Model      4. INFORMAL LEARNING  SATISFACTION  To begin defining instructional strategies and technologies that  influence MOOC success, each satisfaction construct must be  individually modeled to theory, tested and then correlated to other  identified constructs. Informal learning satisfaction was selected  as an initial MOOC satisfaction sub factor to analyze with future  factors to be defined in subsequent studies. The following initial  explanatory model for informal learning satisfaction is proposed  to explore how MOOC design and delivery correlates with  satisfaction. Each satisfaction factor is intended as a living  research design to be continuously modified and tested as new  interventions are identified, developed and investigated. Therefore  the proposed informal learning model is not intended to be a  complete model, but a reference point for the reproduction of  research and situation of future development cycles.   This informal learning satisfaction factor looks at the relationship  between three elements used to explore this student type: self- determination, content interaction and self-regulated supports.  Self-determination, a theory that explores an individual's interest  and value of educational experiences [8], is used to explore the  mindset and subsequent MOOC interactions of this student type.  Content interaction in an informal learning environment is  optional and measurement of these events can help identify poorly  scaffolded and low engagement material that could turn this  student type away. Finally, self-regulated supports like checklists  may help informal learners to manage their learning process [9,  19]. Trace data of such interactions may help identify the efficacy  of tools and their relationship with informal learning satisfaction.   5. OPERATIONAL EXAMPLE  Full SEM model analysis requires multiple satisfaction constructs  to be analyzed together; therefore, testing of additional  satisfaction factors must predicate full analysis. Until additional  factors can be correlated, Confirmatory Factor Analysis (CFA), a  type of SEM analysis, is an appropriate initial analytical step for  testing the model of a single satisfaction construct. The informal  learning satisfaction model was tested using CFA, with data  collected in a cMOOC offered at the University of Hawaii at  Manoa (N=28). Two students opted out of the study bringing the  final sub-population to 26 students. Students were informed of the  study upon registration in the MOOC and capable of opting out  and having accumulated research data deleted at anytime. Data  were collected by the Learning Management System using the  Experience API, a social constructivist informed data  specification aligned with the pedagogy of cMOOCs generally,  and this MOOC specifically [17]. All data collected for informal  learning satisfaction are outlined in Table 1.   Table 1: Sub Factors and Measure Data   Elements Data Point   Content  Interaction   Total content views: Total number of times  viewing a page with instructional content    Total design views: Total number of times  viewing student final project submissions   Self Regulated  Supports   Check offs: Number of times student used an  embedded and optional content completion  checklist    Self  Determination   Extra discussions: Total number of discussion  posts beyond amount targeted by instructor    Extra peer review: Total number of peer  projects reviewed by MOOC students beyond  the amount targeted by the instructor      5.1 Results  Goodness-of-Fit indices are used to assess how well the proposed  informal learning satisfaction model fits the data set [26]. The first  analysis, the Comparative Fix Index (CFI), resulted in a value of  .925, smaller than the recommended cut-off of .95 [14].  Additionally, the Room Mean Square Error of Approximation  (RMSEA) index value of 0.178 was found, this value exceeds the  accepted 0.10 cutoff [6] indicating the model is a poor fit to the  available data and further refinement is needed. See Figure 2 for  standardized factor loadings, * indicates statistically significant  relationships at a p < .001 level. Analysis was done using R and  the open source statistical package lavaan.     Figure 2: Informal Learning Satisfaction MOOC Model      6. CONCLUSIONS  While a portion of the poor fit can be explained by a small sample  size, the variety of factor loadings ranging from .969 to -0.286 as  well as the poor fit indices clearly indicate a model that does not  accurately reflect a single construct. Content interaction, self- regulated supports and self-determination may have impact on  student satisfaction based on past research, but they do not appear  to contribute to the same satisfaction construct in our initial  analysis.     Further work is needed to define an informal learning satisfaction  construct that can be eventually analyzed in relation to other types  of MOOC participant satisfaction. Although the model tested in     this study did not result in strong evidence towards an informal  learning satisfaction model, it should be noted that these data  elements should now be considered as potential traces for other  satisfaction constructs. It is through this iterative development and  testing that a full MOOC Satisfaction Model can be ultimately  achieved.     7. RECOMMENDATIONS  Using learning analytics trace data, this study explored the  identification of informal learning satisfaction of MOOC  participants as part of a larger SEM model identifying multiple  satisfaction factors. Initial results indicate that content interaction,  self-regulation supports in the form of checklists, and self- determination may not help identify informal learning satisfaction  as originally predicted. While this result was unexpected, it was  the intent of this study to propose the analysis of MOOC design  from the perspective of student satisfaction. In that light, we  found that various MOOC design elements that may have been  designed to positively influence learning are not necessarily  working towards the same student motivations. Therefore, we  suggest future researchers continue to propose alternative  satisfaction factor models that can be ultimately incorporated and  analyzed into the larger MOOC Satisfaction Model.    8. REFERENCES    [1] Allen, I. E., and Seaman, J. 2014. Grade change: Tracking   online education in the United States. Babson Survey  Research Group and Quahog Research Group, LLC,  Oakland, CA. Available at  http://www.onlinelearningsurvey.com/reports/gradechange.p df   [2] Anderson, T., and McGreal, R. 2012. Disruptive pedagogies  and technologies in universities. Educ Technol Soc. 15, 4,  380-389. Retrieved from http://www.ifets.info/   [3] Baggaley, J. 2013. MOOC rampant. Distance Education. 34,  3, 368-378. DOI=  http://dx.doi.org/10.1080/01587919.2013.835768   [4] Belanger, Y., and Thornton, J. 2013. Bioelectricity: A  quantitative approach Duke Universitys first MOOC.  Available at  http://dukespace.lib.duke.edu/dspace/bitstream/handle/10161 /6216/duke_bioelectricity_mooc_fall2012.pdfsequence=1.   [5] Bragg, A. B. 2014. MOOCs: Where to from here Train Dev  J. 41, 1, 20-21.    [6] Browne, M. W., and Cudeck, R. 1993. Alternative ways of  assessing model fit. Sage focus editions. 154, 136-136.   [7] CotoNet. 2015. MOOC List. Available at https://www.mooc- list.com   [8] Deci, E. L., Vallerand, R. J., Pelletier, L. G., and Ryan, R.  M. 1991. Motivation and education: The self-determination  perspective. Educational psychologist. 26, 3-4, 325-346.   [9] Delclos, V.R. and Harrington, C. 1991. Effects of strategy  monitoring and proactive instruction on childrens problem- solving performance. J Educ Psychol. 83, 3542.   [10] Downes, S. 2012. The rise of MOOCs. Recuperado el, 1.    [11] Fini, A. 2009. The technological dimension of a Massive  Open Online Course: The case of the CCK08 course tools.  International Review of Research in Open and Distance  Learning. 10, 5. Available at  http://www.irrodl.org/index.php/irrodl/article/view/643/1402   [12] Heutte, J., Kaplan, J., Fenouillet, F., Caron, P.A., and  Rosselle, M. 2014. MOOC user persistence: Lessons from  French educational policy adoption and deployment of a  pilot course. In Learning Technology for Education in  Cloud. MOOC and Big Data, L. Uden, J. Sinclair, Y.H. Tao  and D. Liberona Ed. vol. 446. Springer International  Publishing, New York, NY, 13-24.   [13] Hoffman, E.S. and Menchaca, M.P. 2015. Personal learning  goals versus attrition in MOOCs: A learner framework for  MOOC 2.0. In World Conference on E-Learning (Kona,  Hawaii, 2015) Association for the Advancement of  Computing in Education.   [14] Hu, L. T., and Bentler, P. M. 1999. Cutoff criteria for fit  indexes in covariance structure analysis: Conventional  criteria versus new alternatives. Structural equation  modeling: a multidisciplinary journal. 6, 1, 1-55.    [15] Jordan, K. 2014. Initial trends in enrolment and completion  of massive open online courses. The International Review of  Research in Open and Distributed Learning. 15, 1, 133-160.  Available at  http://www.irrodl.org/index.php/irrodl/article/view/1651   [16] Kassabian, D. W. 2014. The value of MOOCs to early  adopter universities. EDUCAUSE Review. Available at  http://www.educause.edu/ero/article/value-moocs-early- adopter-universities   [17] Kevan, J., and Ryan, P. 2015. Experience API: Flexible,  decentralized and activity-centric data collection.  Technology, Knowledge and Learning. 1-7. DOI=  http://dx.doi.org/ 10.1007/s10758-015-9260-x   [18] King, A. 1991. Effects of training in strategic questioning on  childrens problem-solving performance. J Educ Psychol. 83,  307317.   [19] Knox, J., Bayne, S., Macleod, H., Ross, J., and Sinclair, C.  2012. MOOCs pedagogy: The challenges of developing for  Coursera. Association for Learning Technology Online  Newsletter. Available at  https://newsletter.alt.ac.uk/2012/08/mooc-pedagogy-the- challenges-of-developing-for-coursera/   [20] Koller, D., Ng, A., Do, C., and Chen, Z. 2013. Retention and  intention in massive open online courses: In depth. Educause  Review. 48, 3, 62-63. Available at  http://www.educause.edu/ero/article/retention-and-intention- massive-open-online-courses-depth-0   [21] Liyanagunawardena, T. R. 2014. MOOC experience: A  participant's reflection. ACM SIGCAS Computers and  Society. 44, 1, 9-14. DOI=  http://dx.doi.org/10.1145/2602147.2602149   [22] Liyanagunawardena, T. R., Adams, A. A., and Williams, S.  A. 2013. MOOCs: A systematic study of the published  literature 2008-2012. International Review of Research in  Open and Distance Learning. 14, 3, 202-227. Available at  http://www.irrodl.org/     [23] Martin, F. G. 2012. Education: Will massive open online  courses change how we teach (Viewpoints).  Communications of the ACM. 55, 8, 26. DOI=  http://dx.doi.org/10.1145/2240236.2240246   [24] Milligan, C., Littlejohn, A., and Margaryan, A. 2013.  Patterns of engagement in connectivist MOOCs. MERLOT  Journal of Online Learning and Teaching. 9, 2, 149-159.  Available at  http://jolt.merlot.org/vol9no2/milligan_0613.htm   [25] Pirani, J. 2013. A compendium of MOOC perspectives,  research, and resources. EDUCAUSE Review. Available at  http://www.educause.edu/ero/article/compendium-mooc- perspectives-research-and-resources   [26] Raykov, T., and Marcoulides, G. A. 2012. A first course in  structural equation modeling. Routledge. DOI=  http://dx.doi.org/10.4324/9780203930687   [27] Reich, J. 2014. MOOC completion and retention in the  context of student intent. EDUCAUSE Review. Available at  http://www.educause.edu/ero/article/mooc-completion-and- retention-context-student-intent   [28] Reich, J. 2015. Rebooting MOOC research. Science. 347,  6217, 34-35. DOI=  http://dx.doi.org/10.1126/science.1261627   [29] Siemens, G. 2005. Connectivism: A learning theory for the  digital age. International Journal of Instructional  Technology and Distance Learning. 2, 1, 3-10. Available at  http://www.itdl.org/Journal/Jan_05/article01.htm   [30] Siemens, G. 2012. MOOCs are really a platform [Blog].  Elearnspace. Available at   http://www.elearnspace.org/blog/2012/07/25/moocs-are- really-a-platform/   [31] Siemens, G. 2013. Massive Open Online Courses:  Innovation in education, In Open Educational Resources:  Innovation, Research and Practice, R. McGreal, W.  Kinuthia and S. Marshall Ed. Vancouver, BC Canada:  Commonwealth of Learning and Athabasca University. 5-16.   [32] Stein, R. M., and Allione, G. 2014. Mass attrition: An  analysis of drop out from a Principles of Microeconomics  MOOC. PIER Working Paper 14-031: Penn Institute for  Economic Research. DOI=  http://dx.doi.org/10.2139/ssrn.2505028   [33] Vardi, M. Y. 2012. Will MOOCs destroy academia (Editor's  Letter). Communications of the ACM. 55, 11, 5. DOI=  http://dx.doi.org/10.1145/2366316.2366317   [34] Wiley, D. 2012. The MOOC misnomer [Blog]. Iterating  toward Openness. Available at  http://opencontent.org/blog/archives/2436   [35] Yang, D., Sinha, T., Adamson, D., and Rose, C. P. 2013.  Turn on, tune in, drop out: Anticipating student dropouts in  massive open online courses, in Proceedings of the 2013  Annual Conference on Neural Information Processing  Systems, Data-Driven Education Workshop (Lake Tahoe,  Nevada, 2013) 10, 13.   [36] Yuan, L., Powell, S., and Cetis, J. 2013. MOOCs and open  education: Implications for higher education.   [37] Zheng, S., Rosson, M. B., Shih, P.C., and Carroll, J.M. 2015.  Understanding student motivation, behaviors and perceptions  in MOOCs. ACM Press. 1882-1895. DOI=  http://dx.doi.org/10.1145/2675133.2675217        