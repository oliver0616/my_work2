Analysing Engagement in an Online Management Programme and Implications for Course Design  Marc Wells Educational Technology Unit  Imperial College London m.wells@imperial.ac.uk  Alex Wollenschlaeger London Knowledge Lab  Birkbeck, Univ. of London awolle01@dcs.bbk.ac.uk  David Lefevre Educational Technology Unit  Imperial College London david.lefevre@imperial.ac.uk  George D. Magoulas London Knowledge Lab  Birkbeck, Univ. of London gmagoulas@dcs.bbk.ac.uk  Alexandra Poulovassilis London Knowledge Lab  Birkbeck, Univ. of London ap@dcs.bbk.ac.uk  ABSTRACT  We analyse engagement and performance data arising from participants interactions with an in-house LMS at Imperial College London while a cohort of students follow two courses on a new online postgraduate degree in Management. We identify and investigate two main questions relating to the relationships between engagement and performance, draw- ing recommendations for improved guidelines to inform the design of such courses.  Categories and Subject Descriptors  K.3.1 [Computer Uses in Education]: Distance Learning  Keywords  Analysing interaction data, engagement and performance, predicting student performance  1. INTRODUCTION Two key affordances of online provision in the context  of management education are the ability to offer students a more flexible programme of study and the opportunity to deliver education to an additional pool of students who are unable or unwilling to attend classes on campus. To this end, Imperial College London has developed a digital campus to deliver several postgraduate degree programmes online. This consists of an in-house Learning Management System (LMS), online courseware, and provision of tablet computers to all students. All course materials and learn- ing interactions are held within the learning platform. The system has proven very popular with both students and tu- tors, and it has been co-developed and evaluated with these stakeholder groups over a number of years [6].  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.  LAK 16, April 25 - 29, 2016, Edinburgh, United Kingdom  c 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-4190-5/16/04. . . $15.00  DOI: http://dx.doi.org/10.1145/2883851.2883894  The platform tracks interactions and activity completions by students, presenting an opportunity to undertake a pilot project analysing potential relationships between different forms of participant engagement in the platform in order to better understand how students are engaging with their online courses and how the design of the courses may be im- proved for the benefit of subsequent cohorts. The research presented here has used interaction data from the first term (semester) of a new 2-year online postgraduate degree in Management. This term lasted 10 weeks during which stu- dents studied two compulsory courses, in Accounting and in Marketing. We report on the design and application of a range of analyses of the interaction data, with the aim of investigating two key questions: Q1: Effect of staff engagement on student engagement. Q2 : Effect of student engagement on student performance.  Section 2 discusses background and related work. Sec- tion 3 presents the design of our research. In Sections 4 and 5 we present and discuss our results. Section 6 draws overall conclusions and identifies directions of future work.  2. RELATED WORK Siemens [5] and Dyckhoff et al. [3] provide broad exposes  of the field of learning analytics and conclude by emphasising the need to develop tools that are useful to learners, teach- ers, institutions and researchers. A necessary step towards the development of such tools is the establishment of rela- tionships between the behaviour of different agents within a learning system and subsequent outputs such as learners levels of performance and satisfaction. The focus of our re- search here is learner engagement. Much work has been done recently in identifying patterns of learner engagement within Massive Open Online Course (MOOC) environments, e.g. [2, 4], in order to identify more successful students, identify students at risk of dropping out, and support students self- awareness. Patterns of learner engagement have also been analysed on more traditional distance learning courses, again with an emphasis on predicting students at risk [7].  A previous study [1] has focussed on learner engagement in the context of online management programmes. This study of 48 online MBA courses, from one institution, investigated the impact of course technologies, instructor behaviours and learner behaviours on perceived learning, learner performance and learner satisfaction. Instructor behaviour was found to    Table 1: Student demographics Number  Total 67 Gender Women 17  Men 50 Region Africa/Middle East 19  Americas 13 Asia/Pacific 14 Europe 3 UK 18  Highest qualification Bachelors 42 Masters 20 Doctoral 4 Professional 1  Employment sector Energy/Mining 14 Banking/Finance 10 Telecomm 6 Consulting 5 Cons. Goods/Retail 5 IT/Technology 5 Education 4 Other 18  predict learner satisfaction, however students social pres- ence was found to be significant in predicting all three out- puts.  The present research contributes to this body of litera- ture by analysing learner engagement within one particular category of online learning. The Online Management pro- gramme at Imperial can be distinguished from MOOCs, and from many other distance learning courses, due to the rela- tively small cohort size of students on the programme, the highly selective nature of admissions, the presence of a small amount of face-to-face tuition (there are three on-campus weeks, one at the start of year 1 and two at the start of year 2) and the high levels of support provided by course staff. As a consequence, student retention is not a primary issue as very few students fail to complete their degrees. Moreover, because Imperials in-house LMS has been co-developed and evaluated with students, tutors and administrators over a number of years, acceptance of this technology by these co- horts of students is also not a primary issue in our context (c.f. [1]). However, there is still variability in students per- formance and their levels of satisfaction with their courses. Both these factors are therefore worthy of attention from a learning perspective, and in this paper we focus on the former.  3. DESIGN The Online Management programme at Imperial is highly  selective and draws a diverse audience of students from around the world. For the 2014-15 session of the new postgraduate degree in Management that is our focus here, 67 students from 29 countries on five continents were admitted (see Ta- ble 1). The median student age was 35 (interquartile range [33,38]). All students had significant work experience, with a median of 10 years (interquartile range [7,12.5]).  3.1 Course Design Our study here focusses on the first two courses taken  in the 2014-15 session of the new postgraduate degree: Ac- counting and Marketing. Both courses followed the same delivery structure: 2 weeks pre-study, 10 weeks term time study, and a 4 week exam period. As per equivalent face- to-face MBA programmes, the course design places an em- phasis on encouraging an active approach to learning and community-oriented activities. Students are asked to com-  Table 2: Accounting course design Module structure Activity Breakdown  Pre-Study [DE] [100%] Week 1 [DE, PA, CC, F] [60%, 30% 8%, 2%] Week 2 [DE, PA, CC, F] [70%, 11%, 8%,9%,2%] Week 3 [DE, PA, CC, PS, F] [48%, 20%, 1%, 20%, 11%] Week 4 [DE, PA, CC, PS] [30%, 43%, 16%,11%] Week 5 [DE, CC, PS] [59%, 37%, 4%] Week 6 [DE, PA, PS, F] [44%, 44%, 10% 2%] Week 7 [DE, PA, CC, PS, F] [50%, 18%, 11%, 14%, 8%] Week 8 [DE, PA] [62%, 38%] Week 9 [DE, PA, CC] [50%, 31%, 18%] Week 10 [DE, CC, PS, F] [13%, 49%, 23%, 15%] Exam Period [DE] [100%] CC: Construction and connection; DE: Demonstration and exposition; F: Feedback PA: Practice and application; PS: Production and submission  Table 3: Marketing course design Module structure Activity Breakdown  Pre-Study [DE] [100%] Week 1 [DE, PA, CC, PS, F]] [66%, 8%, 8%, 13%, 5%] Week 2 [DE, CC, PS, F] [39%, 38%, 20%, 3%] Week 3 [DE, CC, F] [43%, 52%, 5%] Week 4 [DE, CC, PS, F] [31%, 46%, 10%, 13%] Week 5 [DE, PA, CC, PS] [58%, 4%, 25%, 13%] Week 6 [DE, CC, PS] [51%, 19%, 30%] Week 7 [DE, CC, PS] [23%, 41%, 36%] Week 8 [DE, CC, PS, F] [33%, 36%, 29%, 2%] Week 9 [DE, PA, CC, PS, F] [40%, 3%, 30%, 10%, 17%] Week 10 [DE, PA, PS] [32%, 15%, 53%] Exam Period [DE, CC, F] [48%, 20%, 32%]  plete a sequence of activities each week which are predom- inantly asynchronous in nature. The activities can be cat- egorised as: Demonstration and exposition, Practice and application, Construction and connection, Production and submission, and Feedback. Tables 2 and 3 outline the deliv- ery structure of each course along with the design breakdown of activities.  3.2 Data collected Engagement data was collected for students and for course  staff, where course staff refers to the course leaders (one for Accounting and two for Marketing), the teaching assis- tants (one for each course) and the administrative staff (two staff supporting the whole degree). For students, engage- ment events were categorized according to their initiation mechanism and included material-initiated, tutor-initiated and student-initiated events:  Material-initiated events were events that were the re- sult of prompts within the course materials. During the instructional design phase of the course development these material-initiated events were embedded into the course de- livery to ensure students had the opportunity to apply learn- ing concepts and share their knowledge with other students. The types of prompting events reflected the course design, covering practice and application activities, such as quizzes, questions and polls, and construction and connection activ- ities, such as word cloud and geotagging exercises and open discussions.  Tutor-initiated events were replies by students to forum and newsfeed topics initiated by course staff. The rationale for adopting this measure was that students who are more engaged would be more likely to participate in discussions initiated by course staff. For this study, no attempt was made to discriminate between forum replies by analysing the contents of the replies, the only requirement being that the reply was made by students not by course staff. A more detailed content-based analysis will be undertaken in future    work. A third measure considered was student-initiated engage-  ment events, defined as the number of forum topics initiated by individual students. The reasoning behind this choice of metric was that more engaged students would be more likely to initiate discussions with the course tutor and their fellow students on the discussion forums. Here, too, no attempt was made to analyse the content of the topics that were initiated, and again we leave this as future work.  For staff engagement, the principal metrics were the num- ber of forum discussion topics initiated by staff members and, more implicitly, the overall course design, principally the distribution of activities. Both metrics serve to the de- fine the number of potential engagement venues for students.  To complement the engagement data, performance and demographic data was collected for all students. Perfor- mance data included the marks obtained for the coursework and exam components of the two courses as well as the over- all mark. Demographic data is shown in Table 1.  3.3 Analysis The analyses planned to investigate Questions 1 and 2  were dictated by the available data. Question 1 examined whether the level of engagement shown by course staff had any effect on the levels of engagement of students. As de- scribed above, the primary measure for this analysis was the number of engagement events for both staff and stu- dents. This question was addressed largely through descrip- tive means. Student engagement events were aggregated across all students and grouped by initiation route: mate- rial, tutor or student initiation, as defined above. Overall student engagement, calculated as a sum across all initia- tion routes, was also considered. These aggregated measures were plotted against time so that trends associated with spe- cific characteristics of each course and key events such as exam dates or the end of term periods could be visualized.  Question 2 was centred on students themselves and ex- amined whether engaged students performed better. Cor- relation and simple linear regression analyses were used to investigate interactions between overall student engagement, as defined for Question 1, and overall course performance.  4. RESULTS  4.1 Question 1 Figures 1  3 show, respectively, the numbers of student-  initiated, tutor-initiated and material-initiated engagement events occurring during the pre-study, term-time study and exam period of the Accounting course and the Marketing course. Figure 4 shows the aggregated overall engagement. Important timed events, indicated by dashed vertical lines, are shown in the graphs and include: the start of the pre- term preparation time (prep), the start of the term (start), the end of the term (end), the due date for coursework (coursework), and the date of the final exam (exam).  For both courses, we see that student-initiated engage- ment was relatively stable over time. For the Accounting course, there was a spike in engagement in the weeks fol- lowing the end of the term and immediately preceding the examination period, suggesting that students were engaging more frequently in discussions about the course materials ahead of the assessment and exam.  Tutor-initiated engagement was low for both courses, in  absolute terms, although this may be in part due to the chosen metric, as course staff do not tend to initiate fo- rum discussions. In contrast, material-initiated engagement was high for both courses, representing the majority of the overall engagement. There was a downward trend in this as the courses progressed, more pronounced for the Accounting course. Since material-initiated events are the result of en- gagement activities that are explicitly planned by the course staff, this downward trend is likely to be reflective of a lower number of opportunities for student engagement rather than a lack of engagement by students.  Overall student engagement across the three categories was similar for the two courses, at least initially (Figure 4). The lower overall engagement observed for the Accounting course towards the end of the term is the result of a signif- icant drop in material-initiated engagement opportunities. To provide an overview of engagement for each course, the student-, tutor- and material-initiated engagement events are plotted together for Accounting in Figure 5 and Mar- keting in Figure 6. These graphs highlight again the higher proportion of engagement events that were initiated by the course material.  Week  En ga  ge m  en t e  ve nt  s  (n  )  prep 1 2 3 4 5 6 7 8 9 10 exam  0 10  20 30  40 50  60 70  80 accounting marketing start end coursework exam  Figure 1: Student initiated engagement  Week  En ga  ge m  en t e  ve nt  s  (n  )  prep 1 2 3 4 5 6 7 8 9 10 exam  0 2  4 6  8 10 accounting  marketing start end coursework exam  Figure 2: Tutor initiated engagement  4.2 Question 2 For this question, we wished to determine whether the  level of engagement exhibited by students was reflected in the marks obtained in assessment activities. This required a measure of individual student engagement, and a natu- ral choice was to use the overall engagement as defined for Question 1, aggregated at the student level. Student per- formance was represented by the overall mark obtained by a student on a course (Accounting or Marketing).  The Pearson correlation coefficient () between student engagement and course mark was 0.389 for Accounting and    Week  En ga  ge m  en t e  ve nt  s  (n  )  prep 1 2 3 4 5 6 7 8 9 10 exam  0 50  15 0  25 0  35 0  accounting marketing start end coursework exam  Figure 3: Material initiated engagement  Week  En ga  ge m  en t e  ve nt  s  (n  )  prep 1 2 3 4 5 6 7 8 9 10 exam  0 50  15 0  25 0  35 0  accounting marketing start end coursework exam  Figure 4: Total student engagement  0.228 for Marketing, suggesting that there is a weak rela- tionship. Simple regression analysis was used to further study this relationship by regressing overall course marks on overall engagement. For Accounting, the simple linear regression coefficient was positive and significantly differ- ent from zero, although the magnitude was small (coef = 0.5041, p = 0.00116, R2 = 0.151; Figure 7). For Marketing, the coefficient was not significantly different from zero (coef = 0.07680, p = 0.0635; Figure 8). These correlation and regression results suggest that there may have been a small, positive relationship between engagement and performance at the level of individual students.  5. DISCUSSION  5.1 Influencing student engagement Distance learning students by necessity have less interac-  tion with course staff. One of the primary questions ad- dressed here was whether there was a relationship between the level of engagement of students and that of staff. Fig- ures 4, 5 and 6 summarize the overall engagement of students across the two courses analyzed. The most striking observa- tion, seen for both the Accounting and Marketing courses, is the drop off in engagement in the second half of the term as compared with the first half. This is most apparent in the material-initiated student engagement (Figure 3).  For the Accounting course, the drop in material-initiated engagement was followed by an increase in student-initiated engagement (Figure 1). This spike could have two possible explanations: this is the period just before the final exam, therefore students often have more questions; alternatively, another explanation could be the lack of a revision session for the Accounting course, and hence students engagement in more online activity to compensate for that. The Marketing  Week  En ga  ge m  en t e  ve nt  s  (n  )  prep 1 2 3 4 5 6 7 8 9 10 exam  0 50  15 0  25 0  35 0  student tutor material start end coursework exam  Figure 5: Accounting student engagement  Week  En ga  ge m  en t e  ve nt  s  (n  )  prep 1 2 3 4 5 6 7 8 9 10 exam  0 50  15 0  25 0  35 0  student tutor material start end coursework exam  Figure 6: Marketing student engagement  course, conversely, did have an online synchronous session with the course leader in the weeks leading up to the final exam, which could explain the lack of a similar spike in student-initiated engagement for that course.  Following the analysis presented here, subsequent scrutiny of the designs of the two courses revealed a gradual reduc- tion in the engagement activities in the second half of both courses (more pronounced in Accounting) as more revision material tended to be introduced. This presents an opportu- nity for the Programme team to review these course designs ahead of their next delivery. The differentiation between the Accounting and Marketing courses in this respect presents an opportunity for peer interaction between the respective course leaders (even going so far as to show them the graphs in Figures 5 and 6) to encourage reflection, peer discussion and ultimately improvement of the course designs.  5.2 Student engagement and performance As Imperials Online Management programme is deliv-  ered predominantly online, the inherent motivation and self- discipline of each student is important in ensuring success on the programme. In our study here, we examined whether there is a relationship between engagement and performance at the student level. From correlation and simple linear re- gression analyses, it appears that there may be a weak posi- tive relationship between individual student engagement and performance. This effect was small and inconsistent, being more pronounced for the Accounting course (Figures 7 and 8).  A pertinent point here is the uniformity of the profile of students who are admitted to Imperials Business School (the student cohort is highly selective, to include people with suitable educational and employment experiences). More- over, since by design the majority of engagement events are driven by the course material, the overall student engage-    0 10 20 30 40 50 60  30 40  50 60  70 80  90  Engagement events (n)  C ou  rs e   m ar  k  (%  )  Figure 7: Regression of overall mark vs engagement events on Accounting course  0 10 20 30 40 50 60  50 55  60 65  70 75  80  Engagement events (n)  C ou  rs e   m ar  k  (%  )  Figure 8: Regression of overall mark vs engagement events on Marketing course  ment metric may not capture individual student character- istics well. A more suitable metric that more effectively captures individual differences may be able to identify more clearly an effect between engagement and performance. This is an area of ongoing study.  6. CONCLUSIONS This paper has considered a new online postgraduate de-  gree in Management at Imperial College London, delivered online through an in-house LMS, and has analysed inter- action data relating to a cohort of 67 students taking the first two courses of the degree. Two main questions were considered relating to the relationships between engagement and performance in this highly selected group of students. Our analyses showed that student-initiated engagement was relatively stable over time, although increasing in the run- up to the examination period if there was a lack of an ex- plicitly planned revision session in the course. Material- initiated events are the result of engagement activities ex- plicitly planned by the course staff, and our analyses showed a drop-off in these in the second half of both courses. Sub- sequent scrutiny of the course designs revealed a reduction in opportunities for engagement as more revision material was introduced. Since our correlation and regression results suggest that there may be a small, positive relationship be- tween engagement and performance at the level of individual students, our recommendations to course leaders going for- wards are to: (i) include an explicit revision session within their courses, and (ii) continue to design opportunities for material-initiated engagement even within the sessions in the latter parts of their courses that are introducing revi-  sion material. One of the guiding principles of course design on Impe-  rials Online Management Programme is to encourage sus- tained and synchronised engagement by a student cohort with rich online course material, rather than ad hoc recourse to contacting the course staff. The rationale for this is to maximise students opportunities to share their experiences through the planned discussion activities. A secondary con- sideration is scalability: by keeping the student cohort in- step it should not be necessary to deploy increasing numbers of course tutors as cohort numbers grow. This secondary consideration remains be tested: for example, it is antici- pated that the second intake on the new postgraduate degree in Management will comprise 150+ students, presenting the opportunity to investigate further this hypothesis.  We are now planning larger-scale investigations of Ques- tions 1 and 2, over more courses and more students as the current and new student cohorts progress through the post- graduate degree in Management, and more broadly through other degrees delivered at Imperials digital campus. These larger-scale studies will address additional questions, such as learners levels of satisfaction and perceived learning, and will include finer-grained analyses of students interactions, including analysing the contents of students posts. Our overarching aim is to employ the analyses described here, as well as design new ones, in order to investigate the re- lationships between different forms of participant engage- ment in the learning platform and their effects on students levels of performance and satisfaction, with the goal of de- riving improved guidelines for course designs and engaging course leaders in reflection, peer discussion and ongoing pro- fessional development.  7. REFERENCES [1] J. Arbaugh. System, scholar or students Which most  influences online MBA course effectiveness Journal of Computer Assisted Learning, 30(4):349362, 2014.  [2] C. Coffrin, L. Corrin, P. de Barba, and G. Kennedy. Visualizing patterns of student engagement and performance in moocs. In Proc. LAK14, pages 8392, 2014.  [3] A. L. Dyckhoff, V. Lukarov, A. Muslim, M. A. Chatti, and U. Schroeder. Supporting action research with learning analytics. In Proc. LAK 2013, pages 220229.  [4] R. Ferguson and D. Clow. Examining engagement: analysing learner subpopulations in massive open online courses (MOOCs). In Proc. LAK 2015, pages 5158.  [5] G. Siemens. Learning analytics: envisioning a research discipline and a domain of practice. In Proc. LAK 2012, pages 48.  [6] M. Wells, D. Lefevre, and F. Begklis. Innovation via a Thin LMS: A middleware alternative to the traditional learning management system. In Proc. 30th Ascilite Conference. Macquarie University, Australia, 2013.  [7] A. Wolff, Z. Zdrahal, A. Nikolov, and M. Pantucek. Improving retention: predicting at-risk students by analysing clicking behaviour in a virtual learning environment. In Proc. LAK 2013, pages 145149.    