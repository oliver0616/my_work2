Elaborating Data Intensive Research Methods through  Researcher-Practitioner Partnerships   Mingyu Feng  SRI International   333 Ravenswood Ave  Menlo Park, CA   mingyu.feng@sri.com  Andrew E. Krumm  SRI International   333 Ravenswood Ave  Menlo Park, CA   andrew.krumm@sri.com  Alex J. Bowers  Columbia University  525 West 120th St.   New York, NY 10027  bowers@tc.edu     Timothy Podkul   SRI International   333 Ravenswood Ave  Menlo Park, CA   timothy.podkul@sri.com   ABSTRACT  Technologies used by teachers and students generate vast   amounts of data that can be analyzed to provide insights into  improving teaching and learning. However, practitioners are left  out of the process. We describe the development of an approach  by which researchers and practitioners can work together to use  data intensive research methods to launch improvement efforts  within schools. This paper describes elements of the first year of a  researcher-practitioner partnership, highlighting initial findings,  challenges, and strategies for overcoming these challenges.     Categories and Subject Descriptors  K.3.m [Computers and Education]: Miscellaneous.    General Terms  Measurement, Design, Human Factors.   Keywords  Data intensive research, researcher-practitioner partnership,   learning analytics   1. INTRODUCTION  Multiple technologies, such as learning management systems,   tutoring systems, digital curriculums, and open-access,  supplemental instructional resources, are regularly used in  schools. Many of these systems track students use, thus providing  a rich data stream that can be analyzed to better understand  teaching and learning [e.g. 1, 11]. However, often missing from  the current research landscape is the voice of practitioners. In  many ways, the field is driven by solutions (e.g., dashboards and  data mining techniques) looking for problems [5, 6, 17], with little  explication on how to productively work with practitioners in a  collaborative way. Thus, our focus is on describing the process of  developing research-practice partnerships where the voice and  needs of practitioners drive the collaborative inquiry [8]. In this  paper, we report on aspects of the first year of a project that  sought to develop a series of repeatable and scalable processes to  support researchers and practitioners collaboratively engage in  data intensive research. To begin developing tools, routines, and  processes for supporting researchers and practitioners in working  together, the approach documented in this paper builds on a  research-practice partnership between researchers and  practitioners at a charter management organization (CMO)   operating in California.1 The CMO serves diverse students, uses  advanced technologies, and has a strong commitment to making  data-driven instructional decisions. Through a customized online  platform, students access most of their learning resources across  all grades and subject areas. Students use the platform in mostly  self-directed ways, with monitoring and support from teachers.    Multiple researchers have documented how practitioners can  effectively use standardized test scores, grades, and behavioral  infractions (e.g., [2, 7]). Researchers have also demonstrated how  to use data intensive methods to identify patterns among these  same variables (e.g., [3, 4]). A next step for data intensive  research is to engage practitioners earlier in the process, building  on their insights in shaping analyses to ensure buy-in from both  researchers and practitioners [8]. This project uses a design based  research approach [15] and theories from organizational and  learning sciences to inform the development and refinement of  partnership activities. As this paper demonstrates, a partnership- based approach can be effective for developing and sustaining  change efforts in schools because it can aid practitioners in  developing new knowledge and skills applicable to future  problems and datasets after the partnership ends [9].    2. UNDERSTANDING NEEDS AND  CONTEXT   We engaged in an iterative cycle of needs analyses by jointly  identifying pressing problems of practice facing the CMO. We  started the process with joint meetings that involved researchers  and a representative team from the CMO including principals,  teacher professional development leads, and members of the  technology team. The research team initially facilitated a blue  sky, ideation activity where researchers and practitioners  brainstormed potential questions. The partnership then iteratively  triaged and refined blue sky questions. Questions were selected  based on the benefits of answering a question in relation to  potential costs for students, teachers, or administrators. The entire  process led to a number of focus areas and research questions that  were meaningful to all audience and do-able given the constraints  of time and data quality.   Another important early task was to better understand the  CMOs context, which included (1) discerning how students  interact with teachers and content and (2) identifying ways in  which teachers and administrators currently use data (i.e., what is  being looked at and when). Researchers attended professional  development sessions, exchanged emails, and conducted meetings  to clarify what instruction looks. CMO staff walked researchers  through the process they use to manage, analyze, and report on  data for various audiences. One key takeaway from these efforts  was that managing and merging datasets was a particular pain  point for CMO staff and one that prohibited potentially useful                                                                     1 In the United States, a CMO is like a traditional K-12 school district in   that they are public schools; yet they operate under a uniquely defined  charter, the specifics of constitutes a charter vary by states.   Permission to make digital or hard copies of part or all of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. Copyrights  for third-party components of this work must be honored. For all other  uses, contact the Owner/Author.  Copyright is held by the owner/author(s).  LAK '16, April 25-29, 2016, Edinburgh, United Kingdom  @ 2016 ACM 978-1-4503-4190-5/16/04.  DOI: http://dx.doi.org/10.1145/2883851.2883908   http://dx.doi.org/10.1145/2883851.2883908   analyses. Moreover, from a teachers perspective, data was shown  to them on how well students did (e.g., assessment scores) and not  necessarily what they were doing (e.g., resources accessed).    Although the processes described above took significant time  and effort, it was extremely important for the partnership and for  later data analysis work. Data analysts often have a strong desire  to jump in to mine the data to look for interesting patterns or make  accurate predictions. However, when working with practitioners  who face specific challenges, it is important to make sure that  researchers have a good understanding of the school context and  are answering meaningful questions that practitioners could  engage in and are willing and able to take action on.   3. CAPACITY BUILDING  The research team conducted preliminary data analyses and   through an iterative process, the partnership reviewed results and  identified ways data analyses could be integrated into regular  work practices in schools. Collaboratively interpreting data with  practitioners is an important element of the partnerships capacity  building efforts. We scaffolded practitioners understanding of  analyses by explicitly instructing CMO staff on researchers  thinking and the methods that were used to analyze, and visualize  data as well as interpret results. Instead of having researchers  present results, we organized discussions as hands-on exploration  opportunities for CMO staff and encouraged them to try to make  sense out of the results using data visualizations, for example, that  did not contain the CMOs data in order to promote understanding  of the techniques that were employed before engaging with CMO- specific data that used the same visualizations. We also relied on  relatively basic data exploration and modeling approaches and  supported the interpretation of various representations, such as  histograms, scatter plots, trend lines, and box plots.   4. BUILDING INFRASTRUCTURES  Throughout the first year of the project, we identified the role   of (1) partnership and (2) analytics infrastructures that appeared  necessary for supporting collaborative research These supports  include the routines and tools that researchers will potentially  need to consider in order to effectively collaborate with  practitioners. Our experience showed that the key pieces to build a  strong partnership include: (1) jointly developed goals that are  conditional and revisited; (2) intentional efforts to build capacity  and promote sustainability; (3) mutually agreed communication  routines, roles, and responsibilities; and (4) long-term data sharing  agreements. The second support included the analytics  infrastructure that we established during the early stage of the  project. Elements of this infrastructure deal with the nuts and bolts  of managing files, analyzing data, and reporting on data products.  Necessary but not sufficient conditions include (1) a shared  understanding of available data and the activity system from  which they are drawn and (2) processes for sharing data and data  products that are secure and easy to access.   5. CONCLUSION   Although the promise of practitioners drawing on data to   inform decisions is widely recognized, effective implementation  has proven challenging ([e.g. 10, 13]). We argue that one way to  overcome many of the challenges is to include practitioners as  early as possible in the process. However, engaging practitioners  intimately in multiple facets of a research project comes with its  own challenges. The approach we took was to enhance  practitioners ability to interpret and take action with data and to  focus on developing basic infrastructures that can support work  long term. The style of inquiry and the school-by-school results of  a partnership approach will likely not appeal to all researchers  nor should it. Yet, our efforts show that the skills of researchers  can be applied in multiple ways to support practitioners and that  researchers can benefit from closer ties to what is happening in  classrooms.   6. ACKNOWLEDGEMENTS  The research was supported by the NSF, through Grant DRL-  1444621. The opinions expressed are those of the authors and do  not necessarily represent views of the NSF.   REFERENCES  [1] Baker, R. S. (2013). Learning, Schooling, and Data   Analytics. In M. Murphy, S. Redding & J. Twyman (Eds.),  Handbook on innovations in learning. Charlotte, NC:  Information Age Publishing.    [2] Boudett, K. P., City, E. A., & Murnane, R. J. (2013). Data  Wise: A step-by-step guide to using assessment results to  improve teaching and learning. Revised and expanded  edition. Cambridge, MA: Harvard Education Press.   [3] Bowers, A. J. (2010). Analyzing the longitudinal K-12  grading histories of entire cohorts of students: Grades, data  driven decision-making, dropping out and hierarchical  cluster analysis. Practical Assessment Research and  Evaluation, 15, 1-18.   [4] Bowers, A. J., & Sprott, R. (2012). Examining the Multiple  Trajectories Associated with Dropping Out of High School:  A Growth Mixture Model Analysis. Journal of Educational  Research, 105, 176-195.   [5] Bryk, A. S., Gomez, L., Grunow, A., & LeMahieu, P. (2015).  Learning to improve: How Americas schools can get better  at getting better. Cambridge, MA: Harvard Education Press.   [6] Cho, V., & Wayman, J. C. (2015). Districts Efforts for Data  Use and Computer Data Systems: The Role of Sense making  in System Use and Implementation. Teachers College  Record, 116(2), 1-45.    [7] Coburn, C. E., & Turner, E. O. (2011). Research on data use:  A framework and analysis. Measurement, 9, 173-206.   [8] Coburn, C. E., Penuel, W. R., & Geil, K. E. (2013).  Research-practice partnerships. New York, NY: William T.  Grant Foundation.    [9] Coburn, C. E., Russell, J. L., Kaufman, J. H., & Stein, M. K.  (2012). Supporting sustainability: Teachers advice networks  and ambitious instructional reform. American Journal of  Education, 119(1), 137-182.   [10] Franke, M. L., Carpenter, T. P., Levi, L., & Fennema, E.  (2001). Capturing teacher's generative growth: A follow-up  study of professional development in mathematics. American  Education Research Journal, 38(3), 653-690.   [11] Koedinger, K. R., D'Mello, S., McLaughlin, E. A., Pardos, Z.  A., & Ros, C. P. (2015). Data mining and education. Wiley  Interdisciplinary Reviews: Cognitive Science.    [12] Marsh, J. A. (2012). Interventions Promoting Educators Use  of Data: Research Insights and Gaps. Teachers College  Record, 114(11), 1-48.   [13] Means, B., Chen, E., Debarger, A., & Padilla, C. (2010).  Teachers Ability to Use Data to Inform Instruction:  Challenges and Supports. Washington, DC: U.S. Department  of Education.   [14] Penuel, W. R., & Martin, C. (2015, April). Design-Based  Implementation Research as a Strategy for Expanding  Opportunity to Learn in School Districts. Paper presented at  the Research Conference of the NCTM, Boston, MA.   [15] Schutt, R., & O'Neil, C. (2013). Doing Data Science: Straight  Talk from the Frontline. Cambridge, MA: O'Reilly.       