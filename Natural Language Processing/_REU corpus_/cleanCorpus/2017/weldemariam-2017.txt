Studying Engagement and Performance with Learning Technology in an African Classroom  Juliet Mutahi IBM Research Africa  Nairobi, Kenya tjulimuta@ke.ibm.com  Andrew Kinai IBM Research Africa  Nairobi, Kenya andkinai@ke.ibm.com  Nelson Bore IBM Research Africa  Nairobi, Kenya nelsonbo@ke.ibm.com  Abdigani Diriye IBM Research Africa  Nairobi, Kenya a.diriye@ke.ibm.com  Komminist Weldemariam IBM Research Africa  Nairobi, Kenya k.weldemariam@ke.ibm.com  ABSTRACT In this paper, we study the engagement and performance of students in a classroom using a system the Cognitive Learning Companion (CLC). CLC is designed to keep track of the relationship between the student, content interaction and learning progression. It also pro- vides evidence-based engagement-oriented actionable insights to teachers by assessing information from a sensor-rich instrumented learning environment in order to infer a learners cognitive and aective states. Data captured from the instrumented environment is aggregated and analyzed to create interlinked insights helping teachers identify how students engage with learning content and view their performance records on selected assignments. We con- ducted a 1 month pilot with 27 learners in a primary school in Nairobi, Kenya during their maths and science instructional peri- ods. We present our primary analysis of content-level interactions and engagement at the individual student and classroom level.  CCS CONCEPTS Information systems Online analytical processing;  KEYWORDS Education; Engagement; Learning Analytics; Mobile Development; Developing Countries;  1 INTRODUCTION e usage of ICT to improve how education is delivered is visible with the large-scale adoption of tablets in K-12 and Hi-Ed [4]. Rapid improvements in ICT is possible; countries have started to adopt ICT and their school systems are leap-frogging over more archaic and expensive devices that were of most utility during the PC era. As technology currently exists, governments of developing nations that are working toward ICT adoption in the classroom can choose  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for prot or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permied. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specic permission and/or a fee. Request permissions from permissions@acm.org. LAK 17, Vancouver, BC, Canada   2017 ACM. 978-1-4503-4870-6/17/03. . .$$15.00 DOI: hp://dx.doi.org/10.1145/3027385.3027395  from a plethora of aordable personal learning devices connected to cheaper and faster networks.  For many, the rst and only computing experience will be mo- bile; and a growing popularity of social computing and educational applications and services on mobile devices drives strong consumer demand. In the midst of this technological shi in education, teach- ers are still expected to perform various activities in tandem from aective recognition and counseling, maintaining engagement of all pupils in the classroom, and intervening to aide poorly perform- ing students. Experienced teachers accomplish these tasks beer than new teachers, but some aspects of the student psyche, aec- tive state, and needs are not readily understood even by the most experienced teacher.  In developing nations, this problem is especially acute: poor facilities, a high student to teacher ratio, and a lack of technology solutions to provide insights and functionality to assist their stu- dents in their learning. is provides the motivation for this paper, and a novel system called the CLC [7] that aides the teacher in understanding their students learning in and out of class.  Teachers are expected to perform various activities within and outside of their classroom. For example, on one hand they require to understand and intervene to their students cognitive or aective ability in relation to their engagement and performance in the classroom. While experienced teachers may accomplish these tasks, but some aspects of the students aective state and needs are not easily understood even by the most experienced teacher.  In this paper, we focus on studying the engagement and perfor- mance of students in a classroom using the CLC system. In prior work, measuring learners engagement and interaction is widely discussed  see, e.g., in [13, 5, 8]. For example, the study in [3] qualitatively demonstrated how learning content (mainly video) production decisions aect student engagement by studying video engagement in online learning. ey measured engagement based on the time spent on watching each video and number of aempts to answer assessment items. While we also measured learners en- gagement, the focus was predominately in a classroom in K-12 seings.  In the following sections, we review the architecture of a novel adaptive learning technology platform called Cognitive Learning Companion in Section 2. We discuss the pilot setup and present research questions in Section 3. Section 4 reports the evaluation of    Event Framework  Notification   Manager Mode Switcher  User Manager  Diary Board Context Manager  CLC Clients (Android/iOS)  App Server  Analytics   Lib  Learning   Content   Hub (LCH)  Student   Master    Data (SMD)  Moodle   Client   (Web   Browser)  Content Catalog Database  Moodle   APIs  Server   Controller  Content Manager  Attention   Manager  Content Viewer Guided Lecture   Planner  Discussion   Facilitator Adaptive Tutor  Digital Learning Environment (DLE) Student   Activity   Info  CLC   APIs  Event   Frame  work  Feedback Dashboard   Manager  Figure 1: Overview of the CLC system as in [7].  the eectiveness of our platform based on a 1 month pilot in real- world classroom. More specically, we examine the content-level interaction, performance of students and the usage of the platform.  2 OVERVIEW OF THE CLC SYSTEM Figure 1 shows a high-level architectural overview of the system (details can be found [7]). CLC is a suite of cognitive capabilities supporting multiple modes of learning enabled on the mobile, and delivered through the cloud. CLC is both a learning and a teaching companion; an essential aid for the student as well as the teacher in the blended learning journey, one that also keeps the parents engaged in the process. An essential feature of CLC is the ability to capture ne-grained user interactions with content and device, and respond to it appropriately based on the context. ese interactions will be aggregated over time and analyzed to develop rich learner models (e.g., knowledge models, learning styles) based on which actionable insights will be provided to the teacher and student in various models of learning.  As a multi-modal system, CLC can operate in school mode, re- mote mode, and an interactive mode, and can eortlessly switch from one mode to another based on the learning context while con- tinuously updating knowledge, interest and interaction models as users interact with content. As it moves from one mode to the next, it elevates its functionality from being an assistant to the teacher (school), to being a partner to the teacher and student (remote), to being personalized tutor supporting adaptive learning (interactive). In each of these roles, CLC provides a suite of cognitive capabilities to assist the end user.  For example, in school mode, CLC can recommend in-classroom teaching materials for a curriculum topic, taking into account stu- dent learning activities and progress outside of class. It can infer when a student is not paying aention, and intervene as needed. It can also suggest personalized homework assignments and tutoring sessions for students.  In remote mode, CLC acts as a partner bridging the inside and outside classroom experience by intelligently facilitating remote discussions between the students and teachers, leveraging previ- ously asked questions and answers in the process. It also captures  contextual information associated with the remote mode, which may impede the students learning and can advise the teacher on appropriate interventions.  In interactive mode, CLC can act as a personalized and adaptive tutor intelligently selecting and sequencing tutoring concepts and learning content, adapting the experience to the students progres- sion, and providing problem solving scaolding to guide the student along the way. Across all the modes, CLC updates learner models related to knowledge, interests and learning styles, and preserves learning history, provides feedback from one mode to the another to propagate the learning context and ensure a seamless experience.  CLC captures ne-grained student learning activity events by in- strumenting a learners mobile learning environment via an event framework. Such event steams form the Student Activity Infor- mation (SAI) which sit on the cloud [6], and is used to develop analytical and cognitive models. e insights that CLC will gen- erate make use of analysis of SAI and will generate actionable insights with factors such as performance, engagement, context, aendance/dropout, teachers eectiveness that characterize learn- ing outcomes, as well as teachers and schools eectiveness. e insights are the basis for identifying at-risk students, create indi- vidual or group proles for each at-risk cluster, and develop pre- liminary intervention plans. For instance, CLC will recommend interventions that improve learning outcomes for underperforming learners (e.g., those with poor reading skills), introduces advanced learning/reading plans for well-performing learners, that provide resources and support for schools, as well as that allow to develop system guided feedback mechanisms for beer transparency and accountability measurement in schools.  Motivated by the above factors, the CLC (Cognitive Learning Companion) has been developed through extensive interactions with primary school teachers from a leading K-12 group of schools in Nairobi, Kenya, that are interested in adopting eective blended teaching/learning practices with their students. Like most online learning systems, CLC supports delivery of content and assessments to students, and reports performance metrics to teachers. What dierentiates CLC from many other systems, however, is the focus on student engagement and interaction. CLC seeks to interpret performance in the light of how the student approached learning, as    inferred from his/her content interaction paerns, comments, and questions, as well as aective states. is is captured through non- intrusive instrumentation of mobile client interfaces and sensors that lets CLC capture ne-grained user interactions with content and sensors (or devices) while learning.  A holistic analysis of performance and engagement yields tar- geted, evidence-based and actionable insights for teachers, and sup- port for integrating those recommendations within the teachers instructional or intervention plans for the class. CLC has thus been designed not as a supplementary, stand-alone system, but with the teacher, student (and eventually parents) and classroom in the loop. Native support for oine learning and periodic synchronization provides additional operational assistance to seamlessly connect diverse blended learning contexts inside and outside the classroom. Finally, while the CLC system is designed and implemented by closely interacting with teachers in Kenya, the underlying concept and system is applicable to any K-12 school system elsewhere in the world.  3 PILOT AND DATA COLLECTION We deployed the system in a local school in Nairobi Kenya for a 4 week pilot program (January  February 2015) in a classroom composed of 27 students aending Grade 5mathematics and science classes, and 4 teachers. e teachers comprised one science teacher, one mathematics teacher and two headteachers who were assigned to physically observe the classroom dynamics and engagement.  Each of the students were equipped with an Android tablet run- ning the CLC student client. We used a Galaxy Tab 4 tablet (spec- ications: CPU Speed 1.2GHz, RAM 1.5GB, ROM 8GB, Standard Baery Capacity 4000 mAh). e client is connected to cloud- enabled backend services (APIs) through a combination of mobile data bundle and School WiFi.  e ocial time allocated for the class lecture was 35 minutes. During this period the teacher has to properly breakdown the lec- ture into two or more sessions (e.g., lecturing, revision, Q&A, and/or classwork sessions) based on prescribed lesson plan, and then be- gins to distribute the 35 minutes to the individual sessions accord- ingly. Note that a lesson plan consists of learning activities, learning materials and group of students and a sequence of learning activities with or without learning materials for groups of students within a dened period of time to arrive at certain learning prociencies.  Twelve lessons were conducted for each subject, and 16 quizzes (composed of a total of 169 questions) were given to students. e students were instructed to use our instrumented platform to carry out their learning while separate teachers taught their re- spective subjects of mathematics and science through the CLC. e total user data collected over the 4 week period for the classroom amounted to 20.6 MB, giving ran average document size of 4KB. We also gathered both quantitative and qualitative data compris- ing quizzes, self-reported performance, usage and engagement of content, video/image data, and aendance data.  While CLC comprises three modes of operation, the pilot was primarily focused on the school mode and remote modes. is was to test our rst hypothesis that learners performance is inuenced by interaction with learning content as well as the class instructor.  4 ANALYSIS In this section, we analyzed content-level interactions analysis at the individual student and classroom level. is allowed teachers to understand how their students are engaged with learning resources, and then to incorporate personalized or group interventions in their strategies. Performance of students on various (sub-) strands (with respects to skills, knowledge and understanding) of tests, quizzes and assessments with results accessible to the classroom teacher, head-teacher and/or administration. Item-level analysis at the individual student and classroom level allows teachers to analyze whether individual or group of students miss the same quiz question items, and then to adjust their teaching strategies.  4.1 Analyzing Classroom Alignment Using the SAI (Student Activity Info) data collected, we analyzed and measured the classroom alignment based on students and teacher engagements in the classroom. For example, Figures 2 and 3 show the alignment between the teacher and the students. e plots are derived from the SAI data of students and teachers interactions with content from a mathematics lesson on Least Common Multiple (LCM) of Numbers.  0  1  2  3  4  5  0 1 2 3 4 5 6 7 8 9 10  Figure 2: Teacher classroom engagement with LCM of Numbers.  0  20  40  60  80  100  120  0 1 2 3 4 5 6 7 8 9 10  Figure 3: Classroom (27 students) engagement with LCM of Numbers content item.  We see on Figure 2 shows that the teacher spent most of their time on page 5 whilst Figure 3 indicates that most of the students were concentrated on Page 3. Further analysis of the content re- vealed that Page 3 was heavily loaded with examples. ese ex- amples can serve as material for the students to beer understand the subject being taught, hence the larger periods of time spent on Page 3. We reviewed the ndings with the classroom teacher and headteacher. Upon reviewing the data, they commented that students at the school typically did not have enough background    knowledge on prerequisite concepts. e teachers noted that it has been a challenge for Grade 5 mathematics teachers in the past stu- dent and their students have shown poor performance in that topic. It was also mentioned that in Grade 4 the students are given a basic introduction on LCM and numbers, and the Class 5 mathematics teacher is expected to start with easy examples to gauge whether the students are able to comprehend the basics on the prerequisite concept before moving on to more complex and dicult examples.  We also found two key take-aways on how the content items are prepared and used from the data. We observed that when there is no signicant update/change to the learning curriculum from one year to the next, then most teachers reuse content from previous years without updating or changing the learning content (e.g. lecture notes and examples). It was also noted that teachers rarely receive feedback on the content items they use in the classroom such as the diculty level, compressing burden, illustrative richness, etc of the content items. None of the participating teachers (including the headteachers) received formal training to create digital lecture materials. Furthermore, there is no standardized guideline to assist them in creating lecture materials, what there though are teacher specic lesson plans derived from generic Scheme of Work.  We analyzed the alignment between students and the teachers in a classroom for the Least Common Multiple (LCM) of Numbers content item (see Figure 2 and 3). e alignment between the student and the classroom teacher shows most of the concentration is in Page 3 and Page 5.  e engagement of a particular student for the same content item but outside a classroom is shown in Figure 4. Interestingly, unlike the the data from the classroom engagement, we found that the students jumped to Page 7 by skipping Pages 1-6. e students were highly engaged on Pages 7-9 (Figure 4) despite the teacher not covering these pages in the classroom.  0  1  2  3  4  5  0 1 2 3 4 5 6 7 8 9 10  Figure 4: Page 7-9 of the Least Common Multiple (LCM) of Numbers content item.  While looking at Pages 7-9 of the content item, the materials pre- sented in these pages are less condensed (low compression burden). is gives an indication as to why the student is highly engaged on those pages. However, we noted that the LCM by Short Method technique was presented aer the examples shown in Pages 7 and 8. Hence, the student has to go back-and-forth between these pages. We also noted that the two examples presented in Page 7 and 8 are identical. We asked a number of probing questions to the teachers such as What intervention would they take if they were to re-teach this content item again or in the future We feedback we received from this was, I would reorganize by re-sequencing the pages based on diculty and density of the page.  4.2 Performance Analysis We analyzed the performance data of the students based on the 16 quizzes for science and mathematics. Our goals were threefold: (i) understand the relationship between the time spent on a quiz and performance, (ii) explore the relationship between quiz diculties, time spent and performance achieved, and (iii) proling students based on quiz aempt paerns. In the quizzes, we do not pre-assign the amount of time it takes to aempt an individual question or a quiz. e teachers, based on their experiences, decide how long a given quiz will take in a classroom.  0 200 400 600 800 1000 1200 1400 1600  0  20  40  60  80  100  120  0  20  40  60  80  100  0 200 400 600 800 1000 1200 1400  Histrogram with Normal Curve  Figure 5: Total time taken to complete assessment against the grades.  Figure 5 shows the total time taken to complete 7 quizzes in mathematics ploed against the score. Wherein on average most students spend about 10 minutes (500-600 seconds) to complete a quiz. We next explored the relationship between time spent on a quiz and performance, and found that there is a positive correlation between the time spent on a quiz and performance  i.e. students who spent longer amounts of time when doing the quiz, had higher performance scores. e local regression for each quiz shows a positive increase in performance over time and then a sudden drop in performance for the classroom.  To further understand what caused the classroom performance to drop, we examined individual topics and their relationship on concept dependency. For instance, Least Common Multiple (LCM), Subtraction of Mixed Numbers, and Addition and Subtraction of Fractions are the three topics being covered in the class to which students were given a quiz for each of these topic at the end of the lesson. e topics are listed with respect to topic sequence as prescribed in the curriculum script, e.g. LCM is the pre-requisite topic for Subtraction of Mixed Numbers. On this pre-requites topic, 69.23% of the classroom (18 students) scored above 75%, 23.08% of the classroom (6 students) scored above 50% but below 75%, and only two students (7.69% of the classroom) scored below 25%. However, the average performance of the classroom dropped on the subsequent advanced topics. As shown in the third row of Table 1, the percentage of the classroomwho scored below the passing mark (50%) increased by a factor. What we do nd underscored across all the quizzes is a positive and consistent relationship between time spent on quizzes and performance score for the three quizzes.  We next study the data gathered from the quiz such as aempts and engagement paerns. In particular, from the performance data we explore ways to best characterize how a student approached a quiz. While analyzing the data, we found that some students    % of Classroom Performance periz Score LCM SMN ASF >= 75% 69.23 26.92 26.92 > 50% & < 75% 23.08 34.62 23.08 < 50% 7.69 38.46 50  Table 1: Classroom performance comparison for three sub- sequent topics.  were consistently repeating the same quiz up to 10 times. ese students appear to be gaming the system by submiing the quiz results multiple times until they achieved the maximum score or until they were identied and told to stop by the teacher.  By analysing the data, we have observed that multiple aempts were recorded for the same quiz. Several students were found to retake and submit the same quiz multiple times. In each aempt, we observed a slight increase in their score. For instance, one student scored 0 in his rst aempt, but aer his 9th aempt he scored a perfect 100%. Further analysis of the data across multiple quizzes revealed characteristic behaviour exhibited by this category of students such as a high number of aempts, and a high number of wrong answers. In Figure 6, we tabulate the performance and the number of wrong aempts during a quiz, and nd distinct category of outliers in dierent subjects. It is therefore possible to dierentiate quiz gamers based on their behaviour against other students taking the same quiz.  0  100  200  300  400  500  600  0 20 40 60 80 100  N o.   W ro  ng   Q  ui z   At te  m pt  s  Scores (Out of 100%)  Student Scores and Wrong Attempts  Mathematics Quiz  Science QuizMathematic Quiz Outliers  Science Quiz  Outliers  Figure 6: Scatter plot outliers for mathematics and science quizzes.  Finally, wemeasured and compared students engagement against performance. Using the performance data, we classied students into high performers (score above 75%), average performers (score between 50 and 74%), and low performers (score below 50%) stu- dents. is was then correlated with the relationship between engagement of students with content and performance. We found that on average that students with high-levels of engagements tend to perform well in the given quizzes.  5 CONCLUSION AND FUTUREWORK Technology is changing how education is delivered inside and outside of the classroom. In this paper, we have presented a novel adaptive learning system called Cognitive Learning Companion (CLC). We found through our study technological interventions are well received by teachers and they agree that this is more ecient and eective. e study shed light on how students would game the system to get beer results that should be addressed in subsequent versions of the platform.  We conducted a one-month longitudinal study with 27 learners in a local school in Nairobi, Kenya to examine the eectiveness of the proposed learning companion. Our ndings showed that there is frequent misalignment between the pace and amount of aention spent on dierent content between the students and teachers. is was due to a lack of feedback on the diculty and amount of content of the teaching material developed by the teachers. We were able to easily and eectively help the teachers identify through the points of misalignment and aspects of their teaching material and curricula that should be edited or receive more/less aention. e study revealed a strong correlation between performance and engagement: where more engaged students would perform on average beer.  Finally, we experienced signicant resource constraints and chal- lenges (e.g. intermient connectivity, baery power, etc) during the deployment experiences, and this should be a consideration when developing systems for resource constraint regions or countries.  Future work would entail enhancing CLC by examining various algorithms to provide real-time insights and predictive capabili- ties for the teachers. We also plan to develop a smart cooperative content downloading module that may combine a novel combi- nation of computed resource level, reliability index, and segment determination to download, aggregate and distribute downloaded chunks. e ability to improve resource utilization for low-end devices while scheduling download contents.  REFERENCES [1] Jaye Clarkes-Nias, Juliet Mutahi, Andrew Kinai, Oliver Bent, Komminist Welde-  mariam, and Saurabh Srivastava. 2015. Towards Capturing Learners Sentiment and Context. In L@S. 217222.  [2] Computing Research Association. 2015. Data-Intensive Research in Ed- ucation: Current Work and Next Steps. (2015). hp://cra.org/ cra-releases-report-on-data-intensive-research-in-education/.  [3] Philip J. Guo, Juho Kim, and Rob Rubin. 2014. How Video Production Aects Student Engagement: An Empirical Study of MOOC Videos. In L@S 14. ACM, New York, NY, USA, 4150. DOI:hp://dx.doi.org/10.1145/2556325.2566239  [4] Nagy K Hanna. 2003. Why National Strategies are needed for ICT-enabled Development. World Bank Sta Paper. Washington, DC: World Bank (2003).  [5] Curtis R. Henrie, Lisa R. Halverson, and Charles R. Graham. 2015. Measuring Student Engagement in Technology-mediated Learning. Comput. Educ. 90, C (Dec. 2015), 3653. DOI:hp://dx.doi.org/10.1016/j.compedu.2015.09.005  [6] Juliet Mutahi, Oliver Bent, Andrew Kinai, Komminist Weldemariam, and Bikram Sengupta. 2015. Capturing Learners Activity Events from a Mobile Learning System Using Adaptive Event Framework. In MOBILESo 2015. 109112.  [7] Juliet Mutahi, Oliver Bent, Andrew Kinai, Komminist Weldemariam, Bikram Sengupta, and Danish Contractor. 2015. Seamless blended learning using the Cognitive Learning Companion: A systemic view. IBM Journal of Research and Development 59, 6 (2015).  [8] Jane Sinclair, Mahew Butler, Michael Morgan, and Sara Kalvala. 2015. Measures of Student Engagement in Computer Science. In ITiCSE 15. ACM, 242247. DOI: hp://dx.doi.org/10.1145/2729094.2742586  http://cra.org/cra-releases-report-on-data-intensive-research-in-education/ http://cra.org/cra-releases-report-on-data-intensive-research-in-education/ http://dx.doi.org/10.1145/2556325.2566239 http://dx.doi.org/10.1016/j.compedu.2015.09.005 http://dx.doi.org/10.1145/2729094.2742586  	Abstract 	1 Introduction 	2 Overview of the CLC System 	3 Pilot and Data Collection 	4 Analysis 	4.1 Analyzing Classroom Alignment 	4.2 Performance Analysis  	5 conclusion and future work 	References   