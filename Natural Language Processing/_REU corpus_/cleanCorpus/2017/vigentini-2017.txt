FutureLearn data: what we currently have, what we are  learning and how it is demonstrating learning in MOOCs   Lorenzo Vigentini  UNSW Australia   l.vigentini@unsw.edu.au   Manuel Len Urrutia  University of Southampton UK  m.leon-urrutia@soton.ac.uk   Ben Fields  FutureLearn   ben.fields@futurelearn.com     ABSTRACT  Compared to other platforms such as Coursera and EdX,  FutureLearn is a relatively new player in the MOOC arena and  received limited coverage in the Learning Analytics and  Educational Data Mining research. Founded by a partnership  between the Open University in the UK, the BBC, The British  Library and (originally) 12 universities in the UK, FutureLearn  has two distinctive features relevant to the way their data is  displayed and analyzed: 1) it was designed with a specific  educational philosophy in mind which focuses on the social  dimension of learning and 2) every learning activity provide  opportunities for formal discussion and commenting. This  workshop provides an opportunity to invite contributions and  connect individual and groups to share their research activities on  an international stage. As the first of its kind, this workshop will  bring in a number of scholars and practitioners, as well as data  scientists and analyst involved in the reporting, researching and  developments emerging from the data offered by the platform.    CCS Concepts   Information systems  Information systems applications   Decision support systems  Data analytics  Human-centred  computing  Visualization  Visual analytics.   Keywords  MOOCs; visualization dashboard; learning analytics.   1. INTRODUCTION  Many higher education institutions have invested in the  development of MOOCs. Some have partnered with one or more  leading MOOC providers leveraging on the capabilities of  different platforms (i.e. Coursera, EdX, FutureLearn etc.) [9, 12],  others have been experimenting with a collection of open  resources and encouraged learners to participate in learning  experiences at scale, without the constraints of specific platforms  and promoting a connectivist experience of learning [1, 6, 10, 13,  16, 18]. With the experimentations in learning design, more  started to question the effectiveness of the forms of learning that  can be supported by the introduction, and given that a large  amount of data has become available, it is timely to explore how  to best make use of it.    In fact, with the increased availability of MOOC data, there is an  opportunity to provide insights to educators and developers into  learners behaviours, and empower learners to understand their  patterns of engagement and performance through learning   analytics [19]. The former allows exploring learning design at  scale and has the potential to inform pedagogy. The latter has the  potential to improve the learning experience and develop crucial  metacognitive skills essential for self-directed and lifelong  learners. In more recent times there has been a shift to move from  descriptive analytics to analytics able to inform and direct practice  [5, 21, 22]. This was also advocated by Gasevic and colleagues as  a key area of further research in their review of research in  MOOCs [8]. In fact, while a lot of work has been done, there are  two crucial problems hindering the application of learning  analytics methods to support and shape pedagogy in MOOCs: 1)  the constraints of the platforms (i.e. the tools and course design)  and 2) the availability of data when it is needed.   Looking at the wealth of research in MOOCs, a lot is done post- hoc when the respective platforms release the data for  exploration, and often data is locked within institutions limited by  their agreements with platform providers. Research has looked at  Coursera data [2, 15] and the dashboard offered to partners  institutions [7]. In addition, the relative openness of EdX, allowed  different teams to develop extensions/plugins to access and use  analytics [4, 14, 17, 20].   FutureLearn went down a different pathway, focusing on  standardization and simplicity, offering data files to partner  institutions to enable them to make sense of the interaction  occurring in the various courses. Additionally, a report (based on  R scripts) is offered to stakeholders, but this is limited in a  number of ways: it is static, it is focusing on selected information  and, most importantly, it does not provide real-time access to  data. The lack of a tool to visualise data from the engagement  with FL MOOCs sparked two separate initiatives to develop tools  bringing analytics to different stakeholders [3, 11].   2. SCOPE AND OPPORTUNITY   This workshop provides an opportunity to invite contributions as  short paper submissions, and share the work already done by a  number of partner institutions showcasing existing processes,  methods and tools used to analyse, present and use the data  offered by the FL platform.   The workshop will consist of two streams: a research/practitioner  track and a technical track. The two streams are intended to  present case studies demonstrating how practitioners use the data  to inform pedagogical design, what questions and findings  researchers uncover in the data (and what is still missing), and the  type and nature of technology stack explored to analyse and  present data.    Focusing on a hands-on approach, the workshop will provide  opportunities to both technical and less technical people to  leverage on what is offered and learn from others.    It is expected that participants will share not only their findings,  but also some of the code, so that the work started with this  workshop will continue beyond the conference. The workshop  will also be an opportunity to share issues, problems and to  identify what data is missing and what would be useful to have.    Permission to make digital or hard copies of part or all of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. Copyrights  for third-party components of this work must be honored. For all other  uses, contact the Owner/Author. Copyright is held by the  owner/author(s).  LAK '17, March 13-17, 2017, Vancouver, BC, Canada  ACM 978-1-4503-4870-6/17/03.  http://dx.doi.org/10.1145/3027385.3029433       3. WHO IS THIS WORKSHOP FOR  Those who wish to understand the possibilities offered by the data  already offered by FutureLearn, discuss and share innovations,  impact on education, and explore future directions in the  application of learning analytics (LA) to Massive Open Online  Courses (MOOC) design and development as well as learning  design with MOOCs. Likely interested participants:    Educators/Teachers and researchers   Technologists and educational developers   Learning scientists and Data scientists/analysts   Academic managers   Entrepreneurs   and anyone else interested in MOOCs (focusing on   FutureLearn in this workshop) and LA   4. OUTCOMES FOR ATTENDING  PARTICIPANTS  All contributions (short 5-pages papers) accepted for this  workshop will be included in the LAK CEUR Workshop  Proceedings (http://ceur-ws.org/).  Participants will be able to:    Get an idea of the state of the art of work with FutureLearn  data across institutions, disciplines and roles;    Discuss cases, issues and problems, sharing outcomes (both  successes and failures in using the data offered);    Reflect on the impact of the work presented on learning  design and the learners experiences;    Enable the development of common tools that educators and  researchers may be able to re-use in their own contexts;    Connect relevant people with one another, in the broad area  of data and LA applied to MOOCs and FutureLearn in  particular.    Explore opportunities of sharing results for cross-course  analysis and benchmarking   The inclusion of the FutureLearn data team demonstrates their  commitment to support partners, collaborate and co-develop  effective solutions to improve research opportunities, learning  design and ultimately the learners experience.   5. REFERENCES  [1] Arnold, P. et al. 2014. Offering cMOOCs collaboratively: The   COER13 experience from the convenors perspective.  eLeanrning Papers. 37, (2014), 6368.   [2] Chandrasekaran, M.K. et al. 2015. Learning Instructor  Intervention from MOOC Forums: Early Results and Issues.  arXiv:1504.07206 [cs]. (Apr. 2015).   [3] Chitsaz, M. et al. 2016. Toward the development of a dynamic  dashboard for FutureLearn MOOCs: insights and directions.  Proceeding of ASCILITE (Adelaide, SA, 2016).   [4] Cobos, R. et al. 2016. Open-DLAs: An Open Dashboard for  Learning Analytics. Proceedings of the Third (2016) ACM  Conference on Learning @ Scale (New York, NY, USA,  2016), 265268.   [5] Corrin, L. et al. 2015. Loop: A learning analytics tool to  provide teachers with useful data visualisations. Proceedings  of ASCILITE (Perth, Australia, 2015), 409413.  http://www.2015conference.ascilite.org/wp- content/uploads/2015/11/ascilite-2015-proceedings.pdf   [6] Dawson, S. et al. 2015. Recognising learner autonomy:  Lessons and reflections from a joint x/c MOOC.   Proceedings of Higher Education Research and  Development Society of Australia 2015.   [7] Do, C.B. et al. 2013. Self-Driven Mastery in Massive Open  Online Courses. MOOCs FORUM. 1, P (Sep. 2013), 1416.   [8] Gasevic, D. et al. 2014. Where is research on massive open  online courses headed A data analysis of the MOOC  Research Initiative. The International Review of Research in  Open and Distributed Learning. 15, 5, 134-176 (Oct. 2014).   [9] Jordan, K. 2014. Initial trends in enrolment and completion of  massive open online courses. The International Review of  Research in Open and Distributed Learning. 15, 1, 134-60.   [10] Kanwar, A. and Mishra, S. 2015. The impact of OER and  MOOCs on ODL: an international perspective. International  Distance Education Development Forum, Peking University,  Beijing, China, 10 October 2015.  http://oasis.col.org/handle/11599/1734   [11] Leon Urrutia, M. et al. 2016. Visualising the MOOC  experience: a dynamic MOOC dashboard built through  institutional collaboration. Proceedings of the European  MOOC Stakeholder Summit 2016. 461-471.   [12] McAuley, A. et al. 2010. The MOOC model for digital  practice. (2010). http://www.davecormier.com/edblog/wp- content/uploads/MOOC_Final.pdf   [13] McIntyre, S. et al. 2015. Learning to Teach OnlineEvolving  approaches to professional development for global reach and  impact. e-Learning Excellence Awards 2015: An Anthology  of Case Histories. 128140.   [14] Pardos, Z.A. and Kao, K. 2015. moocRP: An Open-source  Analytics Platform. Proceedings of the Second (2015) ACM  Conference on Learning @ Scale (New York), 103110.   [15] Parod, B. 2014. Developing an Analytics Dashboard for  Coursera MOOC Discussion Forums.  https://www.cni.org/wp- content/uploads/2014/12/Mon_Parod_DevMOOCDashboard .pdf   [16] Ros, C.P. et al. 2015. Challenges and opportunities of dual- layer MOOCs: Reflections from an edX deployment study.  Proceedings of the 11th International Conference on  Computer Supported Collaborative Learning (CSCL 2015).  848-851.   [17] Ruiz, J.S. et al. 2014. Towards the Development of a  Learning Analytics Extension in Open edX. Proceedings of  the Second International Conference on Technological  Ecosystems for Enhancing Multiculturality (New York, NY,  USA), 299306.   [18] dos Santos, A.I. et al. 2016. Opportunities and challenges for  the future of MOOCs and open education in Europe.   [19] Siemens, G. et al. 2011. Open Learning Analytics: an  integrated & modularized platform. Proposal to design,  implement and evaluate an open platform to integrate  heterogeneous learning analytics techniques..   [20] Veeramachaneni, K. et al. 2014. MOOCdb: Developing  Standards and Systems to Support MOOC Data Science.  arXiv:1406.2015 [cs]. (Jun. 2014).   [21] Wise, A.F. 2014. Designing Pedagogical Interventions to  Support Student Use of Learning Analytics. Proceedings of  the Fourth International Conference on Learning Analytics  And Knowledge (New York, NY, USA, 2014), 203211.   [22] Wise, A.F. et al. 2016. Developing Learning Analytics  Design Knowledge in the Middle Space: The Student  Tuning Model and Align Design Framework for Learning  Analytics Use. Online Learning. 20, 2.  http://olj.onlinelearningconsortium.org/index.php/olj/article/ view/783 .     