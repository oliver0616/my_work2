MOOCs and the Funnel of Participation  Doug Clow   The Open University  Walton Hall, Milton Keynes  MK7 6AA, United Kingdom   +44 1908 654861  Doug.Clow@open.ac.uk            ABSTRACT  Massive Online Open Courses (MOOCs) are growing  substantially in numbers, and also in interest from the educational  community. MOOCs offer particular challenges for what is  becoming accepted as mainstream practice in learning analytics.   Partly for this reason, and partly because of the relative newness  of MOOCs as a widespread phenomenon, there is not yet a  substantial body of literature on the learning analytics of MOOCs.  However, one clear finding is that drop-out/non-completion rates  are substantially higher than in more traditional education.   This paper explores these issues, and introduces the metaphor of a  funnel of participation to reconceptualise the steep drop-off in  activity, and the pattern of steeply unequal participation, which  appear to be characteristic of MOOCs and similar learning  environments. Empirical data to support this funnel of  participation are presented from three online learning sites: iSpot  (observations of nature), Cloudworks (a place to share, find and  discuss learning and teaching ideas and experiences), and  openED 2.0, a MOOC on business and management that ran  between 2010-2012. Implications of the funnel for MOOCs,  formal education, and learning analytics practice are discussed.   Categories and Subject Descriptors  J.1 [Administrative Data Processing] Education; K.3.1  [Computer Uses in Education] Collaborative learning,  Computer-assisted instruction (CAI), Computer-managed  instruction (CMI), Distance learning   General Terms  Algorithms, Management, Measurement, Performance, Design,  Economics, Human Factors, Theory, Legal Aspects   Keywords  Learning analytics, participation, MOOCs.   1. INTRODUCTION   A MOOC is an online course with the option of free and open  registration, a publicly shared curriculum, and open-ended  outcomes [38]. MOOCs have the potential to provoke major  shifts in educational practice [48] and are officially [...] the  higher education buzzword of 2012 [51]. There are two distinct  branches: the connectivist MOOCs (cMOOCs) inspired by   Downes, Siemens, Cormier, Groom et al, and the more recent,  more formal MOOCs (xMOOCs), including Udacity, MITx, EdX,  Coursea and Udemy [28].  The pedagogy of these branches are  quite distinct: cMOOCs are underpinned by connectivism [52,  33], a sophisticated and innovative reconceptualisation of what it  means to know and to learn, whereas xMOOCs are so far based  on a very old and out-dated behaviourist pedagogy, relying  primarily on information transmission [7]. This paper will use  MOOC as an umbrella term covering both branches, and will take  a broad view of Course to include any structured open, online  learning opportunity.   2. LEARNING ANALYTICS AND MOOCS  MOOCs  and particularly the cMOOCs closely associated with  many learning analytics figures  pose particular challenges for  learning analytics practice. Participation in a MOOC is emergent,  fragmented, diffuse, and diverse [38]; it seems unlikely that the  learning analytics process will be any less so.   Much learning analytics work presupposes a formal education  context. When learning analytics are most effective, they are an  integrated part of a whole system of learner support, which is hard  to deliver in a MOOC.   The foundational work on Signals at Purdue [4, 5, 9] is based  around a predictive model of likely completion. This is potentially  problematic in a MOOC context. Essa and Ayad [22] set out to  extend predictive modeling to accommodate the considerable  variability in learning contexts across different courses and  different institutions. Whether such efforts to encompass  diversity can include MOOCs is, at present, an open question. A  more profound problem with predictive modeling in MOOCs is  the lack of human resource to mediate the feedback, and the lack  of support available to learners who have come to know that they  are at risk. One useful design framework for learning analytics  [26] can be readily applied to a MOOC, but the terminology (e.g.  teachers and students) may need to be applied loosely.  On the other hand, some learning analytics technologies present  fewer issues in a non-formal context, such as recommendation  engines and other semantic technologies, content analytics [23],  social network analysis and visualisation (for an arresting example  applied to a MOOC, see [10]), and social learning analytics [8].   3. LEARNING ANALYTICS OF MOOCS  There has not yet been extensive published research on xMOOCs,  partly because they are so new, and partly because of their  proprietary nature. On the other hand, cMOOCs have been  researched in some depth, including a specific concern with  learning analytics.   PLENK2010 has received perhaps the most thorough treatment,  with mixed-methods approaches employing a range of qualitative  and quantitative sources, including Moodle data-mining, Twitter  metrics, content analysis, surveys, and interviews [25, 31]. Other  cMOOCs have received similar attention  e.g. CCK08 [24, 35]     Permission to make digital or hard copies of part or all of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. Copyrights  for components of this work owned by others than ACM must be  honored. Abstracting with credit is permitted. To copy otherwise, to  republish, to post on servers or to redistribute to lists, requires prior  specific permission and/or a fee.  LAK '13, April 08 - 12 2013, Leuven, Belgium  Copyright 2013 ACM 978-1-4503-1785-6/13/04$15.00.     185    and CCK11 [32]. The clear message from these studies is the  importance of methods beyond the simply mechanical /  quantitative.   Learning analytics is possible in the wider context of open, online  learning environments. Pham et al [42] explored two learning  blogospheres, where social network analysis and content  analysis yielded interesting results, including a steeply unequal  fat tailed distribution of posting frequency (which they  erroneously label a power law).  There are two significant points of difference in learning analytics  in MOOCs compared to formal education: one qualitative, and  one quantitative. The qualitative difference is the rationale behind  the course and the aspirations of its designers. In a cMOOC, the  designers are explicitly not intending to specify end points before  the course starts, so a learner who starts but does not complete  may well be seen as a success, depending on the reasons. The  quantitative difference is, as the old saw has it, one that is  sufficiently large to be a qualitative difference: the rate of drop- out is so very much larger in MOOCs. This idea is encapsulated in  the funnel of participation.   4. THE FUNNEL OF PARTICIPATION  The funnel of participation is inspired by the marketing funnel,  or purchase funnel, an idea in widespread use in marketing and  sales (see e.g. [29]). This attempts to model a customers journey  from initial awareness to a sale, typically in four stages:  Awareness  they have to know the product exists; Interest  they  have to want that sort of thing; Desire  they have to want the  specific product; Action  purchase. This model is not without  criticism. More recent thinking argues for more sophistication and  a focus on what the customer does after purchase [17, 41], but the  model remains a widely-used and useful structuring device. The  marketing funnel approach is used in higher education in  marketing departments, and in alumni fundraising, but is not  generally applied to student progress while enrolled.   In the marketing funnel, there is typically significant attrition in  numbers through the stages. A vast number of people need to  become aware that the product exists; a fraction of those will be  interested in that class of product; a fraction of those will form a  desire for the specific product; and, finally, a proportion of those  will make a purchase.    In formal education, despite concerns about drop-out rates, the  total attrition from enrolment/registration to graduation is  typically much lower. In a MOOC, the attrition rate is  significantly higher  approaching those seen in marketing. This is  the basis of the funnel of participation, as shown in Figure 1.     Figure 1: The funnel of participation   Here, the first step is Awareness: potential learners must know  that the MOOC exists. Next is Registration  only a small  proportion of those who are aware will want to sign up and  succeed in doing so. Then a fraction of those registered will go on   to engage in some Activity or other, and some of those will make  meaningful learning Progress. The drop off at each stage is large.   The simple funnel as presented here can be extended in  granularity. So, for instance, the Activity category can be split in  to simply making a contribution, and making more extensive or  higher-level contributions.    The funnel is intended to be applicable in a range of pedagogical  and theoretical contexts, from connectivism to a nave information  transmission model. It is also designed to be congruent with other,  broader conceptions of online participation, such as Communities  of Practice and legitimate peripheral participation [34, 55] Dron  and Andersons collective applications [20], Preece and  Shneidermans Reader-to-Leader Framework [43], and the Fairy  Rings of Participation model [14, 36].    There are also parallels with standard web marketing ideas around  conversion of visitors through to site-specific goals, such as site  registration and online purchases, and click-through and  conversion rates for online advertising.   It should be stressed, however, that the funnel of participation  does not presuppose a fixed outcome: it requires only a shared  form of registration, a shared form of activity, and some notion of  what it would mean to progress, however open-ended.    There are two key features of the funnel: steep drop-off from each  stage to the next, and steeply unequal patterns of participation.  These fat-tailed distributions (often mislabelled power laws)  are characteristic of most if not all online social activity. It has  been long noted as a feature of open networks [3, 44, 49], and is  also seen in formal education where the activity is online [47].   5. EMPIRICAL UNDERPINNING   Table 1: Summary analytics for three different learning sites,  from site opening to 7 Nov 2012. Visits and Unique visitors   from Google Analytics. Registrations and Contributors  (have made at least one contribution) from site databases.   The funnel of participation is underpinned by empirical data.  Three examples are presented here, from three entirely separate  learning websites. The first is iSpot (www.ispot.org.uk), a social  learning community aimed at helping beginners learn to identify  nature observations  [14, 37, 53]. The second is Cloudworks  (www.cloudworks.ac.uk), a professional learning community for  educators and educational researchers [15, 16]. The third is  openED (www.open-ed.eu), an open online course in business and  management aimed at postgraduate/practitioner level [1, 13].  While there is some overlap in the team behind these three sites  (including the author), the user communities are entirely distinct,  with only a handful of users present on more than one of them.    iSpot Cloudworks openED   Visits 1,100,000 275,000 30,000   Unique visitors 390,000  (35%)   165,000  (60%)   15,500  (52%)   Registrations 21,000  (5%)   5,239  (3%)   1,429  (9%)   Contributors 9,000  (43%)   1,750  (33%)   198  (14%)    Contributor rate  2.3% 1.0% 1.3%   186    Table 1 shows summary figures for participation on the three  sites. Two features leap out. First is the dramatic fall-off in each  step in greater involvement. The second is how similar the rates of  attrition are across the three sites.   Closer analysis of these three communities yields further  examples of the funnel, with steep drop-off, and highly unequally  distributed patterns of activity. For iSpot, this pattern has been  explored at length [14]; an updated analysis yielded no significant  differences. For Cloudworks, the funnel can be seen in the number  of users making different numbers of contributions (Table 2). For  openED, the pattern is explored in more detail in Section 6 of this  paper.   Table 2: Number of users who have made given numbers of  contributions to Cloudworks.    The funnel of participation has been observed on other MOOCs  and similar sites. For instance, PLENK2010 had 1,641  registrations, but about 40-60 individuals on average contributed  actively to the course on a regular basis [25], or 2.4-3.7%  close  to the overall contributor rate seen above. On CCK08, there were  2,200 participants [19]; there were 83 respondents to the post- course survey, of whom 15 said they had completed the entire  course (and 13 of those were studying formally for credit) [24].  Similarly, on Athabasca Landing, a social learning site for  (formal) students at Athabasca University, 78% of the content is  created by 21% of the users, and around 18-21% of the users are  active [45].   The funnel is also apparent  at least at the very coarsest level  in    reported completion rates for xMOOCs. These are variously said  to be less than 10% of registered students completing the course  [28] or generally between 10 and 20 percent [30].  The first  MITx course, Circuits and Electronics, attracted over 150,000  participants, but fewer than half look at the first problem set,  and only 7,157 passed, or about 5% [18]. Courseras first  Software Engineering course enrolled 50,000 students, of whom  3,500 passed, or 7% [40].   These rates are considerably lower than for conventional higher  education, where in the UK completion rates are over 90% for  highly selective high-status universities, and above 60% for  universities with a broader social mission. It is notable, however,  that rates for online and distance universities fall somewhere  between conventional HE and xMOOCs: University of Phoenix  completion rates are 31-36% for undergraduate-level degrees [54],  while completion rates for the Universitat Oberta de Catalunya  (UOC, Open University of Catalonia) have ranged between 33%  and 67% [27].   6. THE OPENED 2.0 COURSE  Having looked broadly at evidence of the funnel of participation,  this paper now looks more closely at one specific example: the  openED 2.0 course.   The openED 2.0 project explored a framework for collaborative,  open, multi-institutional development of a course, coupled with an  open, online model of delivery. Seven European organisations  worked together to create the course, largely based on existing  Open Educational Resources (OER). The main learning  environment was a customised version of Joomla, with additional  learning support provided by email, IRC chats, and Elluminate  conferencing. The course was presented three times between 2010   and 2012. The principles and rationale for openED and related  courses are articulated extensively elsewhere [39], and an account  of the approach to the design of the course has been published [1].  The projects deliverables included a full report of the evaluation  [13]. This section presents a further quantitative analysis of the  participation data.     Figure 2: Log plot of the number of visits to openED per user,   ranked by number of visits.   0  0.5  1  1.5  2  2.5  0 50 100 150 200 250  rank  lo g(  fo ru  m  p  os ts  )    Figure 3: Log plot of the number of forum posts on openED   per user, ranked by number of forum posts.  Visit data could be attributed with confidence to 691 individuals;  199 individuals made posts to the course forums. As can be seen  from Figures 2 and 3, the distribution of both visits and posts to  the forum was steeply unequal, or fat tailed. Neither, however,  follow a power law (see [11]). The visit data could be connected  to the forum data for 178 users; there was a clear correlation  between the two (R = 0.86, p < 0.0001), as would be expected.  These patterns of steeply-unequal participation and steep, staged  drop out fit the key characteristics of the funnel of participation.   7. DISCUSSION  The funnel of participation is a real, significant phenomenon in  MOOCs and related courses. Compared to formal learning, there  tends to be much higher rates of drop-out, and steeply unequal  patterns of participation. This is probably an almost-inevitable  consequence of any open, online activity: there is less initial  commitment, so the filtering happens at a later stage [38]; and the  well-attested tendency for steeply unequal patterns of  participation to emerge in online activity is manifest.   The phenomenon shows that MOOCs alone cannot replace  degrees or most other formal qualifications. The significant efforts   Contributions 0 1-5 5-9 10-49 50+   Users  3,489 1,322 192 192 44   187    that institutions put in to supporting their learners to reach a  commonality of learning outcome are necessary, and have a real  effect. As Siemens [50] argues, the long-term value for  universities is likely to lie in precisely those things that cannot be  cheaply duplicated through a MOOC.   Does it matter if MOOCs have high drop-out rates Some argue  that it is a positive sign of an exploratory phase [46]; Daniel [18]  points out that answers to this question create a sharp distinction  between the xMOOCs providers and other distance learning  institutions, with the xMOOCs observing that early drop-outs do  not add significantly to costs [30]. What constitutes drop-out and  completion can be a complex problem, particularly for online and  distance institutions, such as the UK Open University [6] and  UOC [27]: rates are highly sensitive to their precise definition,  and vary widely between courses. Is it drop-out, or non- continuation, or climb-out This is a long-standing issue for  distance educators [3], and is a bigger question in MOOCs,  because the phenomenon is so much larger. Where we have  indications of problems (e.g. the evidence that some learners find  cMOOCs confusing [24, 38]), we have a responsibility to do what  we can to address them.   Learning analytics offers great potential, but the choice of  intervention in a MOOC may be niew problematic. For example,  in a formal situation, a prediction of likely failure to complete is  instantly meaningful, relevant, and can be mediated by skilled  learning professionals, and the learner can be supported by a  range of existing resources and specialists.   The value in learning analytics comes from closing the loop  effectively to complete the Learning Analytics Cycle [12]. The  funnel of participation shows that this is a particular challenge for  MOOCs and similar open, online environments: they tend towards  steep drop-offs and highly unequal patterns of participation.  However, the experience of online and distance teaching  institutions, where the rates of drop-out fall somewhere between  conventional courses and MOOCs, suggests that it is possible to  mitigate the impact of the funnel. There is likely to be significant  value in further work to empirically explore and validate how  learning analytics can help learners in a MOOC context.   8. ACKNOWLEDGEMENTS  The author wishes to thank James Aczel for his invaluable  contribution to the creation and launch of the openED project, and  Simon Cross for his work on the project. Thanks are also due to  the project partners and the participants in the course. The  openED course was funded by the European Commission through  the Lifelong Learning Programme as project 505667-LLP-1-2009- 1-PT-KA3-KA3MP. This paper remains, however, the sole  responsibility of the author.   9. REFERENCES  [1] Aczel, J., Cross, S., Meiszner, A., Hardy, P., McAndrew, P.,   and Clow, D. 2011. Some issues affecting the sustainability  of open learning courses. EDEN 2011 Annual Conference,  Dublin, Ireland, 19-22 June 2011.   [2] Anderson, C. 2006. The Long Tail: How endless choice is  creating unlimited demand. London: Random House.   [3] Anderson, T. 2012. Interesting analysis of a c-MOOC.  http://terrya.edublogs.org/2012/07/25/interesting-network- analysis-of-a-c-mooc/   [4] Arnold, K. E. 2010. Signals: Applying academic analytics.  EDUCAUSE Quarterly, 33, 1.   [5] Arnold, K. E. & Pistilli, M. D. 2012. Course Signals at  Purdue: Using learning analytics to increase student  success. Proc. 2nd Int. Conf. on Learning Analytics &  Knowledge. New York: ACM.   [6] Ashby, A. 2004. Monitoring student retention in the Open  University: definition, measurement, interpretation and  action. Open Learning, 19, 1, 65-77.   [7] Bates, T. 2012. Whats right and whats wrong about  Coursera-style MOOCs.  http://www.tonybates.ca/2012/08/05/whats-right-and-whats- wrong-about-coursera-style-moocs/   [8] Buckingham Shum, S., & Ferguson, R. (2012). Social  Learning Analytics. Ed. Tech. & Society, 15, 3, 326.   [9] Campbell, J.P., and Oblinger, D.G. 2007. Academic  Analytics. EDUCAUSE Quarterly, October 2007.   [10] CBlissMath. 2012.  http://www.youtube.com/watchv=K_dIXNGVZnk   [11] Clauset, A., Shalizi, C.R., Newman, M.E.J. 2009. Power-law  distributions in empirical data. SIAM Review 51(4), 661-703.   [12] Clow, D. 2012. The Learning Analytics Cycle: Closing the  loop effectively. Proc. 2nd Int. Conf. on Learning Analytics  & Knowledge. New York: ACM.   [13] Clow, D., Cross, S., and McAndrew, P. (2012). Quality  Assurance  D7.3 Assessment Report. EU Deliverable:  openED, 505667-LLP-1-2009-1-PT-KA3-KA3MP.   [14] Clow, D., and Makriyannis, E. 2011. iSpot Analysed:  Participatory Learning and Reputation. Proc.1st Int. Conf. on  Learning Analytics and Knowledge, Banff, Alberta, Canada.   [15] Conole, G., Culver, J., Williams, P., Cross, S., Clark, P., and  Brasher, A. 2008. Cloudworks: social networking for  learning design. Proc. ascilite Melbourne 2008.   [16] Conole, G., and Culver, J. 2010. The design of Cloudworks:  Applying social networking practice to foster the exchange  of learning and teaching ideas and designs. Comput. Educ.,  54(3), 679 692.   [17] Court, D., Elzinga, D., Mulder, S., and Vetvik, O.J. 2009.  The consumer decision journey. McKinsey Quarterly, June  2009.  http://www.mckinseyquarterly.com/Media_Entertainment/Pu blishing/The_consumer_decision_journey_2373#   [18] Daniel, J. 2012. Making Sense of MOOCs: Musings in a  Maze of Myth, Paradox and Possibility.  http://sirjohn.ca/wordpress/wp- content/uploads/2012/08/120925MOOCspaper2.pdf   [19] Downes, S., and others. 2011. The MOOC Guide  https://sites.google.com/site/themoocguide/home   [20] Dron, J., and Anderson, T. 2009. On the Design of Collective  Applications. 2009 Int. Conf. on Computational Science and  Engineering, 368374.   [21] Esposito, A. 2012. Research ethics in emerging forms of  online learning: issues arising from a hypothetical study on a  MOOC. Electronic J. e-Learning 10, 3, 315-325.   [22] Essa, A., and Ayad, H. 2012. Student Success System: Risk  Analytics and Data Visualization using Ensembles of  Predictive Models. Proc. 2nd Int. Conf. on Learning  Analytics & Knowledge. New York: ACM.   188    [23] Ferguson, R. 2012. The state of learning analytics in 2012: a  review and future challenges. Technical Report No. KMI-12- 01, Knowledge Media Institute, The Open University  http://kmi. open. ac. uk/publications/techreport/kmi-12-01   [24] Fini, A. 2009. The Technological Dimension of a Massive  Open Online Course: The Case of the CCK08 Course Tools.  IRRODL, 10, 5.    [25] Fournier, H., Kop, R., and Sitla, H. 2011. The value of  learning analytics to networked learning on a personal  learning environment. Proc.1st Int. Conf. on Learning  Analytics and Knowledge, Banff, Alberta, Canada.   [26] Greller, W., and Drachsler, H. 2012. Translating Learning  into Numbers: A Generic Framework for Learning Analytics.  Ed. Tech. & Society, 15, 3, 4257.     [27] Grau-Valldosera, J. and Minguilln, J. 2011. Redefining  dropping out in online higher education: a case study from  the UOC. Proc.1st Int. Conf. on Learning Analytics and  Knowledge, Banff, Alberta, Canada.   [28] Hill, P. 2012. Four Barriers That MOOCs Must Overcome  To Build a Sustainable Model.  http://mfeldstein.com/four- barriers-that-moocs-must-overcome-to-become-sustainable- model   [29] Jobber, D. 1995. Principles and practice of marketing.  McGraw-Hill, Berkshire.   [30] Kolowich, S. 2012. How will MOOCs make money Inside  Higher Ed.  http://www.insidehighered.com/news/2012/06/11/experts- speculate-possible-business-models-mooc-providers   [31] Kop, R. 2011. The Challenges to Connectivist Learning on  Open Online Networks: Learning Experiences during a  Massive Open Online Course Analysis of Plenk2010.  IRRODL, 12, 3.   [32] Kop, R., Fournier, H., and Mak, J.S.F. 2011. A Pedagogy of  Abundance or a Pedagogy to Support Human Beings  Participant Support on Massive Open Online Courses.  IRRODL, 12, 7.   [33] Kop, R., and Hill, A. 2008. Connectivism: Learning theory  of the future or vestige of the past IRRODL, 9, 3.   [34] Lave, J., and Wenger, E. 1991 Situated Learning: Legitimate  Peripheral Participation. Cambridge University Press,  Cambridge.   [35] Mak, S.F.J, Williams, R., and Mackness, J. 2010. Blogs and  forums as communication and learning tools in a MOOC.   Proc. 7th Int. Conf. on Networked Learning. University of  Lancaster, UK.   [36] Makriyannis, E., and de Liddo, A., 2010. Fairy Rings of  Participation: The invisible network influencing participation  in online communities. Proc. 7th Conf. on Networked  Learning. University of Lancaster, UK.   [37] McAndrew, P., Scanlon, E., and Clow, D. 2010. An Open  Future for Higher Education. Educause Quarterly, 33(1).   [38] McAulay, A., Stewart, B., and Siemens, G. 2010. The  MOOC model for digital practice. University of Prince  Edward Island.  http://www.elearnspace.org/Articles/MOOC_Final.pdf   [39] Meiszner, A., 2011. The Why and How of Open Education.  UNU-MERIT, Maastricht, Netherlands. http://unu.edu/news/  book-the-why-and-how-of-open-education.html   [40] Meyer, R. 2012. What Its Like to Teach a MOOC (And  What the Hecks a MOOC). The Atlantic.  http://www.theatlantic.com/technology/archive/2012/07/what -its-like-to-teach-a-mooc-and-what-the-hecks-a- mooc/260000/ XXX   [41] Noble, S. 2010 Its Time To Bury The Marketing Funnel.  Forbes. http://www.forbes.com/2010/12/08/customer-life- cycle-leadership-cmo-network-funnel.html   [42] Pham, M.C., Derntl, M., Cao, Y., an Klamm, R. 2012.  Learning Analytics for Learning Blogospheres, In. E.  Popescu et al. (Eds.): ICWL 2012, LNCS 7558, 258267.   [43] Preece, J., and Shneiderman, B. 2009. The Reader-to-Leader  Framework: Motivating Technology-Mediated Social  Participation. AIS T. HCI. 1, 1, 13-32.   [44] Priedhorsky, R., Chen, J., Lam, S., Panciera, K., Terveen, L.,  and Riedl, J. (2007). Creating, destroying, and restoring  value in Wikipedia. 2007 Int. ACM Conf. on Supporting  Group Work, Sanibel Island, Florida, 259-268. New York:  ACM.   [45] Rahman, N. and Dron, J. 2012. Challenges and opportunities  for learning analytics when formal teaching meets social  spaces. Proc. 2nd Int. Conf. on Learning Analytics &  Knowledge. New York: ACM.   [46] Rosen, R.J. 2012. Overblown-Claims-of-Failure Watch: How  Not to Gauge the Success of Online Courses. The Atlantic.  http://www.theatlantic.com/technology/archive/2012/07/over blown-claims-of-failure-watch-how-not-to-gauge-the- success-of-online-courses/260159/   [47] Rosewell, J. and Hirst, T. 2008 Equability and dominance in  online forums.  CALRG Conference, 18-19 June 2008.  http://kn.open.ac.uk/public/document.cfmdocid=11627   [48] Sharples, M. et al. 2012. Innovating Pedagogy 2012: Open  University Innovation Report 1. The Open University,  Milton Keynes, UK.   [49] Shirky, C. 2003 Power Laws, Weblogs, and Inequality,  http://www.shirky.com/writings/powerlaw_weblog.html   [50] Siemens, G. 2011. Duplication theory of educational value.  http://www.elearnspace.org/blog/2011/09/15/duplication- theory-of-educational-value/   [51] Siemens, G. 2012. MOOCs are really a platform.  http://www.elearnspace.org/blog/2012/07/25/moocs-are- really-a-platform/   [52] Siemens, G., and Downes, S. 2008, 2009. Connectivism &  connected knowledge: CCK08, CCK09.  http://ltc.umanitoba.ca/connectivism/   [53] Silvertown, J. 2009. A new dawn for citizen science. Trends  in Ecology and Evolution 24, 9, 467-471.   [54] University of Phoenix. 2012. 2011 Academic Annual Report.  http://www.phoenix.edu/about_us/publications/academic- annual-report.html   [55] Wenger, E. 1998. Communities of Practice: Learning,  Meaning and Identity. Cambridge University Press,  Cambridge.   189      