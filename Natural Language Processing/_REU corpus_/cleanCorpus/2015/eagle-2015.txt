Exploring Networks of Problem-Solving Interactions  Michael Eagle, Drew Hicks, Barry Peddycord III, and Tiffany Barnes Department of Computer Science  North Carolina State University 890 Oval Drive, Campus Box 8206  Raleigh, NC 27695-8206 {mjeagle, aghicks, bwpeddyc, tmbarnes}@ncsu.edu  ABSTRACT Intelligent tutoring systems and other computer-aided learn- ing environments produce large amounts of transactional data on student problem-solving behavior, in previous work we modeled the student-tutor interaction data as a com- plex network, and successfully generated automated next- step hints as well as visualizations for educators. In this work we discuss the types of tutoring environments that are best modeled by interaction networks, and how the empir- ical observations of problem-solving result in common net- work features. We find that interaction networks exhibit the properties of scale-free networks such as vertex degree distributions that follow power law. We compare data from two versions of a propositional logic tutor, as well as two different representations of data from an educational game on programming. We find that statistics such as degree as- sortativity and the scale-free metric allow comparison of the network structures across domains, and provide insight into student problem solving behavior.  1. INTRODUCTION Problem solving is an important skill across many fields,  including science, technology, engineering, and math (STEM). Working open-ended problems may encourage learning in higher levels of cognitive domains [7]. Intelligent tutors have been shown to be as effective as human tutors in sup- porting learning in many domains, in part because of indi- vidualized, immediate feedback, enabled by expert systems which diagnose the knowledge state of the student [36]. An additional benefit of computer-based environments is that they record extensive logs of student work, at a detail other- wise not possible. Stamper et al. used these logs to automat- ically build intelligent feedback into a otherwise non adap- tive system [35]. One potential weakness of tutoring systems and other computer-aided instructional environments is that they can make it difficult for instructors to track how their students are solving problems within the system, this type of detachment can lead to a decreased sense of control and  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. LAK 15 Poughkeepsie, NY, USA Copyright 2015 ACM 978-1-4503-3417-4/15/03 http://dx.doi.org/10.1145/2723576.2723630 ...$15.00.  can affect adaptation of the tutor [33]. In this work we explore student-tutor interaction networks,  an empirical sample of student-walks though a problem- space modeled as a complex network. Interaction networks were designed specifically for tutors with problem-solving tasks in which there are many goals and many paths to those goals, and that the user moves along those paths by using a set of actions. We explore interaction networks from mul- tiple datasets and find that they exhibit scale-free proper- ties. We find that interaction networks from different tutors share similarities in scale-free metrics and find that global and local vertex degree assortativity provide insight into the nature of the problem solving environments.  We present success stories from a variety of tutoring sys- tems and argue that interaction networks are useful for a wide variety of problem solving instructional environments, even when the potential problem-space might look to be in- tractable. The scale-free properties of the network make it possible to discover the important regions of a network even with a small sample of student data. We expect that inter- action networks are a good representation for describing a large amount of student data; provide a common language for performing cross tutor evaluation of problem solving en- vironments; and that the intuitive nature of the model helps convey results from the data in a way that is interpretable for both research and instructor.  1.1 Previous Work Creation of adaptive educational programs is expensive.  Intelligent tutoring systems require content experts and ped- agogical experts to work with tutor developers to identify the skills students are applying and the associated feedback to deliver [26]. In order to address the difficulty in author- ing intelligent tutoring content, Barnes and Stamper built an approach called the Hint Factory to use student data to build a Markov Decision Process (MDP) of student problem- solving approaches to serve as a domain model for automatic hint generation [34]. Hint factory has been applied across domains [17, 30, 14], and been shown to increase student retention in tutors [35]. Eagle and Barnes abstracted this domain model into a complex network representation of the student-tutor interactions called an interaction network [13]. These networks worked well as visualizations of student work within tutors and Johnson et al. successfully created a vi- sualization tool InVis specifically to aid instructors in un- derstanding student-tutor interaction data [22]. Preliminary results on mining the interaction networks found that apply- ing network mining techniques to interaction networks can help uncover useful sub-regions that represent diverse stu-  21    dent approaches to solving a particular problem [12]. In this work we expand on the theoretical framework of the inter- action networks, explore their structure, and the processes that generate them.  2. MODELING PROBLEM SOLVING Before we can model user interactions within a problem-  solving environment, we first need to define our theoretical foundations for what we consider problem solving, as well as what types of environments we will be studying. There are many different ways to define problem solving, Anderson referred to problem solving as any goal-directed sequence of cognitive operations [3]. Classical problem solving from Newell and Simon [27] break this down into mental repre- sentations and Problem Space; with problem solving being the internal (cognitive) and external activity based manip- ulation of that Problem Space. Our goal is to model trans- actional data, which is human-computer interactions that occur in interactive systems; specifically, we are interested in educational systems such as Intelligent Tutoring Systems or other Computer Aided Instructional programs.  The distinction between internal and external problem representation is important, as our goal is not necessarily to model individual cognitive processes such as those repre- sented in ACT-Rs [4] Imaginal module, which contains steps the user makes in internal cognition. The external manip- ulation is closer to the Manual Control module in ACT-R. We know the result of the cognitive processes, but do not know precisely what those processes were. In this sense, we treat the students as a black-box, measure their outputs, and then use that to make inferences into the processes within groups of students. Jonassen in Toward a Design Theory of Problem Solving identified 11 different types of problem solving, based on problem features such as structuredness, complexity, and context [23]. Some of these problem types more easily lend themselves towards computer-based educa- tion than others. With ill-structured problems with no de- fined correctness such as Case Analysis Problems or Design Problems rarely represented due to difficulty in computa- tionally evaluating answers.  We will focus on the problem type Rule-Using Problems. Jonassen defines as problems with correct solutions, multiple solution paths, and multiple rules that govern the process. Rule-using problems constitutes a new class of problem solving, so no research about these specific kinds of prob- lems exists. Cognitive processes and design principles will have to be generalized from any research on prototypic ex- amples of this class (e.g., online searching) in addition to cognitive task analysis [23]. The nature of building a com- puter aided instructional program often requires a set of well-defined rules which the student must use to manipulate the tutor environment in order to find a desired solution. Modeling student problem solving behavior with interaction networks will work best in these rule-using and puzzle en- vironments. However, with cleaver problem representation other problem solving types could potentially still find in- teraction networks useful.  2.1 Interaction Network The interaction network is an empirical result of a sample  of human-walkers on a problem-space. In sequential problem solving environments, or Rule-using Problems, a solution path describes a sequence of state changes from a starting  position towards a desired end position. Actions are used to change from state to state. For this work we will only consider discrete time environments with deterministic state transitions. An interaction network is created from trans- actional student-logs recorded when students work in the tutor. We describe interaction networks with terms inspired from classical planning, such as STRIPS [16]. The inter- action network concisely describes the information from a large number of problem solving sequences. It is modeled as a weighted network, with relevant information; such as time spent, frequency, number of errors, and type of action, encoded into the edges and vertices. Interaction networks represent empirical student-tutor observations and do not represent students internal cognitive states that may occur between recorded actions.  Each Interaction within the network is an empirical re- sult (represented in transactional log-files) of some cognitive operations. Which we are defining as Activity-based manip- ulation of the environment State. With the Activities being the Rules or Actions available within the environment. We use State rather than Problem Space as we are modeling the empirical program State rather than the internal Problem Space manipulations.  We define the State as a representation of the environ- ment, it should initially represent enough information to re- generate the tutors interface at each step and be generalized as needed with matching functions. We could then describe the State Space in a way similar to game-theory as the set of states that represent every possible legal configuration of the environment from an initial state, and State Space Complex- ity as the number of elements in this set [2]. Depending on the types of actions available in the environment, the State Space and Problem Space could easily be infinite. However, as an empirical model, we have the Observed State Space which refers to the set of program States that we have ob- served and the interaction network itself is a proxy to the Observed Problem Space.  We use a State Matching Function to determine which states we consider equivalent. Matching functions that allow some variation help provide more overlap and smaller state space, since problem-solving attempts have more of a chance of matching with prior approaches.  We define Action as:   Action ID  unique identifier for the rule used  Precondition  parameters for the action  Postcondition  action results  We define an Interaction as:   Start State  the state before the action is taken  End State  the state after the completion of the ac-  tion  Action  the action causing the state change  Property Map  extra interaction-specific information  An interaction network is constructed by treating the set of interactions for a specific program as an edge list, and collapsing parallel edges with identical actions (as defined by a action matching function) into weighted edges, these weighted edges represent a set of transactions. Program states and actions are compared with their respective Match- ing Functions. Matching functions determine when interac- tions will be consolidated into a single Vertex/Edge. Prop- erty maps are attached to the network to hold additional information about states and edges, such as student IDs, elapsed time, start states, goal states, etc.  22    Defined as a Property Map: Set of Vertices:  Unique ID  defined by the State Matching Function  Set of out Edges  actions taken to leave this state  Set of in Edges  actions taken to end in this state  Property Map  contains key/value pairs to a variety  of state specific attributes Set of Edges:  Unique ID  defined by the Action Matching Function  Start State  the state before the action is taken  End State  the state after the completion of the ac-  tion  Property Map  contains key/value pairs to edge spe-  cific attributes Matching Functions:  State Matching Function  determines which states  are considered the same  Action Matching Function  determines which actions  are considered the same Interaction networks can be built using any system logs  that can be mapped into {state, action, resulting-state} tu- ples. In our prior work, we have also represented the states as the set of post conditions (results of performing actions in the tutor.) We have proposed both ordered and unordered matching functions. Ordered matches mean that the two matching states have exactly the same steps executed in the same order. Unordered matches mean that the two matching states have all the same parts, but may not have been done in the same order. The less restrictive the matching func- tion, the more concise the interaction network, this lowers the number of vertices in the network at the cost of hav- ing potentially less contextual information; Figure 1 uses unordered matches from a propositional logic tutor.  Figure 1: An example interaction network. The vertices represent tutor states, edges represent ac- tions that go from state to state, edge thickness is weighted by frequency, goal states are green, and vertices with high attrition rates have red boarders.  2.2 Interpretation An Interaction Network is a subset of the problem solution  space, which includes a number of states and solutions that  are not only not observed in data, but are also unlikely to ever be visited by a human. If we consider each attempt to solve a problem as a black-box walker across the problem solution space we can see how different biases in the walkers choice of actions result in different interaction networks.  Consider a population of random walkers that starts at the problem initial state and chooses random actions. Now consider walkers from a population that have a particular bias in the actions chosen at particular states. This bias will cause states to be visited differently, and could result in large parts of the problem solution space to go unvisited. Figure 2 shows an example with three different populations of walkers. The black states refer to states that exist within the state space and are visited by random walkers, but are never visited by either group of bias walkers.  Therefore, we interpret an Interaction Network is a sample of problem solving behavior from a population for a partic- ular problem. And while different populations of student- walkers will share the same potential solution space, they could have very different interaction networks. In Eagle et al. [12] two experimental groups were compared by observ- ing the areas of the interaction network that each group tended to visit more than would be expected if the groups were from the same population. The question presented now is, how much data is needed in the sample to generate a rep- resentative of the population  Figure 2: Example of a problem-space. The black states represent parts of the problem space are are not visited by human walkers. The blue and orange states represent the states observed from two differ- ent populations of human walkers.  Barnes and Stamper [6] approached the question of how much data is needed to get a certain amount of overlap in student solution attempts by incrementally adding student attempts and measuring the step overlap over a large series of trials. This was done with the goal of producing auto- matically generated hints, and thus solution-attempts that did not reach the goal were not considered. Peddycord et al. [30] performed a similar technique to evaluate differences in overlap between two different interaction network state rep- resentations. Again, this was a measure of how often the  23    interaction network state for a new student interaction had previously been seen, as the goal of their study was to gener- ate hints they also used only solution-attempts that reached the goal states.  As stated above we treat the students as a black-box, mea- sure their outputs, and then use that to make inferences into the processes within groups of students. Interaction networks are an empirical sample of student-walks through a problem-space modeled as a complex network. Interac- tion networks were designed specifically for open-ended rule- using problems; where the problem is well structured, as are types of actions that can be performed within the environ- ment. There can be many goals, and many paths to those goals. There is little to gain from modeling problems that do not offer meaningful choices [32], such as the example in figure 3, where any action will move the student closer to the goal.  We have observed similar features across a variety of dif- ferent educational domains and expect that there are some problem-solving aspects of rule-using tutors that are shared between different domains. Figure 4 shows an example of one common feature we would expect to occur within a rule- using problem with a single goal-state. The students branch from a shared start state and then later either converge on the goal or go down a path without a goal. Rabin, referred to this structure as a convexity [32], in the context of design- ing or describing meaningful decisions in a video game. We have targeted these bubbles and used them as a method to simplify the interaction networks for visualizations [21]. We expand upon this idea, by adding multiple goals in figure 5, as well as areas where students converge that are not the goal.  Figure 3: Interesting problems must have meaning- ful choices. No matter what action the student takes they move from the start state (white) toward the goal state (green), the rule-using problems we want to focus on allow divergence.  Figure 4: The vertices represent a convexity, or bubble, which is a region within an interaction net- work where the problem expands from one state and then later converges to a single state. If there are multiple paths to get to the goals, and they can cross over, these types of structures should exist in the network.  Figure 5: Observed networks rarely have complete bubbles, the grey edges and vertices represent places that the either we have yet to observe a student visiting or that it cannot be reached.  2.3 Network Features Even though the theoretical state space and problem-space  can be very large or infinite, the empirical state-space is small enough to explore. We can explore the high level fea- tures of interaction networks by computing some common network invariants. For example, the degree of a state rep- resents how many states it is connected to. A state with a high out-degree is a part of the problem in which there are a large number of possible actions. Likewise, a state with a high in-degree is a part of the problem that is converged on by a large number of other states see figure 7.  We will look at two particular metrics that can help de- scribe the overall nature of the interaction networks. Scale- free networks are a broad class of complex networks that have degree distribution which follows power law [5]. We will also look at assortativity, the degree to which vertices with the same degree are connected to each other [28].  2.3.1 Scale-Free Qualitative observation of interaction networks from data,  such as Deep Thought in [35], revealed that the degree dis- tribution was concentrated on a relatively small number of the states. Several largely studied complex networks such as World Wide Web links, biological networks, and social networks are conjectured to have degree distributions which follow a power law [9]. These networks are called scale-free networks [5]. Barabasi and Albert theorized that scale-free networks are caused by preferential attachment processes; these processes bias the distribution of a value over ob- jects by how much of the value the objects already have [5]. Barabasi and Alberts preferential attachment is one of sev- eral different methods of generating scale-free networks [11]. Our theory is that the samples of non-random student walk- ers who generate the interaction network are more likely to perform similar actions to other walkers from the same pop- ulation, this results in shared preferences for certain types of actions or states.  An important feature of scale-free networks is that they are resilient to error and attack to [1]. Several vertices were removed from Figure 5, however the network remained con- nected and in more or less the same shape. The high degree vertices act as hubs and hold the network together, random vertex removals will not matter unless a hub is removed. One method to visually check a network to see if it could be scale-free is to plot the log-log plot [19]. We can also fit the  24    parameters using [29], [9], and use the Kolmogorov-Smirnov test to check the hypothesis that the degree distribution is from a distribution other than power law [25].  To investigate the scale-free nature of interaction net- works, we measured the examined networks generated from three sets of data:  Deep Thought (see Section 4.1)  11 problems  Deep Thought 3 (see Section 4.1)  40 problems  BOTS (see Section 4.4)  13 problems  For the problems in the BOTS dataset, we looked at inter- action networks generated from two different state matching functions, (codestates and worldstates,) see Table 3.  2.3.2 Assortativity and Self Similarity The power law degree distribution indicates that there  are a few vertices that contain the majority of the overall degrees. Degree assortativity describes the correlation of degree between vertices and their neighbors[28]. The assor- tativity metric r ranges between -1 and 1. A network with r = 1 would have each vertex only sharing edges vertices of the same degree. Likewise, if r = 1 vertices in the network would only share edges with vertices of different degree. Several commonly studied classes of networks tend to have patterns in their assortativity. Social networks tend to have high assortativity, while biological and technological networks tend to have high dissortativity [28]. Randomly generated scale-free graphs, such as those generated from Barabasi and Alberts preferential attachment tend to have r values closer to 0.  Li et al. proposed further classifying networks with power law degree distributions into scale-free (self-similar) and scale- rich (self-dissimilar) networks[24]. Li et al. proposed the metric:  s(g) =   (i,j)E  didj , (1)  which measures the extent to which the graph g has a hub- like core, s is higher when high-degree vertices share edges [24]. The normalized version of the s-metric:  S(g) = s(g)  smax , (2)  where smax is a graph which maximizes the s-metric for a de- gree distribution, and is a measure of how close the network is to having a central core of highly connected centrally- located vertices [24]. A low S(g) indicates a scale-rich net- work in which high degree vertices do not form hubs. This is important as in the context of interaction networks, these hubs represent states from which students make a larger pro- portion of actions. Not being able to reach a state in the program has the potential to prevent the student from find- ing the goal. High values of S(g) also indicate self-similar fractile like patterns, which we expect to see in parts of the network (figure 5.)  We computed the assortativity and S(g) metrics for prob- lems from both Deep Thought as well as the BOTS game, shown in Table 1. For the most part the interaction net- works do not exhibit high levels of assortativity, with the BOTS data leaning slightly towards dissortativity. The high S(g) values indicate that the high degree vertices are con- nected, when paired with assortativity we can get an idea of how the lower degree vertices are attached. Dissortative scale-free networks have low degree vertices attached to the  high degree hub vertices and are less likely to share edges with other low degree vertices. Assortative scale-free net- works have regions of highly connected hubs, and regions of low degree vertices that are rarely connected directly to the hubs. Finally, the r = 0 scale-free networks are likely to contain mixtures of assortative and dissortative regions. Piraveenan et al. showed that networks with low values of assortativity could be composed of assortative and dissorta- tive connected components [31].  Table 1: Averages across the datasets, dr is the di- rected assortativity, r is the undirected assortativ- ity, and S(g) is the scale-free metric.  Dataset dr r S(g)  Code -0.25 -0.30 0.79 World -0.33 -0.31 0.92 DT1 -0.03 0.01 0.54 DT3 0.16 0.16 0.79  Figure 6: An example of an assortative network (right) where vertices connect to vertices with sim- ilar degree, and a dissortative network (left) where vertices share edges with vertices of different degree.  Table 2: Interaction networks generated from prob- lems in the 2009 Hint Factory dataset [35]. Alpha is the exponent of the fitted power-law distribution, logLik is the log-likelihood of the fit with xmin, KS is the Kolmogorov-Smirnov test statistic (smaller score indicates better fit), p is the p-value of the KS test, values less than 0.05 reject a power-law fit.  Network N alpha xmin logLik KS p  dt1-1 1295 3.50 8.00 -107.92 0.05 1.00 dt1-2 1030 3.49 6.00 -185.74 0.02 1.00 dt1-3 1264 3.20 4.00 -350.76 0.04 0.97 dt1-4 1278 2.89 4.00 -409.83 0.03 0.99 dt1-5 1420 3.63 6.00 -190.10 0.03 1.00 dt2-2 1313 3.93 9.00 -86.94 0.06 1.00 dt2-3 1197 3.23 4.00 -313.22 0.03 1.00 dt2-4 232 3.14 2.00 -243.77 0.03 0.98 dt2-5 758 3.67 4.00 -162.06 0.02 1.00 dt3-1 1524 3.30 4.00 -328.82 0.06 0.54 dt3-2 1276 3.49 4.00 -201.36 0.05 0.97  25    Table 3: Averages across all interaction networks generated from problems in the BOTs(Code and World) and DT(DT1 and DT3). Variables are the same as those in Table 2.  Dataset N alpha xmin logLik KS p  Code 224.38 2.94 3.38 -78.88 0.08 0.74 World 51.69 3.34 7.00 -71.01 0.10 0.94 DT1 1144.27 3.41 5.00 -234.59 0.04 0.95 DT3 330.69 3.78 2.22 -184.16 0.03 0.99  Figure 7: The in-degree vs. out-degree ratio can re- veal information about the complexity of problems. Degree assortativity is the tendency for vertices to share edges with vertices with a similar degree.  3. APPLICATIONS Interaction networks have three primary applications. The  first, is to automatically generate next-step hints by learning a Hint Policy from a network built from a corpus of student data, and then using that policy and a Hint Template to turn the policy output into human readable next-step hints. The second is to allow instructors to visualize the problem solving behavior of a large group of students. The third is as a source for graph mining and network clustering. Although many of these applications can overlap, such as using net- work clustering to create better visualizations as in [14].  3.1 Hint Policies Interaction networks are a generalization from previous  work of Stamper, Barnes, and Eagle [35] on automatically generating hints based on previously collected student data. One of the primary uses of interaction networks is to gener- ate a Hint Policy, that is, a policy that selects a next-step action for a given state. Table 4 shows an example Hint Template which translates the Action recommended by the Hint Policy into a human readable hint. Hints can be gen- erated from an interaction network by applying the Hint Factory MDP method as presented in [35]. When modeling data from a problem-solving environment into an interaction network, it is important to consider the information that will be contained within the Action (edge), as this is where the Hint Template will draw its information.  3.2 Visualization The interaction network summarizes a large number of  transactions into a representation that is much more acces- sible for instructors for understanding how their students are using a learning environment. Johnson et al. devel- oped a visualization tool called InVis to help instructors  Table 4: Example Hint Template which translates the elements of an Action into 4 levels of hints.  Hint # Hint Text  1 Try to derive [postcondition] working forward 2 Highlight [precondition1] and [precondition2] to  derive it 3 Click on the rule [action ID] 4 Highlight [precondition1] and [precondition2] and  click on [action ID] to get [postcondition]  explore the interaction networks by adding features such as Zoom, Filter, and Details on Demand[22]. Professors using InVis were successful in performing a series of data search- ing tasks, they also able to create hypotheses and test them by exploring the data [22]. InVis was also used to explore the behavior of students in a educational game for Cartesian coordinates, exploration of the interaction networks revealed off task behavior, as well as a series of common student mis- takes, the developers used the information gained from the interaction networks to change some of the user interface to reduce these undesirable behaviors [14].  3.3 Graph Mining Eagle et al. proposed using network clustering techniques  on interaction networks as a method of extracting poten- tial sub-goals from student work [13]. Eagle et al. ex- tended this by leveraging edge-betweenness, a metric that determines edge importance based on the number of short- est paths between all nodes it is on, to extract Approach Maps from a interaction network [12]. The Approach Map method was able to reduce the number of vertices required to describe the interaction networks for the Deep Thought tutor from around 1200 states to around 15 regions (highly connected sub graphs.) The Approach Maps were useful in qualitatively representing the different student approaches to problems. Eagle et al. was also able to show differences in between-group behavior for students, by preforming sta- tistical analysis on each groups representation within the approach map regions. We have included one approach map in figure 8. The vertices in this representation are regions (densely connected sub graphs,) the Hint group (blue) vis- ited several regions along the goal path with greater than expected frequency when compared to the control group. The control group, (which never received hints,) was signif- icantly more likely to visit several regions when compared with the experimental group (who had access to next-step hints). Approach Maps provide a powerful summary of the student behavior within a tutoring system by taking advan- tage of the interaction network model.  4. SUCCESS STORIES In this section we provide examples of environments in  which interaction networks or the precursor MDP method, techniques have been used to either automatically generate feedback for new users based on previously collected data, or for the visualization of student work.  4.1 The Deep Thought Tutor Deep Thought is a propositional logic tutor in which stu-  dents are given a set of propositions and tasked with finding  26    Figure 8: The Approach Map for problem 2.4. Edges and vertices can be read as the number of students who performed action(s) to derive propo- sition(s). Several approaches are revealed, with the hint group strongly preferring to work the problem forwards. The control group is more likely to try approaches from which there are no goal paths.  a conclusion via the manipulation of the givens with basic logic axioms [10]. Deep Thought allows students to work both forward and backwards to solve logic problems.  For example a student starts at state A  D,A  (B  C),D  E, where each premise is separated by a comma. The student performs SIMP (DE), applying simplifica- tion (SIMP) to the premise D  E and derives D. This leads to the resulting-state of A  D,A  (B  C),D  E,D. Errors are actions performed by students that are illegal operations of logic and the tutor. For example: The student is in state AD,A (BC),DE,D. The stu- dent performs the interaction SIMP (A D) in an attempt to derive A. The resulting state would remain A D,A  (B  C),D  E,D; the log-file would mark this edge as an error.  There are several ways to model the state of the proof. The default tutor state would be the problem premises and conclusion, with the steps derived added to the state in the order they were derived. This could be thought of as a direct translation of the directed graph visible in figure 9. We re- lax this definition and use a matching function which treats each state as a partially ordered set, with lexicographically ordered forward-derived steps (resulting from an unordered matching function) listed with commas between them, fol- lowed by a sign, then a lexicographically ordered set of backward derived propositions. Our action matching func- tion compares the axiom, direction (forward or backward), and pre-conditions and post-conditions.  4.2 BeadLoom Game The Culturally Situated Design Tools (CSDT) [15] were  designed to teach mathematics from a cultural context. The BeadLoom Game (BLG) [8] is a game-based extension of the CSDT: Virtual BeadLoom. The BLG and the original CSDT were built to give their users experience and prac- tice with Cartesian coordinates, the intended audience was middle school aged children.  The BLG added game elements in order to increase moti- vation and learning [8]. In the BLG, players place beads on a 41x41 Cartesian grid using six different tools, shown in Ta- ble 5, as well as an undo command. All actions take a color parameter; and there are 12 different colors available. The loom starts empty and once beads are added they cannot be removed unless players uses the undo action. However, beads can be overwritten by future actions. The goal of the game is to create a specific image with these tools. Figure 10 shows an example from the BLG, in this image the player is attempting to draw the image on the left; the player has started by drawing a red rectangle using the rectangle tool. The goal of the BeadLoom Game is to solve each puzzle in the fewest moves possible.  Table 5: Actions Available in the BLG Action Parameters Draw Point X, Y Draw Line X1, Y1, X2, Y2 Draw Rectangle X1, Y1, X2, Y2 Draw Triangle X1, Y1, X2, Y2, X3, Y3 Linear Iteration X, Y, Length, +beads, rows, dir. Triangle Iteration X, Y, stepHeight, +beads, rows, dir. Undo Returns to previous step  The state representation is a 41x41 array containing the 12 color values from the BLG game. Actions are represented  Table 6: Example Play Sequence Start-State Action Result-State  rectangle(-5 1 5 11)  rectangle(1 -5 11 5)  rectangle(-5 -11 5 -1)  rectangle(-11 -5 -6 5)  rectangle(-5 -5 -1 0)  27    by the six available bead-placement tools, as well as the relevant parameters for each tool. Table 6 shows how the BLG data is translated into the network model. The player moves from a blank starting state to a state containing a red square by using the rectangle tool. For the BLG data, order of actions is not preserved in the state description. That is, if the player had reached the same state (same red square) by repeatedly using the point tool, that final state would be considered equal.  4.3 iList The developers of iList (a linked-list tutor) also used the  Hint Factory approach, however their underlying model is based on snapshots of the tutors internal state rather than the transactional logs of user interactions [17]. The authors use the results of the student actions rather than the actions themselves, to define states. An action in iList is a change between two states, and is defined by the modification made between the two states rather than by specific commands from the user.  As a state-matching function, the authors find isomorphic internal representations for the tutor. Any of the tutors internal states which are isomorphic to each other will be mapped to the same state in the interaction network. Simi- larly, the Action Matching Function selected by the authors was based on precisely the start state and end state, regard- less of the actual commands input by the user. Therefore, any move from state A to state B will be matched to the same action in the interaction network.  To evaluate the efficacy of the data-driven feedback, the authors ran an experiment including five conditions; Three versions of iList, one group with human tutors, and one group with an unrelated task. The version of iList that pro- vided data-driven feedback was referred to as iList-3. Of the three versions of iList, iList-3 had the largest average change in pre-to-post test scores, and the authors found these re- sults to be similar to those achieved by a human tutor.  After working with iList-3, the authors continued using data-driven methods to provide feedback, this time in the form of what they called ( proactive feedback) [18]. This feedback was intended to guide the user towards a more de- sirable state, which is analogous to hints provided in other systems using Hint Factory. This tutor was shown to out- perform all previous versions of iList.  4.4 BOTS BOTS is a serious game designed to teach basic program-  ming concepts to novice computer users and programmers [20]. BOTS features open-ended problems with many possi- ble solutions. In order to be able to generate hints for these problems without expert intervention, the developers used data-driven hint generation.  In BOTS, players are tasked with moving robots around a grid-based world, picking up objects and placing them on buttons. Once every button in the level is pressed down, the level is complete. Players control the robots paths by writing programs in a graphical language, using loops and functions as well as simple commands like Step Forward and Turn left. Even the very simplest levels in BOTS have many correct (though not optimal) solutions. For this reason, the developers chose to represent students solutions using programs and output (taken at runtime) rather than each addition or modification of an instruction. The states  Figure 9: Example problem state in the Deep Thought logic tutor.  Figure 10: The BeadLoom Game Interface: the goal of the game is to create the pattern on the left in as few moves as possible. Here the player has started by using the rectangle tool to create the first part of the pattern. Next a player might choose the color blue, and draw a blue rectangle, by entering the coordinates in the panel in the bottom right.  Figure 11: An example problem in BOTS. The goal is to use commands to move the red robot, carrying boxes to their destinations. The players are scored on the number of commands used, with lower scores representing better, more efficient solutions.  28    generated from programs are referred to as codestates while those generated from output are referred to as worldstates.  Using these representations, if two students end up run- ning the same program (or getting the same output) they are considered to be in the same state, regardless of the com- mands they used to get there. These representations were chosen in order to increase the amount of overlap between students, allowing hints to be generated more frequently. For BOTS, the states of the interaction network are states in the world and the positions of each individual object in the world. Analogous objects are strictly identical, so swap- ping the place of two identical blocks, for example, would result in an identical state. The action is the change to the robots program made to result in the new state when the program is run. This means that one interaction in the net- work might consist of several lower-level GUI interactions within the system. For BOTS, the state matching function is implicit based on the ordering of elements in the state representation. The action matching function considers ac- tions to be the same if they have precisely the same previous state and result state, regardless of differences in the pro- gram; however, the differences in programs are retained for the purpose of offering lower-level feedback. The Hint Policy used for the existing work with BOTS is based on the policy used for Deep Thought; however, due to the differences in state representation, the developers have to consider step cost as well as the number of edges when scoring states. This is because it is possible for a student to solve a prob- lem in a single action by solving the problem on their first attempt. However, even without taking that into considera- tion, the developers were able to generate hints that suggest a next-state for the robot, which worked particularly well on paths where previous students had made many attempts.  5. DISCUSSION Despite differences in educational domain, we can model  student-tutor interactions from puzzle games, programming tutors, and propositional logic environments in a common structure. While the educational objectives are different, the problem solving nature of the environments is shared. The potential state-space of many of these domains is infi- nite, however the majority of that space is not likely to be traversed by human walkers. This is related to the idea of preferential attachment and we predict that networks of in- teractions will tend to have a degree distribution that follows power law. It also helps explain the results from Barnes and Stampers cold start [6] where they found that they could start offering automatically generated hints for the major- ity of students even with a small initial sample; this is be- cause the important high degree nodes are likely to be visited within the first few student attempts.  This scale-free nature results in networks that have a small number of vertices containing a large degree, we can use metrics such as assortativity and the S(g) metric of self- similarity to gain a high level understanding of the net- works organization. For example, the BOTS networks tend to have high degree vertices connect to other high degree ver- tices through low degree bridges. For problem solving this means that students move from high choice areas to bridge vertices with low action choice, from which they move into areas of high action choice. The BOTS data is interesting be- cause it shows the effect that different state matching func- tions have on the network topology; the assortativity does  not change greatly, but S(g) increases a moderate amount indicating the higher overall connectedness of the network.  In the DT3 data the trend is toward moving between high degree regions with occasional connections to low degree re- gions, for problem solving this means the students move from high choice states to other high choice states or into bridging regions of low choice states. This makes sense for the domain as each step in the propositional logic proof adds a new proposition to the state; as the student gets closer to the goal there are less reasonable actions to perform. It is interesting to see the differences between DT and DT3, the major difference in the tutors is that DT3 selects next prob- lems for students based on their performance while DT has static problem sequence. The DT3 problem selection results in networks built from samples of less diverse populations of student data. Less diverse bias-walkers explore the same regions of the state space and will have smaller networks overall networks (evidenced by the lower average vertices.) The DT dataset had a static set of problems, when a student became stuck they would have no choice other than to search for a solution or quit the problem. This could be part of the reason why the S(g) score is lower, as the increased walker diversity combined with greater search depth resulted in a network that was less self-similar.  Shared bias in choosing actions results in common paths and solution states, and if different populations of walkers have different bias we can expect to see them have different common paths and states. Interaction networks provide a means for exploring problem solving behavior in rule-using tutors, and looking for between-group differences. Previous work confirmed between-group differences in region visita- tion with approach maps [12], see figure 8. We expect to see that local, region sub-graph, versions of S(g) and assortativ- ity differ between regions of the network. Highly self-similar networks are likely to contain patterns, such as those we dis- cussed in section 2.2. Future work could look to explore the generative processes of these network shapes, we hypothe- size that there are some common network sub-graphs, or mo- tifs, that are shared across tutor domains. We are currently working on modeling more tutoring, game, and simulation environments in order to further explore the differences and similarities between them and discover cross-domain tech- niques to improve student learning.  Several diverse domains have had success using interac- tion networks to model student problem solving, such as puzzle games, propositional logic tutors, and programming tutors. Features of rule-using interactive tutors and student individual differences (bias) in action selection can be com- pared across educational domains by describing the shape of the network. Interaction networks tend to have power law degree distributions, fairly high measures of self-similarity, S(g), scale-free scores. Combining these metrics with assor- tativity reveals the overall shape of the network. Interac- tion networks can be a common language in which to dis- cuss hint generation and student work in rule-using problem solving environments. Even when the theoretical problem- space seems intractable, interaction networks created from observed transaction logs can provide a surprising amount of useful information.  29    6. REFERENCES [1] R. Albert, H. Jeong, and A.-L. Barabasi. Error and  attack tolerance of complex networks. Nature, 406(6794):378382, 07 2000.  [2] V. L. Allis. Searching for solutions in games and artificial intelligence. 1994.  [3] J. R. Anderson. Problem solving and learning. American Psychologist, 48(1):35, 1993.  [4] J. R. Anderson. How can the human mind occur in the physical universe Oxford University Press, New York, NY, USA, 2007.  [5] A.-L. Barabasi and R. Albert. Emergence of scaling in random networks. science, 286(5439):509512, 1999.  [6] T. Barnes and J. Stamper. Toward automatic hint generation for logic proof tutoring using historical student data. Proceedings of the 9th International Conference on Intelligent Tutoring Systems (ITS 2008), pages 373382, 2008.  [7] B. S. Bloom. Taxonomy of Educational Objectives: The Classification of Educational Goals. Taxonomy of educational objectives: the classification of educational goals. Longman Group, New York, 1956.  [8] A. Boyce and T. Barnes. Beadloom game: using game elements to increase motivation and learning. In Proceedings of the Fifth International Conference on the Foundations of Digital Games, FDG 10, pages 2531, New York, NY, USA, 2010. ACM.  [9] A. Clauset, C. R. Shalizi, and M. E. Newman. Power-law distributions in empirical data. SIAM review, 51(4):661703, 2009.  [10] M. J. Croy. Graphic interface design and deductive proof construction. J. Comput. Math. Sci. Teach., 18:371385, December 1999.  [11] S. N. Dorogovtsev and J. F. Mendes. Evolution of networks. Advances in physics, 51(4):10791187, 2002.  [12] M. Eagle and T. Barnes. Exploring differences in problem solving with data-driven approach maps. Proceedings of the Seventh International Conference on Educational Data Mining, 2014.  [13] M. Eagle, M. Johnson, and T. Barnes. Interaction Networks: Generating High Level Hints Based on Network Community Clustering. educationaldatamining.org, pages 14.  [14] M. Eagle, M. Johnson, T. Barnes, and A. K. Boyce. Exploring player behavior with visual analytics. In FDG, pages 380383, 2013.  [15] R. Eglash, A. Bennett, C. ODONNELL, S. Jennings, and M. Cintorino. Culturally situated design tools: Ethnocomputing from field site to classroom. American anthropologist, 108(2):347362, 2006.  [16] R. Fikes and N. Nilsson. Strips: a new approach to the application of theorem proving to problem solving. Artificial Intelligence, 1971.  [17] D. Fossati, B. Di Eugenio, S. Ohlsson, C. W. Brown, L. Chen, and D. G. Cosejo. I learn from you, you learn from me: How to make ilist learn from students. In AIED, pages 491498, 2009.  [18] D. Fossati, B. Eugenio, S. Ohlsson, C. Brown, and L. Chen. Generating proactive feedback to help students stay on track. In V. Aleven, J. Kay, and J. Mostow, editors, Intelligent Tutoring Systems, volume 6095 of Lecture Notes in Computer Science,  pages 315317. Springer Berlin Heidelberg, 2010.  [19] D.-I. O. Hein, D.-W.-I. M. Schwind, and W. Konig. Scale-free networks. Wirtschaftsinformatik, 48(4):267275, 2006.  [20] A. Hicks. Creation, evaluation, and presentation of user-generated content in community game-based tutors. In Proceedings of the International Conference on the Foundations of Digital Games, pages 276278. ACM, 2012.  [21] M. Johnson, M. Eagle, J. Stamper, and T. Barnes. An algorithm for reducing the complexity of interaction networks.  [22] M. W. Johnson, M. Eagle, and T. Barnes. Invis: An interactive visualization tool for exploring interaction networks.  [23] D. Jonassen. Toward a design theory of problem solving. Educational Technology Research and Development, 48(4):6385, 2000.  [24] L. Li, D. Alderson, J. C. Doyle, and W. Willinger. Towards a theory of scale-free graphs: Definition, properties, and implications. Internet Mathematics, 2(4):431523, 2005.  [25] F. J. Massey Jr. The kolmogorov-smirnov test for goodness of fit. Journal of the American statistical Association, 46(253):6878, 1951.  [26] T. Murray. Authoring intelligent tutoring systems: An analysis of the state of the art. International Journal of Artificial Intelligence in Education (IJAIED), 10:98129, 1999.  [27] A. Newell, H. A. Simon, et al. Human problem solving, volume 104. Prentice-Hall Englewood Cliffs, NJ, 1972.  [28] M. E. Newman. Assortative Mixing in Networks. Physical Review Letters, 89(20):208701, Oct. 2002.  [29] M. E. Newman. Power laws, pareto distributions and zipfs law. Contemporary physics, 46(5):323351, 2005.  [30] B. Peddycord III, A. Hicks, and T. Barnes. Generating hints for programming problems using intermediate output.  [31] M. Piraveenan, K. S. K. Chung, and S. Uddin. Assortativity of links in directed networks. Proceedings of Fundamentals of Computer Science, 2012.  [32] S. Rabin. Introduction to game development. Cengage Learning, 2010.  [33] H. M. Selim. Critical success factors for e-learning acceptance: Confirmatory factor models. Computers and Education, 49(2):396  413, 2007.  [34] J. Stamper, T. Barnes, L. Lehmann, and M. Croy. A pilot study on logic proof tutoring using hints generated from historical student data. Proceedings of the 1st International Conference on Educational Data Mining (EDM 2008), pages 197201, 2008.  [35] J. Stamper, M. Eagle, T. Barnes, and M. Croy. Experimental evaluation of automatic hint generation for a logic tutor. International Journal of Artificial Intelligence in Education (IJAIED), 22(1):318, 2013.  [36] K. VanLehn. The relative effectiveness of human tutoring, intelligent tutoring systems, and other tutoring systems. Educational Psychologist, 46(4):197221, 2011.  30      