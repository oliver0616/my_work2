LAK17 Hackathon - Getting the right information to the  right people so they can take the right action   Adam Cooper  Tribal Group  Sheffield, UK   adam.cooper@tribalgroup.com     Tanya Dorey-Elias  Thompson Rivers University   Kamloops, BC, CA  telias@tru.ca      Alan Berg  ICT Services   University of Amsterdam, NL  a.m.berg@uva.nl      Niall Sclater  Jisc   Bristol, UK  niall.sclater@jisc.ac.uk     Kirsty Kitto   Queensland University of Technology  Brisbane, AU   kirsty.kitto@qut.edu.au     ABSTRACT  The hackathon is intended to be a practical hands-on workshop  involving participants from academia and commercial  organizations with both technical and practitioner expertise. It  will consider the outstanding challenge of visualizations which  are effective for the intended audience: informing action, not  likely to be misinterpreted, and embodying contextual  appropriacy, etc. It will surface particular issues as workshop  challenges and explore responses to these challenges as  visualizations resting upon interoperability standards and API- oriented open architectures.   CCS Concepts   Human-centered computing  Visualization  Information  systems  Information systems applications  Data mining   Applied computing  Education  Learning management  systems   Keywords  Hackathon; visualization; interoperability; actionable insights;  contextual appropriacy; open learning analytics   1. WORKSHOP BACKGROUND  This proposal builds on successful workshops organized at the  two previous LAK conferences by Jisc and Apereo, two leading  organizations promoting the development of open architectures,  interoperable solutions, good practice, and effective  deployments for learning analytics. The LAK16 workshop in  Edinburgh attracted 32 participants from both commercial  organizations and the academic world, with both technical and  practitioner expertise represented.   The workshop will take the form of a hackathon. As such, it  will, as previous events did, engage expertise from different  stakeholders - educators, developers, and data scientists - to  build knowledge through practical activities with coding and  data wrangling being a significant component of the activities  involved. Experience of previous hackathons shows that   practical activity helps to promote a greater understanding of  what lies in the intersection between what different stakeholders  understand what learning analytics means, and helps to provide  a productive platform for negotiating the trade-off between what  is desirable and feasible in practice.   The first hackathon, in 2015, focused on the Apereo1 Open  Dashboard, with data sourced from an xAPI [3] Learning  Record Store. It illustrated how the concept of an Open Learning  Analytics3 architecture was developing but also shone light on  some structural weaknesses: shortage of usable data for  demonstration/development/quality-assurance/etc, and  something of a gulf between the conceptions held by different  stakeholders as to what a learning analytics dashboard would  contain. Subsequent work by workshop organizers has begun to  develop repeatable methods for generating synthetic data to help  address the first weakness [1]. The second has been the topic of  ongoing research (vide infra).  The second hackathon, in 2016, continued to explore the  practicalities of Open Learning Analytics. Using Jiscs emerging  Learning Analytics architecture [8] as a reference point, with  some data generated using the synthetic data methods which the  first hackathon stimulated, the participants in the hackathon:  scrutinized Jiscs interoperability recipes, tested the  interoperability of learning record stores, learning analytics  processors, and dashboards, and assessed the learning analytics  standards landscape. The hackathon had a lasting effect, with  numerous improvements to Jiscs interoperability recipes, and a  strong message from the LAK community in favor of the greater  integration of emerging learning analytics standards - xAPI and  Caliper - contributing to the cooperation of ADL and IMS from  mid-2016.   For the third hackathon, we propose to build upon three assets:  previous workshops, recent research, and recently-developed  software. The first comprises the previous two LAK hackathons,  the 2015 LAK Workshop Visual Aspects of Learning  Analytics [2], and the 2016 LAK Workshop Data Literacy for  Learning Analytics [9]. We will set the scene for the workshop  using recent research on actionable analytics [6], student  feedback [4], and embedding learning analytics in pedagogic  practice [5]. Finally, we will introduce Jiscs student app2, which                                                                        1 Apereo Foundation, https://www.apereo.org/content/about  2 https://analytics.jiscinvolve.org/wp/category/student-app/   Permission to make digital or hard copies of part or all of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. Copyrights  for third-party components of this work must be honored. For all other  uses, contact the Owner/Author.   Copyright is held by the owner/author(s).  LAK '17, March 13-17, 2017, Vancouver, BC, Canada  ACM 978-1-4503-4870-6/17/03.  DOI: http://dx.doi.org/10.1145/3027385.3029435     is being piloted with students across the UK after extensive  consultation and design activities.   The workshop will address the outstanding challenge of  visualizations which are effective for the intended audience:  informing action, not likely to be misinterpreted, and  embodying contextual appropriacy, etc. It will make space to  explore, challenge the status quo, and sketch ideas for use by  learners and teachers, considering the interplay between their  agency and the learning analytics in use. An additional  distinctive character for the workshop is that it will emphasize  the relationship of this broad question to APIs and  interoperability standards, as critical aspects of application  outside the researchers laboratory, building on the vision of the  SoLAR Open Learning Analytics initiative3.   2. WORKSHOP OBJECTIVES AND  INTENDED OUTCOMES  The workshop theme will be the role of visualizations to support  getting the right information to the right people so they can  take the right action. In addressing this theme, the workshop  will continue to be underpinned by two technological facets:    identification of the relationship to interoperability  standards, open architectures and APIs; and    promotion of open and synthetic data.  Within this theme, emphasis, but not exclusive attention, will be  on student-facing solutions such as apps, dashboards and  personal learning record stores. The workshop participants will  determine the detailed objectives of each working group,  stimulated by outlines of challenges posed by the organizers and  contributed by participants at the start of the workshop. The  challenges posed by the organizers are:    Traffic-light indicators of risk and engagement scores are  intuitively appealing; but how can we create visualizations  for student support professionals which convey uncertainty  about the results and reveal more about risk to allow more  informed action    Which ways of communicating the results of learning  analytics to students - without intermediation through a  professional - are desirable, effective, and free from  unacceptable side-effects    While there has been considerable research on learning  analytics for Self-Regulated Learning (SRL) [7], this not  been in relation to mainstream institutional systems. How far  can we go with systems and data that are generally in use  What are the implications for interoperability standards  development    How do we envisage surfacing the contents of a personal  learning record store These will enable individuals to  maintain a high degree of control and ownership over their  learning records as they progress through different stages of  their education and employment. What are the limitations in  current software and APIs   Whatever the topic chosen by the working groups, the  overarching intention of the hackathon is to:    Stimulate greater understanding of the space in the  intersection between the expertise of educational  practitioners, software developers/engineers, and data  scientists. In particular to provide an opportunity for                                                                        3 https://solaresearch.org/initiatives/ola/   participants to gain insight into the way in which the  contexts and the intended purposes of learning analytics  foreshadow desirable methods of presenting the results of it.    Identify and record priorities and evidence for  interoperability standards/recipes development.    Identify development opportunities for existing APIs, to  diverse components in the learning analytics architectural  landscape, to access the right data in efficient ways.    Create example visualizations in response to the workshop  challenges, based on realistic systems/data and with input  from people with diverse expertise.   The organizers will make available data and API-enabled  learning analytics software to support the hackathon, and will  solicit similar contributions from other parties. Workshop  outputs will be openly available in a GitHub repository4.   3. ACKNOWLEDGMENTS  We would like to acknowledge the Apereo Foundation and Jisc,  whose continued support has helped to instigate and sustain  LAK Hackathon activity.   4. REFERENCES  [1] Berg, A.M. et al. 2016. The Role of a Reference Synthetic   Data Generator within the Field of Learning Analytics.  Journal of Learning Analytics. 3, 1 (2016), 107128. DOI:  http://dx.doi.org/10.18608/jla.2016.31.7   [2] Duval, E. et al. eds. 2015. VISLA 2015, Visual Aspects of  Learning Analytics. CEUR Workshop Proceedings 1518.   [3] Experience API v1.0.1. 2013. Retrieved January 24, 2017  from http://www.adlnet.gov/wp- content/uploads/2013/10/xAPI_v1.0.1-2013-10-01.pdf.   [4] Khan, I. and Pardo, A. 2016. Data2U: scalable real time  student feedback in active learning environments. In Proc.  of the Sixth Int. Conf. on Learning Analytics & Knowledge  (LAK '16). ACM, New York, NY, USA, 249-253.   [5] Kitto, K. et al. 2016. Incorporating student-facing learning  analytics into pedagogical practice. In Proceedings of the  33rd Annual ASCILITE Conference (Ascilite16). Adelaide,  S.A., Australia.   [6] Pardo, A. et al. 2016. Generating actionable predictive  models of academic performance. In Proc. of the Sixth Int.  Conf. on Learning Analytics & Knowledge (LAK '16).  ACM, New York, NY, USA, 474-478.    [7] Roll, I. and Winne, P.H. 2015. Understanding, evaluating,  and supporting self-regulated learning using learning  analytics. Journal of Learning Analytics. 2, 1 (2015), 712.  DOI: http://dx.doi.org/10.18608/jla.2015.21.2   [8] Sclater, N. et al. 2015. Developing an open architecture for  learning analytics. EUNIS Journal of Higher Education IT -  Issue 2015:4. Retrieved January 24, 2017 from  http://www.eunis.org/download/2015/papers/EUNIS2015_s ubmission_61.pdf.    [9] Wolff, A. et al. 2016. Data literacy for learning analytics.  In Proc. of the Sixth Int. Conf. on Learning Analytics &  Knowledge (LAK '16). ACM, New York, NY, USA, 500- 501. DOI: http://dx.doi.org/10.1145/2883851.2883864                                                                         4 This will follow previous hackathon practice illustrated by the   2016 Hackathon GitHub repository.  https://github.com/AlanMarkBerg/hack-at-lack16     