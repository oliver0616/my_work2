Exploring the relation between Self-regulation, Online  Activities, and Academic Performance: A case study   Abelardo Pardo1  Abelardo.pardo@sydney.edu.au   Feifei Han2  Feifei.han@sydney.edu.au   Robert A. Ellis2  Robert.ellis@sydney.edu.au  1School of Electrical and Information Engineering  2Institute for Teaching and Learning   The University of Sydney, NSW 2006, Australia     ABSTRACT   The areas of educational data mining and learning analytics focus  on the extraction of knowledge and actionable items from data  sets containing detailed information about students. However, the  potential impact from these techniques is increased when properly  contextualized within a learning environment. More studies are  needed to explore the connection between student interactions,  approaches to learning, and academic performance. Self-regulated  learning (SRL) is defined as the extent to which a student is able  to motivationally, metacognitively, and cognitively engage in a  learning experience. SRL has been the focus of research in  traditional classroom learning and is also argued to play a vital  role in the online or blended learning contexts. In this paper, we  study how SRL affects students online interactions with various  learning activities and its influence in academic performance. The  results derived from a naturalistic experiment among a cohort of  first year engineering students showed that positive self-regulated  strategies (PSRS) and negative self-regulated strategies (NSRS)  affected both the interaction with online activities and academic  performance. NSRS directly predicted academic outcomes,  whereas PSRS only contributed indirectly to academic  performance via the interactions with online activities. These  results point to concrete avenues to promote self-regulation  among students in this type of learning contexts.   Categories and Subject Descriptors   Applied computing~Computer-assisted instruction  Applied  computing~E-learning   General Terms  Measurement, Performance, Human Factors, Theory.   Keywords  Learning analytics, Self-regulation, Higher education, SEM.   1. INTRODUCTION  A significant portion of the Higher education sector has  experienced a rapid change through the adoption of Internet and  Web-based technologies as an integral part of the student learning   experience. This change has resulted in the widespread use of  blended (or hybrid) learning contexts. Advances in research have  redefined the boundaries of online learning, which is now seen as  learning that is distributed over time and place using various  technologies, engaging students in multiple forms of interaction  [14]. Nowadays, students in higher education institutions are  participating in learning experiences that go beyond sitting in a  traditional classroom context. Blended learning is not only  quickly filling the new educational demand, but is also providing  new ways for student engagement and to promote their interests  and motivation [13, 15, 30]. Research has indicated that students  who attend hybrid courses which combine online and face-to-face  delivery performed better and perceived learning being more  effective than students in traditional face-to-face classroom  learning (e.g., [30]). However, researchers argued that effective  online learning often requires students to be self-disciplined and  self-regulated [11, 21, 24]. These factors may be equally effective  when translated to blended learning contexts.  Several research areas related to education have tried to avoid the  one size fits all problem proposing multiple techniques to adapt a  learning experience to the needs of each learner. The areas of  learning analytics and educational data mining approach this  problem using comprehensive collections of data about students  and the use of algorithms to derive the knowledge and insight to  help understand and improve their overall experience [5]. But  data does not speak by itself, and pedagogical and epistemological  assumptions need to be taken into account to fully understand  how to improve a learning experience [26]. The research  community has identified the need to bring multiple disciplines  with different conceptions about learning in what it has been  defined as the middle space, in order to maximize the potential of  learning analytics solutions [43]. However, there is a need for  more studies that combine research methodologies from these  areas. This paper attempts to explore further this middle space  through a study to explore the relationship between self-regulated  learning, digital traces of student interaction with online activities,  and academic performance.  The rest of the document is organized as follows. Section 2  describes the related work in the areas of self-regulated learning,  learning analytics, and the combination of data and educational  theories. Section 3 describes the methodology used for the case  study. Section 4 presents the results obtained in the study. Section  5 includes a discussion of the main consequences of these results.  The paper concludes with a set of conclusions and future avenues  to explore described in Section 6.   2. RELATED WORK  The widespread use of Learning Management Systems in higher  education institutions has made large quantities of data traces   Permission to make digital or hard copies of all or part of this work for  personal or classroom use is granted without fee provided that copies  are not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. Copyrights  for components of this work owned by others than the author(s) must be  honored. Abstracting with credit is permitted. To copy otherwise, or  republish, to post on servers or to redistribute to lists, requires prior  specific permission and/or a fee. Request permissions from  Permissions@acm.org.  LAK '16, April 25 - 29, 2016, Edinburgh, United Kingdom   Copyright is held by the owner/author(s). Publication rights licensed to  ACM.  ACM 978-1-4503-4190-5/16/04$15.00   DOI: http://dx.doi.org/10.1145/2883851.2883883     available. Data is now being obtained from virtual appliances,  social networks, learning management system or enrolment  processes. This data was soon identified as a potential source of  information to improve the quality of a learning experience [36,  47]. This detailed information has the potential of facilitating the  understanding of how students learn [5, 26, 29]. The abundant log  data recorded by technologies offers insightful information as to  students interactive patterns with a wide range of online learning  activities [29]. There are numerous studies in this area reporting  relations between academic performance and information derived  from data traces [32].  Data mining techniques have been used to discover relationships  among factors in a learning experiences to, for example, create  models to predict student academic performance (e.g., [1, 16-17,   41] or detecting students at risk [44].    2.1 Combining educational data mining,  analytics and educational theories   However, relying solely on low level data capturing the  interaction of students with online activities reveals partial  information and does not provide insight about the underlying  problems while students learn [42]. To address this limitation,  researchers in learning analytics and educational data mining have  identified the need for a synergistic approach combining  educational data mining techniques and other fields such as  educational psychology, curriculum and pedagogy, and sociology  in education. The objective is to better identify which factors  facilitate or hinder effective behavior in students while they  interact in a learning environment (e.g., [42-43]). The study  described in this paper explores how data self-reported by  students about their self-regulation strategies can be combined  with traces of interaction with online activities to predict  academic performance.   2.2 Self-regulated learning  Self-regulation is defined as the extent to which students are  motivationally, metacognitively, and cognitively engaged in their  learning processes [12, 52]. There are various models for self- regulated learning (SRL), each placing emphasis in different  aspects (e.g., [3, 8, 12, 37, 48, 53]). For instance, Winne places  the focus on the cognitive aspect of SRL, whereas the model  proposed by [33] is established based on sociocultural  perspectives. Some researchers perceive SRL as an event-based  phenomenon (e.g., [2, 4, 22]), whereas others view SRL as a  progression through metacognitive monitoring and control (e.g.,  [48, 51]). Adopting a social-cognitive perspective, Duncan and  McKeachie argued that SRL should be treated as dynamic and  contextually bound [15], wherein SRL behaviors are not a static  trait of students per se. This means that students may change their  motivation and SRL behavior and strategy depending on the  nature of the course, its structure and the proposed learning  activities. In this paper we have adopted this conceptualization of  SRL. In other words, we assume that the perception that students  have of the learning environment and task characteristics (external  environment) together with their own state of mind (internal  environment) may either facilitate or hamper their use of self- regulating strategies [37-39]. Even though SRL encompasses the  areas of motivation, cognition, behavior, and context, this paper  explores how students use self-regulated strategies as a whole.  Self-regulation of cognition and behavior forms an essential part  of the learning processes. Past research has consistently shown   that students self-regulated learning behaviors affect their level of  academic success [6, 31, 55, 57]. Able self-regulated learners are  often described as actively setting learning goals, employing  effective and efficient learning strategies, making appropriate  learning plans, adapting their approach  from task to task,  monitoring their learning persistently, and making adjustments  when needed [10, 35, 40, 54]. While there are numerous  publications exploring the design of online learning activities to  facilitate self-regulated student behavior (e.g., [14, 19, 27, 46],  fewer studies investigate the self-regulation strategies when  combined with detailed data about student t interactions with  online learning activities, and their academic performance. Winne  [51] identified the need to adopt a wider lens to SRL specially  when technology is used to support a learning experience where  students make choices and decisions about which tools they are  going to use and how are they going to use them.  This paper presents the results of a study that explores precisely  this type of relation in the context of a first year engineering  course. Students are given set online resources that requires them  a certain level of interaction. The study explores the relationship  between their agency, the type of interactions with the online  environment, and their academic performance.   3. METHOD  3.1 Research Context  The study was conducted in a semester-long course on computer  system for first year engineering students. By the end of the  course, students should be able to design, build and configure an  electronic system, demonstrate their understanding of how  computers work, and write reports about the design process and  its results. In addition to these skills, the course has been designed  to promote independent inquiry abilities, effective  communication, information literacy, and an understanding of  ethical issues in the profession. The course was designed as a  blended learning experience consisting of a face-to-face  component and online learning component, both of them with  their corresponding assessments. The face-to-face learning part  involved a weekly two-hour lecture, a weekly two-hour tutorial,  and a weekly three-hour laboratory session. The online learning  component was required to be completed by students in their own  time through a custom-designed learning management system able  to trace, monitor, and record all the online learning activities by  students unique login identification number. The online activities  were designed with an estimated total dedication of 4 hours per  week. An average of seven activities per week were scheduled  throughout the semester. This portion of the course was assessed  as 15% (1.5% per week) of the overall course mark.   3.2 Participants  The study was conducted with 145 (n = 145) first year students  who were studying a four year Bachelor of Engineering Degree in  a research-intensive university in Australia.    3.3 Instrument  Three methods were used to collect the data in the study.   3.3.1 Self-regulated strategy use questionnaire  Students were asked to answer the questions included in the Self- Regulation Section of the Motivated Strategies for Learning  Questionnaire (MSLQ, [38]). The data was extracted from nine  items answered on a 7-point Likert scale, with 1 indicating never     true of me and 7 representing always true of me. Three of the  nine items were negatively worded. The results were collected  during the first week of the course.   3.3.2 Interactions with online activities  The course required students to interact with an online  environment providing resources such as videos, multiple choice  questions, summative and formative assessment, etc. The learning  management system hosting these resources recorded the  interaction of the students while learning. At the end of the  semester the accumulated number of events was obtained for each  student in the following categories:    Access to any HTML page of the course material  (Resource).    Expand/Collapse of a section within a page. Some pages  had headings with the content collapsed that was exposed  when clicking in the title (Col-Exp).    Events while using the embedded videos: play, pause,  begin, and end a video (Video)    Events while answering the multiple choice questions next  to the videos (VMCQ).    Events while answering the multiple choice questions in the  course notes (MCQ).    Access to a page containing a dashboard illustrating the  level of interaction with the course activities (Dboard).   3.3.3 Academic performance  The academic performance was obtained from the final course  mark. This mark was calculated by taking into account the  following assessments: online lecture preparation activities (10%),  online tutorial preparation and participation (10%), written report  about laboratory session (5%), collaborative project (15%), mid- term examination (20%), and final examination (40%), on a scale  from 1 to 100. The Mean (M) of the final mark was 65.50 with a  Standard Deviation (SD) of 16.12.   3.4 Procedure  After ethics approval was obtained for the study, we obtained the  written consent for the voluntary participation in the first session  of the semester. The collection of the data related to the  interaction with the online activities was collected all throughout  the semester. Students were required to submit partial work to be  assessed every week. The data about academic performance was  collected upon course completion.   3.5 Data Analysis  The data analysis has been carried out in five stages. The first  stage included Exploratory Factor Analysis (EFA) of the data  obtained from the Self-regulation strategy use questionnaire  (SRSUQ). Principal Component Analysis was used followed by  varimax rotation to examine the factor structure of the results.  Following suggestions of [18], we deleted from the result those  items whose coefficients were < .40 within a factor and those with  high multiple coefficients loaded across factors. In the second  stage we examined the reliability of the retained scales.  The third  stage included the use of correlation analysis to see the  relationship between self-regulated strategy use, the interaction  with the online activities, and academic performance at the  variable level. In the fourth stage we first conducted a hierarchical  cluster analysis to identify subgroups of participants where the   similarities and the differences in their self-regulated strategy use  and academic performance could be maximized. On the basis of  the identified clusters, one-way ANOVA was performed to see  whether learners in different clusters exhibit different patterns for  interactions with online activities. This allowed us to examine the  relationship between self-regulated strategy use, online learning  activities, and academic performance at the student level. In the  final stage of the study we constructed a structural equation model  (SEM) to examine the predictions of self-regulated strategy use,  tool use, and academic performance.    4. RESULTS  4.1 EFA and reliability of the scales for self- regulated strategy use   The results of the EFA for the SRSUQ are displayed in Table 1.  The obtained rotated factor loadings translated in the selection of  seven of the nine items from the original questionnaire. The final  two factors included 4 items in the Positive Self-regulated  Strategy (PSRS) scale, and 3 items in Negative Self-regulated  Strategy (NSRS) scale. The eigen-values of the PSRS and the  NSRS were 2.07 and 1.96 respectively, explaining 29.51 % and  27.94% of the total variance respectively. The values of  Cronbachs alpha were .68 and .72 for the PSRS and the NSRS,  implying that the two scales were reliable.   Table 1: Results of EFA for the SRSUQ   Scales  (Cronbach) Item Description   Rotated  factor   loadings   PSRS  (.68)   I ask myself questions to make sure I  know the material I have been  studying.   .63    I work on practice exercises and  answer end of chapter questions even  when I dont have to.   .74    Even when study materials are dull  and uninteresting, I keep working  until I finish.   .77    I work hard to get a good grade even  when I dont like a class. .69    NSRS  (.72)   When work is hard, I either give up or  study only the easy parts.  .73   I often find that I have been reading  for class but dont know what it is all  about.    .84   I find that when the teacher is talking  I think of other things and dont really  listen to what is being said.    .81   Values less than .40 removed; KMO: .83   4.2 Correlation analysis  The results of correlation analyses are shown in Table 2. While  PSRS did not significantly relate to student academic performance  (r = -.02, p = .85), the NSRS significantly and negatively  associated with academic performance (r = -.20, p < .01).  However, the PSRS showed significant and positive association  with three of the events registered in the online environment,  namely Dboard (r = .18, p < .05), Expand/Collapse-of sections in  the course notes (r = .21, p < .05), and Col-exp (r = .23, p < .01).  This association means that the more students adopted positive  self-regulated strategies in the course, the more likely they used     the above three online activities. In contrast, the correlations  between NSRS and the access to online activities turned to be  non-significant. Additionally, academic performance was found to  be positively related to most of the indicators derived from online  interactions, including Dboard (r = .24, p < .01), Col-exp (r = .35,  p < .01), Resource (r = .44, p < .01), and MCQ (r = .28, p < .01).  This positive correlation suggests that the more frequently an  individual engaged with these learning activities, the more likely  they were to obtain a higher course score in the course. The  significant and positive correlation between PSRS and online  activities, and the positive relation between these and academic  performance may indicate that the PSRS could contribute to the  academic performance via the use of online tools. This means that  it is possible that the PSRS contributed to the academic  performance indirectly rather than directly. The relation between  these factors was used to build a structural equation model as  discussed in Section 4.4.   Table 2: Correlation analysis    PSRS NSRS AP  NSRS .13 --- ---  AP -.02 -.20** ---  D-board .18* -.03 .24**  Col-Exp .21* .15 .35**  Resource .23** .10 .44**  Video .14 -.03 .14  MCQ .17 -.01 .28**  VMCQ .06 -.11 .14  Notes: ** p < .01, * p < .05,    4.3 Cluster and ANOVA analyses  A hierarchical cluster analysis using Wards method was  conducted using as criteria PSRS, NSRS, and the academic  performance. The purpose of this analysis is to see if it is possible  to identify subgroups of students with differences in their self- regulated strategy that also have different academic performance.  The cluster analysis resulted in three solutions: two, three, and  four clusters. Using the increasing value of the squared Euclidean  distance between clusters, a two-cluster solution was sought, and  the results of ANOVA are presented in Table 3.    As it can be seen, the 145 students were classified into a group of  86 High Self-regulated and High-performing students (cluster 1),  and a group of 59 Low Self-regulated and Low-performing  students (cluster 2). The students in cluster 1 differed from those  in cluster 2 in terms of the PSRS use (F (1, 144) = 90.20, p < .01,  2 = .39), NSRS use (F (1, 144) = 37.20, p < .01, 2 = .21), and  the academic performance (F (1, 144) = 24.60, p < .01, 2 = .15).  To be more specific, the High Self-regulated and High-performing  students reported adopting more of the positive self-regulated  strategies (M = 0.51), less of the negative self-regulated strategies  (M = -0.38), and achieved a relatively higher final score (M =  0.32) than the Low Self-regulated and Low-performing students.  On the other hand, the Low Self-regulated and Low-performing  students adopted a less positive self-regulated strategy (M = - 0.75), more negative self-regulated strategy (M = 0.55), and their  academic performance was relatively poorer (M = -0.46).   Based on the cluster membership, a series of additional ANOVA  were performed to examine whether students in the two clusters  had differed interaction with the online activities. The results  reported from the sixth row in Table 3 reveal that the two groups  of students had significant differences in the frequencies of   interactions with five of the seven online activities. The factors  Dboard (F (1, 144) = 9.82, p < .01, 2 = .06), Col-Exp (F (1, 144)  = 5.76, p < .05, 2 = .04), Resource (F (1, 144) = 10.47, p < .01,  2 = .07), MCQ (F (1, 144) = 7.92, p < .01, 2 = .05), and Exercise  (F (1, 144) = 15.17, p < .01, 2 = .10) had statistically significant  differences between the clusters. The two remaining factors Video  and VMCQ did not have a statistically significant difference  among clusters. The High Self-regulated and High-Performing  students interacted significantly more frequently with those five  activities than the students with Low Self-regulated and Low  performance. These results demonstrate that there is a relationship  between the use of a self-regulation strategy, academic  performance, and interactions with online activities at the level of  individual students.   Table 3: Summary statistics of the two-cluster solution   Variable High (86) Low (59) F p 2   Mean Mean      PSRS 0.51 -0.75 90.20 .00 .39  NSRS -0.38 0.55 37.20 .00 .21   AP 0.32 -0.46 24.60 .00 .15  D-board 0.21 -0.30 9.82 .00 .06  Col-Exp 0.16 -0.24 5.76 .02 .04  Resource 0.22 -0.31 10.47 .00 .07   Video 0.12 -0.17 2.89 .09 .02  MCQ 0.19 -0.28 7.92 .01 .05   VMCQ 0.11 -0.17 2.74 .10 .02  Notes: High = High Self-regulated and High Performing learners,  Low = Low Self-regulated and Low Performing learners.   4.4 Structural Equation Model  To examine how PSRS, NSRS, and the interactions with online  activities contribute to a student academic performance, we  constructed a SEM. The three variables in the model were derived  from PSRS, NSRS, and the interaction with online activities. The  PSRS and NSRS variables were constructed by computing the  mean of each scale. The variable Activity was constructed by  aggregating the frequencies of interactions with all the activities.  The resulting model is shown in Figure 1.      Figure 1: The resulting structural equation model   The following criteria were used to evaluate the fit of the SEM. A  non-significant chi-square value led to acceptance of the null  hypothesis that the model fits the population [20]. The goodness- of-fit statistics were also consulted for model evaluation. We used  the Tucker-Lewis Index (TLI, [45]), the Comparative Fit Index  (CFI, [7]), and the root mean square error of approximation  (RMSEA, [9]) as our primary goodness-of-fit statistics. The  values of TLI and CFI are in the range from 0.00 to 1.00, with  values greater than .90 as an acceptable fit to the data [23]. In  terms of the RMSEA, according to [9], a value of .06 and below is  indicative of a good fit between the hypothesized model and the  observed data [9, 23].      The results of the SEM revealed that our data fit the hypothesized  model:  (2) = 0.95, p = .62, CFI = 1.00, TLI = 1.06, RMSEA =  .05. The resulting paths are shown in Figure 1. As it can be seen,  the NSRS has a significant and negative path to the academic  performance ( = -.18, p < .05), whereas the interaction with  online activities has a significant and positive path to students  academic performance ( = .40, p < .01). At the same time, PSRS  significantly and positively predicted interaction with online  activities ( = .27, p < .01). The model also shows that the PSRS  has significant and positive indirect effect on the academic  performance ( = .11, p < .01). Even though the direct  contribution of PSRS to the academic performance is not high, it  has a more significant indirect contribution through the  interactions with online activities.    5. DISCUSSION  This study has investigated the relationship between students  self-regulated strategy use, interactions with online learning  activities, and academic performance in a first year engineering  course. The results showed that while PSRS did not show a  significant correlation with academic performance, NSRS did  have a negative relation with academic performance. Additionally,  the academic performance was found to be positively associated  with frequencies of interactions with a number of online learning  activities. The cluster analysis further identified two groups of  students based on their self-reported use of self-regulated strategy  and academic performance. The students in the High Self- regulated and High performing group adopted more PSRS, less  NSRS, obtained higher final marks in the course, and tended to  interact more frequently with online learning activities. The  results are the opposite for the Low Self-regulated and Low- performing cluster. The results derived from the structural  equation model show indicate that while the NSRS negatively  contributed to the academic performance, and the interactions  with online activities positively predicted the students final  course mark. Additionally, the PSRS had an indirect but  significant path to the academic performance. These results are  consistent with previous research in SRL that self-regulated  learning behavior is a significant factor affecting students  learning outcomes [6, 31, 55, 57]. We found, however, that PSRS  and NSRS contributed to the learning outcomes differently. While  NSRS was a significant factor, which directly predicted  performance, PSRS only affected students online learning  behaviors directly, and indirectly impacted students academic  performance. These results may mean that interventions that target  NSRS could possibly enhance students learning outcomes, but  this postulation needs to be empirically tested via a longitudinal  design or intervention studies. The interactions with online  learning activities were also found to be a significant contributor  to students final course marks, suggesting that quantity of  engagement with online learning is important in this blended  learning context.  Although it is difficult to point out directions of causality between  PSRS and interactions with online activities with our cross- sectional data, it is plausible that the features of online learning  activities are able to foster an increased level of self-regulated  learning and enable learners to become more metacognitively  aware of learning processes (e.g., [27, 28, 50]). It is also possible  that learners who tend to adopt more positive self-regulated  strategies in learning also have a tendency to interact with online  learning activities more frequently. One way to identify the  direction of causality would be through a well-conceptualized   intervention study. Researchers may compare the interactions of  online activities among four groups of learners: a control group of  students interacting with normally designed online activities; a  control group of students interacting with online activities whose  features are designed to encourage SRSU; an experiment group of  students who will receive instructions on how to improve self- regulated strategy use interacting with normally designed online  activities; and an experiment group of students interacting with  online activities whose features are designed to encourage SRSU.  Only through this kind of experiment, may we know the casual  relation between SRSU and online learning.   The results of the study offer some practical implications for  university lecturers to consider. According to our results, lecturers  should consider strategies to reduce students negative self- regulated strategy use and promote positive self-regulated strategy  use. As argued by [29], students need to be made aware of self- regulated strategies, and initially use them in guided and  structured manner. (p. 1303). These authors further identified  three aspects for self-regulated strategies to be built in the  learning environment in order to enhance students self- regulation, namely: activities for self-regulation, resources for  self-regulation, and supports for self-regulation. At the level of  activities, those activities, which are able to stimulate learners  reflections on the process of problem-solving are believed to  enhance learners self-regulated learning [8]. Therefore,  instructors may use reflective journals or diaries as part of  normative assessment for learners to reflect upon their learning  processes. At the level of resources, McMahon and Oliver [34]  advocate to use multiple sources, which are relevant and  challenge, so that these learning sources require learners to  process information deeply using self-regulated strategies. At the  level of support, instructors should provide learners with  constructive and useful feedback to improve their self-regulated  learning. There is also a place for instructors to instruct self- regulation directly so that students awareness of self-regulated  learning can be raised.   6. CONCLUSION  Self-regulation has been identified to play a very important role in  online and blended learning scenarios contexts. Although there  are numerous publications exploring the design of learning  activities to foster self-regulation, few studies explore the  connection between self-reported self-regulation data with  quantitative data about student interaction with activities and their  relation with academic performance. This paper presents the  results obtained from a case study deployed at a first year  engineering course with a blended, active learning strategy.  Three data sources were used for the study. The subset of items  inquiring about self-regulation in the Motivational and Self- Regulated Learning Questionnaire were used to encode two  factors: Positive and Negative self-regulation strategies (PSRS  and NSRS). The number of events accumulated the digital traces  produced by the students when interacting with the online  activities provided six additional factors. Finally, the academic  performance was represented by a single factor with the final  score in the course.  An initial correlation analysis showed a lack of significant  correlation between PSRS and academic performance. On the  other hand, there was a statistically significant negative  correlation between NPRS and academic performance. Four of the  six factors derived from the digital traces showed also a strong     statistically significant correlation with academic performance. A  clustering algorithm produced two robust clusters: users with both  high self-regulation and performance, and users with both low  self-regulation and performance. The factors derived from digital  traces had significantly different means in these clusters  suggesting that students in these clusters clearly interact  differently with the activities.  Finally, a structural equation model was created that provided a  more detailed vision of the relation between these factors. NSRS  affected negatively academic performance. The interaction with  online activities had a very strong positive effect on the academic  performance. The model also showed an indirect effect of PSRS  on the interaction with online activities.  The main conclusion of these results is that instructors could re- design the course to foster a higher adoption of self-regulation  through the online activities. As future work, we envision a more  detailed study that allows clarifying the causality relation between  self-regulation and how students behave in this blended learning  context.     7. ACKNOWLEDGEMENT  The authors wish to acknowledge the financial support of the  Australian Research Council through grant DP150104163.     8. REFERENCES  [1] Antunes, C. 2010. Anticipating students failure as soon as   possible. In Handbook of Educational Data Mining, C.  Romero, S. Ventura, M. Pechenizkiy, and R. Baker, Eds.  CRC Press, Boca Raton, FL. 353-362.   [2] Azevedo, R. 2009. Theoretical, methodological, and  analytical challenges in the research on metacognition and  self-regulation: A commentary. Metacognition and Learning.  4, 1 (2009), 87-95.   [3] Azevedo, R., Moos, D. C., Greene, J. A., Winters, F. I., and  Cromley, J. G. 2008. Why is externally-facilitated regulated  learning more effective than self-regulated learning with  hypermedia Educational Technology Research and  Development. 56, 1 (Feb. 2008), 45-72.   [4] Azevedo, R., Moos, D. C., Witherspoon, A. M., and  Chauncey, A. D. 2010. Measuring cognitive and  metacognitive regulatory processes used during hypermedia  learning: Theoretical, conceptual, and methodological issues.  Educational Psychologist. 45, 4 (2010), 1-14.   [5] Baker, R. and Siemens, G. 2014. Educational data mining  and learning analytics. In The Cambridge Handbook of the  Learning Sciences (2nd ed.), R. K. Sawyer, Ed. Cambridge  University Press, New York, NY, 253-274.   [6] Beishuizen, J. and Steffens, K. 2011. A conceptual  framework for research on self-regulated learning. In Self- regulated Learning in Technology Enhanced Learning  Environments: A European Perspective, R. Carneiro, P.  Lefrere, K. Steffens, K. and J. Underwood, Eds. Sense  Publishers, Rotterdam, 3-20,   [7] Bentler, P. M. 1990. Comparative fit indexes in structural  models. Psychological Bulletin. 107, 2 (1990), 238-246.   [8] Boekaerts, M. 1997. Self-regulated learning: A new concept  embraced by researchers, policy makers, educators, teachers,  and students. Learning and Instruction. 7, 2 (June. 1997),  161-186.   [9] Browne, M. W. and Cudeck, R. 1993. Alternative ways of  assessing model fit. In Testing Structural Equation Models,  K. A. Bollen and J. S. Long, Eds. Sage, Beverly Hills, CA,  136-162.   [10] Butler, D. L and Winne, P. H. 1995. Feedback and self- regulated learning: A theoretical synthesis. Review of  Educational Research. 65, 3 (1995), 245-281.   [11] Collis, B. 2003. Course redesign for blended learning:  Modern optics for technical professionals. International  Journal of Continuing Engineering Education and Lifelong  Learning. 13, 1-2 (2003), 22-38.   [12] Corno, L. and Mandinach, E. B. 1983. The role of cognitive  engagement in classroom learning and motivation.  Educational Psychologist, 18, 2 (1983), 88-108.   [13] Dabbagh, N. and Kitsantas, A. 2005. Using web-based  pedagogical tools as scaffolds for self-regulated learning.  Instructional Science. 33, 5-6 (2005), 513-514. DOI=  http://doi.acm.org/10.1145/332040.332491.   [14] Dabbagh, N. and Kitsantas, A. 2013. Using Learning  Management Systems as metacognitive tools to support self- regulation in higher education contexts. In International  Handbook of Metacognition and Learning Technologies, R.  Azevedo and V. Aleven, Eds. Springer, New York, NY, 197- 212.   [15] Duncan, T. G. and McKeachie, W. J. 2005. The making of  the Motivated Strategies for Learning Questionnaire.  Educational Psychologist. 40, 2 (2005), 117-128.   [16] Essa, A. and Ayad, H. 2012a. Improving student success  using predictive models and data visualisations. Research in  Learning Technology. 5, (Aug. 2012), 58-70.   [17] Essa, A. and Ayad, H. 2012b. Student success system: Risk  analytics and data visualization using Ensembles of  Predictive Models. Proceedings of the 2nd International  Conference on Learning Analytics and Knowledge (New  York, USA, April 2012). DOI=10.1145/2330601.2330641.   [18] Field, A. 2013. Discovering Statistics Using SPSS (4th Ed).  Sage, London.   [19] Ge. X. 2013. Designing learning technologies to support  self-regulation during III-Structured Problem-solving  Processes. In Handbook of Metacognition and Learning  Technologies, R. Azevedo and V. Aleven, Eds. Springer,  New York, NY, 213-228.   [20] Geiser, C. 2013. Data Analysis with Mplus. Guilford, New  York, NY.   [21] Graham, C. R. 2006. Blended learning systems: Definitions,  current trends, and future directions. In Handbook of  Blended Learning: Global Perspectives, Local Designs, C. J.  Bonk and C. R. Graham, Eds. Pfeiffer Publishing, San  Francisco, CA, 1-21.   [22] Greene, J. A., & Azevedo, R. 2010. The measurement of  learners self-regulated cognitive and metacognitive  processes while using computer-based learning     environments. Educational Psychologist. 45, 4 (2010), 203- 209.   [23] Hu, L. and Bentler, P. M. 1999. Cutoff criteria for fit indexes  in covariance structure analysis: Conventional criteria versus  new alternatives. Structural Equation Modelling. 6, 1 (1999),  1-55.   [24] Huang, R. and Zhou, Y. 2006. Designing blended learning  focused on knowledge category and learning activities. In  Handbook of Blended Learning: Global Perspectives, Local  Designs, C. J. Bonk and C. R. Graham, Eds. Pfeiffer  Publishing, San Francisco, CA, 296-310.   [25] Kitsantas, A. and Dabbagh, N. 2010. Learning to Learn with  Integrative Learning Technologies (ILT): A Practical Guide  for Academic Success.  Information Age, Greenwich, CT.   [26] Knight, S., Shum, S. B., and Littleton, K. 2014.  Epistemology, assessment, pedagogy: Where learning meets  analytics in the middle space. Journal of Learning Analytics.  1, 1 (2014), 23-47.   [27] Lajoie, S. P., Naismith, L., Poitras, E. Hong, Y-J, Cruz- Panesso, I.et al. 2013. Technologies-rich tools to support  self-regulated learning and performance in medicine. In  Handbook of Metacognition and Learning Technologies, R.  Azevedo and V. Aleven, Eds. Springer, New York, NY, 229- 242.   [28] Lester, J. C., Mott, B. W., Robison, J. L., Rowe, J. P., and  Shores, L. R. 2013. Supporting self-regulated science  learning in narrative-centered learning environments. In  Handbook of Metacognition and Learning Technologies, R.  Azevedo and V. Aleven, Eds. Springer, New York, NY, 471- 484.   [29] Lockyer, L., Heathcote, E., and Dawson, S. 2013. Informing  pedagogical action: Aligning learning analytics with learning  design. American Behavioral Scientist. 57, 10 (Mar. 2013),  1439-1459.   [30] Lovett, M., Meyer, O., and Thille, C. 2008. The Open  Learning Initiative: Measuring the effectiveness of the OLI  statistics course in accelerating student learning. Journal of  Interactive Media in Education.  DOI=http://doi.org/10.5334/2008-14.   [31] Lyn, L., Cuskelly, M., OCallaghan, M., and Grey, P. 2011.  Self-regulation: A new perspective on learning problems  experienced by children born extremely preterm. Australian  Journal of Educational & Developmental Psychology. 11, 1- 10.    [32] Macfadyen, L. P. and Dawson, S. Mining LMS data to  develop an early Warning System for educators: A proof of  concept. Computers & Education. 54, (Feb. 2010), 588-599.   [33] McCaslin, M. and Hickey, D. T.  2001. Educational  psychology, social constructivisim, and educational practice:  A case of emergent identity. Educational Psychologist. 36, 2  (2001), 133-140.   [34] McMahon, M. and Oliver, R. 2001. Promoting self-regulated  learning in an on-line environment. In Proceedings of World  Conference on Educational Multimedia, Hypermedia and  Telecommunications 2001, C. Montgomerie and J. Viteli  Eds. AACE, Chesapeake, VA, 1299-1305.    [35] Meltzer, L. 2007. Executive Function in Education: From  Theory to Practice. The Guilford Press, New York, NY.   [36] Newlin, M. H. and Wang, A. Y. (2002). Predictors of  performance in the virtual classroom: Identifying and helping  at-risk cyber-students. Technological Horizons in Education.  29, 10 (2002), 21.   [37] Pintrich, P. R.  2000. The role of goal orientation in self- regulated learning. In Handbook of Self-regulation, M.  Boekaerts, P. R. Pintrich, and M. Zeidener, Eds. Academic  Press, San Diego, CA, 451-521.   [38] Pintrich, P. R. and De Groot, E. V. 1990. Motivational and  self-regulated learning component of classroom academic  performance. Journal of Educational Psychology. 82, 1  (1990), 33-40.   [39] Pintrich, P. R. Wolters, C., and Baxter, G. 2000. Assessing  metacognition and self-regulated learning. In Issues in the  Measurement of Metacognition, G. Schraw and J. Impara,  Eds. Institute of Mental Measurements, Lincoln, NE, 531- 566.   [40] Puustinen, M. and Pulkkinen, L. 2001. Models of self- regulated learning: A review. Scandinavian Journal of  Educational Research. 45, 3 (2001), 269-286.   [41] Romero, C., Lpez, M.-I., Luna, J.-M. and Ventura, S. 2013.  Predicting students final performance from participation in  on-line discussion forums. Computers & Education. 68,  (Oct. 2013), 458-472.    [42] Shum, S. B. and Crick, R. D. 2012. Learning dispositions  and transferable competencies: Pedagogy, modelling and  learning analytics. Proceedings of the 2nd International  Conference on Learning Analytics and Knowledge (New  York, USA, April 2012). DOI=10.1145/2330601.2330629.    [43] Suthers, D. and Road, E.W. 2013. Learning analytics as a  Middle Space. Proceedings of the 3rd International  conference on Learning Analytics and Knowledge (Leuven,  Belgium, April 08-12, 2013).  DOI=10.1145/2460296.2460298   [44] Tanes, Z., Arnold, K. E., King, A. Z., and Remnet, 2011. M.  A. Using signals for appropriate feedback: Perceptions and  practices. Computers & Education. 57, 4 (Dec. 2011), 2414- 22.   [45] Tucker, L. R. and Lewis, C. 1973. A reliability coefficient  for maximum likelihood factor analysis. Psychometrika. 38,  1 (Mar. 1973), 1-10.   [46] Venkatesh, V., Shaikh, K., Zuberi, A., Urbaniak, K., Gallant,  T., et al. 2013. Development of task understanding and  monitoring in information retrieval environments:  Demystifying metacogntive and self-regulatory mechanisms  in graduate learners using topic maps indexing technologies  to improve essay-writing skills. In Handbook of  Metacognition and Learning Technologies, R. Azevedo and  V. Aleven, Eds. Springer, New York, NY, 277-292.   [47] Wang, A. Y., and Newlin, M. H. 2000. Characteristics of  students who enroll and succeed in psychology web-based  classes. Journal of Educational Psychology, 92, (Mar. 2000),  137-143.   [48] Winne, P. H. 2001. Self-regulated learning viewed from  models of information processing. In Self-regulated  Learning and Academic Achievement: Theoretical  Perspectives (2nd ed.), G Cshra and J. Impara Eds. Buros  Institute of Mental Measurements, Lincoln, NE, 43-97.     [49] Winne, P. H. 2006. How software technologies can improve  research on learning and bolster school reform. Educational  Psychologist. 41, 1 (2006), 5-17.   [50] Winne, P. H. and Hadwin, A. F. 2013. nStudy: Tracing and  supporting self-regulated learning in the Internet. In  Handbook of Metacognition and Learning Technologies, R.  Azevedo and V. Aleven, Eds. Springer, New York, NY, 293- 310.   [51] Winne, P. H. and Perry, N. E. 2000. Measuring self- regulated learning. In Handbook of Self-regulation, M.  Boekaerts, P. R. Pintrich, and M. Zeidner, Eds. Academic  Press, San Diego, CA, 531-566.   [52] Zimmerman, B. J. 1989. A social cognitive view of self- regulated academic learning. Journal of Educational  Psychology. 81, 3 (1989), 329-339.   [53] Zimmerman, B. J. 2000. Attaining self-regulation: A social  cognitive perspective. In Handbook of Self-regulation, M.  Boekaerts, P. R. Pintrich, and M. Zeidener, Eds. Academic  Press, San Diego, CA, 13-39.   [54] Zimmerman, B. J. 2001. Theories of self-regulated learning  and academic achievement: An overview and analysis. In  Self-regulated Learning and Academic Achievement:  Theoretical Perspectives (2nd ed.), B. J. Zimmerman and D.  H. Schunk, Eds. Lawrence Erlbaum Associates, New York,  NY, 1-38.   [55] Zimmerman, B. J. 2008. Investigating self-regulation and  motivation: Historical background, methodological  developments, and future prospects. American Educational  Research Journal. 45, 1 (2009), 166-183.   [56] Zimmerman, B. J., and Schunk, D. H. 2008. Motivation: An  essential dimension of self-regulated learning. In Motivation  and Self-regulated Learning: Theory, Research and  Applications, B. J. Zimmerman, D. H. Schunk, Eds.  Lawrence Erlbaum Associates, New York, NY, 1-30.   [57] Zimmerman, B. J. and Schunk, D. H. 2011. Self-regulated  learning and performance. In Handbook of Self-Regulation of  Learning and Performance, B. J. Zimmerman and D. H.  Schunk, Eds. Routledge, New York, NY, 1-12.          