Learning design and feedback processes at scale:  stocktaking emergent theory and practice    DesignLAK16 workshop: https://sites.google.com/site/designlak16  Ulla Ringtved   Aalborg University & University  College Northern Denmark,  P.O. Box 71 Denmark -9100   Aalborg, Denmark  +61 (0) 72698000  ulr@hum.aau.dk   Sandra Milligan  University of Melbourne   Melbourne Graduate School of  Education, 234 Queensberry St,   Parkville VIC 3010 Australia  +61 (0) 402115005   s.milligan@unimelb.edu.au   Linda Corrin  University of Melbourne, Melbourne   Centre for the Study of Higher  Education, Elisabeth Murdoch   Building, Parkville VIC 3010 Australia  +61 (03) 90359685   lcorrin@unimelb.edu.au     ABSTRACT  Design for learning in scaled courses is shifting away from  replication of traditional on-campus or online teaching towards  exploiting the distinctive characteristic and potentials of scale to  transform both teaching and learning. Scaled learning  environments such as MOOCs may represent a new paradigm for  teaching. This workshop involves consideration of the how  learning occurs in scaled environments, and how learning  designers and analysts can assist. It will explore questions at the  heart of effective learning design, using expert panelists and  collaborative knowledge-building techniques to arrive at a stock- take of thinking.   Categories and Subject Descriptors  H.1: Models and Principles   General Terms  Management Performance, Design, Human Factors, Theory.   Keywords  learning analytics, learning design, scaled courses, feedback,  crowd-sourced learning, learning at scale.   1. INTRODUCTION  Since the advent of MOOCs and other forms of learning at scale,  attention has focused on how leaning occurs in these contexts, and  how to improve it. Scaled courses lack the normal affordances of  the traditional higher education classroom. There is no collegiate  community of like-minded peers with similar backgrounds and  aspirations with whom the experience is shared. Nor are there  teachers or tutors to whom the student can turn, who know the  student, and their capability and who monitor and guide their  leaning over a period of time, sometimes years. Learning in a  MOOC is, at first glance, an individual task, tackled alone and  apart from others. Some like it and prosper. For others it is  difficult, even alienating. Some people generate high levels of  learning, others cant or dont.    Early examination of success in MOOCs has focused on what  works, both in terms of MOOC design, and the characteristics of   successful learners. Participants who prosper are a small  proportion of learners who are highly self-regulated, and able to  harness quality learner feedback from the crowd or from  automated teaching agents of the platform [1-3].They have a set of  learning skills, made up of a constellation of attitudes, values,  beliefs, understanding and knowledge about leaning, and  awareness of how these skills work for them. They create an  environment for themselves that provides the social and  pedagogical support they need.    Equally important is to understand the needs of learners whose  learning skills in this environment are low, and how their learning  skills can be developed. Learning design needs to give full rein to  the self-regulated learner and simultaneously guide the dependent  majority of learners to become more self-regulated.   Learning design is not simple, in any environment. Arranging  feedback, assessment and pedagogy that works in learning is hard,  effects often impossible to predict. The utility of feedback can be  marginal, its effects transient and negative [8-10]. Organising the  right feedback to a student at the right time is the holy grail of  most teachers, and in this, MOOCs have advantages: design teams  can use learning analytics, the crowd, and peers as well as input  from teaching staff, aligned with quality designs to provide a  tireless, constant stream of quality, relevant feedback to the  learner at the time they need it. The combined power of good  feedback, good assessment, good collaboration and learning  analytics may well provide a step towards that holy grail of  interest to all teachers, not just those designing MOOCs.       2. WORKSHOP QUESTIONS  A range of research projects and studies are seeking insight into   how to effect good design in scaled open courses [4-7], delving  into what self-regulated learners need to generate higher order  learning, and what teaching staff can to do provide and support it.  The field is fast-moving and challenging.    Teaching in scaled open courses is a design task, a team  activity in which technology and analytics are central elements.  Increasingly, the perspective of teachers working in the area is  shifting away from replication of the traditional on-campus or  online teaching-learning relationship towards exploiting the  distinctive characteristics and potentials of scale to transform both  teaching and learning.    This workshop will explore the theory and practice of designing  for learning in digital scaled courses, aimed to support the self- regulated learner. Questions at the heart of this are: Do scaled  learning environments such as MOOCs represent a new paradigm   Permission to make digital or hard copies of part or all of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. Copyrights  for third-party components of this work must be honored. For all other  uses, contact the Owner/Author.  Copyright is held by the owner/author(s).  LAK '16, April 25-29, 2016, Edinburgh, United Kingdom  ACM978-1-4503-4190-5/16/04.  DOI: http://dx.doi.org/10.1145/2883851.2883856     for teaching What are the significant features of scaled  teaching/learning that set it apart What are the challenges facing  the learner in scaled learning environments What is known about  the behaviours of successful learners What distinctive learning  skills do they require Can they be developed, and how What are  the challenges facing the designer What are the key design  approaches in scaled courses How can learning analytic  help What are some priorities for action Where are the gaps in  knowledge/understanding that could be informed by research  Where are the gaps in analytics tools and techniques      3. WORKSHOP METHODS  This workshop is to distill the emergent principles guiding best   practice in use of learning analytics in learning design for scaled  courses. It is designed for researchers and teaching practitioners  interested and/or expert in the process of teaching, learning and  assessment in MOOCs and other forms of learning at scale. It  aims to synthesis views about learning analytics, feedback,  assessment and its role from researchers and practitioners in areas  of learning analytics in MOOCs, self-regulation and learning  skills, learning design, and online learning platform design.    The workshop is structured around several elements. A series of  invited expert panelists from research teams working in the area  will give overviews of their work, to frame the debate. Working  sessions will be organised around the questions, outlined above.  Participants are expected to actively input their own experience  and insights via a fast-moving, participative, knowledge-building  process, the world caf, (http://www.theworldcafe.com). Such  processes are designed to synthesise and develop knowledge and  understanding of a diverse range of participants from different  disciplines and experiential backgrounds, different nationalities  and different sectors. The process will build on various groupings  that emerge from the participant base, and ensure that each  individual has an opportunity to interact at some depth with  people from similar backgrounds, and people from different  backgrounds as well. The process is effective in knowledge  building and also effective for building networks and connections,  and promoting cross-disciplinary and cross-contextual  understanding. Knowledge aggregations methods will be used,  promising to be energetic, engaging and fun as well. In a final  panel, rapporteurs will feed back to the groups some of the key  ideas that emerged. Each rapporteur will also produce a brief  report synthesizing the key themes in their area after the workshop  for distribution to participants and publication in the workshop  proceedings.    3. ABOUT THE ORGANISERS  Ulla Ringtved is organizer of the Learning Analytics Summer  Institute 2013 and 2015 at Aalborg University, Denmark. Her  research focuses on automation of feedback and assessment in  Technology Enhanced Learning (TEL), and on the  implementation of open educational resources in learning and  teaching in Higher Education, including in MOOCs. She teaches  at UCN and AAU in the areas of technology and learning, and  professional development for learning professionals, focusing on  feedback, assessment and learning analytics. She is an  experienced workshop facilitator and teaches and researches in a  diversity of TEL environments.      Sandra Milligan is a member of the Learning Analytics  Research Group at the University of Melbourne; is Convener of a  University of Melbourne MOOC targeting professional learning  and research engagement of teachers; and is conducting research  on new approaches to assessment and certification in MOOCs.  She works under the auspices of the Science of Learning Research  Centre and the Assessment Research Centre. She is a publisher,  has taken to market three of her own technology start-up  companies, worked at senior levels in large multi-national  companies and in government, and served as director for a range  of organisations. She is an experienced presenter, and writer.   Linda Corrin has been involved in educational technology- related research, curriculum development, and academic  development in higher education for the past 12 years. Lindas  research interests include examining students engagement with  technology, learning analytics, student feedback, and learning  design. Her current research includes a crossinstitutional study  which aims to develop a better understanding of the ways in  which learning analytics can be interpreted, applied and actioned  by teachers to improve teaching and learning practices. Linda was  a founding member of the Victorian and Tasmanian Learning  Analytics Network in Australia.   4. REFERENCES   [1] Milligan, S. K. Crowd-sourced learning in MOOCs:   learning analytics meets measurement theory. In Proceedings of  the Learning Analytics and Knowledge Conference Poughkeepsie,  NY, USA, 2015. ACM.    [2] Ferguson, R. and Sharples, M. Innovative Pedagogy at  Massive Scale: Teaching and Learning in MOOCs. Springer,  2014.   [3] Lockyer, L. and Dawson, S. Where Learning Analytics  Meets Learning Design Workshop. In Proceedings of the LAK'12  Conference, ACM Vancouver, B Canada, 29 April- 2 May, 2012.    [4] Milligan, C. and Littlejohn, A. Professional Learning in  Massive Open Online Courses:Design Recommendations, 2015.   [5] Milligan, S. K. and Griffin, P. Mining a MOOC: What our  MOOC taught us about professional learning, teaching and  assessment. IGI Global, City, 2015.   [6] Kennedy, G., Corrin, L., Lockyer, L., Dawson, S., Williams,  D., Mulder, R., Khamis, S., & Copeland, S. Completing the loop:  returning learning analytics to teachers. In B. Hegarty, J.  McDonald, & S.-K. Loke (Eds.), Rhetoric and Reality: Critical  perspectives on educational technology. Proceedings ascilite  Dunedin 2014 (pp. 436-440).    [7] Milligan, C., Littlejohn, A. and Margaryan, A. Patterns of  Engagement in Connectivist MOOCs. Journal of Online Learning  & Teaching, 9, 2 2013), 149-159.    [8] Kluger, A. and DeNisi, A. The effects of feedback  interventions on performance: a historical review, a meta-analysis,  and a preliminary feedback intervention theory. Psychological  Bulletin, 119, 2 1996), 30.   [9] Black, P., McCormick, R., James, M. and Pedder, D.  Learning How to Learn and Assessment for Learning: a  Theoretical Inquiry. Research Papers in Education, 21 (02) 2006.   [10] Hattie, J., & Timperley, H. (2007). The power of feedback.  Review of Educational Research, 77(1), 81-112.        