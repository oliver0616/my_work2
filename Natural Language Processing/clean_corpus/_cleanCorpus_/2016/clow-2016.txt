      LAK Failathon  Doug Clow1*, Rebecca Ferguson1, Leah Macfadyen2, Paul Prinsloo3, Sharon Slade1    1The Open University   Walton Hall, Milton Keynes  MK7 6AA, UK   Firstname.Surname@open.ac.uk     2The University of British Columbia,   Faculty of Arts,  1866 Main Mall,    Vancouver, BC, V6T 1Z1  leah.macfadyen@ubc.ca     3University of South Africa    3-15, Club 1, PO Box 392, Unisa   0003, South Africa   prinsp@unisa.ac.za       ABSTRACT  As in many fields, most papers in the learning analytics literature  report success or, at least, read as if they are reporting success.  This is almost certainly not because learning analytics research  and activity are always successful. Generally, we report our  successes widely, but keep our failures to ourselves. As Bismarck  is alleged to have said: it is wise to learn from the mistakes of  others. This workshop offers an opportunity for researchers and  practitioners to share their failures in a lower-stakes environment,  to help them learn from each others mistakes.    Categories and Subject Descriptors  K.3.1 [Computers and Education]: Computer Uses in   Education.   General Terms  Management, Human Factors.   Keywords  Failure, Publication bias, Positive results, Negative results.   1. MOTIVATION AND OBJECTIVES  1.1 The learning analytics literature is biased  Publication bias is a well-known problem in many empirical  disciplines, notably health and medicine. This is sometimes called  the file drawer effect. Researchers are incentivized to analyse  their data to find positive results; positive results are more likely  to be written up; and positive results are more likely to be  accepted as publications. Negative results are more likely to  languish, unloved, in file drawers.   The EU-funded Learning Analytics Community Exchange  (LACE) project1 is building an Evidence Hub for learning  analytics. The LACE Evidence Hub focuses on evidence for and  against a set of key propositions about learning analytics.  Evidence presented on the site is categorised according to whether  it supports or detracts from a particular proposition.                                                                         1 http://www.laceproject.eu      Preliminary results suggest that learning analytics is no exception  to the general trend: more than half the evidence in the Hub is  classified as positive, and most of the rest is neutral or mixed. (A  full account of this work is in preparation.)   Anecdotally, we know that not all learning analytics research  yields positive results, and that the majority of large-scale projects  encounter at least some serious problems. There are a few  examples of these issues being reported in the learning analytics  literature, such as Dawson & Macfadyens paper [1], but such  reports remain unusual.   Further, publication bias is a problem for well-conducted studies.  Very few outlets exist for those who want to publish accounts of  studies that failed to generate interpretable results because of  mistakes by the researchers.    Similar considerations apply to projects and activities applying  learning analytics: successful work is given far more prominence  than failure.   In summary, we tend to publicise our successes, and keep our  failures to ourselves.   1.2 This prevents effective learning within the  community  The printed literature enables us to learn of and from success.  Failure can be an extremely rich source of learning. Indeed, some  learning theories make explicit use of mistakes and failures in the  learning process.   Learning from ones own mistakes can be a very powerful source  of expertise. However, it is more efficient  and less unpleasant   to learn from other peoples mistakes too. But this is difficult  without access to information about failure.   1.3 Strong pressures keep it that way  Why is it like this   The incentives that contribute to publication bias are considerable,  and hard to change. In the medical field, there are moves such as  requiring pre-registration of trials and protocols, but the evidence  that these solve the problem is limited to date. Some journals now  explicitly welcome negative results, and some devoted purely to  negative results have sprung up.    However, the human pressure to publicise success but downplay  failure is likely to persist. Organisational pressures on researchers  and practitioners seem likely to increase.   Permission to make digital or hard copies of all or part of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. To copy  otherwise, to republish, to post on servers or to redistribute to lists,  requires prior specific permission and/or a fee.   LAK 16 Edinburgh, Scotland   Copyright 2016 ACM           1.4 A failure workshop can help  Such powerful social and systemic forces cannot be changed  quickly or easily.    However, there are opportunities for learning from each others  failures outside formal routes. The social spaces at LAK provide  informal opportunities for sharing these sorts of experience.    This workshop aims to offer a more explicit and structured space  for this to happen. We hope to create a space where researchers  and practitioners can learn from each others mistakes.   Many teachers will be familiar with learners being reluctant to  admit mistakes in public. This is one major rationale for the  existence of closed discussion forums (Learning Management  Systems/Virtual Learning Environments) in education: if the  discussion is entirely open to the world, learners may be too  reticent about failure to contribute. For this reason, this workshop  will be semi-private, held under the Chatham House Rule (see  below).   2. TARGET GROUP  This workshop is targeted at all researchers and practitioners in  learning analytics who are interested in learning from other  peoples failures, and are willing to share their own experience of  failure in the workshop.   No specific preparation is required, but participants will need to  be ready to talk about their own mistakes, and respect the  confidentiality of the session.   3. FORMAT  This will be a half-day workshop.   In the first session, there will be a series of presentations from the  organisers and other experienced learning analytics practitioners  (see below), who will present accounts of their own failures, with  time for discussion. After the coffee break, participants will  discuss their own failures in small groups, reporting summary  feedback to a short final plenary session.   To encourage free and frank discussion, the meeting will be held  under the Chatham House Rule:   When a meeting, or part thereof, is held under the Chatham  House Rule, participants are free to use the information received,  but neither the identity nor the affiliation of the speaker(s), nor  that of any other participant, may be revealed.2   Thus, participants can talk about or publish or act on what they  hear from other participants, but may not say who said it or what  organization or project it referred to. For the avoidance of doubt,  this applies to social media use as well: it is fine to tweet  interesting or amusing anecdotes, but not to attribute them  (directly or by implication) to either the person, the project, or the  organization.   4. ORGANISERS & PRESENTERS  This workshop is organized by the EU-funded Learning Analytics  Community Exchange (LACE) project. The organisers are  confirmed presenters in the morning session. Those listed as  presenters have agreed in principle to contribute.                                                                        2 https://www.chathamhouse.org/about/chatham-house-rule   4.1 Organisers & Presenters  Doug Clow, The Open University, UK   Doug Clow is a Senior Lecturer working on learning analytics at  The Open University, UK, and has more than 20 years  experience of projects harnessing new technology to improve  learning. He has published some of his successes at LAK and  tends to tell only his best friends about his failures. Doug is  currently part of a large-scale transformatory analytics programme  at the OU, and the LACE project. He has been co-organiser of  three SoLAR Flares in the UK.   Rebecca Ferguson, Open University, UK   Rebecca Ferguson is a Senior Lecturer at The Open University in  the UK, focused on educational futures, learning analytics,  MOOCs, augmented learning and online social learning. She is a  member of the steering committee of the Society for Learning  Analytics Research (SoLAR) and a Programme Chair of the  Practitioner Track at LAK16. She leads the LAEP project, which  is considering the implications and opportunities of learning  analytics for European educational policy. She co-chaired the 1st  and 2nd International Workshops on Discourse-Centric Learning  Analytics, held in Belgium and the US, as well as three SoLAR  Flares held in the UK.    Leah Macfadyen, The University of British Columbia   Leah Macfadyen is Program Director, Evaluation & Learning  Analytics  in the Faculty of Arts at the University of British  Columbia. Her applied research projects include development of  visual models of student enrollment pathways to assist with  curriculum re-development, social network analysis of learner  engagement patterns in MOOCs and LMS-based courses, and  visualization of themes in unstructured data (course evaluation  comments) as well as continued testing of models of student  activity and fine-grained indicators of achievement in online  courses. Her experience of the challenges of implementing  learning analytics in her large institution has pushed her to write  and think about strategic approaches for implementing learning  analytics at scale. She is also a member of the SoLAR Executive.  Paul Prinsloo, UNISA   Paul Prinsloo is a Research Professor in Open Distance Learning  (ODL) in the College of Economic and Management Sciences,  University of South Africa (Unisa). His academic background  includes fields as diverse as theology, art history, business  management, online learning, and religious studies. Paul is an  established South African National Research Foundation (NRF)  rated researcher and has published numerous articles in the fields  of teaching and learning, student success in distance education  contexts, learning analytics, curriculum development and  corporate citizenship. He was awarded international fellowships to  the Open University in 2007, 2009, and 2010 and received the  Unisa Chancellors Award for Outstanding Research in 2008.   Sharon Slade, Open University, UK   Sharon is a Senior Lecturer and Regional Manager in the Open  University Business School. She leads and participates in projects  which feed into teaching and learning across the Open University.  For example, she acted as the Business Lead for 3 institutional  projects linked to the provision of tailored curriculum-based  student support. She is also chairing the team which has recently  developed a new OU policy for the ethical use of learning           analytics. Her current research interests relate to ethical issues in  learning analytics.   4.2 Presenters  (Subject to timetabling constraints with other workshops at LAK.)   Shane Dawson, University of South Australia   Shane Dawson is the Director of the Teaching Innovation Unit at  the University of South Australia. Shane's research focuses on the  use of social network analysis and learner ICT interaction data to  inform and benchmark teaching and learning quality. Shane is a  founding executive member of the Society for Learning Analytics  Research and past conference chair of the International Learning  Analytics and Knowledge conference. He is a co-developer of  SNAPP an open source social network visualization tool designed  for teaching staff to better understand, identify and evaluate  student learning, engagement, academic performance and creative  capacity.   Hendrik Drachsler, Open University, NL   Hendrik Drachsler is Assistant Professor at the Welten Institute of  the Open University of the Netherlands. His research interests  include Learning Analytics, Personalisation technologies,   Recommender Systems, Educational data, Open Science, mobile  devices, and their applications in the fields of technology  enhanced learning, science 2.0, and health 2.0. He is chairing the  EATEL SIG dataTEL and the national SIG Learning Analytics of  the Dutch umbrella organisation SURF. He is WP2 leader of the  LinkedUp project and the scientific coordinator of LACE project.   Maren Scheffel, Open University, NL   Maren Scheffel is a researcher and PhD candidate at the Welten  Institute of the Open University of the Netherlands. She is a  computational linguist and has been working in the field of  technology enhanced learning (TEL) for several years where she  was involved in several national and international TEL projects.  Currently, she focuses her research on learning analytics,  reflection and awareness support, personalisation and educational  data. She is currently working on the LACE project.    5. REFERENCES  [1] Macfadyen, L.P. and Dawson, S. 2012. Numbers Are Not   Enough. Why e-Learning Analytics Failed to Inform an  Institutional Strategic Plan. Educational Technology &  Society. 15, 3 (2012), 149163.         