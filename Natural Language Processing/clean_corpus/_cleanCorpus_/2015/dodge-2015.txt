Improving Undergraduate Student Achievement in Large  Blended Courses Through Data-Driven Interventions   Bernie Dodge  San Diego State University   Learning Design and Technology   San Diego CA 92182-4561   +1 619 594-7401  bdodge@mail.sdsu.edu   John Whitmer  Blackboard, Inc  40 Gold Street   San Francisco, CA 94133  +1 530 554-1528   john.whitmer@blackboard.com   James P. Frazee  San Diego State University   Instructional Technology Services  San Diego CA 92182-8114   +1 619 594-2893  jfrazee@mail.sdsu.edu        ABSTRACT  This pilot study applied Learning Analytics methods to identify  students at-risk of not succeeding in two high enrollment courses  with historically low pass rates at San Diego State University:  PSY 101 and STAT 119. With input from instructors, targeted  interventions were developed and sent to participating students  (n=882) suggesting ways to improve their performance. An  experimental design was used with half of the students randomly  assigned to receive these interventions via email and the other half  being analyzed for at-risk triggers but receiving no intervention.  Pre-course surveys on student motivation [4] and prior subject  matter knowledge were conducted, and students were asked to  maintain weekly logs of their activity online and offline connected  to the courses. Regression analyses, incorporating feature  selection methods to account for student demographic data, were  used to compare the impact of the interventions between the  control and experimental groups. Results showed that the  interventions were associated with a higher final grade in one  course, but only for a particular demographic group.    Categories and Subject Descriptors  K.3.1. Computer Uses in Education   General Terms  Performance, Experimentation.   Keywords  Learning management systems, learning analytics, time logs,  motivation, blended learning, interventions, large enrollment  courses, at-risk student prediction.                  Permission to make digital or hard copies of part or all of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that copies  bear this notice and the full citation on the first page. Copyrights for third- party components of this work must be honored. For all other uses, contact  the Owner/Author.     Copyright is held by the owner/author(s).  LAK '15, Mar 16-20, 2015, Poughkeepsie, NY, USA  ACM 978-1-4503-3417-4/15/03.  http://dx.doi.org/10.1145/2723576.2723657   INTRODUCTION  The intent of this study was to identify methods and interventions  that would reduce the number of students who fail early on in  their academic career. It was also designed to discover approaches  that could be practically adopted by faculty with minimal support  and thus are scalable to a large number of courses.   1. METHOD  1.1 Courses  Faculty from two courses with high numbers of students not  passing the course volunteered to participate in the study in the  Spring 2014 semester: Introductory Psychology (PSY 101) and  Introduction to Business Statistics (STAT 119).  Two sections of  each course were used in the study. Each of these courses met  twice a week for 75 minutes. One session was held face to face in  a 500-seat lecture hall with large screens and clickers; the other  was delivered online. Both the face to face and online lectures  were archived and available for students to access later.   1.2 Learner Profile  There were approximately 1,605 students enrolled in the four  sections involved in the study. Of this total, 882 (55%) consented  to participate in the study. The learners were predominantly  female (69%), and almost all were 17-19 years old (86%). 37% of  the students from under-represented minority groups.  There was  also a large participation (38%) by students from low socio- economic statuses, as indicated by eligibility for Pell grants.    1.3 Hypotheses  The research hypotheses driving this study are:   1. Student interaction data from multiple academic  technology sources provides a better prediction of  course achievement than LMS data alone.    2. Faculty interventions with at-risk students, identified  through academic technology interaction data, has a  positive relationship with student likelihood to pass the  course.    3. There are significant differences in the relationship  between student use of faculty interventions and student  achievement based on student characteristics  (motivation toward subject matter, demographic factors,  prior educational experience, and current education  status).    412    1.4 Research Design  An experimental design with independent measures was used.  Within each section, 50% of the students within each course  section were randomly assigned to either the treatment (n = 442)  or control group (n = 440). All other aspects of the courses were  identical. This approach allowed the isolation of the intervention  from other potentially confounding factors.   1.5 Demographic Data  After the semester was completed, demographic data were  analyzed to shed light on factors related to course achievement  and possible differences in results based on these characteristics.  These variables were pre-selected by the campus Institutional  Research department as having previously demonstrated  relationships with student achievement and/or identifying  populations deemed of special priority to provide support. A total  of 43 variables was identified, including race/ethnicity, socio- economic status, grade level, first-generation college student, etc.   1.6 Treatment  The interventions in this study were developed collaboratively  with the two faculty participants rather than being imposed on  them by technologists or administrators. As a result of these  ongoing conversations, the following triggers were identified:  Logins to the Blackboard LMS, exam and quiz grades, and clicker  points (a proxy for attending the live lecture).   Interventions were developed in the form of emails sent on behalf  of the faculty to students using the internal mail application within  Blackboard. The messages included online and in-person  resources that could help them improve their course performance.   2. RESULTS  All together, a total of 21 trigger events based on use reports  were created for students in PSY 101 and 19 trigger events were  created for students in STAT 119.  The distribution of the total  number of triggers flagged for students follows in Figure 1. As  can be seen, most students in the courses received one or more  triggers (70% STAT, 86% PSY).  Most students received a few  triggers, with the large majority receiving 1-4 triggers.       Figure 1 Number of Triggers Received      2.1 Accuracy of Triggers at Predicting Grade  In both courses, the triggers were significantly (p<0.0001) related  to student final grade for students receiving at least one trigger.   Figures two and three demonstrate this relationship for the STAT  and PSY courses. The STAT course, which had a lower overall  number of triggers as a percentage of students, had a stronger   relationship between the triggers and final grade, explaining 66%  of the variation in final grade.  The PSY course, while still  significant, had a weaker relationship, explaining 48% of the  variation in final grade.     2.2 Effectiveness of Interventions  Analysis of variance (ANOVA) found no significant difference  for either course between the experimental and control groups on  course achievement,    Looking more deeply by taking demographic variables into  account, we did find a significant difference between achievement  based on one variable: Pell-eligibility, which is a proxy for low  socio-economic status.  Among PSY students, those students who  were Pell-eligible and received the interventions were less likely  to have a grade requiring them to repeat the course (e.g. < C-).  Pearson Chi2 analysis comparing the Pell and non-Pell  populations by participating in the control group resulted in  Chi2(1) = 6.4007, Pr = 0.000. Within the control group, 67 passed  the course and 20 did not. As Figure 2 illustrates, within the  experimental group 91% passed the course and 9% did not.    If all Pell eligible students had received the interventions, we can  estimate that all but 15 students would have passed the class, an  improvement over the 27 that need to take it again.     Figure 2: Relationship Between Receiving Interventions and  Passing the PSY 101 Course (Pell-Eligible vs All Students)     This differential effect of interventions on the Pell-Eligible  students was not seen in the STAT 119 class, however.     3. DISCUSSION  Faculty and researchers designing this study perceived the email  interventions to be the best treatment possible within the  constraints of the study, but likely to have a limited impact on  student achievement.  There are certainly many other  interventions that one could imagine (e.g. supplemental  instruction, one-on-one tutoring sessions, directed study  resources) with a higher potential impact.    4. CONCLUSION  The limited impact of the emailed interventions used this year  suggests the need for stronger interventions. The authors are  currently laying out a framework for describing and designing  interventions for future study.     5. ACKNOWLEDGMENTS  Thanks to San Diego State University President Elliot Hirshman  for his Building on Excellence strategic plan and to Geoffrey  Chase, Dean of Undergraduate Studies for supporting this effort  through the Learning Analytics Working Group.  413      