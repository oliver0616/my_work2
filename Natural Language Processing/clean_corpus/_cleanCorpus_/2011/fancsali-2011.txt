Variable Construction for Predictive and Causal Modeling of Online Education Data  Stephen E. Fancsali Department of Philosophy, Carnegie Mellon University; Pittsburgh, PA 15213, USA  Product Strategy and Development, Apollo Group, Inc.; 199 Fremont St., Suite 1400, San Francisco, CA 94105, USA  sfancsal@andrew.cmu.edu  ABSTRACT We consider the problem of predictive and causal modeling of data collected by courseware in online education settings, focusing on graphical causal models as a formalism for such modeling. We review results from a prior study, present a new pilot study, and suggest that novel methods of con- structing variables for analysis may improve our ability to infer predictors and causes of learning outcomes in online education. Finally, several general problems for causal dis- covery from such data are surveyed along with potential so- lutions.  Keywords online education, causal discovery, graphical models, Bayesian networks, dimensionality reduction  1. INTRODUCTION Scientists and engineers at the Apollo Group are develop-  ing an Individualized Learning Platform (ILP) for online ed- ucation, the broad overview of which is illustrated by Fig. 1 [1]. The ILP is being constructed using insight from domain experts in cognitive and learning sciences while deploying a data-driven Intelligence Engine that takes input data or signals from the ILP and provides appropriate guidance to administrators, faculty, and students to better customize and individualize the online learning experience. A wide variety of information is provided to and recorded by the ILP, including information about learner and faculty con- text, aspects of curriculum, and so on. Coupling insight from educational theory with the Intelligence Engine will al- low the Apollo Group to enhance learner satisfaction while improving learning outcomes and supporting other institu- tional goals. Ann Browns influential work [2] calls for a design-based empiricism, and the reader will find Fig. 1 only slightly adapted from a diagram in that work. The ILP is designed around several core principles, one of which is that guidance be evidence-based [1]. This paper focuses on a can- didate methodology to achieve this core objective, focusing  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. LAK11 February 27-March 1, 2011, Banff, AB, Canada. Copyright 2011 ACM 978-1-4503-1057-4/11/02 ...$10.00.  Figure 1: Illustration of Apollo Groups Individual- ized Learning Platform, reproduced from [1].  on the discovery of causes of positive learning outcomes in the online education environment.  The learning management system of the ILP will track student progress and activity in online courses. A cen- tral challenge is to determine the predictors, and especially causes, of student learning outcomes given these records of their activities and interactions. Predictive models are use- ful for purposes such as identifying students likely to with- draw from courses or otherwise have negative learning out- comes; such models rely on discovering symptoms in stu- dent behaviors and activity to predict likely outcomes. If we can identify, from passive observation, students at risk for negative learning outcomes, instructors can flag students to target existing resources toward them to rectify problems a student may be having. However, symptoms and predic- tors of learning outcomes need not identify causes of learning outcomes. When we acquire causal knowledge, we acquire the ability to predict values of variables post-intervention. Traditional statistical methods focus on predictive tasks, al- lowing us to forecast or classify from observed attributes of a unit (e.g., student) but not to reliably do so after manipu- lation of the environment (e.g., online courseware, methods of instruction, etc.). If we are able to identify causes, we can better design interventions to drive learning gain and other positive outcomes for students, knowing that post- intervention these changes will drive better learning out- comes. Further, such knowledge can lead to the development and engineering of better online learning platforms and en-  54    vironments. However, there are several hurdles to overcome to achieve such insight.  We focus on the complexity of data collected in the online environment and begin to address the dearth of literature focusing on transforming log-style, transactional data col- lected in online courseware for use with causal discovery pro- cedures.1 In the next section we sketch an extant framework for causal discovery from non-experimental datasets. In Sec- tion 3, we survey a past application of this framework in the online education domain. We outline the multi-faceted com- plexity of data collected in online education environments in Section 4. In Section 5, we describe a pilot study of data from an online graduate economics course and suggest in Section 6, based on the results of the pilot study, that we need to construct new measures of student behavior from underlying raw variables. In Section 7 we outline three remaining general problems for causal discovery in the on- line education domain and provide concluding remarks in Section 8.  2. CAUSAL DISCOVERY FROM OBSERVA- TIONAL DATA  Data collected in log files and databases that underlie on- line courseware are non-experimental, historical data. As a result, we are rarely in the position to learn causal relations in the paradigmatic manner of the sciences: namely, from randomized experimental data. Despite natural differences in courses from offering to offering and from instructor to instructor, we as investigators cannot reach into the past to intervene and experiment with courseware or other aspects of the online education experience. Over the past twenty years, there has been a large research program by philoso- phers, statisticians, and computer scientists to develop many different methods for the discovery of causal relations from observational datasets.  Much of this research has focused on causal interpreta- tions of probabilistic graphical models, specifically directed acyclic2 graphs (DAGs) with associated probability distri- butions, called Bayesian networks ([7], [8]). Within this for- malism, variables are represented by nodes in a graph with edges between nodes representing direct causal relationships between variables. Consider the graph of Fig. 2, model- ing qualitative, hypothetical causal relationships among at- tributes of students in an imaginary online course. Several attributes might be particularly salient for non-traditional students to whom online education and degree programs are appealing.  We model relationships between hypothetical measures of employment, size of family (familySize), time obligations not related to a students education (obligations), time spent studying, motivation, length of messages in an online dis- cussion forum (messageLength), academic ability, and final exam scores in a course (final). In our hypothetical model, student final exam performance has two direct causes: stu- dent ability and studying. Further, the model represents re-  1A noteworthy exception for educational data is ([3]), though their analysis is not directed specifically at causal discovery. 2Feedback cycles (in time) can be modeled within the Bayes nets framework by, for example, deploying variables indexed by time. Some literature ([4], [5], [6]) focuses on the discov- ery of cyclic graphical models, though work on this topic is underdeveloped compared to the Bayes nets formalism.  Figure 2: Graphical representation of hypothetical causal relationships for students in an online course  Figure 3: Hypothetical illustration of causal rela- tions that could lead to a faithfulness violation  lationships among the determinants of a students studying behavior.  If two crucial (usually reasonable) assumptions hold-the Causal Markov Axiom and the Causal Faithfulness Condi- tion [7]3 - then the causal structure encoded in the Bayesian network graph implies a set of probabilistic (conditional) independence relations between the variables. The Causal Markov Axiom asserts4 that, assuming there are no unmea- sured common causes of variables we consider, a variable is probabilistically independent of its non-descendents (non- effects) conditional on its direct causes. The assumption of Faithfulness asserts that all probabilistic independencies that are actually observed occur only because of an absence of a direct causal relation. That is, conditional independence between variables does not occur by accident (via canceling out settings of parameters, for example).  To illustrate how a violation of this assumption might oc- cur, consider a slight modification to hypothetical causal re- lations among three variables from Fig. 2 in Fig. 3, in which the association represented by each arrow is positive or nega- tive. Suppose we posit that increased family size has a nega- tive impact on employment; the student is likely to work less as the size of his or her family increases but that employment  3There is substantial philosophical literature about the Causal Markov Axiom and the Causal Faithfulness Condi- tion (e.g., [9], [10], [11], [12], [13], [14], [15]). I pass over this controversy as these assumptions are standard in the causal learning framework deployed here. 4Assuming it is possible to represent the underlying causal structure as a directed acyclic graph  55    and family size both contribute to increased non-educational time obligations. The negative effect of familySize on em- ployment combined with the positive effect of employment on obligations, given appropriate (perhaps unlikely) param- eter values (representing strength of causal relations), may exactly cancel out the positive effect of familySize on obli- gations. Suchcanceling outparameter values could lead us to believe that familySize and obligations are independent, despite the fact that there is a direct causal relation be- tween the two. This hypothetical judgment of independence despite a direct causal relation is a violation of faithfulness.  While a causal Bayesian network implies conditional in- dependencies, this graphs  independencies mapping is many-one: for any particular graph G, there will typically be other graphs, though not all graphs, that predict the same (conditional) independencies, and so are observation- ally indistinguishable from G. We are all familiar with the old maxim that correlation does not imply causation. For example, if verbosity in online message forums (message- Length) and studying are correlated, this can be explained by messageLength  studying, studying  messageLength, or studying and messageLength sharing a common cause (as they do in Fig. 2, motivation), or a combination of these explanations. Multiple graphs can imply the same observed correlations and/or independencies. We can use observa- tional data to learn a set of (observationally indistinguish- able) causal structures: namely, exactly the set of possi- bilities that could have produced the observed pattern of independencies in the data. Causal Bayesian network struc- ture learning algorithms, e.g., the PC algorithm [7] and GES ([16], [17]), under suitable assumptions, will identify (the set of observationally equivalent graphs containing) the correct DAG in the large sample limit.  Two rough intuitions illustrate basic principles of search for graphical causal models from conditional independence relations. The first concernsscreening offrelations whereby, to consider a simple three variable example, two variables, say messageLength and studying, are correlated but become independent when we condition upon a third variable, mo- tivation; this conditional independence claim tells us that messageLength and studying are not directly causally re- lated. Assuming there are no unmeasured common causes of messageLength, studying, and motivation, this conditional independence claim is explained by three possible causal structures: messageLengthmotivation studying ; study- ing  motivation  messageLength; or messageLength  motivation  studying. If we lack background knowledge, these three graphs are indistinguishable from observational data. However, if we assume student motivation to be in- herent or at least temporally prior to their enrollment in a program and behavior in a course, then we can infer that motivation is a common cause of messageLength and study- ing.  The second intuition has us consider two independent vari- ables that share a common effect. Suppose that a students level of motivation and non-educational, time-consuming obli- gations are independent. We expect that each of these stu- dent attributes share a common effect in the amount of time a student devotes to study. Unconditionally the in- structor cannot infer anything about a students motivation level from the knowledge that a student has many time- consuming obligations outside of the course in which they are enrolled; the instructor, however, can make inferences  about a students motivation when the student (honestly) reports to the instructor how much they study. If we know that a student is studying a lot while juggling many obli- gations, we infer something about the students motivation level, namely that is high. We can similarly infer from a students report that they are highly motivated and yet are not studying as much as they would like that they are likely dealing with many outside obligations. In both cases, when we condition on a common effect two otherwise independent variables now provide information about each other. In the graph of Fig. 2, this is represented as what is called a col- lider,where arrows from motivation and obligations meet at studying (motivation  studying  obligations). Assuming (however unlikely) that we omit no common causes, there are no other graphical structures that explain this constraint on conditional independencies (or dependencies). That is, we can orient edges into acolliderwhen such circumstances arise as we search over conditional independence relations in a larger dataset.  Since we also assume that graphs are acyclic, having ori- ented colliders, we can often orient edges in such ways that avoid creating colliders where they were not discovered via tests for conditional independence. Thus, we can often orient many edges to make causal inferences from observa- tional data alone. A constraint-based algorithm such as PC simply systematizes search over (sets of) variables in a data set to determine the conditional independence relations that hold among the variables and produces the set of graphical structures that imply those relations.  3. A SIMPLE CAUSAL MODEL OF OUT- COMES IN AN ONLINE LEARNING EN- VIRONMENT  The work below is certainly not the first to deploy meth- ods for causal discovery in the online education domain. Scheines et al. ([18]), for example, focused on a set of vari- ables relevant to students in an online causal and statistical reasoning course, including measures of:   students background knowledge (pre: a measure of pretest abilities derived from GRE items)   behavior in online courseware (print : a measure of the extent to which students print out online course mate- rial, and volqs: a measure of the number of interactive, voluntary understanding questions attempted within the courseware), and   learning outcomes (quiz : an average of quiz scores over several course modules, and final : final exam grade).  They then used several causal Bayes net learning algo- rithms to develop a path analytic model (Fig. 4) for these variables. They found interesting links between the back- ground variable as well as their behavioral variables and learning outcomes. Examining this model, student final exam performance is well-predicted by the extent to which students check their understanding, and printing out read- ing material is negatively associated with these self-checks. Controlling for other possible mediators they still find a negative effect (though it is only marginally significant) of greater printing behavior on final exam score. They cau- tiously suggest an interpretation of this effect as due to dif- fering study habits. Students who print out material are  56    Figure 4: Linear path analytic model of student be- havior and outcomes in an online causal and sta- tistical reasoning course [18]; marginally significant edges are dashed  less likely to engage the voluntary, interactive questions dur- ing studying while students who did not print out material may be more likely to do so. Student behavior with re- spect to printing course material may also be indicative of other study habits, though those habits were unmeasured in this analysis. Thus, we find a fruitful deployment of causal discovery methods to find behavioral and background at- tributes of students in the online environment that are pre- dictive of (and more cautiously, causally related to) learning outcomes.  4. THE COMPLEXITY OF COLLECTED DATA AND VARIABLE CONSTRUCTION  Having briefly explored basic principles of causal discov- ery, we consider a second, more distinctive challenge to dis- covering causal models that arises from the complexity of the data collected from online courseware systems. Most on- line courseware collects an enormous amount of data about a multitude of different phenomena, which leads to very high-dimensional datasets. Variables collected fall into three rough categories:  1. purely observed variables with (relatively) straightfor- ward interpretations or meanings  2. measured indicators of underlyinglatentphenomena, and  3. raw variables that require some form of construction to be interpretable or meaningful.  The first two categories are well-treated in the literature on causal discovery as well as multivariate analysis in gen- eral. Further, latent variable modeling is an active area of research in the social science methodology (e.g., psychomet- rics) community. We also briefly discuss procedures for the discovery of latent variable models later in this work. There is, however, little literature dealing with the third category of variables in a principled way with respect to causal dis- covery.  Natural and social scientists construct variables frequently, but the approach taken is usually either based on signifi- cant, richly detailed background theory or ad-hoc guesswork. Consider, for example, weather forecasting, in which prog- nostications are made frequently in terms of high pressure and low pressure weather systems. While these systems  Figure 5: Illustrative example of the difference be- tween latent variable modeling and deterministic variable construction. The larger rectangle envelops a discovery and estimation problem, the smaller rectangle a construction problem.  cover large geographic regions, their features-strength, size, speed, etc.-are constructed from a multitude of directly ob- served barometric pressure readings spread out over large geographic regions. Meteorologists high and low pressure systems are instances of constructed variables, while indi- vidual, localized barometric pressure readings are the raw variables from which such constructions arise. In general, a host of situations call for principled, data-driven methods for constructing variables from underlying raw data.  In many cases, we measure many variables but it is not clear just what the causal variables of interest should be. While latent variable modeling is one way to potentially reduce the dimensionality of data, in some situations it is more appropriate to seek dimensionality reduction methods whereby we construct new measured variables as determin- istic functions of raw measured variables. This difference between latent variable modeling (i.e., group 2 above) and the construction of variables via deterministic functions of raw variables is partly illustrated in Fig. 5. The larger rectangle of Fig. 5 illustrates a discovery and estimation problem within the framework of latent variable models. When deploying a latent variable model, the modeler must first decide (or discover) the appropriate causal structure relating latent variables to their manifest effects and then estimate the parameters (factor loadings) quantifying the nature of these causal relationships. Conditional upon the latent variable, each of its noisy, measured (or manifest) indicators (X1, X2, and X3 ) is independent of the other measures. Whether this condition is appropriately tested or assumed, this assumption is usually called that of local independence.  Contrast this estimation problem with the heuristic illus- tration of a variable construction problem in the smaller rectangle of Fig. 5. Here, we call X1, X2, and X3 our raw variables and deterministically construct a new vari- able called scale from these raw variables. Since we are using a latent variable model to motivate the illustration, there are no direct connections between X1, X2, and X3, but this need not be the case in general. Whether or not the raw variables are unconditionally independent, they remain or become dependent when conditioning upon the determinis- tically constructed new variable. Consider the situation in which we construct scale as the sum of only X1 and X2, and assume X1 and X2 to be unconditionally independent.  57    Given information that scale takes on the value 10 (condi- tioning on scale) and that X2 takes on the value 7, then we know the value of X1 to be 3. Thus, conditioning on scale, X2 provides us information about X1, so the two compo- nents of scale are conditionally dependent. In situations in which latent variable models are deployed, scales like this are often constructed as well, and this is just one special case of the general problem at hand.  Of course in general, not just any constructions will do. The problem that we face is to reduce a set ofrawvariables {R1, ..., Rn} to some smaller set of variables {C1, ..., Ck} via deterministic functions {f1, ..., fk} of the raw variables in order to achieve some objective or goal. In the online educa- tion domain, we focus on predicting and identifying causes of learning outcomes as assessed by exam scores, course grades, or perhaps even another constructed variable5 incorporating several aspects of learning outcomes. This search problem is clearly intractable; the search space must be constrained by some combination of background knowledge and a guid- ing/focal objective function. Background knowledge may be rather general. For example, we might know that the rele- vant constructed variables will be linear combinations of the raw variables. Other forms of background knowledge may be domain- or application-specific, such as providing a spec- ification of which raw variables are relevant for particular constructed variables and which may be disregarded.  Objective functions, similarly, may take on a multitude of forms. We might seek functions of raw variables that lead to the best prediction of a particular target variable. Alterna- tively, we might seek functions of raw variables that lead to greatest amount of causal knowledge with respect to some target variable. Any number of other objective functions may be appropriate in any number of situations, but note that the best constructed variables can change depending on the objective function. Once some sensible combination of background knowledge and an objective function have been specified, we will (hopefully) have a space of functions that is searchable. Thus, we can search for variable con- structions for particular purposes. We later consider a spe- cific example of message forum data from an online learning environment to flesh out some possibilities for this program of research.  5. A SIMPLE PILOT STUDY One might plausibly wonder whether variable construc-  tion is actually required for successful prediction. We thus first demonstrate that predictions about a set of students en- rolled in an online, several month graduate economics course can be improved through the use of constructed variables. We note at the outset, however, that an unqualified causal interpretation of the resulting DAG is tricky at best, though further research to find more plausible or appropriatecausal constructions is ongoing. Nevertheless, a (graphical) repre- sentation of the probabilistic dependence structure for these variables can significantly improve predictions. We focus on variables in three rough semantic categories provided in Table 1.  Our categorization provides a rough time ordering. Back- ground (including demographic) variables are those upon  5In this work we principally focus on constructing predictors and causes of a given target variable, rather than construct- ing the target variable itself; the latter problem is briefly discussed later.  which we cannot in principle intervene but that might prove useful for predictive and/or classification purposes. Behav- ioral variables measure aspects of students interaction with online courseware and are vital to the purpose of discovering the behavioral causes of student learning outcomes. These are also the variables most likely to require construction to be meaningfully interpreted. Learning outcome variables are assessed at specific times within the course in our example. Two individual assignments are graded during the course while an individual final exam is assessed at the end of the course. Final course grades are calculated including both individual assessments and assessments of a students work with a group of other students.  Data from a sample of 815 students are provided to the PC algorithm6 along with time-ordering background knowledge.  The algorithm returns a set of DAGs which imply the conditional independence relationships judged present in the data via statistical test. One DAG is chosen, and a path an- alytic model is estimated according to that structure. This model is provided as Fig. 6.7 Both the structure of the model and estimated parameters characterize qualitative and quantitative relationships among the variables under consid- eration.  As we are especially concerned with discovering the pre- dictors and causes of learning outcomes, we focus on two particular learning outcome variables. The first is student final course grade (grade points). The model provides us with something of asanitycheck of our method in this case. Among the variables directly connected to grade points are variables which constitute the basis by which the instruc- tor assigns the final grade, including both assignment scores and the final exam score. Other influencers are GPA and both counts of messages, the instructors number of private messages to the student as well as the count of the students public and group messages. If we take GPA to be a proxy for general student ability in online courses of this sort (which we implicitly do by taking GPA to be a background variable as opposed to an outcome), then this seems like a sensible picture of the predictors of the final course grade. However, the final course grade may not be our best target for deter- mining the causes of learning outcomes. After all, the same instructor provides grades for assignments as well as the fi- nal assessment via the course grade, and the final course grade is really (in part) just a function of these components. Further, the final course grade includes assessments of a stu- dents group work, so an independent, objective assessment of individual learning outcomes would be helpful. This we find in our second learning outcome variable of interest, fi- nal exam points.  Students in this sample had different instructors, but all took a final exam, provided by a textbook manufacturer, that was independently graded. This provides us with a relatively clean, objective instrument to assess learning out- comes with respect to the material of this online economics course. However, the set of variables directly connected to final exam points is relatively small. We find that the un- mediated predictors of a students final exam score are sex,  6Algorithms deployed in this work are all implemented in the freely distributed Tetrad IV suite of algorithms available at http://www.phil.cmu.edu/projects/tetrad. 7The model of Fig. 6 is judged to fit the data by a relevant statistical test comparing the implied covariance matrix of this model with the sample covariance matrix [19].  58    Table 1: Description of measured and constructed variables included in pilot study background behavioral outcomes age student public/group msg.  count assignment 1 (% score)  sex inst. private msg. count assignment 2 (% score) Pell Grant eligibility chapter view count final exam score GPA final course grade (points  on a 4.0 scale) avg. MBA course final exam score inst. avg. peer review score  GPA, and average score on other MBA course final exams. This may provide support for our use of the latter two vari- ables as proxies for ability, but we find no direct connections between this independent learning outcome assessment and behavioral variables we consider in this analysis. This, of course, does not mean that behavior and learning outcomes are unrelated. Perhaps we have just not constructed and included the appropriate sets of behavioral variables. We must explore the intriguing possibility that we failed to ap- propriately carve up our behavioral raw data.  One crucial way that student behavior is captured in this environment is through messages that students post in an online forum. We need to carefully consider ways in which we can construct variables out of this data. Our first pass included ad hoc constructions of studentPublicGroupMes- sageCount and instructorPrivateMessageCount ; we did not find significant, unmediated links to final exam score, though some interesting relationships between demographic features, message behavior, and other variables were discovered. Given the richness and importance of student and instructor inter- actions via these messages, we choose forum message data as the illustrative example of the problem of variable con- struction.8  6. THE CONSTRUCTION OF NEW VARI- ABLES  Real, deployed online courseware collects data for every forum message posted by students in a given course. We focus here on only a handful of these characteristics to mo- tivate the problem of variable construction search. For each message we know:   message creator   message timestamp   message content   the forum in which the message was posted, and   whether the course facilitator judged the message as substantive or not.  8viewChapterCount is also an ad hoc construction from sep- arate logs in the online courseware that could just as easily be the target of investigation for principled variable con- struction and search.  These messages can be organized by student9 (as message creator, excluding messages posted by course instructors), and raw variables can be created that correspond to the message attributes. In a course with 50 students, the most prolific of whom posted 100 messages, this scheme results in 400 raw variables. A schema of the resulting data set is shown in Table 2.  The form of the data (binary, real valued, text, etc.), as well as background knowledge, informs the space of func- tions over which we might search. A plausible objective function is to optimize predictions for each student of mea- sured learning outcomes, such as score on a final exam or course grade. We seek useful, meaningful constructed vari- ables to incorporate into causal and/or predictive models. Numerous potential constructed variables arise even out of our simple toy example.  A simple example involves word counts from the content fields for each student. We let C denote the indices of con- tent fields in our dataset (C = {2, 6, 10, 14, 18, ..., 398}):  averageWordCount =   iC wordCount(Ri)  iC I(wordCount(Ri) > 0) , (1)  where wordCount is a function that count words given a field of text as an argument, and I is the indicator function (taking value 1 when the content field is not empty, 0 other- wise). Letting F denote the set of indices for variables that identify the particular forum in which students posted (i.e., F = {3, 7, 11, ..., 399}), we can reproduce a variable from our pilot study:  studentPublicGroupMessageCount = iF  I(Ri = PUBLIC Ri = GROUP ) (2)  Letting S denote the set of indices for variables containing the binary substantive message flag, which takes value 1 when a message is substantive and 0 otherwise, (i.e., S = {4, 8, 12, ..., 400}), another simple example is:  countSubstantivePosts =  iS  I(Ri = 1) (3)  9The reader might sensibly inquire why we choose to orga- nize message data by student (as opposed to, for example, organizing the data by message). This choice provides an or- ganization in which most variables in the data are roughly independently and identically distributed (or i.i.d.). This is necessary for us to proceed with causal discovery techniques we deploy. The data would not be i.i.d. were it organized by message, having a variable representing the message creator.  59    Figure 6: Estimated linear path analytic model from our pilot study. Rectangles are placed around two learning outcomes on which we focus.  Table 2: Hypothetical table for forum message raw variables organized by student R1 R2 R3 R4 ... R397 R398 R399 R400  Student time1 content1 forum1 subflag1 ... time100 content100 forum100 subflag100 s1 s2 ... s50  We might consider many alternatives. We can deploy any number of functions just on the content and timing of mes- sages. Guided by background knowledge and the form of the data, we iteratively search over potential variable construc- tions and judge them via resulting models in which they are used. We seek variable constructions and models incorpo- rating them that maximize our ability to predict a students final exam score and infer causes of learning outcomes.  Given often lacking background knowledge tying together education domains with causal inference from data obtained from online courseware, as well as the dimensionality, granu- larity, and complexity of the latter, we are forced not only to search over potential causal structures that explain the data but also to search for the variables that take part in that modeling. Search for more, better variable constructions is currently ongoing and a topic for further research.  7. FUTURE DIRECTIONS FOR CAUSAL DIS- COVERY FROM ONLINE EDUCATION DATA  Having delved into the problem of variable construction in considerable depth, we focus on three further problems for predictive and causal inference from online educational data. The resolution of these problems may affect approaches to variable construction and search, but they are general prob- lems for predictive and causal inference even when variables  for analysis are given. Roughly these problems are:  1. the treatment of certain categorical variables for causal structure search  2. measurement of target variables intended to capture learning outcomes, and  3. inferring the presence of unmeasured (latent) common causes.  We provide a brief overview of each of these problems and suggest some potential solutions. Getting a handle on ap- proaches to these three problems in addition to the problem of variable construction will certainly advance the state-of- the-art with respect to causal discovery in online education settings as well as for learning analytics in general.  7.1 The Treatment of Certain Categorical Vari- ables for Causal Structure Search  A variety of phenomena in our pilot study are best rep- resented by discrete variables; we include binary variables, for example, representing gender and Pell Grant eligibility. Other discrete and categorical phenomena cannot be ignored in attempts to discover causal structure. For example, learn- ers may come from various demographic and ethnographic groups, and instructors may have various levels of prepara- tion and credentials. To produce satisfying causal explana-  60    tions of student learning, we must attempt to control for differences arising because of these categorical phenomena.  If we treat the set of learners who, for example, had a particular instructor for a course as a separate sample for analysis, we consider a much smaller sample, leading to con- cerns for small effect sizes and the power of statistical tests deployed for causal structure search. Further, discrete vari- ables may pick out genuinely different populations of learn- ers having different underlying causal structures. We focus on differences between instructors. Certain aspects of the educational experience of the student may be independent of the instructor (e.g., student messaging behavior may be unrelated to a particular instructor or course offering); other aspects may be dependent on the instructor, and the under- lying causal structure we attempt to model may be different from instructor to instructor.  In our pilot study, we included a measure of the instruc- tors peer review score as a first attempt to control for the instructor of each course, but this approach is sub-optimal as this variable takes on the same value for every student within a given class and is thus not independent and identi- cally distributed (or i.i.d.).10 Further, conditional indepen- dence relations that obtain in distributions for individual instructors may not obtain in the distribution created by the combination of data sets for all instructors. Also, infor- mation common to distributions for every instructor can be destroyed even if instructors courses are well-represented by the same causal structure (cf. [20], [21]). We need some way of investigating what are potentially different causal struc- tures among instructors to provide causal insights into the dynamics of online courseware on a relatively large scale.  An intuition about how to attack this problem comes from considering what we might call invariant edges. We begin by stratifying our full dataset into datasets for each indi- vidual instructor. We call invariant edges those that are discovered by graphical search procedures when applied to each instructors respective data set. We should expect, for example, that the edges oriented into grade points will re- main invariant across instructors, as the final course grade is a (noisy) function of various components included in the model. We know the causes of the final course grade in this sense, but we might also discover other features of the underlying causal structure by finding other invariant edges. However, invariance over all data sets might be too strict a standard.  Ramsey et al. [21] attack a similar methodological prob- lem; they seek to discover what we might callapproximately invariant edges from brain imaging (fMRI) studies in cog- nitive neuroscience. Seeking to discover qualitative causal relations amongst regions-of-interest (ROIs)11 in the brain, they provide a modification of a causal structure learning algorithm that helps address this related problem. In fMRI  10This illustrates a general problem for deploying methods that rely on statistical tests for conditional independence when we have mixed data (including both categorical and continuous variables). A variety of techniques can be used to mitigate this problem. We might, for example, discretize continuous variables or treat binary or ordinal categorical data as if it were continuous (our strategy for treating binary variables and instructor avg pr in our pilot study). Different situations will suggest different approaches.  11The construction of ROIs is itself another instance of the problem of variable construction that must be dealt with to reliably discover causal relations.  data, from individual to individual, both the strength of causal relations among regions of the brain may differ as well as the underlying causal structure itself may differ. These possibilities coupled with various sources of measurement error lead to different distributions (and data sets) for each individual of a study. The individuals of fMRI studies cor- respond to instructors in our online education setting; we face similar issues of differing strength of causal relations and potentially differing causal structure from instructor- to-instructor. Just as everyone has unique brain physiology, every classroom is unique.  Ramsey et al. [21] propose IMaGES (Independent Multiple- sample Greedy Equivalence Search) as a modified version of Meeks GES ([16], [17]) algorithm. This algorithm searches over equivalence classes of graphs, represented by a partic- ular type of graphical structure called a pattern. Beginning with an empty graph, GES proceeds in two waves. In the first, single edges are added until a Bayesian score assigned to each graph can no longer be improved. In the second wave, individual edges are deleted until the score can no longer be improved. Briefly, IMaGES follows the same score- based procedure as GES, but at each stage the graph under consideration is scored based on its average score over each individual data set. This allows us to discover better models of the data we have despite the possibility of instructor-to- instructor variation in causal strength and causal structure. However, no work has deployed this technique in cases in which we also search for variable constructions or in appli- cations outside of cognitive neuroscience.  7.2 Measurement of Target Variables for Learn- ing Outcomes  In some cases, we are faced with a relatively simple (and relatively noise-free) target variable, for example, student retention rate or a variable representing whether (or when) a student dropped out of a particular course. At other times, our interest is establishing the predictors and causes of learn- ing. To survey the broad scope of the problem of measuring student learning outcomes goes well beyond the scope of this paper. Sometimes we may have a well-devised assessment of learning gain in a particular course, perhaps from pre- test and post-test instruments. We then would seek out the predictors and causes of learning gain as advocated above. Frequently, however, we seek to measure amount of learn- ing, treating it as a hidden construct with several possible indicators or measures.  The design of instruments to measure such latent phe- nomena falls within the realm of the field of psychometrics. Successful instruments to assess constructs like amount of learning must not only have established validity, so that they measure the intended phenomenon, but must also be reliable. Reliability is cashed out in social science research in a variety of ways. Dealing with different instructors, who may grade by different standards, leads us to seek an in- strument with which we can achieve high inter-rater reli- ability. Test-retest reliability is another standard sought for learning assessment instruments. Further, we might be concerned that multiple items that make up an instrument are internally consistent, as assessed commonly by a mea- sure like Cronbachs alpha [22]. Some work has been done (e.g., [23]) connecting such traditional notions of reliabil- ity in the social sciences with reliable causal discovery, but further investigation is necessary.  61    Figure 7: Result of FCI search over data from our pilot study  While the final exam grade we consider in our pilot study has convenient properties for causal and statistical analysis as it is standardized for this course, designed by the course textbook manufacturer, and graded independently of the in- structor, it is not ideal. We should seek out better, more ro- bust indicators to assess learning outcomes, which are likely to vary from course-to-course and from program-to-program. Data-driven methods, augmented by expert domain knowl- edge, can inform the specification of an outcome variable. We provide one potential methodological approach to this problem after we consider a third challenge we face.  7.3 Inferring the Presence of Unmeasured Com- mon Causes  As is realistic in most social science applications, including those in the education domain, we must relax an assumption posited in our pilot study: namely, that our model includes all common causes of any variables therein. This assump- tion is calledcausal sufficiency in causal discovery parlance (cf. [7]). If we relax this assumption and allow that there may be unmeasured or latent confounders of the variables we consider, we can deploy causal discovery algorithms that detect where such confounding may be present. The FCI algorithm [7] is intended to do just this, providing graphical output that indicates if variables potentially share an un- measured common cause. The output of FCI for the data from our pilot study is provided as Fig. 7. Edges that appear as X  Y indicate the presence of an unmeasured common cause of X and Y; edges that appear as X o Y indicate that either X is a cause of Y or they share an unmeasured common cause; edges that appear as X o-o Y indicate that either: (1) X causes Y, (2) Y causes X, (3) X and Y share a common cause, or (4) a combination of (1) and (3) or (2) and (3).  The results align with intuitions in several ways, suggest- ing that measures of message counts share a common cause as well as suggesting that both GPA and average MBA exam scores share a common cause, perhaps something like back- ground knowledge or ability. Other possible interpretations remain. The inference that we have possibly omitted com-  mon causes of variables provides great insight such that we might iteratively construct new models and measure new phenomena.  Returning to the problem discussed in the previous sec- tion, we can deploy FCI search over a set of fixed variables to inspect whether the result suggests that intended learn- ing outcome measures share an unmeasured common cause; such a result provides evidence that latent variable model may be appropriate. We might construct a scale to serve as a proxy for such a latent variable reified as a learning outcome. The Build Pure Clusters algorithm (BPC [24]) might be deployed for a similar purpose to determine the suitable components of such a proxy constructed variable. Under suitable conditions (namely that indicators are lin- early related to the underlying latent), the BPC algorithm discovers sets of variables that are measured indicators of only one underlying phenomenon and that satisfy other im- portant assumptions for causal discovery. This returns to the problem of discovery and estimation illustrated in the large rectangle of Fig. 5. Such an algorithm can be fruitfully deployed, for example, to provide background knowledge to variable construction search procedures in cases in which we seek to construct a scale as a proxy for a latent phenomenon.  8. CONCLUSION We have outlined several problems for causal discovery  from observational, online education data, focusing espe- cially on the complexity of data collected from online course- ware. A pilot study suggests that ad hoc variable con- structions are less successful than we would like for pre- diction and inferring causes of learning outcome variables. This contributes to the need for principled means of search over potential variable constructions from such complex data sets. Further, other important problems for causal discov- ery from data in this domain are illuminated, and we intro- duce techniques that might be deployed to (partially) solve these problems. Open avenues for research are plentiful. Setting up the appropriate space of search for variable con- structions will require the input of domain experts and the implementation of appropriate search procedures. Data for  62    other courses and from other academic programs will have to be considered. New raw variables can be included from the large amount of historical data available for the course used in our pilot study. Finally, the specification oflearning outcomes is a problem faced throughout education. Work- ing from expert domain knowledge, we might seek ways in which data-driven methods can fruitfully address this prob- lem, providing specifications useful for causal discovery and for the learning analytics and educational research commu- nity at large.  Acknowledgments. The author wishes to thank David Danks, Satish Menon, Partha Saha, and Richard Scheines for helpful discussions and comments on early drafts of this work. Further, the author thanks Apollo Group, Inc. for a summer internship to conduct the Simple Pilot Study, and Partha Saha for extensive support and advice on data access, understanding, and manipulation during that time.  9. REFERENCES [1] Menon, S.: A Pedagogy/Andragogy-Neutral  Technology Platform Approach to Improve Learning Effectiveness for Online Learning. Presentation to 6th Pan-Commonwealth Forum on Open Learning. Kochi, India (2010)  [2] Brown, A.L.: Design Experiments: Theoretical and Methodological Challenges in Creating Complex Interventions in Classroom Settings. J. Learn. Sci. 2, 141178 (1992)  [3] Arnold, A., Beck, J.E., Scheines, R.: Feature Discovery in the Context of Educational Data Mining: An Inductive Approach. In: Proceedings of the AAAI2006 Workshop on Educational Data Mining, pp. 713. Boston, MA (2006)  [4] Richardson, T.S.: A Discovery Algorithm for Directed Cyclic Graphs. In: Horvitz, E., Jensen, F. (eds.) Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence, pp. 454461. Morgan Kaufmann, San Francisco (1996)  [5] Pearl, J., Dechter, R.: Identifying independencies in causal graphs with feedback. In: Horvitz, E., Jensen, F. (eds.) Proceedings of the Twelfth Conference on  Uncertainty in Artificial Intelligence, pp. 420U-42. Morgan Kaufmann, San Francisco (1996)  [6] Lacerda, G., Spirtes, P., Ramsey, J., Hoyer, P.O.: Discovering Cyclic Causal Models by Independent Components Analysis. In: McAllester, D., Nicholson, A. (eds.) Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence, pp. 366374. AUAI Press, Corvallis, OR (2008)  [7] Spirtes, P., Glymour, C., Scheines, R.: Causation, Prediction, and Search, 2nd Edition. MIT Press, Cambridge, MA (2000)  [8] Pearl, J.: Causality: Models, Reasoning, and Inference. Cambridge UP (2000)  [9] Sober, E.: Venetian Sea Levels, British Bread Prices, and the Principle of the Common Cause. Brit. J. Phil. Sci. 52, 116 (2001)  [10] Cartwright, N.: Causal Diversity and the Markov Condition. Synthese. 121, 327 (1999)  [11] Cartwright, N.: From Metaphysics to Method: Comments on Manipulability and the Causal Markov Condition. Brit. J. Phil. Sci. 57, 197218 (2006)  [12] Hoover, K.: Nonstationary Time Series, Cointegration, and the Principle of the Common Cause. Brit. J. Phil. Sci. 54, 527551 (2003)  [13] Steel, D.: Indeterminism and the Causal Markov Condition. Brit. J. Phil. Sci. 56, 326 (2005)  [14] Hausman, D.M., Woodward, J.: Independence, Invariance and the Causal Markov Condition. Brit. J. Phil. Sci. 50, 521583 (1999)  [15] Hausman, D.M., Woodward, J.: Modularity and the Causal Markov Condition: A Restatement, Brit. J. Phil. Sci. 55, 147161 (2004)  [16] Meek, C.: Graphical Models: Selecting Causal and Statistical Models. Ph.D. Thesis, Carnegie Mellon University (1997)  [17] Chickering, M.: Optimal Structure Identification with Greedy Search. J. Mach. Learn. Res. 3, 507554 (2002)  [18] Scheines, R., Leinhardt G., Smith, J., Cho, K.: Replacing Lecture with Web-Based Course Materials. J. Edu. Comp. Res. 32, 126 (2005)  [19] Bollen, K.: Structural Equations with Latent Variables. Wiley (1989)  [20] Yule, G.U.: An Introduction to the Theory of Statistics. C. Griffin and Co., London (1919)  [21] Ramsey, J.D., Hanson, S.J., Hanson, C., Halchenko, Y.O., Poldrack, R.A., Glymour, C.: Six Problems for Causal Inference from fMRI. NeuroImage. 49, 15451558 (2010)  [22] Cronbach, L.J.: Coefficient Alpha and the Internal Structure of Tests. Psychometrika. 16, 297334 (1951)  [23] Fancsali, S.: Cronbachs Alpha, Latent Variables, and Causal Inference. M.S. Thesis, Carnegie Mellon University (2008)  [24] Silva, R., Glymour, C., Scheines, R., Spirtes, P.: Learning the Structure of Linear Latent Variable Models. J. Mach. Learn. Res. 7, 191246 (2006)  63      