{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Tagging Technique: <br>\n",
    "### Representing Tagged Tokens\n",
    "The tagged token could be create using str2tuple() library in nltk package or create tuple object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged Token:('test', 'NN')\n"
     ]
    }
   ],
   "source": [
    "tag_token = nltk.tag.str2tuple('test/NN')\n",
    "print(\"Tagged Token:\"+str(tag_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Tagged Token:[('Computing', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('new', 'JJ'), ('mathematics', 'NNS'), ('and', 'CC'), ('new', 'JJ'), ('stethoscope', 'NN'), ('of', 'IN'), ('the', 'DT'), ('21st', 'JJ'), ('century', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "sentences='''\n",
    "Computing/NN is/VBZ the/DT new/JJ mathematics/NNS and/CC new/JJ stethoscope/NN of/IN the/DT 21st/JJ century/NN\n",
    "'''\n",
    "tag_tokens=[nltk.tag.str2tuple(t) for t in sentences.split()]\n",
    "print(\"List of Tagged Token:\"+str(tag_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defualt Tagger: <br>\n",
    "Using nltk package create the default tagger object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Default', 'NN'), ('Tagger', 'NN'), ('tagged', 'NN'), ('everything', 'NN'), ('as', 'NN'), ('you', 'NN'), ('given', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "example_text = \"Default Tagger tagged everything as you given\"\n",
    "text_token = word_tokenize(example_text)\n",
    "result= default_tagger.tag(text_token)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Tagging\n",
    "### NLTK POS-tagger\n",
    "POS-tagger is a build in tagger in nltk package, using prebuilt tagger to tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Computing', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('new', 'JJ'), ('mathematics', 'NNS'), ('and', 'CC'), ('new', 'JJ'), ('stethoscope', 'NN'), ('of', 'IN'), ('the', 'DT'), ('21st', 'JJ'), ('century', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(\"Computing is the new mathematics and new stethoscope of the 21st century\")\n",
    "tagTokens=nltk.pos_tag(tokens)\n",
    "print(tagTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tagged Sentences and non-Tagged Sentences, using brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentences=brown.tagged_sents()\n",
    "non_tagged_sentences=brown.sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagger Evaluation\n",
    "NLTK provide prebuilt tagger evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13130472824476916\n"
     ]
    }
   ],
   "source": [
    "evaluation=default_tagger.evaluate(brown_tag_sent)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression <br>\n",
    "use regular expression to create the patterns to tag for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19537768086586887\n"
     ]
    }
   ],
   "source": [
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),               # gerunds\n",
    "    (r'.*ed$', 'VBD'),                # simple past\n",
    "    (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "    (r'.*ould$', 'MD'),               # modals\n",
    "    (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "    (r'.*s$', 'NNS'),                 # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "    (r'.*', 'NN')                     # nouns (default)\n",
    "]\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "brown_reg_tagged=regexp_tagger.tag(non_tagged_sentences[3])\n",
    "print(regexp_tagger.evaluate(brown_tag_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup Tagger <br>\n",
    "tag words with most common use POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4804614568477909\n"
     ]
    }
   ],
   "source": [
    "fd = nltk.FreqDist(brown.words())\n",
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words())\n",
    "most_freq_words = fd.most_common(100)\n",
    "likely_tags = dict((word, cfd[word].max()) for (word, _) in most_freq_words)\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags)\n",
    "print(baseline_tagger.evaluate(brown_tag_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Part of Speech Tagging <br>\n",
    "### n-gram Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10206319146815508\n"
     ]
    }
   ],
   "source": [
    "brownTagSent = brown.tagged_sents(categories ='news')\n",
    "brownSent = brown.sents(categories ='news')\n",
    "size = int(len(brownTagSent)*0.9)\n",
    "train = brownTagSent[:size]\n",
    "test = brownTagSent[size:]\n",
    "bigram = nltk.BigramTagger(train)\n",
    "bigram.tag(brownSent[2007])\n",
    "print(bigram.evaluate(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform poorly with unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine n-gram Tagger\n",
    "combine the n-gram Tagger using backoff-tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8452108043456593\n"
     ]
    }
   ],
   "source": [
    "tagger0 = nltk.DefaultTagger('NN')\n",
    "tagger1 = nltk.UnigramTagger(train, backoff=tagger0)\n",
    "tagger2 = nltk.BigramTagger(train, backoff=tagger1)\n",
    "print(tagger2.evaluate(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the reslut improve dramatically after combine the n-gram taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction and DecisionTreeClassifier Part of Speech Tagger\n",
    "Extracing features to create decision tree classifier to train the tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning\n",
      "0.6270512182993535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'IN'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix_fdist = nltk.FreqDist()\n",
    "#extract suffix\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    suffix_fdist[word[-1:]] += 1\n",
    "    suffix_fdist[word[-2:]] += 1\n",
    "    suffix_fdist[word[-3:]] += 1\n",
    "\n",
    "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
    "#part of speech features extract function\n",
    "def pos_features(word):\n",
    "    features = {}\n",
    "    for suffix in common_suffixes:\n",
    "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
    "    return features\n",
    "\n",
    "tagged_words = brown.tagged_words(categories='news')\n",
    "featuresets = [(pos_features(n),g) for (n,g) in tagged_words]\n",
    "size = int(len(featuresets)*0.1)\n",
    "train_set,test_set=featuresets[size:],featuresets[:size]\n",
    "print('trainning')\n",
    "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier,test_set))\n",
    "classifier.classify(pos_features('cat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: <br>\n",
    "    NLTK online Textbook chapter 5 Categorizing and Tagging Words(https://www.nltk.org/book/ch05.html) <br>\n",
    "    NLTK online Textbook chapter 6 Learning to Classify Text(https://www.nltk.org/book/ch06.html) <br>\n",
    "More Information: <br>\n",
    "    All Tags in NLTK for english(https://stackoverflow.com/questions/1833252/java-stanford-nlp-part-of-speech-labels?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
