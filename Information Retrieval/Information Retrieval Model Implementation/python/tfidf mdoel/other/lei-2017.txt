
Data-Assisted Instructional Video Revision via Course-
Level Exploratory Video Retention Analysis 

Chi-Un Lei, Donn Gonda, Xiangyu Hou, Elizabeth Oh, Xinyu Qi, 
Tyrone T.O. Kwok, Yip-Chun Au Yeung, Ray Lau 

Technology-Enriched Learning Initiative, The University of Hong Kong, Pokfulam Road, Hong Kong 

Email: {culei, dgonda, hxiangyu, lizhku, andreaq, tyrone.kwok, pauyeung, raybon}@hku.hk 

  

ABSTRACT 
Since teachers are not physically present in an online class, 

instructional video is the major carrier of course contents in an 

online learning environment. This paper aims to investigate how 

course-level exploratory video retention analysis can be used for 

identifying moments with abnormal watching behaviors and 

revising videos for a higher video retention. We have empirically 

evaluated the effectiveness of video analysis and revisions, based 

on evaluating retentions of revised videos.    

CCS Concepts 
• Applied computing ?  Education ?  Distance learning 

• Applied computing ?  Education ?  E-learning 

Keywords 
video retention; data-informed revision; exploratory analysis;  

1. INTRODUCTION 
Over the past decade, learning analytics (LA) benefited from the 

rapid development of online learning opportunities. Multi-

dimensional data, such as clicking patterns of courseware and 

videos, comes into our sight. Thus, how to accurately digest these 

data into comprehensive insights becomes a significant task for LA 

data visualization. Since teachers are not physically present in an 

online class, instructional video is the one of the major carriers of 

course contents in an online learning environment [1]. Unorganized 

series of instructional videos that are difficult to comprehend may 

demotivate students from watching the entire video or even 

completing the course. In this situation, exploratory video retention 

analysis can help understanding learning progress of students [2].  

Since exploratory video retention analysis had been under-studied 

in the literature, this paper aims to investigate how course-level 

exploratory video retention analysis can be used for 

instructional video revision. We hope that through the analysis, 

teachers can efficiently identify moments in videos for revisions, 

which can eventually improve video watching and learning 

experience. Even though video-watching does not necessarily 

guarantee effective learning, we believe that if learners are willing 

to keep watching videos, they can eventually learn more. 

2. METHODOLOGY 
In this study, we have used exploratory video retention data to 

analyze how learners interacted with the video content in a course. 

Through identifying problematic moments in videos (explained in 

Section 2.1), teachers can then look in depth to identify root causes 

for video revisions. In this study, the video retention indicator 

shows the number of views for a particular moment of a video 

as a percentage of the total number of views of the video. 

2.1 Instructional Video Revision 
Instructional videos can be revised if one of the following situations 

happens: i) the sequence of instructional videos is not in a coherent 

order, ii) the video content is irrelevant to learners, iii) the layout, 

visual aids, and mechanics in the video cannot convey the message 

clearly, and iv) learners failed to comprehend certain ideas, 

examples and/or illustrations. Revisions may include revising video 

contents at problematic moments on a video-level or re-ordering 

videos in a more coherent sequence on a course-level. 

2.2 Data-Assisted Video Revision 
Data-assisted revision is favorable due to the following reasons: i) 

With the high granularity of learner data, problematic moments can 

be specifically indicated. In particular, events are triggered when 

the learner interacts (e.g. play, pause, playback) with the video, in 

a second-by-second level; ii) Learner data can be obtained from all 

learners, including non-active students who has a low tendency to 

answer learner surveys; and iii) Data can be directly collected from 

the video streaming database. As the measurement is less apparent 

to students, the data collected is more authentic for analysis.  

2.3 Analysis via Retention Metrics & Graphs 
In general, videos should have a high percentage of contents viewed 

(i.e. a high video retention metric), as this indicates that the video 

keeps its audience. To be specific, course-level retention metric can 

be used for identifying the problematic ordering of videos in the 

browsing sequence and problematic videos for in-depth analysis. 

Meanwhile, video-level retention graph can be used for identifying 

moments in the video for revisions. These moments are usually the 

ones with atypical browsing behaviors, which indicates learners’ 

difficulties in understanding the content. For example, occurrences 

of moments with >100% video retention metric indicate unusual 

times of replays. They were usually moments illustrating 

unexpectedly complicated textual and visual information within a 

short period. In these situations, learners either replay that moment 

(causing a retention peak at that moment) or stop watching the 

video (causing a drop of retention rate in the rest of the video).  

2.4 Limitations of Existing Studies 
Studies in [3-5] aim at studying video browsing behaviour on a 

video level. However, generated insights in [3,4] have not been 

verified through evaluations of revised videos in subsequent 

cohorts. In [5], difficulties in digesting video content have been 

studied, without proposing pedagogical insights. In [3], course-

level retention metrics have not been explored to show whether the 

order of videos are coherent. In [4], only researcher’s observations 

(without learners’ browsing data) have been used for analysis.  

Permission to make digital or hard copies of part or all of this work for 
personal or classroom use is granted without fee provided that copies are 

not made or distributed for profit or commercial advantage and that copies 

bear this notice and the full citation on the first page. Copyrights for third-
party components of this work must be honored. For all other uses, contact 

the Owner/Author.  

Copyright is held by the owner/author(s). 
LAK '17, March 13-17, 2017, Vancouver, BC, Canada 

ACM 978-1-4503-4870-6/17/03. 

http://dx.doi.org/10.1145/3027385.3029454  

http://dx.doi.org/10.1145/3027385.3029454


Table 1. Comparison of video retentions in two cohorts: (a) 

Problematic videos in Cohort 1, and (b) Corresponding videos 

(with revisions) in Cohort 2. (A): Video length (minutes); (B): 

Views; (C): Average video retention metric (%). Videos coded 

in #, ^ and * are videos with video decomposing, video 

restructuring, and   content revision, respectively. 

(a) 

Video title (A) (B) (C) 

1.3 Camera, action! 5.25 86 33.9 

3.1 Teaching at a massive scale 6.55 28 48.3 

3.2 Forum management 7 25 45.3 

3.3 The HKU experience: HKU03x 5.33 78 41.3 

4.1 What is learning analytics? 2.52 21 56.4 

4.2 Learning analytic cycle 3.97 18 69.1 

4.3 Resource usage analysis (I) 5.82 27 50.6 

4.4 Resource usage analysis (II) 5.57 21 49.6 

Average value of 13 non-revised videos 2.17 48.2 54.2 

(b) 

Video title (A) (B) (C) 

1.3.1 Camera, action! # 2.32 37 73.2 

1.3.2 Screen capture # 1.28 33 88.2 

1.3.3 Studio filming # 1.77 34 71.5 

1.3.4 The HKU experience: HKU03x ^ 5.33 31 75.6 

1.5 MOOC forum management ^ 7.02 39 43.6 

3.1 What is learning analytics? * 2.4 31 77.4 

3.2 Learning analytic cycle * 3.88 29 65.4 

3.3 Resource usage analysis (I) * 5.63 39 62.9 

3.4 Resource usage analysis (II) * 4.05 28 69.5 

3.5 Resource usage analysis (III) * 1.77 24 97.3 

Average value of 13 non-revised videos 2.17 34.4 75.0 

3. DISCUSSIONS: EMPIRICAL RESULTS 
Videos in an online course “Interactive Online Learning” from the 

University of Hong Kong has been investigated. The course aims 

at teaching teachers designing online teaching. 71 learners accessed 

21 videos 931 times in Cohort 1 (April 2016). After revisions, 58 

learners accessed 23 videos 772 times in Cohort 2 (August 2016).  

3.1 Observations from Cohort 1 for Revisions 
i) Although the survey results of Session 3 (MOOC) of the 

course are satisfactory, videos in Session 3 have not been 

widely watched by all learners, as shown in Table 1(a). For 

example, 46% of learners had dropped the video within the 

first 24 seconds. Therefore, we believed that engaging 

learners, who had responded to surveys, may found this topic 

useful. But for most learners, the session about MOOC may 

not be relevant to their teaching environments. Therefore, we 

have cancelled Session 3, through removing Video 3.1 and 

moving Videos 3.2 and 3.3 to other sessions. 

ii) Moments with abnormal video browsing behaviors have been 
identified. For example, in Video 4.3, there was an abnormal 

retention peak at 1:10, as shown in Fig. 1(a). We believe that 

there was inappropriate zooming of figures in the video, 

showing too much unnecessary information at that moment. 

Therefore, we changed the zooming effect of figures and 

omitted unnecessary on-screen information. 

iii) Video retention rate in Video 1.3 starts to drop at 2:44. If we 
look closely on the content, the rest of the video focuses on the 

advanced video production skills. This drop in the retention 

rate makes sense since we assessed the basic video production 

skills only. This insight was further confirmed through the 

face-to-face discussion. Therefore, we decided to separate 

Video 1.3 into three components in Cohort 2 (See Table 1(b)). 

3.2 Evaluations of Revisions in Cohort 2 
Effectiveness of data-assisted video revisions can be checked by 

the video usage in Cohort 2, as shown in Table 1(b). Retention rate 

of videos without revision has been increased by 38.6% only. 

Meanwhile, retention rate of videos with data-assisted revisions has 

been increased by 56.1%. We believed retention rates have been 

improved through restructuring videos. Also, an example of content 

revision based on video retention graph is also shown in Fig. 1(b). 

After revisions, the abnormal retention peak has disappeared, with 

a consequence of higher video retention rate in the latter part of the 

video, due to smooth and coherent learning experience. Based on 

the learner surveys conducted in both Cohorts 1 and 2, the course 

effectiveness has improved from 3.9 to 4.29. Thus, we believed that 

revisions of videos helped students learn better in the course. 

4. FUTURE WORK 
In the future, we aim to include more data samples for an in-depth 

statistical analysis, and include more metrics (e.g., amounts, origins 

and destinations of replays) for a more comprehensive analysis. 

(a) 

 

(b) 

 

Figure 1. Video retention of a lecture video against time: (a) 

Problematic video in Cohort 1, with atypical browsing 

behaviors, in 1:10, and (b) Revised video in Cohort 2, with the 

moment showing the same content indicated by a vertical line. 

5. REFERENCES 
[1] Zhang, D., et al. 2006. Instructional video in e-learning: 

Assessing the impact of interactive video on learning 

effectiveness. Information & Management, 43, 1, 15-27. 

[2] Ho, A. D., et al. 2015. Harvardx and MITx: Two years of open 
online courses (Fall 2012-Summer 2014). Available at SSRN 

2586847. 

[3] Kim, J., et al. 2014. Understanding in-video dropouts and 
interaction peaks in online lecture videos. In Proceedings of 

ACM Conf. on Learning@Scale Conf. ACM. 31-40. 

[4] Swarts, J. 2012. New modes of help: Best practices for 
instructional video. Technical Comm., 59, 3, 195-206. 

[5] Li, N., Kidzinski, et al. 2015. How Do In-video Interactions 
Reflect Perceived Video Difficulty?. In Proc. European 

MOOCs Stakeholder Summit 2015. PAU Education, 112-121. 



