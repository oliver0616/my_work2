
Modeling Common Misconceptions in Learning Process Data 
Ran Liu 

Carnegie Mellon University 
5000 Forbes Avenue 
Pittsburgh, PA 15201 
ranliu@cmu.edu 

Rony Patel 
Carnegie Mellon University 

5000 Forbes Avenue 
Pittsburgh, PA 15201 

rbpatel@andrew.cmu.edu 

Kenneth R. Koedinger 
Carnegie Mellon University 

5000 Forbes Avenue 
Pittsburgh, PA 15201 

koedinger@cmu.edu 
 
 

ABSTRACT 
Student mistakes are often not random but, rather, reflect 
thoughtful yet incorrect strategies. In order for educational 
technologies to make full use of students’ performance data to 
estimate the knowledge of a student, it is important to model not 
only the conceptions but also the misconceptions that a student’s 
particular pattern of successes and errors may indicate. The 
student models that drive the “outer loop” of Intelligent Tutoring 
Systems typically do not represent or track misconceptions. Here, 
we present a method of representing misconceptions in the 
Knowledge Component models, or Q-Matrices, that are used by 
student models to estimate latent knowledge. We show, in a case 
study on a fraction arithmetic dataset, that incorporating a 
misconception into the Knowledge Component model 
dramatically improves the overall model’s fit to data. We also 
derive qualitative insights from comparing predicted learning 
curves across models that incorporate varying misconception-
related parameters. Finally, we show that the inclusion of a 
misconception in the Knowledge Component model can yield 
individual student estimates of misconception strength that are 
significantly correlated with out-of-tutor measures of student 
errors. 

CCS Concepts 
• Applied computing ? Computer-managed instruction 
• Applied computing ? Computer-assisted instruction 

Keywords 
Misconceptions; Knowledge Component Model; Additive Factors 
Model; Q-Matrix; Fraction Arithmetic 

1. INTRODUCTION 
Many meaningful learning experiences result from making 
mistakes and receiving useful feedback. In order for educational 
technologies to fully capitalize on mistakes as opportunities for 
learning, it is important to understand and model the underlying 
factors that give rise to common mistakes. Sometimes, errors 
reflect a simple lack of knowledge about how to solve the 
problem (i.e., if the student asks for a hint or makes a random 
guess). But, often, students make errors that reflect a thoughtful 

yet incorrect strategy. 

Intelligent Tutoring Systems have typically taken common 
mistakes and misconceptions into consideration when 
constructing the activities of the “inner loop” [21]. For example, 
on any given problem, performing a common error that is tagged 
to result from a “buggy rule” will trigger an immediate bug 
message that specifically addresses the misconception. However, 
as Intelligent Tutoring Systems span multiple problems and 
topics, the “outer loop” is what keeps track of students’ 
knowledge of various skills over time, across different problems, 
and uses these estimates to adaptively select problems. The 
longer-term student models that drive the “outer loop” typically 
do not represent or track misconceptions when estimating latent 
knowledge. 

This is largely due to the limited state-of-the-art methods for 
mapping Knowledge Components (KCs)—the underlying facts, 
skills, and concepts required to solve problems [10]—to actual 
problem steps. This mapping is called a Knowledge Component 
(KC) model and is an essential part of how the student model 
tracks knowledge. Currently, any given KC can only be positively 
mapped to performance on a problem step. As a result, student 
models can only track long-term estimates of the degree to which 
students have knowledge that positively contributes to problem 
step success. While misconceptions sometimes lead to the correct 
answer on certain problem steps for the wrong reason, they lead to 
incorrect responses on others. Thus, the current structure of KC 
models cannot accommodate an estimate of misconception 
activation. 

Existing research in psychometrics has produced some methods 
for assessing and modeling student errors and misconceptions [7, 
13, 20]. These models, however, only apply to static performance 
data and do not model the evolution of misconception strength 
over time, as learning unfolds. Thus, they miss out on capturing 
the temporal richness that is present in learning process data [6]. It 
is also not yet clear how these psychometric modeling techniques 
can be integrated with the student models that drive adaptive 
problem selection in Intelligent Tutoring Systems. 

Here, we present a method of representing misconceptions within 
KC models. When combined with a statistical model, these 
expanded KC models allow us to (1) estimate the overall strength 
of a particular misconception within a dataset and (2) 
microgenetically [19] estimate the evolving strength of a 
misconception as learning unfolds across the dataset. In a case 
study, we apply this misconception modeling method to a fraction 
arithmetic dataset. We evaluate how the addition of a 
misconception to the KC model improves the overall student 
model’s fit to data. We also interpret the qualitative insights that 
emerge from explicitly modeling this misconception and the 
unique instructional implications of our results. Finally, we show 
that explicitly representing a misconception in a KC model allows 

Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. Copyrights 
for components of this work owned by others than ACM must be 
honored. Abstracting with credit is permitted. To copy otherwise, or 
republish, to post on servers or to redistribute to lists, requires prior 
specific permission and/or a fee. Request permissions from 
Permissions@acm.org.  
LAK '16, April 25-29, 2016, Edinburgh, United Kingdom  
© 2016 ACM. ISBN 978-1-4503-4190-5/16/04…$15.00  
DOI: http://dx.doi.org/10.1145/2883851.2883967 



us to estimate individual student-level misconception strengths, 
and we validate these estimates using students’ out-of-tutor 
performance data. 

2. BACKGROUND 
2.1 Intelligent Tutoring Systems 
Intelligent Tutoring Systems work by guiding students through a 
sequence of instructional activities (i.e., problems) in an outer 
loop, while monitoring progress on students’ activities and 
providing just-in-time feedback and hints within an inner loop 
[21]. Many Intelligent Tutoring Systems accommodate common 
mistakes and misconceptions in the activities of the inner loop. 
That is, errors that result from misconceptions can be identified in 
the inner loop and lead to bug messages that immediately and 
specifically address the misconception that the error is linked to. 

The long-term student models [6] that power the outer loop of 
Intelligent Tutoring Systems, however, typically do not track 
misconceptions or any type of skill that could negatively impact 
performance on certain problem steps. Since Intelligent Tutoring 
Systems typically span multiple problems and topics, student 
models keep an ongoing estimate of students' knowledge of 
various skills, concepts, and facts (referred to here as Knowledge 
Components, or KCs [10]) over time. Intelligent tutors use these 
estimates to select problems that give students more practice on 
the KCs that need it. The space of KCs within a tutor or dataset is 
defined and mapped to problem steps by a Knowledge 
Component (KC) model. The current state of KC modeling is that 
any given KC can only be positively mapped to performance on a 
problem step. Student models that utilize these KC models cannot 
keep estimates of, or attribute performance to, students’ 
misconceived knowledge. Consequently, they cannot use such 
information to influence problem selection in the long-term, outer 
loop of Intelligent Tutors. 

Estimating the strength of common misconceptions in existing 
educational datasets and discovering the instructional conditions 
or experiences that may strengthen or weaken them is an 
important endeavor in its own right. Yet, current approaches to 
educational data mining have not explicitly represented 
misconceptions (or any type of KC that can negatively affect a 
problem step outcome) in the development and refinement of KC 
models. 

Bayesian Knowledge Tracing, a special case of using Hidden 
Markov Models to model student knowledge as a latent variable, 
is commonly used to drive the outer loop of Intelligent Tutors. A 
different, logistic regression-based model known as the Additive 
Factors Model (AFM) [4] is more commonly used towards 
evaluating, discovering, and refining KC models [11, 12]. 
Because the primary goal of the present paper was to expand the 
flexibility of KC modeling to incorporate a misconception KC, we 
focus on using the Additive Factors Model to conduct our 
investigation and model evaluations. 

2.2 The Additive Factors Model 
AFM is a logistic regression model that extends item response 
theory by incorporating a growth or learning term. This statistical 
model (Equation 1) gives the probability !"# that a student i will 
get a problem step j correct based on the student’s baseline ability 
($"), the baseline difficulty (%&) of the required KCs on that 
problem step ('#&), and the improvement ((&) in each of the 
required KCs with each additional practice opportunity multiplied 
by the number of practice opportunities ()"&) the student has had 
with that KC prior to the current problem step [4]. 

ln , -./01-./2 = $" + ? '#&(%&&?89: + (&)"&)  (1) 
The KC model, otherwise known as the Q-Matrix [3, 20], is 
represented by Qjk. The parameter Qjk takes on a value of 1 if the 
KC k is required for problem step j and a value of 0 if it is not. 

2.3 Knowledge Component Models 
Log data resulting from student use of Intelligent Tutors contain 
information on student attempts on a series of problem steps. Each 
of these problem steps can be tied to one or more Knowledge 
Components (KCs). This mapping of problem steps to KCs is 
accomplished by a KC model. 

KC models are an important basis for the instructional design of 
automated tutors and for accurate assessments of learning. 
Improvements to KC models, when combined with an appropriate 
theoretical interpretation, lead to better predictions of what a 
student knows, thus resulting in better assessment and more 
efficient learning overall [12]. 

The current state of KC modeling is that any given KC can only 
be positively mapped to performance on a problem step. That is, 
the KC model representation contains a 1 for any KC that 
contributes to success on a problem step and a 0 for any KC that 
does not. Thus, student models cannot track long-term estimates 
of students’ misconceived concepts or procedures. Furthermore, 
there is no way to include analyses of misconceptions as part of 
manual [12] or automated [11] KC model discovery and 
refinement. Here, we proposed a way of expanding the flexibility 
of KC modeling to include misconceptions and other 
misconception-like KCs. 

3. MODELING MISCONCEPTION KCs 
Our proposed method for modeling misconceptions as KCs is to 
map them to problem steps to which they could apply, the way 
that regular KCs are, but to utilize -1 in addition to 1 and 0 
coding. A misconception is coded as 1 for problem steps on which 
applying it yields the correct answer and as -1 for problem steps 
on which applying yields an incorrect answer. Problem steps for 
which the misconception does not apply are coded as 0. For 
example, suppose a student was completing problems asking for 
the Least Common Multiple of two numbers and he/she had a 
misconception that one always finds the Least Common Multiple 
by taking the product of the two numbers. There are some cases in 
which this strategy will yield the right answer (e.g., find the Least 
Common Multiple of 5 and 9) albeit for the wrong “reason”, and 
for these problem steps the misconception KC is coded as a 1. 
There are other cases in which this strategy will yield the wrong 
answer (e.g., find the Least Common Multiple of 4 and 12), and 
for these steps it is coded as a -1. 

For regular KCs that represent positive skills and concepts, the 
effect of prior practice opportunities is relatively straightforward 
to count for the purposes of modeling. Any problem step on which 
a regular KC is tagged constitutes a practice opportunity for that 
KC. For misconception KCs, it is less obvious how to count 
“practice opportunities”. Any problem step tagged as -1 by the 
misconception KC is an opportunity to make a misconception-
driven error and, as such, could weaken the misconception upon 
receiving negative feedback. Conversely, any problem step tagged 
as a 1 by the misconception KC is an opportunity to yield a 
misconception-driven correct answer. As such, it could strengthen 
the misconception due to the student receiving positive feedback 
for applying it. In the present modeling approach, we treated 



opportunities to weaken a misconception and opportunities to 
strengthen a misconception as separate parameters to allow them 
to be weighted differently. 

In the following case study, we apply these methods to model a 
well-documented misconception in fraction arithmetic. We create 
a KC to represent how this misconception should affect 
performance outcomes on different problem steps. We then 
compare the following three models: (1) AFM with the Original 
KC Model, (2) AFM with the original KCs plus an added 
misconception KC intercept (termed the Misconception KC 
Model), and (3) AFM with the original KCs plus both a 
misconception KC intercept and opportunity-driven weights on 
the misconception KC (termed the Opportunity-Weighted 
Misconception KC Model). We compare the models in terms of 
how well they predict student performance in the dataset. We also 
offer qualitative interpretations of how the model predictions are 
changed by the additions of a misconception KC intercept and 
opportunity-driven misconception KC weights, respectively.  

4. CASE STUDY: MODELING A 
MISCONCEPTION IN FRACTION 
ARITHMETIC LEARNING 
4.1 The Fraction Arithmetic Dataset 
In order to explore whether modeling a misconception as a KC in 
the method described in Section 3 can improve a model’s 
predictive fit to real data and yield interpretable insights, we 
applied the method to a subset of a fraction arithmetic dataset 
[16], available from the PSLC DataShop [9]. In this subset, 40 
students experienced various fraction arithmetic problem types in 
a mixed, or interleaved, order. Each student completed 24 
problems in which they multiplied fractions (Multiply), 10 
problems in which they added fractions with same denominators 
(AddSameDen), and 14 problems in which they added fractions 
with different denominators (AddDiffDen). Figure 1 shows the 

interface that students saw for each problem type. 

The specific misconception that we modeled here is an incorrect 
strategy that students commonly apply to fraction arithmetic 
problems known as the Independent Whole Number Strategy [8, 
15]. In this strategy, students simply apply the operator to the two 
numerators to generate the numerator of the solution and apply the 
operator to the two denominators to generate the denominator of 
the solution. For example, given a problem like 0< +

<
=, the 

Independent Whole Number Strategy yields an incorrect answer 
of =>. In some cases, like in fraction multiplication problems (e.g., 
0
?  

=
>	), it yields the correct answer (	

=
<"	). 

For our baseline KC model, we used one that was generated by 
hand by a domain expert. The way these KCs map to the different 
problem steps in the dataset is shown in Table 1 (under the 
“Regular KCs” heading). Here, problem steps map directly onto 
the interface elements present in the fraction arithmetic tutor 
(Figure 1).  The Convert-Checkbox KC represents the skill of 
knowing when one does or does not need to convert the 
denominators to a common denominator. There is a KC for 
knowing and carrying out the procedures for each of the three 
problem types (Multiply, AddSameDen, and AddDiffDen). 
Finally, there are two additional KCs that are required for certain 
problem steps in AddDiffDen problems. These skills are finding 
the least common denominator (LCD) and finding equivalent 
fractions (i.e., filling in the numerators correctly after computing 
the LCD). They were tagged for the problem steps involving the 
fractions in the top row of Figure 1d, because they are skills that 
are more complex than simply operating on whole numbers or 
copying numbers. 

4.2 The IWNS Misconception KC 
The misconception KC was coded to predict what the outcomes 
would be for each problem step if students were simply applying 
the Independent Whole Number Strategy. It is coded as 1 for 

Figure 1: Example interfaces for the fraction arithmetic tutor: (a) AddSameDen problems,
(b) Multiply problems, (c) AddDiffDen problems before the student checks the box to convert, and (d) 
AddDiffDen problems after the student checks the box to convert. 



problem steps on which applying the Independent Whole Number 
Strategy yields the correct answer and -1 for problem steps on 
which applying it yields the incorrect answer. Problem steps for 
which it does not apply are coded as 0. 

The IWNS happens to yield the correct numerator and 
denominator for Multiply problems. Thus, it is coded as 1 for 
those Multiply problem steps. It happens to yield the correct 
numerator but the wrong denominator for AddSameDen 
problems. For example, applying the strategy to the problem 0# +<
#		yields 

=
0<, whereas the correct answer should be 

=
#. Thus, it’s 

coded as 1 for the AddSameDen numerator but -1 for the 
AddSameDen denominator. Applying the strategy yields the 
wrong answer for both the initial numerator and denominator of 
AddDiffDen problems (top row, left fraction), so it’s coded as -1 
for those steps. In an AddDiffDen problem (e.g., 0? +

>
#	), once the 

student has computed the least common denominator (12) and the 

equivalent fractions containing that denominator (	 =0< +
0"
0<	), 

applying the strategy to the two equivalent fractions yields the 
correct final numerator (13) but the incorrect final denominator 
(24). Thus, the correct final numerator of an AddDiffDen problem 
is coded as 1 and the correct final denominator is coded as -1. 

Finally, applying the strategy typically involves bypassing the 
conversion checkbox, which happens to be the correct move for 
Multiply and AddSameDen problems (coded as 1 for the Convert-
Checkbox step on those problems) but incorrect for AddDiffDen 
problems (coded as -1 for the Convert-Checkbox step on those 
problems). 

4.3 Model Comparison Results 
We fit the Additive Factors Model with different KC models to 
the data and evaluated relative model fit using the Akaike 
Information Criterion (AIC) and the Bayesian Information 
Criterion (BIC). Both criteria are likelihood-based measures of 

 
Table 1: Representation of how the Regular KCs and the IWNS Misconception KC map to the different problem steps in the 
dataset. 



predictive fit that penalize for model complexity. AIC, in 
particular, is known to be asymptotically equivalent to cross-
validation [2]. For both criteria, lower numbers indicate a better 
relative model fit. Models were fit using the glmer() function from 
the lme4 package in R [18]. 

We first fit the Original KC Model (AFM with the 6 regular KCs 
only). The model fit the data with an AIC of 4238 and a BIC of 
4328. Its parameters estimates are shown in Table 2. For each KC, 
the first line shows the intercept estimates (the baseline easiness 
of the KC) and the subsequent line shows the slope estimates 
(how much students improve on that KC with each additional 

practice opportunity). In this model, all slope estimates are 
positive and statistically significant at p < 0.05, indicating general 
improvement on all KCs as students progressed through the tutor. 

We then fit the Misconception KC Model (AFM with the regular 
KCs plus an intercept for the IWNS Misconception KC). The 
IWNS Misconception KC intercept estimates the overall strength 
of the misconception throughout the tutor. In this model, there 
was no parameter allowing the strength of the misconception to 
change across practice opportunities. This model fit the data with 
an AIC of 4119 and a BIC of 4216. The drop in these values 
indicates a major improvement in model fit with the addition of an 

 
Table 2: Coefficient estimates and p-values for the three models, which differed in their inclusion of misconception KC 
related parameters. Misconception KC related parameter estimates are bolded and italicized. 



intercept parameter for the IWNS Misconception KC. An 
ANOVA chi-square test between the Original KC Model and the 
Misconception KC Model showed that the Misconception KC 
Model was a significantly better fit to data (p < 0.0001). 

The parameters estimates of the Misconception KC Model are 
shown in Table 2. The coefficient estimate for the IWNS 
Misconception KC intercept was 0.626 and was a significant 
predictor (p < 0.0001). Thus, the model estimates that the IWNS 
misconception was a significant contributor to explaining 
performance across students’ use of the fraction arithmetic tutor. 

The comparison between the Original KC Model and the 
Misconception KC Model predictions, aggregated across students 
and plotted separately for each regular KC, is shown in Figure 2. 
Differences between the models’ predictions are observed for the 
Convert-Checkbox, AddSameDen Procedure, AddDiffDen 
Procedure, and Find Equivalent Fraction KCs. These are the KCs 
for which the IWNS Misconception KC makes divergent 
predictions about performance (i.e., has -1 or 0 on problem steps 
where the regular KC predicts 1). 

In particular, the Misconception KC Model predicted specifically 
poor performance on the top row left-fraction numerator, relative 
to performance on the top row right-fraction numerator, in 

AddDiffDen problems. The Original KC Model predicted 
equivalent performance on these two problem steps because they 
involve application of the same positive skill (finding an 
equivalent fraction). The divergence in these two models’ 
predictions is evident in the smooth vs. jagged prediction lines for 
the Find Equivalent Fraction KC (Figure 2). The Misconception 
KC Model’s prediction line is jagged because the top row left-
fraction numerator, on which it predicts worse performance, 
constitutes every other problem step for the Find Equivalent 
Fraction KC. 

Finally, we fit the Opportunity-Weighted Misconception KC 
Model (AFM with the regular KCs, an IWNS Misconception KC 
intercept, and separate slopes reflecting the influence of 
opportunities to strengthen vs. opportunities to weaken the 
misconception. This model fit the data with an AIC of 4093 and a 
BIC of 4203. The further drop in these values reflects an 
improvement in the fit of this model, even compared to The 
Misconception KC Model. An ANOVA chi-square test between 
the models showed that the Opportunity-Weighted Misconception 
KC Model was a significantly better fit than the Misconception 
KC Model (p < 0.0001). 

The parameters estimates of the Opportunity-Weighted 
Misconception KC Model are shown in Table 2. The coefficient 

Figure 2:  A comparison between the Original KC Model (thicker blue line) predictions and the Misconception KC Model 
predictions (thinner red line). The thin, dotted black line represents the actual data, aggregated across students and plotted 
for each regular KC. Points at which the model predictions diverge reflect problem steps where the IWNS Misconception 
KC predicts different performance than the regular KCs do. 



estimate for the IWNS Misconception KC intercept was 0.366 and 
was a significant predictor at p < 0.0001). The coefficient estimate 
for opportunities to strengthen the misconception was 0.038 and 
was significant at p < 0.0001. This reflects an increase in the 
weight of the misconception with each additional opportunity on 
which applying it yields the correct answer, thus creating positive 
feedback for the misconception. The coefficient estimate for 
opportunities to weaken the misconception was -0.052 and was 
significant at p < 0.0001. This reflects a decrease in the weight of 
the misconception with each additional opportunity to apply it, 
yield an incorrect answer, and receive negative feedback. These 
coefficient estimates are consistent with our intuitions about the 
effect of different types of practice opportunities on strengthening 
and weakening the misconception. 

Although the predictions of the Misconception KC Model and the 
Opportunity-Weighted Misconception KC Model are similar, the 
intensity of the effects on predicted performance is modulated 
across opportunity counts in the latter model. Sometimes the 
effects of the misconception are more extreme in the Opportunity-
Weighted Misconception KC Model, likely reflecting the local 
effects of opportunities to strengthen the misconception. At other 
points, the effects of the misconception are milder, likely 
reflecting the local effects of opportunities to weaken the 
misconception. 

4.4 Individual Differences in Misconception 
Weighting 
One of the more interesting applications of modeling 
misconceptions is the potential to detect individual student-level 
misconception “weights”—that is, to discover differences in the 
degree to which individuals have this misconception. Here, we 
test the ability of our misconception modeling method to detect 
these differences. We then validated the model’s estimates against 
individual students’ proportion IWNS errors in their pre-test 
scores. Previous evidence shows that fitting slopes to individual 
students leads to overfitting in the Additive Factors Model [14]. 
Thus, here we focused on modeling individual student-level 
misconception intercepts only. 

To this end, we extended the Misconception KC Model to not 
only include an overall intercept for the IWNS Misconception KC 
but an additional separate intercept for the misconception for each 
student, modeled as a random effect. We then examined the 
relationship between individual students’ estimated misconception 
intercepts and the proportion of their overall errors that were 
IWNS errors at pre-test. 

A Spearman’s correlation between the model’s individual student 
estimates for the IWNS Misconception KC intercept and their 
proportion of IWNS errors at pre-test was statistically significant 
(R=0.46, p=0.002). This provides evidence that the model can 
produce externally valid estimates of the degree to which each 
student is likely to have a particular misconception. 

4.5 Summary & Discussion 
In the present case study, we fit the Additive Factors Model with 
differing KC models to data from a fraction arithmetic tutor. In 
particular, we examined the effects of adding a misconception to 
the KC Model, or Q-Matrix. Here, the Independent Whole 
Number Strategy (IWNS) Misconception KC was coded as 1 for 
any problem steps on which applying the IWNS yields the correct 
answer and coded as -1 for any problem steps on which applying 
the IWNS yields the incorrect answer. 

Results showed that adding an intercept for this IWNS 
Misconception KC improved the model’s fit to data, as evidence 
by a significant drop in model likelihood (with significance 
assessed via ANOVA chi-square tests), even after controlling for 
adding a parameter. Qualitative analyses of the problem steps on 
which the Original KC Model and the Misconception KC Model 
diverge in their predictions show that explicitly modeling a 
misconception KC can yield different instructional implications. 
For example, in AddDiffDen problems, the Misconception KC 
Model selectively predicts poor performance on the top row left-
fraction numerator but not the top row right-fraction numerator. 
The Original KC Model predicted equivalent performance on 
these two problem steps because they involve application of the 
same positive skill, finding an equivalent fraction. The critical 
insight is that the Original KC Model and Misconception KC 
Model differentially attribute the cause of errors on the top row 
right-fraction numerator, and the different causes imply different 
instructional strategies. The Original KC Model attributes the 
errors to a student’s lack of ability to fill in the numerator by 
finding the fraction equivalent to the one given in the problem. 
Based on this, an instructional implication might be to give the 
student further practice on finding equivalent fractions. The 
Misconception KC Model, on the other hand, would attribute the 
errors to the presence of the IWNS misconception. Based on this, 
an instructional implication might be to explicitly draw the 
student’s attention to their misconception and explain why it’s ill 
conceived. 

Adding parameters to separately estimate the influence of 
opportunities to strengthen and opportunities to weaken the 
misconception also significantly improved model fit beyond just 
including the KC intercept. The model’s parameter estimates 
showed that opportunities to strengthen the misconception did 
significantly increase its weight, and opportunities to weaken the 
misconception did significantly decrease its weight. Based on this, 
one instructional implication might be to ensure that students do 
not receive too many opportunities in a row that can potentially 
strengthen the misconception before intervening with 
opportunities that can potentially weaken it. 

Finally, we extended the model to estimate individual student 
IWNS Misconception KC intercepts. The extended model yielded 
coefficient estimates that were significantly correlated with 
students’ proportion of IWNS errors at pre-test. This shows that 
this method of modeling misconceptions can produce externally 
valid estimates of the degree to which each student is likely to 
have a particular misconception. 

5. GENERAL DISCUSSION 
We have demonstrated a method of explicitly representing 
misconceptions in KC models and illustrated some of the potential 
benefits of doing so. In the fraction arithmetic case study, 
explicitly modeling a misconception allowed the 
disproportionately high number of errors in the top row left-
fraction numerator of AddDiffDen problems to be attributed to the 
IWNS misconception as opposed to a difficulty with finding 
equivalent fractions. This changes the implications for instruction, 
which may then be targeted towards alleviating or inhibiting the 
misconception rather than giving students more practice on 
finding equivalent fractions. 

This method of incorporating misconception KCs into a KC 
model, or Q-Matrix, makes it possible for the student model that 
drives the outer loop of Intelligent Tutors to track not only 
positive skills and concepts but also ill-conceived skills and 



concepts. This may affect the way an Intelligent Tutor adaptively 
selects problems. For example, if a student has a high estimated 
misconception weight, the tutor might selectively give him/her 
more practice opportunities in which applying the misconception 
results in negative feedback, to “weaken” the misconception. 
Alternatively, the tutor might adaptively present erroneous 
worked examples [1] of the associated misconceptions. 

This method allows for a direct assessment of the strength of a 
misconception within an instructional condition, as well as for 
individual students (as shown in Section 4.4). It also allows us to 
assess changes in the strength of that misconception with learning. 

More generally, this modeling method contributes significantly to 
learning analytics by extending the flexibility of KC modeling. It 
incorporates the ability to use 1 and -1 coding within a single KC 
to model the ability for a (mis)conception to have both positive 
and negative effects, depending on the problem step. In future 
work, misconception-like KCs could also be discovered and 
refined through automated, data-driven methods like Learning 
Factors Analysis [4, 11]. Standardizing the use of misconception-
like KCs in educational data mining workflow tools such as those 
available in DataShop [9] could be a pathway to enhancing KC 
model development. 

There are, however, some interesting limitations to the present 
method of misconception KC modeling. In order for a logistic 
regression model such as AFM to reasonably fit using both 
regular and misconception KCs, the misconception KCs must 
predict a pattern of performance that is unique from any that can 
be formed by linearly combining the predictions of regular KCs in 
the existing KC model. This often requires data with a detailed 
grain size. In the case study presented here, the high level of detail 
came from tracking the correctness of student actions at every 
unique location in the fraction arithmetic interface. This allowed 
for the misconception KC to generate a unique set of predictions 
across problem steps that no linear combination of regular KCs’ 
predictions could reproduce. This is what allows the model to 
attribute performance patterns to a misconception KC rather than 
capturing it via a particular combination of the regular KCs in the 
original KC model. It is also for this reason that we attempted 
only to model one misconception within this dataset. Each 
additional misconception KC that is added to the model creates 
more challenges for the proper attribution of performance 
patterns. Other than the Independent Whole Number Strategy, 
which account for approximately 25% of all numeric (i.e., non-
hint-request) errors in the process data, we did not find evidence 
that any other common fraction arithmetic misconceptions 
accounted for a significant proportion of errors. Thus, we focused 
on modeling the most common misconception KC here as a proof 
of concept. Future work that models multiple misconceptions, on 
datasets with appropriately detailed performance information for 
reasonable attribution to both conceptions and misconceptions, 
will be fruitful. 

The level of detail required to uniquely differentiate conceptions 
from misconceptions could also come from explicitly modeling 
the specific errors that students make (i.e., what incorrect number 
they tried on their attempt at a problem step). Popular student 
models such as Bayesian Knowledge Tracing (and its many 
contemporary variants), the Additive Factors Model, and the 
Performance Factors Model [17] typically estimate only binary 
outcomes, with no differentiation among incorrect responses. An 
interesting line of further research would be to extend student 
models to better capture different error types. This would allow 

for better attribution of errors to the appropriate KCs from which 
they are generated. 

Logistic regression models such as AFM may also be sub-optimal 
in the way they attribute both success and failure on problem steps 
on which there are multiple KCs tagged [5]. Although this can 
lead to misattribution for any kind of KC, it may especially be 
problematic for the attribution of success/failure to regular vs. 
misconception KCs. For example, when a student gets any one of 
the three Multiply problem steps correct, AFM will attribute this 
success equally to the positive “Multiply” KC and the IWNS 
Misconception KC. However, this intuition seems incorrect. Most 
likely, the success should be primarily attributed to either the 
positive “Multiply” KC or the IWNS Misconception KC. A 
Bayesian model that can attribute successes and failures to KCs 
probabilistically, depending on the relative estimated strength of 
each possible KC, may better capture this intuition. This is a 
worthwhile endeavor for future research. 

6. ACKNOWLEDGMENTS 
This work was supported in part by a Program in Interdisciplinary 
Education Research (PIER) Post-doctoral Training Grant 
(#R305B110003) awarded to RL, and a PIER Pre-doctoral 
Training Grant (#R305B090023) awarded to RP. Both sources of 
funding are supported by the US Department of Education. 

7. REFERENCES 
[1] Adams, D., McLaren, B. M., Durkin, K., Mayer, R. E., 

Rittle-Johnson, B., Isotani, S., & Van Velsen, M. (2014). 
Using erroneous examples to improve mathematics learning 
with a web-based tutoring system. Computers in Human 
Behavior, 36, 401-411. 

[2] Akaike, H. (1985). Prediction and entropy. In Atkinson, A. & 
Fienberg, S., (Eds.), A Celebration of Statistics. Springer: 
New York, 1–24. 

[3] Barnes, T. (2005). The Q-matrix Method: Mining Student 
Response Data for Knowledge. Proceedings of AAAI 2005: 
Educational Data Mining Workshop. 

[4] Cen, H., Koedinger, K. R., & Junker, B. (2006). Learning 
Factors Analysis: A general method for cognitive model 
evaluation and improvement. Proceedings of the 8th 
International Conference of Intelligent Tutoring Systems, 
164-175. 

[5] Cen, H., Koedinger, K. R., Junker, B. (2008). Comparing 
two IRT models for conjunctive skills. Proceedings of the 
9th International Conference of Intelligent Tutoring Systems. 

[6] Corbett, A. T., & Anderson, J. R. (1995). Knowledge 
Tracing: Modeling the Acquisition of Procedural 
Knowledge. User Modeling and User-Adapted Interaction, 
4, 253-278. 

[7] Embretson, S.E., & Reise, S.P. (2000). Item Response 
Theory for Psychologists. Mahwah, NJ: Erlbaum. 

[8] Gelman, R., & Williams, E. (1998). Enabling constraints for 
cognitive development and learning: Domain specificity and 
epigenesis. In D. Kuhn and R. Siegler, (Eds.), Cognition, 
perception and language. Vol. 2. Handbook of Child 
Psychology. New York: John Wiley and Sons, 575-630. 

[9] Koedinger, K. R., Baker, R. S. J. d., Cunningham, K., 
Skogsholm, A., Leber, B., & Stamper, J. (2010). A Data 
Repository for the EDM community: The PSLC DataShop. 
In Romero, C., Ventura, S., Pechenizkiy, M., Baker, R.S.J.d. 
(Eds.) Handbook of Educational Data Mining. Boca Raton, 
FL: CRC Press. 



[10] Koedinger, K.R., Corbett, A.C., & Perfetti, C. (2012). The 
Knowledge-Learning-Instruction (KLI) framework: Bridging 
the science-practice chasm to enhance robust student 
learning. Cognitive Science, 36(5), 757-798. 

[11] Koedinger, K. R., McLaughlin, E. A., & Stamper, J. C. 
(2012). Automated Student Model Improvement. 
Proceedings of the 5th International Conference on 
Educational Data Mining. 

[12] Koedinger, K. R., McLaughlin, E. A., Stamper, J. C., & 
Nixon, T. (2013). Using data-driven discovery of better 
student models to improve student learning. Proceedings of 
the 16th International Conference on Artificial Intelligence 
in Education. 

[13] Kulikowich, J. M., & Alexander, P. A. (1994). Evaluating 
students’ errors on cognitive tasks: Applications of 
polytomous Item Response Theory and log-linear modeling.  
In Reynolds, C. R. (Ed.), Cognitive Assessment: A 
Multidisciplinary Perspective. New York, NY: Springer 
Science, 137-154. 

[14] Liu, R., & Koedinger, K. R. (2015). Variations in learning 
rate: Student classification based on systematic residual error 
patterns across practice opportunities. Proceedings of the 8th 
International Conference on Educational Data Mining. 

[15] Ni Y., & Zhou, Y. D. (2005). Teaching and learning fraction 
and rational numbers: the origins and implications of whole 
number bias. Educational Psychologist, 40, 27–52. 

[16] Patel, R. Fraction Addition and Multiplication. 
pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=1190. 

[17] Pavlik, P. I., Jr., Cen, H., & Koedinger, K. R. (2009). 
Performance factors analysis – A new alternative to 
knowledge tracing. Proceedings of the 14th International 
Conference on Artificial Intelligence in Education, 531–538. 

[18] R Core Team (2013). R: A language and environment for 
statistical computing. R Foundation for Statistical 
Computing, Vienna, Austria. http://www.R-project.org/. 

[19] Siegler, R. S., & Crowley, K. (1991). The microgenetic 
method: a direct means for studying cognitive development. 
American Psychologist, 46(6), 606–620. 

[20] Tatsuoka, K. K. (1983) Rule space: An approach for dealing 
with misconceptions based on item response theory. Journal 
of Educational Measurement, 20, 345-354. 

[21] Van Lehn, K. (2006). The behavior of tutoring systems. 
International Journal of Artificial Intelligence in Education, 
16, 227-265.

 



