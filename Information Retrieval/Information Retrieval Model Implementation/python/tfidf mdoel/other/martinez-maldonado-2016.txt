
Interactive Surfaces and Learning Analytics: Data, 
Orchestration Aspects, Pedagogical Uses and Challenges 

Roberto Martinez-Maldonado1, Bertrand Schneider2,  
Sven Charleer3, Simon Buckingham Shum1, Joris Klerkx3, Erik Duval3 

1University of Technology Sydney, Australia  
{roberto.martinez-maldonado, 

simon.buckinghamshum}@uts.edu.au 

2Stanford University, USA 
schneibe@stanford.edu 

3KU Leuven, Belgium  
{sven.charleer, joris.klerkx, 
erik.duval}@cs.kuleuven.be   

ABSTRACT 
The proliferation of varied types of multi-user interactive surfaces 
(such as digital whiteboards, tabletops and tangible interfaces) is 
opening a new range of applications in face-to-face (f2f) contexts. 
They offer unique opportunities for Learning Analytics (LA) by 
facilitating multi-user sensemaking of automatically captured 
digital footprints of students’ f2f interactions. This paper presents 
an analysis of current research exploring learning analytics 
associated with the use of surface devices. We use a framework to 
analyse our first-hand experiences, and the small number of 
related deployments according to four dimensions: the 
orchestration aspects involved; the phases of the pedagogical 
practice that are supported; the target actors; and the levels of 
iteration of the LA process. The contribution of the paper is two-
fold: 1) a synthesis of conclusions that identify the degree of 
maturity, challenges and pedagogical opportunities of the existing 
applications of learning analytics and interactive surfaces; and 2) 
an analysis framework that can be used to characterise the design 
space of similar areas and LA applications. 

CCS Concepts 
•  Information systems ? Information systems applications ? 
Collaborative and social computing systems and tools 
• Human-centered computing ? HCI  ? Interaction devices. 

Keywords 
Design; groupware; visualisations; design; dashboard; studies in 
the wild, awareness; face-to-face 

1. INTRODUCTION 
While there has been a growing interest in the potential role of 
Learning Analytics (LA) in mobile learning and online activities, 
to a large extent, students’ learning still happens in face-to-face 
(f2f) settings [1]. Blended learning and massive online courses 
have become popular targets for LA solutions [11], but they are 
primarily, or wholly, focused on the non-f2f, online part of 
students’ engagement in learning activities. However, the 
development of effective f2f communication and collaboration 
skills remain key 21st century competencies for employability and 

lifelong learning [13]. Group tasks typically require negotiation, 
brainstorming, and argumentation, usually in the service of some 
form of artefact design. These can be powerful vehicles for 
authentic learning, and typically have a major f2f element [18]. It 
has been emphasised that LA research has a particular perspective 
of attempting to understand learning as a whole, in their full 
complexity [26], which also includes f2f students’ activity.  
Emerging technologies such as touch and tangible interaction, 
gesture recognition and object tracking, have the potential to help 
support f2f students’ activity from a LA perspective. These 
technologies have been increasingly moving from research to 
commercial applications over the last two decades in the form of 
varied types of interactive surfaces [9]. In this paper, we focus on 
multi-user interactive surfaces which are devices that allow touch 
and/or tangible interaction by one or more users. These include 
interactive tabletops, interactive whiteboards (IWB), tangible 
interfaces and smaller-scale devices such as tablets, which can 
allow transitions between individual and group work.  
The proliferation of surface devices is opening a broader range of 
possible applications to facilitate and enrich face-to-face activities 
in educational contexts [12]. Affordances of interactive surfaces 
commonly include the provision of a work space that offers 
multiple direct input points so users can manipulate digital 
content with fingers or through physical trackable objects, while 
they communicate via speech, facial expressions, and gestures [9]. 
Less explored affordances of these devices include the unique 
opportunity they offer to automatically capture students’ digital 
footprints that can be analysed and used to make f2f interactions 
‘visible’. Their intrinsic multi-user capabilities can assist in 
enhancing collocated exploration, discussion and sensemaking of 
LA indicators. Furthermore, Oviatt’s research [19] argues for the 
critical role of creative sketching in learning, placing renewed 
emphasis on digital pens and surfaces.  
These underexplored opportunities motivate the need to define 
key dimensions of a new design space, where surface technology 
and LA tools can meet to address f2f learning challenges. Such an 
explicit design space may not only be helpful as an instrument for 
describing and coordinating current research in the area (e.g. by 
identifying potential uses of the technology and challenges; and 
avoiding duplicate work), but may also provide a conceptual basis 
for the development of new LA tools targeting unmet needs.  
Designing and deploying LA tools using surface devices require 
a comprehensive understanding of interaction design and the 
possibilities that these technologies offer, not just for learning and 
teaching, but also for learning analytics. The design space should 
also consider the pedagogical underpinning, the possible target 
actors, the teaching strategies, data sources, and the degree of 
maturity of development in this area. This paper presents a 
synthesis of conclusions drawn from an empirical analysis of the 

 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. Copyrights 
for components of this work owned by others than ACM must be 
honored. Abstracting with credit is permitted. To copy otherwise, or 
republish, to post on servers or to redistribute to lists, requires prior 
specific permission and/or a fee. Request permissions 
from Permissions@acm.org. 
LAK '16, April 25-29, 2016, Edinburgh, United Kingdom 
© 2016 ACM. ISBN 978-1-4503-4190-5/16/04…$15.00  
DOI: http://dx.doi.org/10.1145/2883851.2883873 



current research and authentic deployments of LA tools utilising 
interactive surfaces. To describe the design space in this emerging 
area, we use an analytical framework, drawing on principles from 
four sources: i) a framework of classroom orchestration [20]; ii) a 
framework to support the implementation of teaching practices 
[10]; iii) the actors who are commonly targeted by LA tools [25]  
and iv) the iterative process they commonly followed by these to 
use and respond to LA tools [27]. We analyse the technological 
and educational aspects of our first-hand experiences, and the 
small number of authentic deployments, of learning analytics 
utilising different types of interactive surfaces. In parallel, our 
approach allows us to analyse the maturity of the multi-user 
interactive surface technology and LA solutions by drawing a 
contrast between interesting pieces of research conducted in 
controlled lab conditions and authentic classroom deployments.  
The contribution of the paper is two-fold: 1) a series of 
conclusions that identify the degree of maturity, orchestration 
aspects, challenges and pedagogical approaches of the existing 
applications of learning analytics in interactive surface-based 
settings; and 2) a combined framework that can be used to 
characterise the learning analytics design space and maturity in 
other areas of application. Moreover, the framework connects 
pedagogical principles with the practical metaphor of classroom 
orchestration in the context of the deployment of LA tools.  
The rest of the paper is structured as follows. The next section 
provides an overview about touch and tangible interaction; and a 
definition of orchestration technology and its links with learning 
analytics. Then, we present the theoretical underpinning of our 
combined framework. After this, we describe the analysis of 
selected case studies using the framework, making an emphasis on 
the particular orchestration challenges, pedagogical uses and 
advantages of using interactive surfaces for LA purposes. We 
conclude with a discussion of the application of our framework, 
the maturity of the area and opportunities for future research.   

2. RELATED WORK 
2.1 Touch and Tangible Surfaces in Education 
Surface computing is still a maturing technology, which has 
become a more natural alternative to traditional mouse and 
keyboard input by allowing users multi-touch interaction using 
fingers, hands or special pens [2]. This shift in input technology 
has opened the interaction space allowing a wide range of new 
collaborative and ubiquitous applications, especially for those 
tasks that are more effectively performed face to face [18]. Some 
example tasks that have been supported by interactive surfaces 
include group planning, diagramming, designing, data 
exploration, brainstorming, knowledge building, and information 
curation. However, whilst advancements in hardware have been 
rapid, application software for large surface devices is still in early 
stages compared with, for example, the market of mobile devices.  
In terms of educational contexts, there has been a great interest in 
using large surface devices for supporting collaborative learning 
pedagogies. IWB’s have been used to conduct whole class 
activities [9], both vertical and horizontal large touch screens 
have been used to conduct small group work [12], and multiple 
tablets have been interconnected to support tasks in pairs [28], or 
to show a user interface just for the teacher [12]. Moreover, the 
use of tangible objects on surface interfaces has been regarded by 
practitioners and researches as a particularly important feature for 
the cognitive development of young students’ coordination and 
3D orientation [6]. Tangible interfaces are promising for tasks that 

require the manipulation of objects, which is not possible in flat 
displays (examples have included narrative, biochemistry and 
simulation systems [6]). Increased interest has also been posed in 
the digital affordances of surface devices to support handwriting 
and sketching [19]. These are often more fluid ways for students 
to communicate and generate ideas, compared with the use of 
mice, and physical or on-screen keyboards.  
Another use of large surface devices has been collaborative data 
visualisation, but not much has been done to support collaborative 
sensemaking of educational data. At the same time, there has not 
been much work in exploiting data captured by these devices in 
similar ways as it has been done with online systems. The capture 
and identification of f2f users’ actions can impose particular 
challenges that are not present in non-f2f scenarios. For example, 
all online actions can be easily recorded and identified by asking 
the user for login credentials. Although overcoming data 
collection challenges can be a current challenge, there is an 
enormous potential to support f2f student’s work in ways that 
have not been yet possible.   
Overall, there has been a steadily increasing interest in using 
touch and tangible devices. Rather than having a wave of novel 
technology occupying the classroom, we are seeing a slower 
paced increase of surface technology used in several areas of life, 
including learning and teaching. It is timely to start considering 
the potential of the support that learning analytics can offer - in 
situ- and, conversely, the new areas of application that these 
emerging devices can bring to learning analytics. 

2.2 Technology for Classroom Orchestration   
The metaphor of orchestration takes account of the variability and 
complexity of classrooms and the key role of teachers in adapting 
the available pedagogic and technological resources to help 
students achieve their intended learning goals [7]. Orchestration 
technology may support the management of the orchestration or 
some part of it. This includes, for example, interfaces that help 
teachers manage the class workflow, enhance their awareness or 
track students’ progress. The metaphor was further embraced by 
other researchers to explain several other aspects that need to be 
attended before and/or after the actual deployment of learning 
tasks, not only in the classroom, but also in online or blended 
learning scenarios [20]. This includes, for example, tools that 
support teachers to deploy their learning designs or reflection, 
assessment and re-design after the activity is completed.  
In short, this perspective empowers teachers as drivers of 
classroom activities and advocates for the use of simple 
technologies that may have important effects. The effectiveness of 
orchestration and the extent to which teachers can respond to the 
ways students perform their tasks is critical because it directly 
impacts these students’ activities, and therefore, their students’ 
learning. Moreover, the metaphor has also been extended by the 
notion of distributed orchestration [24], considering that students 
and other actors of the learning process, can also be responsible 
for part of or all the orchestration tasks. Thus, this makes 
orchestration also applicable to self-managed learning scenarios.  
Our work takes an approach based on orchestration as it is a 
dynamic perspective that attends authentic issues considering that 
learning activities that occur in the classroom may be affected by 
unanticipated processes and contingencies. Differently to learning 
theories that focus on cognitive aspects, orchestration is 
concerned with practical issues and tasks that are not directly 
linked with learning but can shape learning. This makes 



Figure 1. A combination of frameworks creates this 4-
dimensional framework, used to analyse the current state of 

learning analytics on data from interactive surfaces 
 

orchestration very relevant for deploying LA tools in authentic 
learning settings. Learning analytics can have a key role in 
supporting f2f and blended learning activities. To achieve this, a 
clear understanding of orchestration aspects is needed to create 
effective LA solutions in those f2f settings where teachers or 
students need to adapt to unexpected problems, on the fly. 

3. THE COMBINED FRAMEWORK 
The combined framework we used to analyse the current research 
and deployments that combine LA tools and interactive surfaces is 
defined by four dimensions: a) a set of orchestration aspects that 
the LA tools provide support to, b) the phases of the pedagogical 
practice that are supported, c) the target actors of the learning 
analytics and d) the levels of iteration of the learning analytics and 
pedagogical processes (see Figure 1). The combined framework 
forms a 4-dimensional matrix which can categorise the LA 
deployments. Each of these dimensions, and their theoretical 
underpinnings, are described in the rest of this section.  

3.1 Elements of the framework 
3.1.1 Orchestration aspects 
Prieto et al. [20] developed a framework that identifies five 
orchestration aspects. For the first dimension of our analysis 
framework, we considered the first four ‘functional’ aspects of 
orchestration (see Figure 1, a). These aspects can be linked with 
tasks that either teachers or students should perform, and thus, LA 
solutions can be created to support the actors in performing such 
functions or tasks. The fifth aspect refers to the roles of teachers, 
students and other actors, and was considered into a separate 
dimension, linked to the target actors of the LA tools (Figure 1, 
c). The four functional orchestration aspects are the following:  
Design and planning. Learning design includes the preparation of 
the educational materials, pedagogical approaches, social 
dynamics, tasks, scripts, strategies and any other resources that are 
needed to create opportunities of learning for students. Teachers 
commonly have a crucial role in learning design and co-design. 
There can also be other actors specialised in learning design, 
particularly in higher education. Alternatively, students can also 
design or co-design their own learning tasks. The design process 
is not necessarily linear, as design and planning can co-occur 
while the actual activity unfolds or after it is completed [20]. In 
terms of learning analytics, awareness and/or analytical tools may 
support fine tuning of learning designs by providing visualisations 
of student’s data, indicators about how planned tasks actually 
occurred or insights from the community of practice.  
Regulation and management. This aspect refers to the 
coordination of the ongoing teaching process and/or the self-
regulation of the learning activity. This includes the management 
of time for each student’s task, class duration, task distribution 
and social arrangements. In short, this aspect is focused on the 
coordination of the workflow of the learning activity. This 
regulation can be performed through social interaction (e.g. the 
teacher directing the flow of the class or students managing their 
own workflow based on feedback from LA systems) or be partly 
handed over to some Comp. controlled mechanism [20]. LA tools 
can support the actors responsible of the management of the 
learning processes and their constraints by providing, for 
example, key information about the execution of the workflow so 
they could modulate it according to the demands of the activity. 
Adaptation, flexibility and intervention. This aspect refers to the 
capacity of the educational technology, the class script or the 

learning activities to be flexibly adapted to unexpected classroom 
events and the emergence of new tasks. This can include the 
actors creating improvised tasks or adapting the planned tasks 
during the enactment. Similarly, the systems can offer flexible 
functions to handle those adaptations. LA tools can support this 
process by providing teachers or students with key information 
that would allow them to manually intervene or adapt specific 
learning tasks, or for the learning system to automatically adapt 
the tasks to particular student’s needs or provide automated 
interventions to tune the order or the approach to the tasks. 
Awareness and assessment. Awareness, and formative/summative 
assessment tools are clearly critical to orchestrating learning. 
While ‘awareness’ of different sorts pervades all sensemaking 
activity around data [27], for this aspect we focus on those 
awareness mechanisms that are particularly linked to the students’ 
learning activity. This includes tools that can provide key insights 
into students’ learning processes so actors can modify their 
teaching strategies, the provision of feedback, the pedagogical 
approach or the students learning styles. These can be simple tools 
such as basic visualisations of group progress, or more complex 
student modelling or predictive approaches.  

3.1.2 Phases of pedagogical practice 
The second dimension is derived from the Implementing 
Collaborative Learning in the Classroom (ICLC) framework by 
Kaendler et al. [10]. This points at the teacher competencies that 
are needed across the implementation phases of learning strategies 
in classroom sessions. It defines five teacher competencies: 
planning, monitoring, supporting, consolidating and reflecting, 
which span three phases of teaching practice: pre-active, inter-
active, and post-active (Figure 1, b). The authors map planning to 
the pre-active-phase, monitoring, supporting and consolidating to 
the inter-active phase, and reflecting to the post-active-phase. 
Although the teacher competencies could be matched with the 
orchestration aspects described above, the metaphor of 
orchestration is not only concerned with the ability of the teacher 
to perform tasks according to their professional knowledge. 
Rather, it is concerned with how different types of technology can 
support teachers, or students themselves, to manage multi-layered 
activities in a multi-constraints context [7]. Additionally and very 
important is that almost all orchestration aspects can be relevant 
before, during or after the activity [20]. For example, planning 
and learning design commonly occur in the pre-active phase, but 
it can be that a teacher has to adapt the intended design on the fly, 
or accomplish some re-designing work in the post-active phase.  



In summary, by combining both frameworks we can map surface-
based LA in terms of what orchestration support they provide and 
when. We have not yet specified for whom, considered next. 

3.1.3 Target Actors 
LA solutions can be oriented towards different actors of the 
learning process, including students, teachers, intelligent agents, 
administrators, etc [5]. At the same time, LA studies can be 
conducted for research, or prototype system design purposes, 
without being deployed in authentic learning scenarios. Learning 
analytics can also support learning designers to take informed 
decisions about changes that the course may require based on 
evidence. Therefore, to understand the design space of learning 
analytics in a specific area, and its degree of maturity in terms of 
real deployments, we should differentiate the actors who are being 
targeted as end-users of the LA tools. Based on the users targeted 
by the current deployments covered in our analysis, we divide the 
target users into three groups (Figure 1, c): Students, Educators 
(including lecturers, tutors, learning designers) and Researchers 
(including individuals and also the community of research). 

3.1.4 Levels of the Iterative Process 
The fourth dimension introduces the notion of iteration, at two 
levels: Micro and Macro (Figure 1, d). Micro refers to the 
iterative process of LA support within each pedagogical phase. 
This has been described by Verbert et al.’s [27] as the process 
users follow to: have access to data (i. awareness); ask questions 
and assess the relevance of the data (ii. reflection); answer 
questions, getting new insights (iii. sensemaking); to finally 
induce new meaning or behavioural change (iv. impact). This 
four-stage iterative process occurs while users interact with a LA 
tool in a given phase. Iteration at a macro-level is concerned with 
the workflow as the phases (pre-active, inter-active, and post-
active) are repeated over multiple sessions. This is crucial so that 
LA tools can provide support spanning multiple sessions.  
In summary, the combined framework considers that the pre-
active, inter-active, and post-active phases form a linear workflow 
for one specific session (e.g. a classroom session, an experimental 
trial, an online-based task). Each orchestration aspect can be 
supported in any of these phases (e.g. planning is not restricted to 
the pre-active phase, but can occur in the inter-active and post-
active phases). Finally, LA support can be targeted at different 
actors in each phase and macro-iteration.  

4. Analysis of Case Studies 
In this section, we analyse a series of case studies of LA 
applications that use interactive surfaces to support different 

orchestration aspects. Table 1 presents an overview of the design 
space defined by the dimensions of our framework. The table 
maps the Projects analysed (column 1), the Orchestration Aspects 
addressed (2-5); the Pedagogical Phases that are supported (6-8); 
and whether they involve certain levels of Iteration (9-10). The 
actors targeted in each deployment are represented by letters: E 
for educators, teachers, tutors and learning designers; S for 
students and R for researchers. Beyond the dimensions of the 
combined framework, in the case studies we seek to identify the 
forms in which the data is communicated to the actors, such as 
whether it is presented in a raw format (e.g. statistics, algorithms 
results, patterns), through visual representations (e.g., dashboards, 
visualisations, alerts, notifications) or by direct automated actions. 
We also pay attention to the topology of LA tools classified by the 
type of information they offer, including information about 1) the 
task/class progress, 2) students’ interaction, 3) quality of the 
students’ solution and 4) learning (including conceptual change, 
learning to collaborate or learning about the process).  
In the following subsections, we provide a concise description of 
our first-hand experiences from seven case studies (the first 7 
rows in Table 1). These illustrate how the dimensions of the 
combined framework are interwoven to help understand the 
technologies used and pedagogical aspects tackled by the LA 
solutions. To facilitate the presentation of the cases, we grouped 
them by the main actors that are targeted in each (teachers, 
learning designers, students and researchers, respectively). Lastly, 
we briefly describe other LA applications where some sort of 
surface technology has been used (last four rows of Table 1).  

4.1 Supporting Awareness for Teachers 
We start by describing two case studies of analytics support for 
enhancing teachers’ awareness. 

4.1.1 MTFeedback: driving teacher’s attention 
The first case study consisted in providing support to enhance 
teacher’s classroom Awareness and Assessment on the fly (inter-
active phase). The pedagogical intentions of the teachers were that 
students could engage in collaborative discussions and visually 
represent their proposed solutions to posed challenging problems. 
The teacher aimed to conduct this activity face-to-face to support 
students and provide direct feedback to promote verbal discussion 
and argumentation. The setting used was the MTClassroom 
(Figure 2, left). This is a multi-surface classroom environment 
composed of 4-5 large interconnected tabletops and three vertical 
displays. Each tabletop was enriched with a Kinect sensor that 
differentiates individual touches. This allows the capture of an 
identified log of student's actions at each table. A total of 6 

Table 1. Analysis of the current design space of learning analytics applications utilising interactive surfaces.   
Target actors: E=Educators, S=Students, and R=Researchers 

 
 

Project  

Orchestration Aspects Pedagogical Phases Iteration 
Design & 
Planning  

Regulation & 
Management 

Adaptation, 
Flexibility, & 
Intervention  

Awareness & 
Assessment  

Pre-
active 

Inter-
active 

Post-
active 

Micro-
level 

Macro
-level 

MTFeedback [15]    E  *  *  
Analytics for redesign [17] E E  E *  *  * 

CoCo Design table [16] E, R    *   *  
Navi Surface [4]    E,S  * * *  
LARAe.TT [3]  E,S  E,S  * * *  

Co-located eye-tracking [23]    R  *    
Motion sensors [22]    R  *    

Script awareness tool [14]  E E   *  *  
Do Lenh [8]    E, S  *  *  

Monitoring tablets [28]    E  *  *  
Learning catalytics [21]    E  *  *  

 



teachers and more than 300 students were involved 
in a series of realistic studies conducted during 
three regular semester courses. Three types of tasks 
were facilitated by the tabletops: collaborative 
concept mapping, brainstorming and scripted group 
meetings. All the tabletops and the vertical displays 
were controlled by a teacher's tablet-based 
dashboard (Figure 2, right). This also showed 
visualisations that conveyed student's information 
in two dimensions: individual participation and 
group progress in their task. It also showed 
notifications from the MTFeedback subsystem. 
This analysed student's artefacts in the backend to 
generate both positive and negative notifications 
according to the groups’ misconceptions or underperformance, 
automatically identified based on thresholds set by the teacher.  
Empirical evaluations studied if the visualisations and 
notifications shown in the dashboard effectively supported 
teachers’ micro-level iterative LA process, by enhancing their 
classroom awareness and thus allowing them to take more 
informed decisions when selecting the groups that required more 
attention [15]. Results indicated that the system helped to 
seamlessly capture traces of students’ activity, thus allowing the 
generation of live visualisations and notifications for the teacher. 
The deployment of the teacher's dashboard on a tablet allowed 
free mobility to the teacher while having access to control and 
monitoring tools. The visualisations and the notifications allowed 
teachers to attend to groups that needed immediate support and 
provide formative and/or corrective feedback, which translated 
into student’s conceptual changes.  

4.1.2 Learning Analytics for Redesign 
The second study consisted in providing LA support in two forms 
[17]. First, in the post-active phase, enhancing teacher’s 
Awareness and helping her Assess how the initial intentions 
played in the classroom. Second, in the pre-active phase of the 
next class session, providing insights into the aspects of the 
learning tasks that need to be Redesigned. The setting was the 
MTClassroom as for the first case. This study focused on one 
teacher designing and then re-designing 1-hour tutorials for two 
different subjects in two consecutive university semesters. The 
first tutorial involved 236 students distributed in 14 classroom 
sessions. The second involved 140 students distributed in 8 
sessions. The goals and the topic of both tutorials were similar: to 
promote discussion, and deep understanding of political dynamics 
for students to learn how to address organisational issues. Both 
tutorials had a similar macroscript which basically consisted of 
two small-group concept mapping tasks. The captured data 
included: application logs, snapshots of the evolution of each 
group’s concept map and how the teacher advanced the class 
according to her script. Three semi-structured interviews were 
held with the teacher after the tutorials to capture teacher’s 
intentions and reflections. Teacher’s intentions were grouped into 
three categories: class script progress (A), student’s participation 
(B), and students’ achievement (C) in all sessions. In the first the 
LA support was presented to the teacher in the form of 
visualisations (graphs), workflow diagrams, and raw numerical 
results about each of the three pedagogical intention categories. 
This supported teacher’s reflection in the post-active phase of the 
first macro-level iteration of the learning analytics cycle [17]. The 
next two interviews focused on capturing the teacher’s re-design 
decisions as part of the pre-active phase of the next iteration. For 

example, regarding the class script (A), the teacher was provided 
with a fuzzy workflow diagram (e.g. see Figure 3). She identified 
that in most tutorials, students spent too much time in the first 
task, not giving enough time for completing the second task. 
Concerning student’s participation (B), a bar chart was shown to 
the teacher, indicating that within most groups participation had 
not always been equally distributed. A third example (for category 
C) is illustrated by the results from a correlation analysis which 
suggested that a hierarchical concentric arrangement of students' 
concept maps was connected with the achievement of better 
solutions. These insights were informative for the teacher to re-
design the tutorials. For the next tutorial sessions, the teacher 
provided an initial scaffolding solution for students to progress 
more quickly and focus on the subsequent higher-level tasks. The 
teacher also developed a strategy to encourage all students to use 
the tabletop, and to follow a specific concentric layout. 
In this study, the surface devices allowed the automated collection 
of classroom evidence. The data was exploited to generate visual 
and non-visual information to help a teacher compare her planned 
intended goals with how they actually played in the classroom. 
This example illustrates the synergy between surface technology 
and learning analytics to provide continued macro-iterative 
support to teachers’ awareness and planning, across sessions. 

4.2 Analytics for Learning Designers 
One of the functionalities of using large interactive surfaces is that 
they invite all team members to interact with the shared device, 
making their actions visible. The next subsection describes a case 
study of analytics support for learning design.  

4.2.1 CoCoDT: collaborative educational design 
This case study consisted in supporting Design and Planning in 
the pre-active phase. The goal was to understand how surface 
technology and minimalist visual analytics can support high level 
learning design. The setting was the Design Studio [16]. Figure 5 
shows this multi-surface space providing a set of digital and non-
digital tools, including: a tabletop, an IWB, tablets, a white-wall, 
a dashboard, and various paper-based materials. The tabletop and 

Figure 3. Planned time limits for 5 tasks (top row) and the 
enactment of the design for 14 tutorials (bottom row) [17]  

 
 

Figure 2. Left: An ongoing small-group session in the MTClassroom. The 
teacher is holding a tablet-dashboard while providing feedback to one team. 
Right: The dashboard showing visualisations of participation for 4 groups 

 



the IWB run an application called CoCoDT. It offers a large 
interface customised to support rapid construction of candidate 
designs as part of the early stage conceptual design of university 
courses. The tool shows a flipped timeline where users can 
arrange learning tasks on a weekly basis. This allows the 
manipulation of iconic digital objects to configure spatiotemporal 
characteristics of learning tasks and their workflow. 
The dashboard shows live visualisations of the candidate designs 
created in the surface devices. This information includes a list of 
the learning tasks added to each candidate design, a pie chart that 
shows how students’ time would be divided among learning 
spaces (face-to-face and online), and a histogram showing the 
student’s weekly workload (see Figure 5, right). The goal of 
presenting a dashboard with visualisations of multiple candidate 
designs is to support teachers' high level comparison and promote 
understanding of the impact of substituting certain learning tasks 
for equivalent tasks on students’ workload and direct contact time.  
Four teams of three teachers and learning designers participated in 
an observational lab study. The goal of each team was to produce 
two candidate high-level designs of a university course, satisficing 
some competing design goals. Results of the study showed that 
the dashboard was one of the features that was most valued by 
participants. It provided an overall view of the tasks within each 
design and helped most groups in keeping themselves on track 
toward their design goals by having continuous access to 
indicators of their designs. Moreover, the participants valued the 
combination of large devices to have a view of the designs, 
smaller sized tablet devices to seek information as needed, and the 
dashboard to keep awareness of the changes on their designs.  

4.3 Collaborative LA Data Exploration 
Collaborative tools have been used to help small groups keep a 
shared view and articulate their insights more fluidly than with 
single-user displays. Surface devices can be used to support 
collaborative reflection on educational data. Next, we describe 
two case studies of collaborative LA exploration.  

4.3.1 Navi Surface 
This case study aimed to support students by enhancing their 
Awareness about their achievements to help them self-Regulate 
their own learning. The approach relies on a students’ dashboard 
that can be used in the inter-active and/or the post-active phases 
(see Figure 4). The third author and his colleagues used the notion 
of badges to create Navi Surface [4]. Badges are used to abstract 
important aspects of student’s learning processes, including 
intended learning outcomes and produced artefacts such as blog 
posts, shared documents. Navi Surface is a tabletop-based tool 
that allows teachers and students to navigate student’s’ 

achievements for a university 
course. Users can navigate 
through the tool to get more 
information about how and why 
badges were awarded to which 
students, based on the learning 
traces that were captured during 
the course. Multiple items can be 
accessed simultaneously, enabling 
group interaction with the data. 
The teacher can guide the process 
by dragging items onto the 
interface to promote discussion 
about what students have 
achieved, while students can also 

interact and steer the conversation.  
Navi Surface was evaluated with 14 students (4 groups of 2, 3 and 
4 members) who used the tool in groups and individually, and 
were able to access their personal data and that of others. 
Preliminary observations showed that the interface promotes 
engagement, group interaction and evaluation of achievements. 
This can be explained as follows. Most dashboards provide a 
single-user experience, requiring motivation (either intrinsic or 
extrinsic) from a student to access the LA data. The public nature 
of a tabletop (as opposed to a more private personal screen) 
creates a more inviting environment, facilitating a multi-user 
experience for students and their teachers to collaboratively 
explore LA data. The tabletop played a key role as catalyst of 
discussion and participants considered the approach as a fun way 
to interact with LA data. By contrast, when students used the 
tabletop alone, a more hesitant interaction was observed. These 
observations suggest that the collaborative nature of the surface 
device promoted social discourse which may  
4.3.2 LARAe.TT 
The second case study of this section includes the use of 
LARAe.TT [3]. Similarly to Navi Surface, this tabletop tool aims 
to support students’ Awareness and Reflection in the inter-active 
and post-active phase, particularly for Inquiry-Based Learning 
(IBL) activities. In IBL, teachers encourage learners to pose 
questions and formulate hypotheses about a given topic, and 
accomplish independent investigations to support their 
conclusions. LARAe.TT visualises the paths that students follow 
through their inquiry-based learning activities. The tool is 
grounded on IBL process model which distinguishes the next six 
phases: problem identification, operationalisation, data collection, 
data analysis, interpretation and communication. Thus, students 
assume an active role to regulate their own learning as each 
learner can follow her own path. LARAe.TT allows students and 
their teacher(s) to discuss and retrace individual steps taken by 
students. They can look up related content such as hypotheses that 
were formulated, evidence data that was gathered, etc. Figure 7 
shows the LARAe.TT interface, with the visual representations of 

Figure 4. Students using Navi Surface in pairs to explore their 
achievements through a collaborative badge visualisation 

 

Figure 5. Left: A group of deigners looking at the dashboard while designing 2 candidate 
designs (A and B) in the Design Studio. Right: The dashboard showing: a) the tasks 

included in each design, b) the proportion of tasks by learning space, and c) the weekly 
distribution of student’s time between online and f2f work 



student’s paths in the centre. The application provides a series of 
dropzones that allow students and teachers to physically drag 
particular activities to see more details of it in the form of text or 
pictures that are evidence of student activity for a particular IBL 
phase. Additionally, dragging a student name into a personal drop 
zone (coloured squares the figure) allows students to explore and 
filter their data according to the position of participants at the 
tabletop. 
LARAe.TT was presented and evaluated with 15 participants 
(teachers, students and researchers) at a workshop. The evaluation 
explored how the tabletop application can assist both students and 
teachers during the IBL process. It was clear that it could facilitate 
students to assess their own progress and manage the distribution 
of work. LARAe.TT would not only help students explore 
personal achievements, but would also let them compare, reflect 
on and learn from the activities of their 
peers. Teachers on the other hand could 
invite students to the tabletop to initiate 
a discussion, to intervene, discuss 
progress, ask for clarification and 
reasoning, assess activities and point 
out peer activities for comparison. 
Overall, Navi Surface and LARAe.TT 
illustrate a very particular orchestration 
use for interactive surfaces to support 
reflection and post hoc assessment. The 
physicality of the tabletop and the 
design of the interface provide a unique 
opportunity to support collective f2f 
exploration of student’s data with the 
purpose of facilitating discussion 
between students and their teacher.  

4.4 Multi-Modal Learning 
Analytics for Researchers 
The previous case studies suggest that 
interactive surfaces provide rich 
opportunities to support students’ f2f 
interactions and teachers’ orchestration. 
At the same time, they also provide 
researchers with a wealth of information 
to better understand the nature of social 
learning in the inter and post-active 
phases: researchers can use many data 

collection tools to capture students’ interactions as they are 
learning new concepts by using cameras, microphones, motion 
sensors, mobile eye-trackers, galvanic skin response sensors, and 
emotion detection tools. We see interactive surfaces as 
environments where rich learning episodes can occur, which 
makes them ideal candidates for using multi-modal sensors. We 
illustrate this idea with the two examples below.  

4.4.1 Mobile eye-trackers and Joint Visual Attention 
This case study is about capturing a fundamental building block 
of students’ interaction: Joint Visual Attention (JVA). JVA is 
known by developmental psychologist and learning scientists to 
be a pre-requisite for any kind of high-quality collaboration, 
because it allows a group to build a common ground to effectively 
solve a problem. The second author and his colleagues [23] have 
developed innovative ways to capture JVA around interactive 
surfaces. Their methodology involves using fiducial markers 
(Figure 6) to remap students’ gaze onto a ground truth. Since the 
fiducial markers are part of the tangible interface, the interactive 
surface becomes an essential part of being able to collect and 
meaningfully analyse the eye-tracking data. Having both gazes on 
the same physical plane allowed the researchers to determine 
whether students were jointly looking at the same location at the 
same time. They found that the number of times that JVA is 
achieved is not only correlated with students’ quality of 
collaboration, but also reflects higher performances on the 
problem-solving task as well as higher learning gains. This kind 
of data stream allows researchers to generate reliable footprints of 
collaboration quality, and separate productive from less 
productive groups of students. This data could potentially be 
collected in real-time to help teachers decide which groups need 
attention and which ones do not need help. 
One interesting aspect of multi-modal sensors is that they do not 

just allow researchers to more easily collect 
quantitative data, but also facilitate 
qualitative analyses. The next step of this line 
of research is to look at videos augmented 
with gaze information (Figure 6 is showing 
one frame of this kind of video) to support 
qualitative analysis of students’ interactions. 
This kind of analyses was previously difficult 
to conduct, because it required researchers to 
position multiple cameras around a group to 
infer whether two students were 
simultaneously looking at the same location. 
Sensors can now provide this information to 
researchers, which can help speeding up the 
pace of qualitative work.  

4.4.2 Motion sensors and students’ 
physical mobility  

This last case study is about capturing 
another key aspect of f2f interactions: 
students’ ability to use their physical body to 
express ideas and manage collaborative 
processes. These movements can be manually 
coded or captured using a motion sensor. For 
example, Schneider & Blikstein [22] used a 
Kinect sensor to collect data from a study 
conducted with 38 students interacting with a 
tangible interface, resulting in 1 million data 
points describing their body postures. They 

Figure 6. Two students analysing a static 
version of a Tangible interface. Red lines 

show the points used for remapping 
students’ gazes onto a ground truth 

(middle figure) 
 
 

Figure 7 LARAe.TT Activities are shown in the centre of the 
screen. The top dropzone lets users expand an activity to get 

more details. Each user has a coloured, personal drop zone for 
highlighting activities 



then fed this matrix into a simple clustering algorithm to obtain 
the following prototypical body positions (Figure 8). Not 
surprisingly, they found that the time spent by students in the 
“active” posture (left graph of Figure 8) was positively associated 
with their learning gains while the “passive” posture (right graph) 
was negatively correlated with them. More interestingly, they 
found that the number of times students transitioned from one 
posture to another was the strongest predictor for learning. This 
suggests that the most successful students were the ones who not 
only acted, but also systematically stepped back to reflect on their 
actions and think about their next steps. With traditional 
qualitative approaches, it would have taken months to identify and 
code this kind of behaviour. Using sensors and unsupervised 
machine-learning, it took an order of magnitude less time to 
isolate this productive learning behaviour.  
In conclusion, results suggest that surface devices, augmented 
with multi-modal sensors, provide researchers with rich 
opportunities to collect massive datasets about students’ learning 
experiences. Those datasets can be then mined using machine-
learning algorithms, or used to augment videos and facilitate 
qualitative analyses of students’ interactions.   

4.5 Other cases 
Other case studies that we analysed are the following. The first 
author and colleagues investigated the impact of showing the 
teacher visualisations about the enactment of the macro-script 
during a class session through a Script Awareness tool [14]. This 
is the only example we are aware of, that directly supported the 
orchestration aspects of Adaptation and Flexibility to enhance the 
Management of the workflow of a multi-surface classroom. 
Lenh’s work [8] was very similar to the first case study described 
above. His system captured from each small group using multiple 
tangible tables in a classroom. Then, a public dashboard was 
displayed on an IWB for all students and their teacher to be aware 
of their progress on the task in comparison with other groups of 
students. Recent work by Wang et al. [28] proposed similar 
visualisations of the progress of the task for students working with 
and sharing tablets (instead of tabletops). Similar cases of learning 
analytics applied to interactive surfaces are slowly emerging to 
support BYOD (bring your own device) strategies. An example is 
Learning Catalytics [21] which provides some visual analytics to 
teachers about students’ progress and their misconceptions while 
collaborating in the classroom using tablets or mobiles.   

5. DISCUSSION 
This section presents a synthesis of conclusions that identify the 
degree of maturity, challenges and pedagogical opportunities of 
learning analytics and interactive surfaces. In the next subsections, 
we discuss different aspects of the case studies presented above, 
the implications of defining this design space, the particular 
affordances of surface devices and the kinds of analytics that are 
promising to support f2f collaborative learning challenges.   

5.1 Towards real time analytics in the field 
A basic affordance of large surfaces is that (used well) they more 
readily support the ergonomic (perceptual, physical, cognitive, 
social) characteristics of groups than a small surface. So, it is not 
surprising that groupwork is a common denominator in most of 
the cases reviewed, but with the difference that they in some cases 
support novel kinds of interactivity, and critically, make them 
traceable. The case studies showed varied ways to capture 
students’ interactions, enabling teachers to provide enhanced 
feedback while orchestrating a classroom, and permitting the 
collaborative exploration of student data. The combination of 
these technologies has the potential to open up new lines of 
research by allowing automatic processing and mining from large 
amounts of heterogeneous traces of f2f data (such as physical 
actions, gaze, body mobility, speech, etc). Critically, these 
technologies are not only analytics tools for researchers, but show 
promise for providing real-time feedback of activity to students 
and educators. The people who constitute the learning system are 
provided with data about their own process, whereas before, they 
were the object of study by researchers, who were the only people 
with the tools to capture and render such data. Manually analysing 
this kind of f2f data through more classical video coding and 
observational approaches is time-consuming. As surface analytics 
matures, real-time analytics could become practical in authentic 
classroom settings at runtime.   

5.2 Learning analytics approaches 
In the cases reviewed, interactive dashboards and visualisations 
were the most common ways to show educational data to 
educators and students. The focus was on providing information 
about  the task [3; 4; 8; 15; 28] and class [14] progress (Case 1), 
students’ interaction with the shared device (Case 2) [15; 17; 22], 
the class design [16; 17], and, to a lesser extent, the quality of the 
students’ solution (Case 3) [17]. Only two studies provided 
notifications [15; 21] to the teacher during the inter-active phase 
to aid the decision making of the teacher in the classroom. Finally, 
detailed and more complex analytics that give information about 
more abstract aspects of learning such as achievement [4] and 

collaboration [23] have mostly been lab studies 
(Case 4). 

5.3 Current applications and 
learning tasks 
5.3.1 Suitable learning tasks 
The most suitable tasks for surface technology 
seem to be those that involve a combination of 
talk, discussion, manipulation of digital or 
physical objects in a spatiotemporal 

Table 2 Maturity of learning analytics applications utilising interactive 
surfaces. E=educators, S=Students, R=Researchers and n= number of studies 

Orchestration aspects 
Pedagogical phases 

Pre-active Inter-active Post-active 

Adaptation, Flexibility, & Intervention  E  
Regulation & Management  E2,S2 E2,S2 
Awareness & Assessment E R2, E4,S3 E,S 

Design & Planning E2,R  E 
 

Figure 8. The results of the clustering algorithm on students’ 
body posture. The left centroid is active, with both hands on the 
table; the middle one is semi-active, with one hand on the table; 

the right one is passive, with both arms crossed 
 



representation plane, and/or that require larger sized displays. The 
tasks in the case studies included collaborative concept mapping 
[15; 17], brainstorming [15], team meetings [15], data exploration 
[3; 4], logistics training [8; 23], and a physiology challenge [22].     

5.3.2 Classroom dashboards 
The use of dashboards and visualisations in the classroom is still 
in its infancy. With the increasing use of digital surfaces in the 
classroom (e.g. tablets), it will be very common in the near future 
to see more implementations of systems that visualise key aspects 
of student's activity and/or performance or simply visualise or 
notify them for cases where students are disengaged, 
underperforming or not collaborating with their peers. This 
information could also be helpful for the students themselves to 
self-regulate their interaction and learning activities.  

5.3.3 Analytics for collaborative design 
The use of learning analytics to support learning design is also an 
underexplored area of application. The data captured by 
interactive surfaces and the orchestration technology can be 
valuable to facilitate teacher’s reflection on their design [16; 17], 
even if the time constraints of the class make it challenging to 
make big changes on the original plan, they can re-design for the 
following sessions. One case study [17] illustrated how 
orchestration support can be provided by learning analytics at a 
macro level of iteration (across sessions), showing analytics about 
the planned curriculum compared to how it actually occurred.  

5.3.4 Sensors and multi-modal analytics 
Regarding more complex, multi-modal analytics approaches, the 
challenge is to feed these data back to students (and teachers) to 
help them make better informed decision and to support students’ 
collaboration. Gaze awareness tools where students in a remote 
collaboration can see the gaze of their partner in real time on the 
screen can be highly beneficial to students. This allows them to 
monitor the visual activity of their partner, and anticipate their 
contributions, which leads to higher quality of collaboration and 
higher learning gains [23]. 

5.3.5 Interfaces for teachers and students  
Visualisations of individual learner traces on shared surface 
devices can help in bootstrapping dialogue between teacher and 
students. On the one hand, they allow learners to gain insight into 
the learning activities of themselves and their peers and the effects 
these have, while allowing teachers to stay aware of the subtle 
interactions in their course. In addition, teachers and students can 
jointly agree on appropriate learning strategies to follow, based on 
collaborative discussion around real factual data [3]. 

5.4 Maturity and under-attended aspects  
Table 2 presents an overview of the orchestration aspects, actors 
and pedagogical phases currently addressed by the analysed case 
studies. Most effort has been placed on supporting the 
orchestration aspects of Awareness and Assessment and in the 
inter-active and post-active phases of the learning activities (rows 
2 and 3). By contrast, other cells are empty or are populated just 
by 1-2 exemplars. The orchestration aspect that refers to 
Adaptation, Flexibility, & Intervention has barely been explored. 
There is potential to develop solutions that can, for example, 
perform automatic or semi-automatic interventions in students’ 
activities. There are still under-attended actors as well. For 
example, providing LA tools to enhance students’ awareness or 
other orchestration aspects in the physical classroom has not been 

deeply explored. Table 1 (columns 9 and 10) also shows that there 
is potential to provide iterative support at a macro level. This can 
include providing continued LA support across sessions - 
bridging the physical world where interactive surfaces can capture 
some traces of f2f activity, with the digital remote access to 
resources. An alternative indicator of the maturity of this area of 
application is to observe to what extent the LA solutions can be 
readily deployed in authentic classrooms. Most of the examples 
analysed describe lab-based scenarios, indicating that this area is 
rapidly growing but is still exploratory. The only examples of LA 
classroom tools mostly supported the orchestration aspect of 
Awareness through teacher’s [15] or public [8] dashboards.  

6. CONCLUSION 
This paper presented a description of the orchestration aspects, 
challenges and pedagogical opportunities of applying learning 
analytics solutions utilising interactive surfaces to facilitate a 
range of f2f tasks. As illustrated in Tables 1 and 2, this area of is 
still immature as the technology is co-evolving along with 
pedagogical practices that are beginning to recognise the value 
that these pervasive devices may offer. Our analysis framework 
helped us characterise the design space in terms of orchestration 
aspects that need to be addressed, along with the pedagogical 
phases that teachers or students need to accomplish in order to 
prepare for classroom sessions. This framework is promising to 
help decompose other LA deployments, especially for those 
scenarios that can be complex, involving iterative support across 
different classroom sessions and considering different tools, and 
multiple sessions, LA target users and orchestration aspects.  
The paper points at future work still needed to support students 
directly, exploit further unexplored affordances of interactive 
surfaces (such as sketching), and also support other orchestration 
aspects, such as adaptation, flexibility, intervention, management, 
design and planning. Besides, most LA support through 
interactive surfaces has focused on providing visualisations and 
dashboards. Other analytics techniques look particularly 
promising for surface tools, given the activity data they are good 
at capturing. These may include multi-modal analytics (e.g. traces 
of physical actions, or learning analytics approaches for tasks that 
require handwriting and sketching using interactive surface), 
analytics from heterogeneous sources of data (e.g. coming from 
different devices or education software), and the provision of 
(semi) automated systems’ interventions, alarms, or feedback.   

7. ACKNOWLEDGMENTS 
The research projects described in this paper were supported by: 
the European Community’s 7th Framework Programme 
(FP7/2007-2013) (318499-weSPOT project), the Erasmus+ 
programme, Key Action 2 Strategic Partnerships, of the European 
Union (2015-1-UK01-KA203-013767-ABLE project), the 
Australian Research Council (Grant FL100100203), the National 
Science Foundation (NSF #0835854) and the Leading House 
Technologies for Vocation Education, funded by the Swiss State 
Secretariat for Education, Research and Innovation. 

8. REFERENCES 
[1] Bowers, J., and Kumar, P. 2015. Students' Perceptions of 

Teaching and Social Presence: A Comparative Analysis of 
Face-to-Face and Online Learning Environments. Int. J. Web-
Based Learn. Teach. Technol., 10, 1, 27-44. 
DOI=10.4018/ijwltt.2015010103 



[2] Brown, J., Wilson, J., Gossage, S., Hack, C., and Biddle, R. 
2013. Surface Computing and Collaborative Analysis Work. 
Synt. Lectures on Human-Centered Informatics, 6, 4, 1-168. 
DOI=10.2200/S00492ED1V01Y201303HCI019 

[3] Charleer, S., Klerkx, J., and Duval, E. 2015. Exploring 
Inquiry-Based Learning Analytics through Interactive 
Surfaces. In Proceedings of the Workshop on Visual Aspects 
of Learning Analytics held at the Int. Conf. LAK'15, 1-4.  

[4] Charleer, S., Klerkx, J., Odriozola, S., Luis, J., and Duval, E. 
2013. Improving awareness and reflection through 
collaborative, interactive visualizations of badges. In 
Proceedings of Workshop on Awareness and Refl. in Tech. 
Enhanced Learning, 69-81.  

[5] Chatti, M. A., Dyckhoff, A. L., Schroeder, U., and Thüs, H. 
2012. A reference model for learning analytics. Int. J. of Tech. 
Enhanced Learning, 4, 5 (May 2012), 318-331. DOI= 
10.1504/IJTEL.2012.051815 

[6] Dillenbourg, P., and Evans, M. 2011. Interactive tabletops in 
education. Int. J. of Comp.Supp. Collab. Learning, 6, 4 (Dec 
2011), 491-514. DOI=10.1007/s11412-011-9127-7 

[7] Dillenbourg, P., Zufferey, G., Alavi, H., Jermann, P., Do-
Lenh, S., Bonnard, Q., Kaplan, F. 2011. Classroom 
orchestration: The third circle of usability. In Proceedings of 
the Int. Conf. on Comp. Supp. Collab. Learning (Hong Kong, 
4-8 July 2011). CSCL '11. NY: Springer 510-517.  

[8] Do-Lenh, S. (2012). Supporting Reflection and Classroom 
Orchestration with Tangible Tabletops. PhD thesis. EPFL, 
Switzerland: CRAFT group, School of Computer Science.  

[9] Evans, M., and Rick, J. 2014. Supporting Learning with 
Interactive Surfaces and Spaces. In J. M. Spector, M. D. 
Merrill, J. Elen & M. J. Bishop, Eds., Handbook of Research 
on Educ. Communications and Technol. Springer, NY, 689-
701. DOI=10.1007/978-1-4614-3185-5_55 

[10] Kaendler, C., Wiedmann, M., Rummel, N., and Spada, H. 
2015. Teacher Competencies for the Implementation of 
Collaborative Learning in the Classroom: a Framework and 
Research Review. Educ. Psychology Review, 27, 3 (Sep 
2015), 505-536. DOI=10.1007/s10648-014-9288-9 

[11] Kay, J., Reimann, P., Diebold, E., and Kummerfeld, B. 2013. 
MOOCs: So Many Learners, So Much Potential. IEEE 
Intelligent Systems, 3 (May 2013), 70-77. 
DOI=10.1109/MIS.2013.66 

[12] Kharrufa, A., Martinez-Maldonado, R., Kay, J., and Olivier, 
P. 2013. Extending tabletop application design to the 
classroom. In Proceedings of the Int. Conf. on Interactive 
Tabletops and Surfaces (St Andrews, UK, 6-9 October 2013). 
ITS '13. NY: ACM, 115-124. 
DOI=10.1145/2512349.2512816 

[13] Lee, K., Tsai, P. S., Chai, C. S., and Koh, J. H. L. 2014. 
Students' perceptions of self-directed learning and 
collaborative learning with and without technology. J. of 
Comp. Assisted Learning, 30, 5 (Oct 2014), 425-437. 
DOI=10.1111/jcal.12055 

[14] Martinez-Maldonado, R., Clayphan, A., and Kay, J. 2015. 
Deploying and Visualising Teacher’s Scripts of Small Group 
Activities in a Multi-Surface Classroom Ecology: a study in-
the-wild. Comp. Supp. Cooperative Work, 24, 2 (Feb 2015), 
177-221. DOI=10.1007/s10606-015-9217-6 

[15] Martinez-Maldonado, R., Clayphan, A., Yacef, K., and Kay, 
J. 2015. MTFeedback: providing notifications to enhance 
teacher awareness of small group work in the classroom. IEEE 
TLT, 8, 2 (Jun 2015), 187-200. 
DOI=10.1109/tlt.2014.2365027 

[16] Martinez-Maldonado, R., Goodyear, P., Dimitriadis, Y., 
Thompson, K., Carvalho, L., Prieto, L. P., and Parisio, M. 
2015. Learning about Collaborative Design for Learning in a 
Multi-Surface Design Studio. In Proceedings of the Int. Conf. 
on Comp.-Supp. Collab. Learning (Gothenburg, Sweden, 7-
11 June 2015). CSCL '15. NY: Springer, 174-181.  

[17] Martinez-Maldonado, R., Kay, J., Yacef, K., Edbauer, M.-T., 
and Dimitriadis, Y. 2012. Orchestrating a multi-tabletop 
classroom: from activity design to enactment and reflection. In 
Proceedings of the Int. Conf. on Interactive Tabletops and 
Surfaces 2012 (Cambridge, USA, 11-14 November 2012). 
ITS '12. NY: ACM, 119-128. 
DOI=10.1145/2396636.2396655 

[18] Olson, J. S., Teasley, S., Covi, L., and Olson, G. 2002. The 
(currently) unique advantages of collocated work. In P. J. 
Hinds & S. Kiesler, Eds., Distributed work: New research on 
working across distance using technology. MIT Press, 
Cambridge, MA, 113-136.  

[19] Oviatt, S. 2013. The design of future educational interfaces: 
Routledge. 

[20] Prieto, L. P., Dlab, M. H., Gutiérrez, I., Abdulwahed, M., 
and Balid, W. 2011. Orchestrating technology enhanced 
learning: a literature review and a conceptual framework. Int. 
J. of Technol. Enhanced Learning, 3, 6, 583-598. 
DOI=10.1504/ijtel.2011.045449 

[21] Schell, J., Lukoff, B., and Mazur, E. 2013. Catalyzing learner 
engagement using cutting-edge classroom response systems in 
higher education. Cutting-edge Tech.in Higher Ed. E, 233-
261. DOI=10.1108/S2044-9968(2013)000006E011 

[22] Schneider, B., and Blikstein, P. 2015. Using exploratory 
tangible user interfaces for supporting collaborative learning 
of probability. IEEE TLT. in press.  

[23] Schneider, B., Kshitij Sharma, E., Sébastien Cuendet, E., 
Guillaume Zufferey, E., Pierre Dillenbourg, E., and Pea, R. D. 
2015. 3D tangibles facilitate joint visual attention in dyads. In 
Proceedings of the Int. Conf. on Comp. Supp. Collab. 
Learning (Hong Kong, 4-8 July 2011). CSCL '11. NY: 
Springer, 158-165.  

[24] Sharples, M. 2013. Shared orchestration within and beyond 
the classroom. Comp. & Educ., 69, 1 (Nov 2013), 504-506. 
DOI=10.1016/j.compedu.2013.04.014 

[25] Siemens, G. 2012. Learning analytics: envisioning a research 
discipline and a domain of practice. In Proceedings of the Int. 
Conf. on Learning Analytics and Knowledge (Vancouver, 
Canada, April 29 - May 2). LAK '12. NY: ACM, 4-8. 
DOI=10.1145/2330601.2330605 

[26] Siemens, G., and Baker, R. S. J. d. 2012. Learning analytics 
and Educ. data mining: towards communication and 
collaboration. In Proceedings of the Int. Conf. on Learning 
Analytics and Knowledge (Vancouver, Canada, April 29 - 
May 2). LAK '12. NY: ACM, 252-254. 
DOI=10.1145/2330601.2330661 

[27] Verbert, K., Duval, E., Klerkx, J., Govaerts, S., and Santos, 
J. L. 2013. Learning Analytics Dashboard Applications. 
American Behavioral Scientist, 57, 10 (Feb, 2013), 1500-
1509. DOI=10.1177/0002764213479363 

[28] Wang, P., Tchounikine, P., and Quignard, M. 2015. A Model 
to Support Monitoring for Classroom Orchestration in a 
Tablet-Based CSCL Activity. In G. Conole, T. Klobu?ar, C. 
Rensing, J. Konert & É. Lavoué, Eds., Design for Teach. and 
Learning in a Networked World. Springer, 491-496. 
DOI=10.1007/978-3-319-24258-3_45 



