
Understanding learning at a glance: An overview of

learning dashboard studies

Beat A. Schwendimann 1, Mar??a Jesu?s Rodr??guez-Triana2, Andrii Vozniuk2, Luis P. Prieto1,
Mina Shirvani Boroujeni1, Adrian Holzer2, Denis Gillet2 and Pierre Dillenbourg1

1CHILI Group, EPFL, Station 20, 1015 Lausanne, Switzerland. Email: {beat.schwendimann, luis.prieto,
mina.shirvaniboroujeni, pierre.dillenbourg}@epfl.ch

2REACT Group, EPFL, Station 9, 1015 Lausanne, Switzerland. Email: {maria.rodrigueztriana, andrii.vozniuk,
adrian.holzer, denis.gillet}@epfl.ch

ABSTRACT
Research on learning dashboards aims to identify what data
is meaningful to di?erent stakeholders in education, and how
data can be presented to support sense-making processes.
This paper summarizes the main outcomes of a system-
atic literature review on learning dashboards, in the fields
of Learning Analytics and Educational Data Mining. The
query was run in five main academic databases and enriched
with papers coming from GScholar, resulting in 346 papers
out of which 55 were included in the final analysis. Our re-
view distinguishes di?erent kinds of research studies as well
as di?erent aspects of learning dashboards and their ma-
turity in terms of evaluation. As the research field is still
relatively young, many of the studies are exploratory and
proof-of-concept. Among the main open issues and future
lines of work in the area of learning dashboards, we identify
the need for longitudinal research in authentic settings, as
well as studies that systematically compare di?erent dash-
board design options.

Categories and Subject Descriptors
K.3.1 [Computers and Education]: Computer Uses in
Education; H.5.2 [Information interfaces and presen-
tation]: User interfaces

Keywords
learning analytics, educational data mining, information vi-
sualization, dashboards, systematic review

1. INTRODUCTION
Visual displays are critical to sense-making as humans can

process large amounts of data if presented in meaningful
ways. A current major challenge in the field of education is

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
LAK ’16, April 25 - 29, 2016, Edinburgh, United Kingdom

c? 2016 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-4190-5/16/04. . . $15.00
DOI: http://dx.doi.org/10.1145/2883851.2883930

how data coming from learning platforms can be made ac-
tionable by analyzing and presenting it in ways meaningful
to di?erent stakeholders [4]. Learning dashboards build on
research in information visualization, learning analytics and
educational data mining. Although these fields are still rela-
tively young, their explosive growth already provides enough
literature to justify a systematic review. Indeed, several re-
views of learning dashboards already exist, although they
only focus on small case studies and contrasting selected ex-
amples (see, for example [5]). Thus, this paper provides a
systematic literature review of research on learning dash-
boards. The research questions addressed by this study are:
- RQ1 : In which contexts are learning dashboards applied?
- RQ2 : What are the characteristics of learning dashboards
developed so far, including their purpose, indicators pre-
sented and technologies used?
- RQ3 : How mature are such e?orts on learning dashboards,
in terms of their evaluation?

2. METHODOLOGY
When conducting the review (following the guidelines pro-

posed by Kitchenham and Charters [2]), we selected five
main academic databases relevant for Technology Enhanced
Learning: ACM Digital Library, IEEE Xplore, Springer-
Link, Science Direct, and Wiley. Google Scholar was also
used in order to detect potentially relevant ’grey literature’
(technical reports and other publications outside of classic
academic publishing channels). The search string used was:
dashboard AND (“learning analytics” OR “educational data
mining” OR “educational datamining”). Hence, the review
focuses specifically on dashboards (“a visual display of the
most important information needed to achieve one or more
objectives; consolidated and arranged on a single screen so
the information can be monitored at a glance” [1]), rather
than visualizations in general. The literature search was
conducted on 21st August, 2015.

A total of 246 papers were obtained from the afore-
mentioned databases; additionally, the top 100 results
from GScholar (from a total of 989) were added to the
analysis. Each paper was reviewed by two researchers
to determine if it was out of scope, of low credibil-
ity, or of low quality. After this filtering, 55 pa-
pers were analyzed in detail (see list of papers here
https://dx.doi.org/10.6084/m9.figshare.2066793.v1).



3. RESULTS

3.1 Types of contributions
While many of papers (39 papers; 71%) described the im-

plementation of a specific learning dashboard, only 3 papers
presented a theoretical proposal or a framework. Interest-
ingly, the definition of ’dashboard’ was addressed in just 4
papers (7%), being di?erent in each one of the cases.

3.2 Learning Context
When considering the context where dashboards were ap-

plied (RQ1), we identified di?erent target users, learning
scenarios, educational levels and pedagogical approaches dis-
cussed in the papers.

Target users. Teachers (41 papers; 75%) and students
(28 papers; 51%) are clearly the main users of the dash-
boards, although administrators and researchers also appear
in some cases.

Learning scenarios. 50 papers (91%) targeted formal
learning while the rest of the papers either addressed non-
formal learning or they did not specify the type of learning.

Educational level. 29 papers (53%) addressed univer-
sity settings and 17 (31%) did not specify the learning con-
text.

Pedagogical approach. Although the papers often
did not refer to a specific pedagogical approach (31 pa-
pers; 56%), there is a noteworthy appearance of computer-
supported collaborative learning (7 papers; 13%), blended
(5 papers; 9%), and online learning (4 papers; 7%).

3.3 Learning Dashboard Solutions
To answer RQ2 (regarding current dashboard solutions),

we analysed the (1) purpose of the dashboard, (2) types
of data sources used, (3) platforms the data was retrieved
from, (4) indicators and (5) visualizations presented in the
dashboard.

Purpose. We distinguished 3 types of dashboard pur-
poses: self-monitoring (28 papers; 51%), monitoring others
(39 papers; 71%) and administrative monitoring (1 paper;
2%). Three papers (5%) did not explicitly state a purpose
for their dashboard.

Types of data sources. The majority of papers (47 pa-
pers; 85%) mentioned logs as their data source for the dash-
board. Learning artefacts were the second most frequently-
used data source (16 papers; 29%), followed by information
explicitly asked from the users (7 papers; 13%), institutional
databases (5 papers; 9%), physical user activity (4 papers;
7%) and external APIs (3 papers; 5%). Finally, 4 papers
(7%) did not specify the used data source.

Platforms. The solutions, presented in the reviewed pa-
pers, relied in total on data coming from 51 distinct plat-
forms, of which 38 papers each mentioned a di?erent plat-
form. Moodle was the most prominent platform being used
in 18% of the papers.

Indicators. From the paper review we obtained over
200 di?erent indicators, which we categorized into 6 groups:
learner, action, content, result, context, and social-related
indicators. Regarding the subject, most of the papers pre-
sented indicators about individuals (47 papers; 85%), fol-
lowed by indicators related to whole classes (25 papers;
45%), small groups (8 papers; 15%), or large ones such as
MOOCs (5 papers; 9%).

Visualization type. The most popular five are bar

charts (33 papers; 60%), line graphs (24 papers; 44%), tables
(21 papers; 38%), pie charts (15 papers; 27%) and network
graphs (10 papers; 18%).

3.4 Evaluation
The maturity of current learning dashboard solutions, in

terms of evaluation presented in the papers (RQ3), is rather
unequal: the majority of papers (58%) contained no evalu-
ation whatsoever. Most papers used mixed methods for the
evaluation (15 papers; 65% of the evaluations), as opposed
to purely qualitative or quantitative evaluations (four and
two instances, respectively). In total, ten papers gathered
evaluation information from teachers, while 19 papers tar-
geted students. Surprisingly, most of the evaluations (74% of
the 23 papers that had evaluations) addressed general con-
structs such as usability, usefulness or user satisfaction,while
very few studies actually looked at (and provided evidence
for) the impact of these technologies on learning (e.g., [3]
did not find statistically significant e?ects).

4. IMPLICATIONS AND FUTURE LINES
OF WORK

The review reveals a lack of an agreed and shared dash-
board definition. Thus, we propose the following definition:
a learning dashboard is a single display that aggregates mul-
tiple visualizations of di?erent indicators about learner(s),
learning process(es) and/or learning context(s). Addition-
ally, we have identified certain trends and gaps that may
lead to future lines of work. For example, more than half of
the papers focused on university settings, which highlights a
need for learning dashboard studies in other settings, such as
K-12 and non-formal settings. Regarding the data sources,
the reviewed papers retrieved data mainly from logs and
only a few used external APIs, physical user activity or in-
stitutional databases. With the development of distributed
and ubiquitous learning, it will become a must to aggregate
complementary data sources. The field still lacks compara-
tive studies among di?erent dashboards or dashboard design
options as well as empirical studies on the long-term impact
and a?ordances of learning dashboards, especially in terms
of learning gains.

5. REFERENCES
[1] S. Few. Information dashboard design. O’Reilly, 2006.
[2] B. Kitchenham and S. Charters. Guidelines for

performing systematic literature reviews in software
engineering. Technical report, Keele University (UK),
2007.

[3] Y. Park and I.-H. Jo. Development of the Learning
Analytics Dashboard to Support Students’ Learning
Performance. Journal of Universal Computer Science,
21(1):110–133, 2015.

[4] R. Sutherland, S. Eagle, and M. Joubert. A vision and
strategy for Technology Enhanced Learning. Report
from the STELLAR Network of Excellence, 2012.

[5] K. Verbert, S. Govaerts, E. Duval, J. L. Santos,
F. Van Assche, G. Parra, and J. Klerkx. Learning
dashboards: an overview and future research
opportunities. Personal and Ubiquitous Computing,
18(6):1499–1514, 2014.



