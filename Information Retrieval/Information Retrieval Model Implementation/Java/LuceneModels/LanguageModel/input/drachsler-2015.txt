
Ethical and Privacy Issues  
in the Application of Learning Analytics  

Hendrik Drachsler 
Open University of the Netherlands 

Welten Institute 
hendrik.drachsler@ou.nl 

 
Gábor Kismihók 

University of Amsterdam 
Center of Job Knowledge Research 

Amsterdam Business School 
G.Kismihok@uva.nl 

 
Weiqin Chen 

Oslo and Akershus University 
College of Applied Sciences 

Weiqin.Chen@hioa.no 
 

Tore Hoel 
Oslo and Akershus University 
College of Applied Sciences 

tore.hoel@hioa.no 
 

Alan Berg 
University of Amsterdam 

ICT Services 
a.m.berg@uva.nl 

 
 

Adam Cooper 
University of Bolton 

CETIS 
a.r.cooper@bolton.ac.uk 

 

Maren Scheffel 
Open University of the Netherlands 

Welten Institute 
Maren.Scheffel@ou.nl 

 
Rebecca Ferguson 
The Open University 

Institute of Educational Technology 
rebecca.ferguson@open.ac.uk 

 
 

Jocelyn Manderveld 
 SURF 

Jocelyn.Manderveld@surfnet.nl 

Abstract 
The large-scale production, collection, aggregation, and 
processing of information from various learning platforms and 
online environments have led to ethical and privacy concerns 
regarding potential harm to individuals and society. In the past, 
these types of concern have impacted on areas as diverse as 
computer science, legal studies and surveillance studies. Within a 
European consortium that brings together the EU project LACE, 
the SURF SIG Learning Analytics, the Apereo Foundation and the 
EATEL SIG dataTEL, we aim to understand the issues with 
greater clarity, and to find ways of overcoming the issues and 
research challenges related to ethical and privacy aspects of 
learning analytics practice. This interactive workshop aims to 
raise awareness of major ethics and privacy issues. It will also be 
used to develop practical solutions to advance the application of 
learning analytics technologies. 

General Terms 
Algorithms, Measurement, Design, Human Factors, Legal Aspects 

Keywords 
Learning analytics, ethics, privacy, legal rights, data ownership, 
surveillance 

1. Introduction 
Until now, there have been few papers published relating to ethics 
and privacy in the research field known as ‘learning analytics’ 
[1]2,[3][4] and even fewer policies or guidelines regarding 
privacy, legal protection rights or other ethical implications that 
address Big Data in Education. One exception is a recent policy 

published by the Open University UK1. Whereas the law relating 
to personally identifiable information (PII) is widely understood, 
there has been insufficient attention to privacy from a user-
centered perspective, and there are no clearly defined best 
practices for scenarios such as anonymisation of educational data. 
One of the particular challenges of the context of education is that 
it requires a degree of openness on the part of the learner. 
Learners perform learning tasks within a learning environment in 
order to increase their knowledge and develop competences, and 
they expect to receive support to overcome gaps in knowledge. 
They also expect to be in a safe environment where they can make 
mistakes without fearing any serious consequences.  
Using learners’ behavior and performance data in the context of 
learning analytics enables others to determine, visualize, and 
report strengths and weaknesses of individual learners and larger 
groups. In principle, this has always been the case in education; 
however, learning analytics enable the provision of this 
information in real time and on demand. Furthermore, learning 
analytics can take much more information into account than 
classroom assessment procedures, and it may not be clear to the 
learner which data is being used. Learning analytics can be used 
to compute the relationships between learners based on their 
interactions, or to compare the investment of a learner in a course 
based on time spent on the learning material, or to compare text 
written by students with pre-existing corpora. Thus, learning 
analytics go far beyond traditional assessment procedures and 
affect the privacy rights of learners in a new manner, necessitating 
a clarification of the concept. In this workshop, we will 
investigate different privacy notions and solutions, and propose 
ways of reconciling these in the field of learning analytics. 

2. Ethics & Privacy in Learning Analytics 
An analysis of papers presented at the LAK14 conference reveals 
that privacy is recognised as an important issue; however, privacy 
is not dealt with in any depth. Twelve of the 57 papers presented 

                                                                    
1http://www.open.ac.uk/students/charter/essential-documents/ethical-use-

student-data-learning-analytics-policy  

Permission to make digital or hard copies of part or all of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. Copyrights 
for third-party components of this work must be honored. For all other 
uses, contact the Owner/Author. Copyright is held by the authors. 

LAK '15, Mar 16-20, 2015, Poughkeepsie, NY, USA  
ACM 978-1-4503-3417-4/15/03. 
http://dx.doi.org/10.1145/2723576.2723642 

 

390



at the conference mentioned privacy, three of them describing 
how data had been anonymised to protect privacy. The rest of the 
papers that mentioned this subject were concerned with privacy 
for example as a barrier [5], as a restriction on data tracking, and a 
property of a cluster of stakeholder concerns revolving around 
risks [6]. 
The challenges posed by privacy are clearly obstacles that need to 
be overcome in order to reap the benefits of learning analytics. 
Arnold et al. noted that “many myths surrounding the use of data, 
privacy infringement and ownership of data need to be dispelled 
and can be properly modulated once the values of learning 
analytics are realized” [7]. This theme was also taken up by [5], 
“Learners need to be convinced that [these analytics] are reliable 
and will improve their learning without intruding into their 
privacy”. Swenson [8] called for ethical literacy among learning 
analytics practitioners, “maintaining an ethical viewpoint and 
fully incorporating ethics into theory, research, and practice of the 
LAK discipline”. 
Aguilar [5] noted that it is important to be mindful of privacy 
when designing user interfaces. However, Piety [10] observed that 
approaches to privacy are likely to depend on context. While 
ethics and privacy are features of educational data sciences in 
many arenas, there are often distinctions between the approaches 
to these issues from private companies and public entities. In 
many countries, public bodies must adhere to regulations and 
standards when dealing with data. For example, those in the USA 
are required to adhere to the Family Educational Rights and 
Privacy Act (FERPA) and other regulations. However,  “in the 
private sector there are fewer restrictions and less regulations 
regarding data collection and use” [10].  
Privacy is typically not defined in the LAK community papers we 
have analyzed. In order to make issues related to privacy more 
central to learning analytics application design, there is a need to 
unpack this concept in terms of its sociocultural context. Privacy 
is related to how data are used in learning analytics. When data 
contain information that can be linked to a specific individual, we 
refer to them as ‘personal data’. We also talk about ‘private data’, 
data that individuals want to keep to themselves and share only on 
their own terms. The boundaries between personal and private 
data are social agreements that depend on who the person is and in 
what social setting the data are created. A key question to be 
addressed is ‘Who owns the data?’ The answer certainly involves 
the individual associated with these data, but assigning ownership 
of the data to this person is often too simple a solution. Data are 
often generated in a social context – they may be seen as a 
resource that is shared within a community or a network. Some 
rights may also rest with the individual or organization that is 
responsible for generating and storing these data, or for arranging 
and visualizing sets of data in ways that generate actionable 
insights. 

3. Workshop Organization 
3.1 Workshop Facilitators  
The workshop will be organized jointly by the FP7 EU LACE 
project (http://www.laceproject.eu), the Apereo Foundation 
(https://www.apereo.org), the SURF SIG Learning Analytics 
(https://www.surfspace.nl/sig/18-learning-analytics/) and the 
European Association for Technology Enhanced Learning 
(EATEL) SIG dataTEL (http://ea-tel.eu/sig-datatel/). All partners 
aim at advancing the learning analytics field by coming up with 
practical solutions and guidelines for ethical & privacy issues that 

are a critical part of most data-driven research in Education. The 
main goals are to increase the knowledge and awareness about 
ethical and privacy boundaries of learning analytics research and 
practice, to identify existing theories of trust and privacy, to 
promote the re-use of best practice solutions on privacy and 
ethics, to foster the cooperation between different learning 
analytics research units, and to develop a kind of code of honor 
for learning analytics research supported by IT-based legal tools.  

3.2 Expected outcomes of the workshop 
We aim to publish the submitted topics and the practical solutions 
gained from the workshop in proceedings that will be 
disseminated by the LACE project after the workshop. 

4. ACKNOWLEDGMENT 
The LACE project is funded by the European Commission 
Seventh Framework Programme, grant number 619424. 

References 
[1] Greller, W., & Drachsler, H. (2012). Translating learning 

into numbers: a generic framework for learning analytics. 
Educational Technology & Society, 15 (3), 42–57. 

[2] Prinsloo, P, & Slade, Sharon. (2013, 8-12 April). An 
evaluation of policy frameworks for addressing ethical 
considerations in learning analytics. Paper presented LAK13, 
Leuven, Belgium. 

[3] Slade, Sharon, & Prinsloo, Paul. (2013). Learning analytics: 
ethical issues and dilemmas. American Behavioral Scientist, 
57 (10), pp. 1510-1529 

[4] Pardo, A., & Siemens, G. (2014). Ethical and privacy 
principles for learning analytics. British Journal of 
Educational Technology, 45(3), 438-450. 

[5] Ferguson, R., De Liddo, A., Whitelock, D., de Laat, M., & 
Buckingham Shum, S. (2014). DCLA14: Second 
International Workshop on Discourse-Centric Learning 
Analytics. (pp. 283-284). In Proceedings of the LAK14, New 
York, USA: ACM Press. doi:10.1145/2567574.2567631 

[6] Drachsler, H., Stoyanov, S., & Specht, M. (2014). The 
impact of learning analytics on the Dutch education system 
(pp. 158–162). In Proceedings of the LAK14, New York, 
USA: ACM Press. doi:10.1145/2567574.2567617 

[7] Arnold, K. E., Lynch, G., & Huston, D. (2014). Building 
Institutional Capacities and Competencies for Systemic 
Learning Analytics Initiatives, (pp. 257-260). In Proceedings 
of the LAK14, New York, USA: ACM 
Press.doi:10.1145/2567574.2567592 

[8] Swenson, J. (2014). Establishing an ethical literacy for 
learning analytics, (pp. 246-250). In Proceedings of LAK14, 
New York, USA: ACM Press.doi:10.1145/2567574.2567631 

[9] Aguilar, S. (2014). Perceptions and Use of an Early Warning 
System During a Higher Education Transition Program, (pp. 
113-117). In Proceedings of LAK14,  New York, USA: ACM 
Press.doi:10.1145/2567574.2567592 

[10] Piety, P. J., Hickey, D. T., & Bishop, M. J. (2014). 
Educational Data Sciences – Framing Emergent Practices for 
Analytics of Learning, Organizations, and Systems, (pp. 193-
202). In Proceedings of LAK14,  New York, USA: ACM 
Press. doi:10.1145/2567574.2567631 

 

391





