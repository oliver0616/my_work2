
Critical realism and learning analytics research: 
epistemological implications of an ontological foundation 

Tim Rogers 
 
 
 
 

University of South Australia 
Learning and Teaching Unit 
Adelaide, South Australia 

tim.rogers@unisa.edu.au 
 

 
 
 
 
 
 

ABSTRACT 
Learning analytics is a broad church that incorporates a range of 
topics and methodologies. As the field has developed some 
tension has emerged regarding a perceived contradiction between 
the implied constructivist ethos of the field and prevalent 
empirical practices that have been characterised as ‘behaviourist’ 
and ‘positivist’. This paper argues that this tension is a sign of 
deeper metatheoretical faultlines that have plagued the social 
sciences more broadly. Critical realism is advanced as a 
philosophy of science that can help reconcile the apparent 
contradictions between the constructivist aims and the empirical 
practices of learning analytics and simultaneously can justify 
learning analytics’ current methodological tolerance. The paper 
concludes that learning analytics, arrayed in realist terms, is 
essentially longitudinal and multimethodological, concerned with 
the socio-technical systems of learning and the problems of 
implementation, and has the potential to be emancipatory. Some 
methodological implications for learning analytics practice are 
discussed.  

Keywords 
Critical realism, philosophy of science, theory. 

1. INTRODUCTION 
Learning analytics (LA) is defined as both a discipline of 
investigation and an approach to inform practical applications, 
seeking to “close the loop”[13] between research and educational 
practice[46]. The generally agreed definition of the field—that LA 
involves the use of data in order to understand and improve 
learning and learning contexts[27]—has been increasingly 
interpreted as a pedagogically informed, learner centred and 
broadly constructivist in aim[18]. 
As an umbrella term, LA has sponsored a multitude of topics and 
methodological approaches. For example, with respect to the 
topics of investigation, LA has examined the potential 
demographic and behavioural indicators of dropout and 
failure[17, 24], learners’ social networks[15], the conditions that 
optimise learning[25], and the politics of adoption[29]. In terms 
of methodology, LA has incorporated methodologies from the 
quantitative and qualitative realms, and numerous techniques 
within each of these broad categories: sophisticated data mining 
and machine learning, varieties of inferential statistics, survey 
research and action research co-exist on conference schedules. 

Despite this ‘let a thousand flowers bloom’ approach, as the field 
develops limits to this catholicity are becoming evident.  While 
many LA researchers and practitioners interpret LA as 
constructivist [45], much of the early work has focused on the 
statistical prediction of outcomes, chiefly grades or retention, by 
relating these target variables to predictor variables harvested 
from students’ demographic and institutional variables, and their 
interaction with the LMS[47].  
Several authors have pointed out the essential contradictions that 
this line of research introduces to the field.  Where LA has an 
interventionist aim to “inform and empower instructors and 
learners”[46], the pursuit of decontextualised variables organised 
in stimulus-organism-response sets can undermine the role of 
sense-making for both learners and teachers, therefore potentially 
diminishing their agency, and so appears antithetical to 
constructivist pedagogies[4, 26]. Hence, advocates of 
constructivist approaches have characterised this research, 
pejoratively, as ‘clickometry’[16], and described it as both 
‘postitivist’ and ‘behaviourist’[4, 26]. Their concern, put starkly, 
is that some key research in LA threatens to inadvertently foster a 
return to behaviourist teaching methodologies, curriculum design 
and institutional strategies that have long been superseded in 
educational theory[4]. 
Nevertheless, these so-called positivist strands of research 
themselves draw on principles that have come to be seen as 
canonical in the short history of the broader analytics movement: 
that the analysis of large data sets can establish the objective 
existence of patterns that lead to novel insights and revolutionise 
practice by upending conventional understandings[14]. This 
pivots on the reasonable assumption that people may not have an 
adequate understanding of the sources and impacts of their own 
actions and that even experts can be mistaken in their attributions 
of cause and have deficient mental models of their domain of 
expertise: baseball scouts with decades of experience may not 
know the key variables that together identify the player qualities 
that make up a winning team[3], and experienced insurers reject 
high risk client segments that  statistical interrogations reveal to 
be pockets of profitability[14]. 
This paper suggests an ontological and epistemological grounding 
that organises the field in a way that both incorporates the myriad 
topics of LA and reconciles the disparate approaches taken, but 
does so by setting boundaries on their purpose within learning 
analytics. The fundamental questions asked are: In what sense is 
learning analytics a learning science, and construed thusly what 
research aims make sense?  
In answer, a sophisticated realist account that entails the centrality 
of ontology is put forward. Construed in this way LA is 
necessarily, and unavoidably, founded on the beliefs that learners 
and educators have about their learning, teaching, and the learning 

Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are not 
made or distributed for profit or commercial advantage and that copies bear 
this notice and the full citation on the first page. Copyrights for components 
of this work owned by others than ACM must be honored. Abstracting with 
credit is permitted. To copy otherwise, or republish, to post on servers or to 
redistribute to lists, requires prior specific permission and/or a fee. Request 
permissions from Permissions@acm.org.  

LAK '15, March 16 - 20, 2015, Poughkeepsie, NY, USA 
ACM 978-1-4503-3417-4/15/03…$15.00 

http://dx.doi.org/10.1145/2723576.2723631 
223

mailto:Permissions@acm.org
http://dx.doi.org/10.1145/2723576.2723631


context. However, LA is not limited by these beliefs, which are 
not unimpeachable and so susceptible to challenge or extension 
through the analysis of data, including the mining of large data 
sets. Indeed, such a challenge need not be antithetical to 
constructivist aims and is in fact core to the constructivist project.  
I conclude that LA, arrayed in realist terms, is essentially 
longitudinal, multimethodological research program that is 
concerned with the socio-technical systems of learning, the 
problems of implementation, and is potentially emancipatory. 

2. EMPIRICISM 
The argument presented here draws primarly on critical realism, 
(CR) a philosophy of science associated for the most part with the 
seminal work of Roy Bhaskar[7, 11] and having an increasing 
impact on the foundational assumptions of a range of social 
sciences[1, 31]. CR makes an incisive, some would say 
decisive[35] critique of the research status quo in the social 
sciences and offers an ontological grounding that reconciles 
quantitative and qualitative research. 
It is not, however, an ‘anything goes’ argument, but more a 
position that subordinates methodology to the purpose of 
establishing enquiry into real, underlying, causal mechanisms. CR 
makes the claim that the empiricism that implicitly drives the 
research practices of the social sciences hamstrings our efforts to 
establish ontologically deep causal theories and instead sponsors 
methodologies that focus on surface level observations that, 
although objective, can be very misleading. A key to 
understanding the power of CR, then, is to surface the embedded 
assumptions in many current practices that make them less science 
than scientism[20, 43]. 
Many researchers working in the social sciences presume that the 
quantitative research practices in their discipline are grounded in a 
universal, asocial scientific rationale (for example, in information 
systems research, clinical psychology and management research 
respectively we have:[6, 33, 42].  However, the descriptive 
correlational scientific practice that underpins most quantitative 
research in the social sciences is derived from a historically 
contingent philosophical account of science known as scientific 
empiricism[20], often referred to as ‘positivism’. That is, the 
experimental and statistical practices that have become the 
standard bearers for rigour and rationality are based on one 
particular version of scientific reasoning. 
Empiricism has its philosophical roots, to a large extent, in the 
empiricist writings of the 18th century Scottish philosopher David 
Hume[5, 7, 20]. Hume was an epistemological idealist that held 
that we have no direct knowledge of objects, only of our sense 
impressions, and it is only in these impressions that we can locate 
secure foundations for knowledge. This was initially endorsed by 
logical positivists in the early part of this century but had the 
problem that it would result in a science of private mental 
experiences, rendering the data it uncovered incapable of 
intersubjective validation[20]. Later empiricists moderated this 
account to claim that sense impressions and the resultant 
descriptions of objects referred to actual physical objects[5]. This 
was known as physicalism and its practitioners preferred to be 
known as scientific empiricists[20]. Scientific empiricism 
underpins most of the purportedly ‘scientific’ research in the 
social sciences. 
Knowledge of causality, according to the original Humean 
account, was garnered through a series of encounters with 

constant conjunctions. Concepts like ‘causal powers’ were held to 
be a mystification. The only actual connection between two 
phenomenon that could be discriminated beyond doubt was given 
in their contiguity[5, 20]. This assumption is the bedrock of the 
empiricist epistemology of science and legitimises the subsequent 
strategies the empiricist adopts to understand and explain the 
social world. Introductory texts on methodology, for example, 
expound as catechism the fundamentals of the scientific empiricist 
approach: 
“Three types of evidence are necessary to demonstrate causality: 
the variables must show a linkage or association; one variable 
must precede the other in time; and there must be an absence of 
other causal factors”[44]. 
This description is essentially the formalisation of the Humean or 
regularity causal account. The goal of the scientific empiricist, be 
it through experimental, quasi-experimental or 
survey/questionnaire methodologies, is to document this 
association of variables, with early empiricists favouring 
observation and induction as the way to the empirical goal of 
secure foundations for knowledge, commonly, and disparagingly, 
referred to as ‘foundationalism’[5]. The scientific empiricists 
eventually supplanted this epistemically imperious goal with the 
stringent but logically satisfying claim that the best science could 
decisively demonstrate was the falsification of theories. They also 
accepted the necessity for a deductive component in theory 
development. In Hempel’s influential deductive-nomological, or 
‘covering law’, account of explanation[22] causal explanation is 
equated with a description of observational regularity. The event 
to be explained, the explanandum, is subsumed under one or more 
covering laws. Explanation is derived from a deduction of a 
description of the explanandum from one or more such laws, 
along with a description of initial conditions, which together 
constitute the explanans. For example, we could deduce “the gas 
expanded” from the causal law “all heated gases expand” and the 
initial condition “the gas was heated”. The upshot of this was that 
explanation and prediction were treated as “symmetrical with 
respect to their logical form”[20]. That is, a change in the tense in 
the example above gives a prediction of what will happen to the 
gas when it is heated. Prediction was thus elevated into a major 
criterion for the adequacy of a causal explanation, and even the 
fundamental goal of the scientific endeavour[20, 35]. 
The immediate problem for the social sciences generally is that 
causal explanations need to describe sufficient causes if they are 
to provide logically deductive explanations and predictions. Yet 
in the social sciences this Humean regularity is never obtained. In 
learning analytics, for example, we may be working with the 
explanandum ‘the students’ learning increased’ and be attempting 
to subsume this under the causal law ‘LMS tool use increases 
student learning’ coupled with the initial condition ‘the students 
were provided with LMS tools’. The problem here is that the 
‘law’ in this case is not a description of an observational 
regularity, so not really a law. A correlation between LMS tool 
use and learning is bound to only hold at times, meaning the 
explanans do not provide logically sufficient conditions for the 
explanandum. Hempel’s solution was to develop a statistical 
covering law model for those sciences that failed to generate 
sufficient causes easily. Statistical or probabilistic explanation 
holds that a probabilistic law coupled with appropriate initial 
conditions makes the explanandum highly likely. The relationship 
is now supportive, rather than a logical deduction. Hempel’s own 
example is “Jim caught the measles” as the explanandum, which 

224



is jointly explained by the covering law “the probability for 
persons exposed to the measles to catch the disease is high” and 
the initial condition “Jim was exposed to the measles”[22]. Even 
though this does not permit absolute certainty in prediction, it 
warrants cautious predictions that were considered good enough 
for a developing science. 
The primary and well-documented problem with the Humean 
causal account is that it cannot distinguish between accidental and 
causal correlations[7, 12]. Clearly, as Hume himself recognised, 
this demonstrates that there is more to cause than correlation, but 
the proposition that cause is given in constant conjunction cannot 
account for this ‘surplus’ element. This problem plays out in two 
related ways. Firstly, events can be proximate and strongly 
correlated without any causal connection whatsoever; I always 
take tea at 10:30, my neighbours always watch the news on 
television at the same time. Any layperson can easily see that 
there is no causal relationship between these events, yet the 
empiricist must struggle with ad hoc adjustments to accommodate 
this. Conversely, events can be poorly correlated but certainly 
causal. The Sabin polio vaccine was only minutely correlated with 
the contraction of Poliomyelitis, but we know that on the rare 
occasions it was contracted the vaccine was indeed the cause[41].  
Again, this must be mystifying to the empiricist. These kinds of 
everyday examples have left empiricists with an enduring problem 
that has not been adequately defended: how can the lay 
understanding be superior to the empiricist’s in distinguishing 
between causal and accidental correlation? This is a point rightly 
emphasised by Bhaskar[7] and Greenwood[20], for without the 
warrant of the Humean causal explanation the epistemological 
prescription of the deductive-nomological account and the 
consequent methodological strategies of empiricism lose their 
logical force. If at the very least correlation is not sufficient to 
establish cause[21] and at the most it is not even necessary[7], 
empiricism is crucially undermined as an adequate account of the 
natural sciences, let alone the social sciences. 
The adherence to the empiricist account of science yielded a 
number of enduring methodological problems: 

 Behaviour substitutes for meaningful action. Presuming 
variables to be constant across contexts runs the evident 
risk of ignoring the meaningful nature of social action. 
The great lesson of the failure of behaviourism was the 
impossibility of identifying actions through the 
description of physical behaviour (such as mouse clicks) 
because the identification of the meaning of any action 
requires the comprehension of the context and of the 
relevant student and educator intentions and their social 
relations. As the poet Stevie Smith suggests, the same 
movement can mean quite different things - “not waving 
but drowning”[48]. 

 Variable co-creation in systemic patterns is ignored. The 
empiricist is necessarily interested in the relationship 
between discrete variables. But many social events and 
objects of interest co-vary because they are internally 
related[8]. For example, the development of an 
assessment procedure that tests objective knowledge as 
facts creates the conditions for students to consider 
content knowledge as paramount. But student beliefs 
about the primacy of content facts become expectations 
about how teaching should look, creating pressures (via, 
for example, student evaluations) for educators to 
continue with a curriculum focussed on fact recall, a 

problem documented in the Problem-based learning 
literature. Student expectations and assessment practices 
together may create a dynamic of increasingly shallow 
curriculums and a timid educational culture, presumably 
the opposite outcome to that envisaged by the 
procedure’s designers. In these systemic relationships 
the identity of variables overlaps and cause is mutual, or 
rather “inheres within a pattern—that, in a manner of 
speaking, is the pattern”[2]. 

 Difficult to measure but causal candidates are omitted 
from analysis. The notion of ‘measurable variables’ 
immediately precludes the investigation of meaningful, 
relational and unquantifiable social objects such as 
reasons, norms and rules. The assumption here is that 
the social world can be adequately understood by 
reference to discrete, constant and quantifiable entities.  

In sum, the empiricist atomistic focus ignores the issue of context, 
or situated meaning, in favour of a descriptive correlative 
cataloguing of events. The presumed benefit is that these 
correlative findings are objective and hence superior to lay 
accounts of cause that may be influenced by bias and other 
distorting tendencies[34, 40]. It is of some concern to the 
empiricist, then, when practitioners fail to utilise their research, 
resulting in the so-called ‘scientist-practitioner divide’ in 
psychology or the related ‘rigour versus relevance’ debate in 
organisational research[32, 37]. The practitioner in both of these 
debates is often considered, from the scientific empiricist’s point 
of view, to be acting irrationally by failing to draw on the 
published ‘scientific’ research[33].  For learning analytics, where 
intervention has been foregrounded as a guiding principle, a 
similar disjuncture between research and practice would be an 
intolerable problem. The argument of the following section 
describing critical realism is that this gap is primarily the result of 
the empiricist framing of the aims of research, which misconstrues 
the purpose of science. The reframing provided by CR is proposed 
as a way of both retaining the scientific goal of objectivity without 
sacrificing the practitioner aim of actionable knowledge for their 
situated problems (i.e. problems governed, at least partly, by their 
specific context). 

CRITICAL REALISM 
CR is a position within the philosophy of science largely but not 
exclusively identified with the work of Roy Bhaskar[7, 11]. CR is 
realist in the sense of advocating, contra Hume, the existence of 
an external world independent of our knowledge of it. Indeed, CR 
argues the social practices that make up science only make sense 
given the assumption that there is something that science is about, 
that exists whether or not there are scientists available to 
comprehend it[7]. CR is critical in several senses. Firstly, the 
surface appearances of the world may be, and often are, 
misleading, hence the need for science in the first place[7]. 
Secondly, science itself is a social and historical process, a 
product of human labour that makes fallible attempts to represent 
or capture the mechanisms and structures that underlie 
appearances, and so is always subject to revision[7]. Thirdly, with 
respect to the social sciences, the potential for underlying 
conditions, mechanisms and structures to have misleading 
appearances and the historically and socially conditioned 
knowledge of these appearances suggests that social science is 
potentially emancipatory[8, 10]. That is, the conditions for 
knowledge may systematically generate false appearances 

225



masking as real causes, and this may be a pre-condition of their 
perpetuation. Knowledge of real causes, therefore, is 
emancipatory much as knowing the actual practices of a conjuring 
trick enables one not to be fooled by the magician. 
Many, perhaps most, of the insights CR has for the natural and 
social sciences stem from one key argument in Bhaskar’s seminal 
A Realist Theory of Science[7]. There Bhaskar develops a 
transcendental argument, detailed below, from the role and 
practice of scientific experimentation that shifts the philosophy of 
science’s gaze from epistemology to ontology.  A transcendental 
argument is one that moves from some uncontroversial ends to 
means or underlying conditions. It seeks to uncover the 
presuppositions implicit in an accepted theory, argument or state 
of affairs. Bhaskar asks the transcendental question “what must 
the world be like for science to be possible?”[7]. Bhaskar takes 
his empiricist opponents’ accepted state of affairs—the success of 
science, particularly with reference to physics and chemistry—and 
explores the preconditions for the establishment of natural laws 
and their subsequent technological exploitation. Here Bhaskar 
focuses on the crucial role of experiments. The purpose of 
experimentation according to the empiricist is the discovery of 
conjunctions that are then expressed as natural laws. Experimental 
setups are designed to isolate causal factors and the exclusion of 
interference conditions through control of the experimental 
environment. The ontic closure obtained makes the regularity 
available where it otherwise would not exist. Experiments, then, 
are social interventions in the natural world that create the 
conditions for the observed relationship between variables[7]. 
The laws thereby discovered are presumed to operate outside of 
the closed conditions of the experimental set-up in the open 
system where they are used to explain phenomena and develop the 
practical technologies that make radio waves, electrical currents, 
bridges, and so on, possible. However, the invariant regularity 
obtained under closed experimental conditions may never be 
realised, let alone experienced by the researcher, outside of the 
laboratory. There must, then, be a difference between invariant 
conjunction and reality as given in empirical laws. The former 
relates to the outcome of the social activity of scientists as they 
intervene to produce the closure that makes conjunction possible. 
Empirical laws, on the other hand, are the expressions of the 
causal powers of things that continue to operate outside of the 
controlled experimental environment, may exist yet be 
unactualized (acid has the power to corrode, even if it is not doing 
so in my test tube), or may be actualized but not observed (the 
process is not detected by scientists although it is taking place). 
Laws, then, are “neither actual nor empirical. Constant 
conjunctions are produced not found”[9]. Science is work, not the 
passive observation of successive events as the empiricist would 
have it. 
Bhaskar’s argument is an attempt to return ontology to the centre 
of the philosophy of science. By making the observable 
coextensive with reality the empiricists have reduced ontology to 
epistemology. Things are as we perceive them, laws are given in 
experience - “We have no knowledge of anything but 
phaenomena”[35], as the empiricist John Stuart Mill put. But the 
transcendental argument from the possibility and intelligibility of 
experimentation conveys instead a world that exists independently 
of our knowledge, which is in part knowable, and can be 
manipulated. The objects of the natural world exist independently 
of our conception of them and act as they do in respect of their 
causal powers. From this realist ontological perspective the role of 

science is to uncover and explain the generative mechanisms and 
structures that give rise to observed phenomena. This implies a 
deep ontology of which surface events are but one aspect. There 
are events as perceived, the empirical level that empiricists have 
fastened upon. Then there is the realm of the actual; events that 
exist but are unobserved. Beyond, or beneath this is the realm of 
the real; the generative mechanisms and structures which give rise 
to the actual and empirical. Reality, then, has ontological depth, 
or is stratified, as opposed to the flat event sequence proposed by 
the Humean causal account. The focus of the explanatory 
programme shifts from prediction on the horizontal plane of 
successive events to vertical explanations that involve historical 
conditions and generative mechanisms[7].  
This recasting of the scientific enterprise uncouples conjunction 
and causation, and hence prediction and explanation. From the 
critical realist analysis the empiricists have erred by conflating 
prediction and explanation. Conjunction is not sufficient or even 
necessary for establishing cause. Causal mechanisms may exist 
and be unobserved because their identity is masked by the 
operation of other laws in the open system (as a leaf can be acted 
on by the laws of thermodynamics and gravity simultaneously[12] 
or exist yet be unexercised (if, for example, the requisite stimulus 
or enabling conditions are unavailable). Critical realism instead 
posits laws as transfactual, that is, they identify causal 
mechanisms that hold in both closed and open systems, although 
their manifestation in the open system is subject to interference 
and enabling conditions. This resolves the puzzle over the 
distinction between accidental and necessary conjunctions, a 
problem that arises from the empiricist’s implicit ontology of 
surface events: 
“There is a distinction between the real structures and 
mechanisms of the world and the actual patterns that they 
generate. And this distinction in turn justifies the more familiar 
one between necessary and accidental sequences. For a necessary 
sequence is simply one which corresponds to, or is in phase with, 
a real connection; that is, it is a real connection actually manifest 
in the sequence of events that occurs.”[7] 
If the work of science is not to observe conjunctions but to 
facilitate, through intervention where possible, the uncovering of 
structures and causal powers, then the deductive account of 
empiricism does not provide an adequate model of scientific 
reasoning. Hempel’s deductive covering law account will not 
suffice because it merely presupposes and formalises the Humean 
causal account. In contrast, critical realists consider retroduction, 
a form of transcendental argument, as the rational process 
scientists engage in when attempting to explain phenomena, 
effects or objects: 

“The process of scientific discovery according to the realist is: 1. 
an effect is identified and described. 2. a hypot  
mechanism is postulated which, if it existed, would explain the 
effect. 3. the attem p         
operation of the mechanism (a) positivel    
activity, designed to isolate and in some cases directly observe the 
mechanism. (b) negatively, by the elim inon of alternative 
explanations.”[35]. 

CRITICAL NATURALISM 
In The Possibility of Naturalism Bhaskar[11] extended the critical 
realist argument to the social sciences. His aim was to 
demonstrate the failings and contradictions of the two standard 
positions on the role, and indeed the possibility, of human 

226



sciences. On the one hand, if the empiricist project was 
inadequate in the natural sciences then it clearly cannot be 
extended to the social realm, and attempting to do so has 
produced serious distortions in scientific practice. On the other 
hand, against the contrasting hermeneutic position that the social 
realm is best interpreted rather than causally explained, Bhaskar 
argues that this interpretive necessity is no barrier to a scientific 
(i.e. causal) examination of the social. In terms of practical 
dividends, the key distinction between this CR version of a social 
science and the empiricist version is that while the logic of the 
scientific enterprise is the same in both the natural and social 
domains, the very different subject matters of these domains will 
ground significant variations in methodology. 
Bhaskar starts by asking what properties society and persons have 
that they might be the object of scientific investigation. 
Continuing a focus on the ontological, he posits transcendental 
arguments from the acknowledged activities of social life (such as 
banking a cheque) to refute both individualist and structuralist 
accounts of the social world. Against individualism he argues that 
many social objects and actions presuppose the social, “A 
tribesman implies a tribe, the cashing of a cheque a banking 
system”[11]. Language itself presupposes a community of 
language users, rules of grammar and a shared vocabulary. Just as 
there is no private language, there is no society made of 
individuals acting autonomously. However, structuralist accounts 
have their limits also, the individualist thesis is correct in the 
sense that “the material presence of social effects consists only in 
changes in people and changes brought about by people on other 
material things”[11]. Social structures are only sustained, 
reproduced and transformed by human agency. Someone banks a 
cheque, speaks a language and invents a word. 
So social structures compel some actions, provide and limit the 
possibilities for others, and proscribe still other actions, but do not 
determine action in a reductionist sense. Within these structures 
individuals occupy positions that both allow the exercise of 
powers and constrain possibilities. A juror is required to 
determine guilt or innocence; a judge is required to determine 
condign punishment. Both have the power, as the result of their 
position in the legal system, to have important and real 
consequences for others through their actions. There are limits to 
action posed by structures also. Judges are required to determine 
judgements within the bounds of precedent and and/or within a 
politically determined range.  
On the question of how the social and psychological form a 
dynamic whole, Bhaskar proposes a “transformational model of 
social activity” (TMSA)[11] to account for the relations of 
individuals and society in the ongoing production of the social 
world. The TMSA attempts to do justice to both the constraints 
imposed and powers afforded by social structures and the 
intentional activity of agents. In the TMSA society is the 
condition for and structures the possibilities for individuals, 
individuals in turn in their actions reproduce or occasionally 
transform society. Individuals do not then create society, because 
it always pre-exists them. But society in turn cannot exist without 
individuals. The requisite skills of the individual are provided 
through socialisation into the practices, norms, and rules that 
govern individual activity within the social world. 
While this account views society as the skilled outcome of agent 
activity[8], this does not mean that agents are consciously 
engaged in producing this outcome - people do not, as Bhaskar 
has put it, marry to reproduce the nuclear family. Indeed, the tacit 

and automatic processes that sustain social structures suggests an 
important distinction between hermeneutic approaches and critical 
naturalism: agents may not be in a position to cast light on the 
meaning, purpose and outcomes of their practices even if they can 
be relied upon to correctly identify them. 

LEARNING ANALYTICS AS A LEARNING 
SCIENCE 
Currently LA is a very broad methodological church and there is 
considerable scope for investigation of a range of issues, 
incorporating intensive and large scale data mining[23], small 
scale modelling of learner social networks[16], political 
considerations of implementations[29] and many more. From a 
CR perspective this is laudable given the focus on improving 
learner outcomes and evolutions in learning contexts that are 
implicit in the generally accepted definitions of the field. LA is 
fundamentally an interventionist science with the potential to 
initiate informed, data driven social change, and this necessitates a 
focus on a wide range of research objects, from learning strategies 
to political strategies, with each area of interest dictating the 
appropriate methodology. However, as things stand it appears that 
a significant proportion of LA’s research effort has been devoted 
to developing predictive models of learning success and 
retention[47] drawing on the analysis of large institutional data 
sets comprised of either all or some of i) static student variables 
(such as demographic profiles); ii) dynamic engagement variables 
drawn from student interaction with their LMS; iii) course 
performance indicators (grades or scores).  While this research has 
clearly demonstrated the potential to accurately predict student 
academic success there has been little theoretical work that would 
allow an interpretation of student behaviour so that the 
explanation of behaviour can be derived[28].  

On the CR account presented above this amounts to a precursor to 
science at best. It presupposes a stimulus-organism-response 
account of student engagement, it relies on decontextualised 
variables whose conjunction is derived for predictive purposes, 
presupposes the affordances of the LMS are universally 
available[28], and so emphasises student motivation is the point 
of leverage.  It is not surprising then that the interventions that 
emerge from this research do not target remedial aspects of 
student learning or educator learning design, but direct students to 
administrative type programs where students are connected to 
resources that, to varying degrees, are decontextualised from their 
course learning; from learning advisors, to study groups, to web 
pages with abstract study tips, and so on. The emphasis, then, is 
on the manipulation of antecedent conditions to control 
behaviour, so it is also not surprising that some in the learning 
analytics community are suspicious that this research effectively 
invites behaviourism back into higher education theory and 
practice[4, 26]. 

However the burden falls on the advocates of a realist stance to 
say how this might be done differently, and why different is 
better. Take the following paper[19] as a contrastive example to 
the predictive research program outlined above. (As this is for 
illustrative purposes only the complexities of the study will be 
bypassed. What follows is a very simplified account.) 

In a natural, longitudinal experiment focused on performing arts 
students in a North American University, Gasevic et al[19] 
observed the relative effects of exposure to a LMS (tool) under 
two feedback conditions – summative assessment and formative 

227



assessment. Students were requested to review and annotate a 
video recording of their performance for self-reflection purposes 
in both courses, and all students in both conditions received 
instructional support material. Students exposed to the summative 
condition went on to study subsequent courses within their degree 
and these courses also included the LMS video annotation tool. 
The researchers drew on the theory of Self-Regulated Learning 
(SRL) to hypothesise that external conditions (namely the 
instructional conditions of the course) would influence the uptake 
of the LMS tool in the course, and also that this would provide the 
requisite experiences for students to develop the appropriate skills 
to use the tool in the future. Comparisons between these two 
groups of students showed that, not surprisingly, students in the 
summative condition accessed the videos to a greater extent than 
their peers in the formative condition, had higher quality 
annotations (measured via word count, word length and text 
cohesion) and exhibited a higher level of metacognitive 
monitoring (measured via transition graphs documenting the kind 
of interaction event such as play, rewind, pause). However, in 
addition to this and in line with the researchers’ expectations, 
students in the summative condition went on in subsequent 
courses, even where only formative assessment was now the 
instructional condition, to a higher level of annotations than 
students who had not been previously exposed to tool use under 
summative conditions, as well as improving the quality of 
annotations. This finding lends support to the SRL account of the 
value of instructional conditions for creating the pre-conditions 
for learning, and thereby offers an explanation for the students’ 
subsequent use of specific LMS tools under varying instructional 
conditions. 

Unlike the predictive studies relying on LMS engagement, this 
study exemplified several aspects consistent with CR research. 
Firstly, it was a study of the causal dimensions of learning, using a 
theoretical model to posit if-then events that evolved over time 
and, crucially, indicated the existence of underlying mechanisms 
as an explanation of behaviour. Rather than documenting the 
relationship between behaviour (clicks in the LMS) with a target 
variable for the sake of prediction, this work attempted to account 
for the behaviour by providing an explanation. 

Returning to the CR process of discovery outlined above: 1. the 
effect under consideration was the differential use of the LMS 2. 
the hypothetical mechanism is postulated which, if it existed, 
would explain the effect (at least in part) was the instructional 
condition of the course 3. the attempt was made to demonstrate 
the existence and operation of the mechanism (a) positively, 
through a longitudinal natural experiment activity, designed to 
isolate the condition of interest and buttress against alternative 
explanations   

One of the inferences derived from this kind of research is that 
prediction is always conditional, and these conditions will have to 
take into account interference and enabling conditions as well as 
the interplay of various causal mechanisms that may operate in 
synchrony and therefore can magnify or negate each other’s 
effect. These are the research dilemmas inherent in examining 
phenomena in open systems (as opposed to closed experimental 
systems). We are much better positioned to discriminate between 
real and artefactual effects if the research stems from a causal 
explanatory framework than predictive, event level one. 
Employing a purely predictive approach using the data from 
Gasevic et al to predict student outcomes would be a largely futile 
exercise if a) the purpose is to improve student learning, and b) 

there is a concomitant need to understand the differential tool-use 
of students. Explanation may lead to valid conditional prediction, 
but prediction gives us very little information about a valid 
explanation. 

Another implication, that is touched on in the Gasevic et al study 
but not further explored, is the potential interplay between 
external conditions (such as instructional conditions) and internal 
conditions (such as student motivation generally and self-efficacy 
specifically). The further and deeper use of the LMS tools by 
students in the summative condition implies that they internalised 
the value of the tool and were confident in its use. However, these 
assumptions were not specifically tested. Further research could 
consider how these two are intertwined, much as structure and 
agency is more generally in the TMSA, and may mutually define 
and/or reinforce each other.   

3. IMPLICATIONS FOR LEARNING 
ANALYTICS 
The purpose of a scientific learning analytics is to identify 
underlying causal mechanisms and provide actionable advice that 
pertains directly to learning. If this, and the general thesis of CR 
given above are accepted, there are a number of implications: 

1. Causal theory is an important aspect of the development of the 
field. CR shifts the focus of science fundamentally from 
prediction on the horizontal plane of successive events to vertical 
explanations that involve historical conditions and generative 
mechanisms.  Generalisation, in this view, is not legitimated by 
the empiricist’s collection of positive instances of correlations but 
through the development and elaboration of theories of causal 
mechanisms and models. 

2. This has implications for the selection of quantitative tools. 
While space does not permit a full discussion of CR’s relationship 
with incumbent social science research methods, suffice to say it 
has a fairly critical view in general and perhaps an unfairly critical 
one of statistical enquiry, especially regression[38]. It does appear 
to be the case that the choice of methodologies and techniques in 
the social sciences was influenced by the predominant theory of 
cause at their birth, and in fact some recent critiques and advances 
(notably Pearl’s graphical counterfactual position) have been 
inspired in part by the understanding that the implicit 
endorsement of Humean assumptions in standard statistical 
practices is problematic[36]. However, others have argued that 
there is nothing inherently antithetical to CR even in regression, 
and that sufficiently rigorous theorising is all that is needed to 
ensure that a focus is maintained on the unfolding of ontological 
causal conditions rather than superficial event level 
correlations[38, 43]. Having said this, a few approaches do 
suggest themselves as having a more natural fit with CR. The 
counterfactual movement that has developed around and extended 
Pearl’s work is an important contribution that has a commitment 
to untangling complex causal phenomena. System dynamics[49] 
has a long history of blending quantitative and qualitative data 
and uncovering systemic causes that cannot be expressed as 
variable relationships but rather as a causal patterns. It has also 
had relatively little impact in many areas of the social sciences, in 
part because its roots are in a different branch of mathematics 
(calculus, part of number theory) to that promulgated by the major 
journals[39]. There is no reason for LA to extend this 
mathematical chauvinism (and no sign so far that it is tempted to).  
Other tools that support data mining and social network analysis 

228



may or may not be easily reconciled with the tenets of CR. The 
question to ask first is the theoretical one, and tool use and 
methodology generally follows from this and the nature of the 
object of interest. 

3. It is very likely that LA, like Information Systems research, is 
naturally predisposed to mixed methodologies[30]. The blending 
of techniques to offer insight into phenomenon comprised of both 
technical and social systems is unlikely to yield its causal story to 
one overarching research approach. The important point here is 
that CR is not endorsing mixed methodologies as an act of 
methodological tolerance, but does so from a point of ontological 
validity. The beliefs that educators and students have about their 
learning are undoubtedly important aspects of the phenomena of 
interest and therefore qualitative research is important. However, 
unlike the majority of hermeneutic approaches CR does not 
consider the beliefs of agents to be incorrigible: they may be 
affected by unacknowledged conditions, unconscious motives, 
and tacit skills[8]. The Gasevic et al study offers a hypothetical 
exploration of this point: if the students attributed the entirety of 
their LMS tool usage to the inspiration (or lack thereof) of the 
teacher, would they necessarily be correct? It is likely, or at least 
worth exploring, that in this case they are mistaken, and that some 
of their tool use is due to an unacknowledged condition and tacit 
skill acquired in their earlier exposure to the tool under 
summative conditions. The possibility of false beliefs, due to 
these subtle effects of structure, and the possibility of their 
objective correction marks learning analytics as a potentially 
emancipatory science where research participants can learn the 
actual sources of their actions[8]. In this sense, the development 
and use of objective data is core to the constructivist project, if 
undertaken with the CR objective of explicating cause via 
explanation.  And of course this applies equally to educators, who 
can be similarly mistaken about the causal dimensions of the 
learning context and their impact via learning design and delivery. 

4. This suggests that research participants are best construed as 
partners[8], and that this in turn implies the value of longitudinal 
studies where alternative causal explanations and interference 
conditions can be progressively eliminated. Despite the justified 
fears of bias and other distorting effects[34, 40] these are not 
insurmountable. For example, in the SRL literature Winne[50] 
argues for the training of research participants in identifying cues 
as the only reasonable way to begin to disambiguate research 
findings. 

4. CONCLUSION 
This paper aimed to introduce realist thought, and in particular 
CR thought, to the field of LA as a way of making sense of the 
variety of methodologies endorsed. The rationale that CR brings 
both substantiates this methodological catholicism yet delimits it 
according to scientific purpose. That purpose is generally 
construed as the ever deeper uncovering of causal mechanisms 
that explain action. This was contrasted with the still dominant 
empiricist metatheory that sponsors research that focusses on 
event regularities. It was argued that this latter focus militates 
against the particular scientific purpose of learning analytics, 
which is to identify underlying causal mechanisms and provide 
actionable advice that pertains directly to learning. To this end a 
comparison was drawn between the general approach taken in 
predictive analytics and the approach taken in one particular 
longitudinal study of LMS adoption. While both of these 
examples drew on similar data, only the second provided a causal 

understanding that enables the researcher, and indeed the 
participants if they are aware of the findings, to understand the 
meaning of actions rather than the cataloguing of behavioural 
markers. 

Finally, a number of implications of these considerations were put 
forward that suggest a yet non-existent, or perhaps only 
embryonic, version of LA. In sum, they suggest that LA research 
is best construed as a partnership between LA researchers and 
their ‘subjects’, be they students or educators, in the investigation 
of the causal roots of the learning dilemmas they are interested in, 
or vexed by. These investigations will be unimpeded by 
methodological prejudices but guided instead by considerations of 
purpose, and likely employ a mixed methodology that unfolds 
over time. To the extent that these investigations uncover 
previously unknown mechanisms that operate in the learning 
context and have a material outcome on the learning process, and 
assuming they are potentially remediated, learning analytics has 
the potential to generate emancipatory outcomes for research 
participants. 

5. REFERENCES 
 
[1] Ackroyd, S. and Fleetwood, S. 2000. Realist perspectives on 

management and organisations. Routledge. 
[2] Argyris, C. 1993. Knowledge for action: A guide to 

overcoming barriers to organizational change. Jossey-Bass. 
[3] Armstrong, J.S. 2012. Predicting job performance: The 

Moneyball factor. Foresight: The International Journal of 
Applied Forecasting (Spring 2012). (2012). 

[4] Atkisson, M. 2011. Learning analytics: A house without a 
foundation? Ways of Knowing. 
http://woknowing.wordpress.com/2011/06/02/learning-
analytics-a-house-without-a-foundation/ 

[5] Aune, B. 1970. Rationalism, empiricism and pragmatism: 
An introduction. Random House. 

[6] Benbasat, I. and Zmud, R.W. 1999. Empirical research in 
information systems: The practice of relevance. MIS 
Quarterly. 23, 1 (1999), 3–16. 

[7] Bhaskar, R. 1975. A realist theory of science. Harvester 
Press. 

[8] Bhaskar, R. 1982. Emergence, explanation and 
emancipation. Explaining Human Behaviour. P. Secord, ed. 
Sage. 275–310. 

[9] Bhaskar, R. 1998. General introduction. Critical realism: 
Essential readings. M. Archer, R. Bhaskar, A. Collier, T. 
Lawson, and A. Norrie, eds. Routledge. ix–xxiv. 

[10] Bhaskar, R. 1980. Scientific explanation and human 
emancipation. Radical Philosophy. 26 (1980), 16ð28. 

[11] Bhaskar, R. 1979. The possibility of naturalism: A 
philosophical critique of the contemporary human sciences. 
Harvester Press. 

[12] Chalmers, A. 1999. What is this thing called science?. 
University of Queensland Press. 

[13] Clow, D. 2012. The learning analytics cycle: Closing the 
loop effectively. Proceedings of the 2Nd International 
Conference on Learning Analytics and Knowledge (New 
York, NY, USA, 2012), 134–138. 

[14] Davenport, T.H. 2006. Competing on Analytics. Harvard 
Business Review. 84, 1 (Jan. 2006), 98–107. 

[15] Dawson, S., Bakharia, A. and Heathcote, E. 2010. SNAPP: 
Realising the affordances of real-time SNA within 
networked learning environments. Proceedings of the 7th 

229



International Conference on Networked Learning (2010), 
125–133. 

[16] Dietrichson, A. 2013. Beyond clickometry: Analytics for 
constructivist pedagogies. International Journal on E-
Learning. 12, 4 (2013), 333–351. 

[17] Dietz-Uhler, B. and Hurn, J.E. 2013. Using learning 
analytics to predict (and improve) student success: A faculty 
perspective. Journal of Interactive and Online Learning. 12, 
1 (Spring 2013), 17–26. 

[18] Ferguson, R. 2012. Learning analytics: Drivers, 
developments and challenges. International Journal of 
Technology Enhanced Learning. 4, 5 (2012), 304–317. 

[19] 
resubmitted. What is the role of teaching in adoption of a 
learning tool? A natural experiment of video annotation tool 
use. (Revised & resubmitted). 

[20] Greenwood, J.D. 1989. Explanation and experiment in 
social psychological science: Realism and the social 
constitution of action. Springer-Verlagpp. 

[21] Harré, R. and Madden, E. 1975. Causal powers. Basil 
Blackwell. 

[22] Hempel, C. and Oppenheim, P. 1948. Studies in the logic of 
explanation. Philosophy of Science. 15, (1948), 137–175. 

[23] Ifenthaler, D. 2012. Determining the effectiveness of 
prompts for self-regulated learning in problem-solving 
scenarios. Journal of Educational Technology & Society. 15, 
1 (May 2012), 38–52. 

[24] Jayaprakash, S.M., Moody, E.W., Lauría, E.J., Regan, J.R. 
and Baron, J.D. 2014. Early alert of academically at-risk 
students: An open source analytics initiative. Journal of 
Learning Analytics. 1, 1 (2014), 6–47. 

[25] Kennedy, G., Enger, L. and Ainley, M. 2008. The elusive 
experience of “flow”: Qualitative and quantitative indicators. 
International Journal of Educational Research. 47, 2 (Jan. 
2008), 109–121. 

[26] Lodge, J. and Lewis, M. 2012. Pigeon pecks and mouse 
clicks: Putting the learning back into learning analytics. 
Future challenges, sustainable futures. Proceedings ascilite 
Wellington. (2012), 560–564. 

[27] Long, P. and Siemens, G. 2011. Penetrating the fog: 
Analytics in learning and education. Educause Review. 46, 5 
(2011), 30–32. 

[28] Lust, G., Juarez Collazo, N.A., Elen, J. and Clarebout, G. 
2012. Content management systems: enriched learning 
opportunities for all? Computers in Human Behavior. 28, 3 
(2012), 795–808. 

[29] Macfadyen, L.P. and Dawson, S. 2012. Numbers Are Not 
Enough. Why e-Learning Analytics Failed to Inform an 
Institutional Strategic Plan. Educational Technology & 
Society 15 3 (2012), 149-163. 

[30] Mingers, J. 2004. Real-izing information systems: critical 
realism as an underpinning philosophy for information 
systems. Information and organization. 14, 2 (2004), 87–
103. 

[31] Mingers, J., Mutch, A. and Willcocks, L. 2013. Critical 
realism in information systems research. MIS Quarterly. 37, 
3 (2013), 795–802. 

[32] Mowday, R. 1997. Reaffirming our scholarly values. The 
Academy of Management Review. 22, 2 (1997), 335–345. 

[33] Nathan, P.E. 2000. The Boulder model: A dream deferred or 
lost? American Psychologist. 55, 2 (2000), 250–252. 

[34] Orne, M.T. 1962. On the social psychology of the 
psychological experiment: With particular reference to 
demand characteristics and their implications. American 
Psychologist. 17 (1962), 776–783. 

[35] Outhwaite, W. 1987. New philosophies of social science: 
Realism, hermeneutics and critical theory. St. Martin’s Press 
Inc. 

[36] Pearl, J. 2009. Causality: Models, reasoning and inference. 
Cambridge University Press. 

[37] Peterson, D.R. 2000. Scientist-practitioner or scientific 
practitioner? American Psychologist. 55, 2 (2000), 252–253. 

[38] Pratschke, J. 2003. Realistic models? Critical realism and 
statistical models in the social sciences. Philosophica. 71, 
(2003), 13–38. 

[39] Repenning, N.P. 2003. Selling system dynamics to (other) 
social scientists. System Dynamics Review. 19, 4 (2003), 
303–327. 

[40] Rosenthal, R. 1966. Experimenter effects in behavioral 
research. Appleton-Century-Crofts. 

[41] Salk, J. and Salk, D. 1977. Control of influenza and 
poliomyelitis with killed virus vaccines. Science. 195, March 
(1977), 834–847. 

[42] Scandura, T. and Williams, E. 2000. Research methodology 
in management: Current practices, trends, and implications 
for future research. Academy of Management Journal. 43, 6 
(2000), 1248–1264. 

[43] Scheff, T.J. 2011. The catastrophe of scientism in 
social/behavioral science. Contemporary Sociology: A 
Journal of Reviews. 40, 3 (Apr. 2011), 264–268. 

[44] Schermerhorn Jr, J.R., Hunt, J.G. and Osborn, R.N. 1994. 
Managing organizational behavior. John Wiley and Sons. 

[45] Siemens, G. 2014. Sensemaking: Beyond analytics as a 
technical activity. http://www.educause.edu/eli/events/eli-
spring-focus-session/2012/sensemaking-beyond-analytics-
technical-activity 

[46] Siemens, G. and Baker, R.S. 2012. Learning analytics and 
educational data mining: Towards communication and 
collaboration. Proceedings of the 2nd international 
conference on learning analytics and knowledge (2012), 
252–254. 

[47] Siemens, G., Dawson, S. and Lynch, G. 2013. Improving the 
quality and productivity of the higher education sector: 
Policy and strategy for systems level deployment of learning 
analytics. Australian Government: Office for Learning and 
Teaching. 

[48] Smith, S. 1962. Selected poems. Longmans. 
[49] Sterman, J.D. 1994. Learning in and about complex systems. 

System Dynamics Review. 10, 2-3 (1994), 291–330. 
[50] Winne, P.H. 1982. Minimizing the black box problem to 

enhance the validity of theories about instructional effects. 
Instructional Science. 11, 1 (1982), 13–28. 

  
 
 

 

230





