
LA Policy: Developing an Institutional Policy for Learning 
Analytics using the RAPID Outcome Mapping Approach 

Yi-Shan Tsai, Dragan Gasevic 

University of Edinburgh 
Edinburgh, United Kingdom 

+44 131 651 6243 

yi-shan.tsai@ed.ac.uk 

+44 131 651 3837 

dragan.gasevic@ed.ac.uk 
 

Pedro J. Muñoz-Merino 
Universidad Carlos III de Madrid 

Madrid, Spain 
+34 91-624-5972 

pedmume@it.uc3m.es 

Shane Dawson 
University of South Australia 
Adelaide SA 5001, Australia 

+61 8 830 27850 

Shane.Dawson@unisa.edu.au 
 

 

 

ABSTRACT 
This workshop aims to promote strategic planning for learning 

analytics in higher education through developing institutional 

policies. While adoption of learning analytics is predominantly 

seen in small-scale and bottom-up patterns, it is believed that a 

systemic implementation can bring the widest impact to the 

education system and lasting benefits to learners. However, the 

success of it highly depends on the adopted strategy that meets the 

needs of various stakeholders and systematically pushes the 

institution towards achieving its targets. It is imperative to 

develop a learning analytics policy that ensures a practice that is 

valid, effective and ethical.  

The workshop involves two components. The first component 

includes a set of presentations about the state of learning analytics 

in higher education, drawing on results from an Australian and a 

European project examining institutional learning analytics policy 

and adoption processes. The second component is an interactive 

session where participants are encouraged to share their 

motivations for adopting learning analytics and the diversity of 

challenges they perceive impede analytics adoption in their 

institution. Using the RAPID Outcome Mapping Approach 

(ROMA), participants will create a draft policy that articulates 

how the various challenges can be addressed. This workshop aims 

to further develop our understanding of how learning analytics 

operates in an organizational system and promote a cultural 

change in how such analytics are adopted in higher education. 

CSS Concepts 

?Applied computing ? Education; ?Security and privacy ? 

Human and societal aspects of security and privacy 

Keywords 
Learning analytics; policy; higher education 

1. INTRODUCTION 
Studies show that there is generally a lack of practical guidance 

for the adoption of learning analytics in higher education 

institutions [2]. A recent survey conducted by Heads of e-

Learning Forum in the UK shows that only five out of fifty-three 

institutional respondents follow a code of practice1 to guide their 

learning analytics implementation process [5]. In a review of the 

adoption of learning analytics in ten universities across USA, 

Australia and UK, Siemens and others found that only a few 

universities have started strategic planning for learning analytics 

deployment despite that significant data collection activities had 

existed in education systems for long [1, 6]. They identified that 

learning analytics was often found in small scale or bottom up 

developments, which tended to lack systematic development and 

planning process. The lack of policies that address both legislative 

and non-legislative issues about the implementation of learning 

analytics in the higher education sector was also identified in a 

systematic literature review conducted by researchers of the 

European Commission funded research project – SHEILA2. The 

bibliographic research of all publications rendered only eight 

codes of practices across Europe and Australia, of which four 

were developed within and for specific universities. This number 

indicates a gap of holistic planning that can ensure the practice of 

learning analytics to be valid, ethical, effective and sustainable. 

The capacity to bring about change in higher education 

institutions where complex and anarchic adaptive systems exist 

has been described as a ‘wicked problem’ [4]. Macfadyen and 

others noted that educational systems tend to be stable and 

resistant to change due to a range of political, social, cultural and 

technical norms. Nevertheless, they argued that higher education 

institutions must implement planning processes for learning 

analytics so that stakeholders can easily align the need for change 

with institutional goals and priorities. In response to the flexible 

and constantly-changing social and institutional contexts, 

Macfadyen and colleagues suggest that an adapted version of the 

RAPID Outcome Mapping Approach (ROMA) approach can 

guide and ultimately lead towards systemic institutional change 

that is enabled through learning analytics. 

The ROMA model was originally designed to support policy and 

strategy process in the field of international development (Figure 

1) [7]. The approach consists of an iterative cycle of seven steps 

that can be adopted to consider the complexity of institutional 

contexts in which factors of people, political structures, data 

infrastructures, and institutional capabilities all have mutual 

influence on each other and on the success of achieving the 

objectives of learning analytics. 

ROMA targets at bringing about evidence-based change to 

                                                                 

1 In this workshop, we use ‘policy’ and ‘code of practice’ 

interchangeably, and both terms refer to a set of guidance that 

addresses both legislative and non-legislative issues. 

2 http://sheilaproject.eu/ 

Permission to make digital or hard copies of part or all of this work for 

personal or classroom use is granted without fee provided that copies are 

not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. Copyrights 

for third-party components of this work must be honored. For all other 

uses, contact the Owner/Author. Copyright is held by the 
owner/author(s). LAK '17, March 13-17, 2017, Vancouver, BC, Canada 

ACM 978-1-4503-4870-6/17/03. 

http://dx.doi.org/10.1145/3027385.3029424 

http://dx.doi.org/10.1145/3027385.3029424


institutions and a reflective culture in the progress of 

implementation in which there is flexibility to adjust the strategy 

when new evidence emerges. This approach is believed to have 

the potential to maximize success of learning analytics in 

institution-wide implementation [2]. As there is no one-size-fits-

all policy for educational change and learning analytics [3], it is 

encouraged that every higher education institution should develop 

a learning analytics policy that considers its specific context and 

addresses challenges wherein. Therefore, we propose a half-day 

workshop to initiate conversations among scholars, practitioners, 

and institutional senior leaders about policy and the state of 

learning analytics in the higher education sector. In addition, there 

will be an opportunity to create a draft of policy using ROMA. 

 

Figure 1. RAPID Outcome Mapping Approach (ROMA) [4] 

This workshop falls in the topic of ‘meta-issues’ for LAK’17 with 

considerations for ethics and law, adoption, and scalability. It will 

contribute to a cultural change in the implementation of learning 

analytics by raising the awareness of strategic planning and giving 

step-by-step guidance to composing a policy.  

2. WORKSHOP OBJECTIVES 
The workshop has three main objectives, including 

- bringing broader understanding of the state of learning 
analytics adoption in higher education;  

- initiating conversations about challenges in the 
implementation of learning analytics; and 

- addressing the above challenges within policies drafted by 
participants with guidance and support from the workshop 

initiators and other participants. 

3. TARGET GROUP 
The target group is primarily policy makers of learning analytics, 

senior management at higher education institutions, learning 

analytics practitioners and researchers. The workshop also 

welcomes stakeholders that are involved in the working team for 

the planning and implementation process, such as project leaders, 

data protection and system officers, Information and Technology 

officers, academics and student representatives. 

4. FORMAT 
This half-day workshop will begin with presentations from two 

research teams (the European SHEILA and Australian3 projects) 

about findings from main activities: literature review (including 

examples of concrete institutional policies), interviews with 

institutional senior leaders, surveys with a large sample of 

                                                                 

3 http://he-analytics.com/au/ 

European institutions, and two group concept mapping studies 

with learning analytics expert and policy maker groups. The 

presentations will cover the following themes: stages of 

implementation in higher education institutions, the success 

claimed to date, challenges identified in the process, and elements 

identified as essential for a higher education institution’s learning 

analytics policy. 

Following the presentations, there will be a discussion time for the 

participants to share about the motivations to adopt learning 

analytics in their institutions and challenges that they face in the 

planning and implementation process. 

After the coffee break, the workshop initiators will demonstrate 

how to draft a learning analytics policy using the ROMA model, 

with evidence drawn upon their research findings. Afterwards, the 

participants, in small groups, will draft a policy that considers the 

specific contexts of their institutions and the challenges that they 

have identified in the first part of the workshop. The workshop 

will conclude with plenary discussions about the products that 

participants create and practicalities about introducing the policy 

to their institutions. 

5. ACKNOWLEDGMENTS 
We would like to thank European Commission for funding the 

SHEILA project (Ref. 562080-EPP-1-2015-1-BE-EPPKA3-PI-

FORW) and the Australian Government’s Office for Learning and 

Teaching for funding the HE-Analytics project (SP13-3249) and 

all participants who joined the project activities and contributed 

valuable insights. This document does not represent the opinion of 

the European Community and the Australian Government. 

6. REFERENCES 
[1] Colvin, C., Rogers, T., Wade, A., Dawson, S., Gasevic, D., 

Shum, S.B., Nelson, K., Alexander, S., Lockyer, L., 

Kennedy, G., Corrin, L. and Fisher, J. 2015. Student 

retention and learning analytics: a snapshot of Australian 

practices and a framework for advancement. The Australian 

Government Office for Learning and Teaching. 

[2] Ferguson, R., Macfadyen, L.P., Clow, D., Tynan, B., 

Alexander, S. and Dawson, S. 2014. Setting Learning 

Analytics in Context: Overcoming the Barriers to Large-

Scale Adoption. Journal of Learning Analytics. 1, 3 (Sep. 

2014), 120–144. 

[3] Gaševi?, D., Dawson, S., Rogers, T. and Gasevic, D. 2016. 

Learning analytics should not promote one size fits all: the 

effects of instructional conditions in predicting academic 

success. The Internet and Higher Education. 28, (2016), 68–

84. 

[4] Macfadyen, L.P., Dawson, S., Pardo, A. and Gaševic, D. 

2014. Embracing Big Data in Complex Educational 

Systems: The Learning Analytics Imperative and the Policy 

Challenge. Research & Practice in Assessment. 9, (2014), 

17–28. 

[5] Newland, B., Martin, L. and Ringan, N. 2015. Learning 

analytics in UK HE 2015: a HeLF survey report. 

[6] Siemens, G., Dawson, S. and Lynch, G. 2013. Improving the 

quality and productivity of the higher education sector: 

policy and strategy for systems-level deployment of learning 

analytics. Society for Learning Analytics Research for the 

Australian Office for Learning and Teaching. 

[7] Young, J. and Mendizabal, E. 2009. Helping researchers 

become policy entrepreneurs - how to develop engagement 

strategies for evidence-based policy-making. Overseas 

Development Institute. 

between multiple stakeholders in situations of ambiguity, uncertainty and values disagreement 

(Rittel & Webber, 1973). A number of theorists have also emphasized that solutions to wicked 

problems – actually complex systems of inter–related problems – “can seldom be obtained 

by independently solving each of the problems of which it is composed . . . Efforts to deal 

separately with such aspects of urban life as transportation, health, crime, and education seem 

to aggravate the total situation”  (Ackoff, 1974, p. 21).  

 Systems theory offers two key areas of insight that are significant for policy development  

for complex educational systems. First, systems theorists recognized that while systems – 

from a single atom to a universe – may appear to be wildly dissimilar, they are all governed by 

common patterns, behaviors and properties: their component parts are multiply interconnected 

by information flows, with identifiable and predictable feedbacks, inputs, outputs, controls and 

transformation processes; they are dynamic, differentiated and bounded; they are hierarchically 

organized and differentiated; and new properties can arise within them as a result of interactions 

between elements. Second, systems theory observes that systems tend to be stable, and that their  

interconnectedness facilitates resilience (for a review of systems theory , see Capra, 1996).

 These observations not only illuminate why piecemeal attempts to effect change in 

educational systems are typically ineffective, but also explains why no one–size–fits–all prescriptive 

approach to policy and strategy development for educational change is available or even possible. 

Usable policy frameworks will not be those which offer a to do list of, for example, steps in learning 

analytics implementation. Instead, successful frameworks will be those which guide leaders and 

participants in exploring and understanding the structures and many interrelationships within 

their own complex system, and identifying points where intervention in their own system will be 

necessary in order to bring about change.

 Drawing on systems and complexity theory, a new generation of authors have begun 

to develop accounts of so–called adaptive approaches to policy and planning for complex 

systems which can allow institutions to respond flexibly to ever–changing social and 

institutional contexts and challenges (Berkhout, Leach, & Scoones, 2003; Haynes, 2003; 

Milliron, Malcolm, & Kil, 2014; Tiesman, van Buuren, & Gerrits, 2009; Young & Mendizabal, 

2009). A full review of adaptive management strategies is beyond the scope of this paper, and 

has been comprehensively undertaken by Head and Alford (2013), who highlight the critical 

roles of cross–institutional collaboration, new forms of leadership (moving beyond the 

orthodox model of transformational leadership) and the development of enabling structures 

and processes (for example, budgeting and finance systems, organizational structure, 

human resources management, and approaches to performance measurement and program 

evaluation). We offer here two sample policy and planning models that may offer valuable 

practical guidance for collaborative teams and leaders in higher education seeking to bring 

about systemic institutional change to support learning analytics.

24                     Volume Nine | Winter 2014

From the technological 

point of  view, learning 

analytics is an emerg-

ing discipline and its 

connection with assess-

ment remains largely 

unexplored.

Figure 1. The RAPID Outcome Mapping Approach (ROMA)



